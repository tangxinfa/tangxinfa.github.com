#+TITLE: 看看俺 - KanKanAn.com
#+DESCRIPTION: 记我所思，忆我所为。
#+DATE: 2013-04-09 12:00:00
#+LANGUAGE: zh-CN
#+STARTUP: logdone content

#+PUBLISH_DIR: .
#+URL: http://blog.kankanan.com

#+DEFAULT_CATEGORY: Posts
#+DISQUS: kankananblog
#+FILENAME_SANITIZER: ob-sanitize-string
#+POST_SORTER: ob-sort-posts-by-title

#+POST_BUILD_SHELL: cmd 1
#+POST_BUILD_SHELL: cmd 2
#+POST_BUILD_SHELL: cmd 3
#+POST_BUILD_SHELL: cmd 4


* Blog details
** Copyright
  :PROPERTIES:
  :SNIPPET:  t
  :END:

版权所有 © 2011-2013 看看俺 – KanKanAn.com

** About
  :PROPERTIES:
  :SNIPPET:  t
  :END:

记我所思，忆我所为

** Navigation
  :PROPERTIES:
  :SNIPPET:  t
  :END:

- [[file:{lisp}(ob:path-to-root){/lisp}/archives.html][/icon-list icon-white/ {lisp}(ob:gettext :archives){/lisp}]]

- [[file:{lisp}(ob:path-to-root){/lisp}/tags.html][/icon-tags icon-white/ {lisp}(ob:gettext :tags){/lisp}]]

- [[file:{lisp}(ob:path-to-root){/lisp}/index.xml][/icon-rss icon-white/ {lisp}(ob:gettext :rss){/lisp}]]


** Navigation Footer
  :PROPERTIES:
  :SNIPPET:  t
  :END:

  - [[file:{lisp}(ob:path-to-root){/lisp}/index.html][/icon-home icon-white/ {lisp}(ob:gettext :home){/lisp}]]

  - [[file:{lisp}(ob:path-to-root){/lisp}/tags.html][/icon-tags icon-white/ {lisp}(ob:gettext :tags){/lisp}]]

  - [[file:{lisp}(ob:path-to-root){/lisp}/archives.html][/icon-list icon-white/ {lisp}(ob:gettext :archives){/lisp}]]

  - [[file:{lisp}(ob:path-to-root){/lisp}/index.xml][/icon-rss icon-white/ {lisp}(ob:gettext :rss){/lisp}]]

  - [[file:{lisp}(ob:path-to-root){/lisp}/changelog.html][/icon-pencil icon-white/ {lisp}(ob:gettext :changelog){/lisp}]]


** {lisp}(ob:gettext :tags){/lisp}
  :PROPERTIES:
  :PAGE:     tags.html
  :TEMPLATE: blog_post-by-tags.html
  :END:

* Changelog
  :PROPERTIES:
  :PAGE:     changelog.html
  :END:

- 2013-04-09
  - 使用[[http://renard.github.com/o-blog][o-blog]]搭建个人博客.

* Posts
** DONE 使用o-blog搭建个人博客                                       :o@blog:
   CLOSED: [2013-04-09 二 12:30]

   新的博客使用[[http://renard.github.com/o-blog][o-blog]]搭建，使用的是自已的分枝[[https://github.com/tangxinfa/o-blog][tangxinfa-o-blog]]，我的分枝主要是对原系统做了一定的简化以便适用于创建个人博客，另修复了一些bug（主要是中文相关），可使用以下配置安装我的分枝：
   #+begin_src lisp
     (setq el-get-sources '((:name tangxinfa-o-blog
                                       :type git 
                                       :url "https://github.com/tangxinfa/o-blog.git"
                                       :load "o-blog.el"
                                       :features o-blog)))
   #+end_src
   #+begin_src sh
     M-x el-get-install tangxinfa-o-blog
   #+end_src

   具体使用可参考本博客的原始org文件：

   #+begin_src sh
     git clone https://github.com/tangxinfa/tangxinfa.github.com.git
   #+end_src

** DONE Archlinux下安装fcitx输入法                          :archlinux:fcitx:
   CLOSED: [2012-12-15 六 21:56]

*** 安装
    
    #+BEGIN_SRC sh
      sudo yaourt -S fcitx-im
      ln -s /etc/xdg/autostart/fcitx-autostart.desktop  ~/.config/autostart/
    #+END_SRC  

*** 配置

    在配置文件~/.xprofile中添加以下内容：
    #+BEGIN_EXAMPLE
      export GTK_IM_MODULE=fcitx
      export QT_IM_MODULE=fcitx
      export XMODIFIERS="@im=fcitx"
      export LC_CTYPE="zh_CN.UTF-8"
    #+END_EXAMPLE

    因为用的是gnome3桌面，需要禁用ibus：
    #+BEGIN_EXAMPLE
      gsettings set org.gnome.settings-daemon.plugins.keyboard active false
    #+END_EXAMPLE
    还需要在键盘快捷键设置界面中将输入源切换的快捷键清除。
   
** DONE Archlinux下安装cups打印系统                          :archlinux:
   CLOSED: <2013-03-27 三 21:56>

  - 安装 ::
#+BEGIN_SRC sh
yaourt -S cups-pdf
#+END_SRC
  
  - 启动 ::
#+BEGIN_SRC sh
sudo systemctl start cups
#+END_SRC

  - 配置 ::
    参考：https://wiki.archlinux.org/index.php/Cups#PDF_virtual_printer

    登录的用户名要为root，否则后面还是无法添加打印机，web界面没有退出登录的选项，可以试试重启cups服务浏览器清除缓存的数据。

** DONE 网页中的自动完成的下拉列表框                      :web:jquery:chosen:
   CLOSED: <2013-03-10 日 21:23>

*** jqueryui的[[http://jqueryui.com/autocomplete/#combobox][组件]]
    示例效果看起来挻好，不过发现几个问题：

    - 和[[http://twitter.github.com/bootstrap/][bootstrap]]有冲突，导致右边的下拉箭头部分都看不见。
    - 操作过程中有时候显示的值和实际的值不一致，应该是中文输入法按键事件在firefox下未触发引起的显示的界面部分和隐藏的select输入框值不同步。
    - 没有提供设置当前选中项、禁用的功能，要自行对生成的界面元素进行处理。
  
    这个只是jqueryui自动完成输入框的一个定制示例，不是很完善，而jqueryui自带的正式版看起来只是一个输入框。

*** [[https://github.com/harvesthq/chosen][chosen]]
    非常完美，配置很简单，而且界面很漂亮，在github上评分很高。

** DONE CityHash算法冲突率测试                                     :hash:
   CLOSED: <2012-11-24 六 18:21>

*** [[http://code.google.com/p/cityhash/][CityHash]]介绍
    [[http://www.google.com][Google]] 2010年开始开发并开源的字符串哈希算法，主要包含CityHash32()、CityHash64()和CityHash128()，分别对应32位、64位、128位哈希算法。

*** 测试样本数据
    16630591行不重复字符串，每一行内容为以制表符分隔的下载地址和引用页。

*** cityhash64测试结果
    没有冲突

*** cityhash32测试结果
    共32246次冲突，冲突率约为千分之二。
    同一哈希值上55次冲突二次，32136次冲突一次。

** DONE C++的函数、闭包与协程                                           :cpp:
    CLOSED: <2013-03-15 五 10:04>
    
*** 实现序号生成器
**** 函数（Function）
     #+begin_src c++
     #include <cassert>
     
     int id_generator(int& base, int step)
     {
         int result = *base;
         *base += step;
         return result;
     }
     
     int main(int argc, char *argv[])
     {
         int odd_base = 1;
         int even_base = 0;    
         assert(id_generator(odd_base, 2) == 1);
         assert(id_generator(odd_base, 2) == 3);
         assert(id_generator(odd_base, 2) == 5);
         assert(id_generator(even_base, 2) == 0);
         assert(id_generator(even_base, 2) == 2);
         assert(id_generator(even_base, 2) == 4);        
         return 0;
     }
     #+end_src

     - 编译 ::
       #+begin_example
       g++ -g add.cpp -o add
       #+end_example

**** 闭包（Closure）
     #+begin_src c++
     #include <cassert>
       
     int main(int argc, char *argv[])
     {
         int base = 1;
         auto id_generator_odd = [=]() mutable { int result = base; base += 2; return result; };
         base = 0;
         auto id_generator_even = [=]() mutable { int result = base; base += 2; return result; };
         assert(id_generator_odd() == 1);
         assert(id_generator_odd() == 3);
         assert(id_generator_odd() == 5);
         assert(id_generator_even() == 0);
         assert(id_generator_even() == 2);
         assert(id_generator_even() == 4);
         assert(base == 0);
         return 0;
     }
     #+end_src

     - 编译 ::
       #+begin_example
       g++ -g closure.cpp -o closure -std=c++0x
       #+end_example

**** 协程（Coroutine）
     #+begin_src c++
     #include <boost/bind.hpp>
     #include <boost/coroutine/all.hpp>
       
     typedef boost::coroutines::coroutine< int(void) > IDGenerator;
       
     void idGenerator(IDGenerator::caller_type& ca, int base, int step)
     {
         do{
             ca(base);
             base += step;
         }while(true);
     }
       
     int main(int argc, char *argv[])
     {
         IDGenerator id_generator_odd(boost::bind(idGenerator, _1, 1, 2));
         IDGenerator id_generator_even(boost::bind(idGenerator, _1, 0, 2));
         assert(id_generator_odd.get() == 1);
         assert(id_generator_odd().get() == 3);
         assert(id_generator_odd().get() == 5);
         assert(id_generator_even.get() == 0);
         assert(id_generator_even().get() == 2);
         assert(id_generator_even().get() == 4);
         return 0;
     }
     #+end_src

     - 编译 ::
       #+begin_example
       g++ -g coroutine.cpp -lboost_context -o coroutine -std=c++0x
       #+end_example

*** 特性比较
**** 函数（Function）
     - 无状态
     - 需要独立定义执行体
     - 调用过程中从头到尾执行体内所有代码
     - 在输入相同的情况下，能够保证输出也相同
     - 没有副作用，多线程安全
     - 要借助外部变量保存状态
     - 调用比较麻烦，需要传入保存状态的参数

**** 闭包（Closure）
     - 有状态，内部直接保存
     - 直接内联定义执行体
     - 调用过程中从头到尾执行体内所有代码
     - 输入相同的情况下，输出可能不同
     - 有副作用，非多线程安全
     - 定义时可以多种方式安全地引用外部变量
     - 调用简单，不需要传入保存状态的参数
       
**** 协程（Coroutine）
     - 有状态，内部直接保存
     - 需要独立定义执行体
     - 调用过程中直接从上次的运行状态继续运行
     - 输入相同的情况下，输出可能不同
     - 严禁多线程访问
     - 调用简单，不需要传入保存状态的参数    

** DONE 在emacs模式行上显示图片的尺寸                                 :emacs:
   CLOSED: <2012-08-03 五 08:55>

   下面的lisp代码用于在emacs模式行上显示图片的尺寸：
   #+BEGIN_SRC lisp
   (add-hook 'image-mode-hook (lambda ()
                             "display image size on mode line."
                             (setq mode-name (format "Image[%s](%s*%s)" 
                                                     image-type 
                                                     (car (image-size (image-get-display-property) t)) 
                                                     (cdr (image-size (image-get-display-property) t))))))
   #+END_SRC

   - 效果如下 ::
   #+begin_example
   [(Image[png](181*415))]
   #+end_example
   
** DONE 在emacs中如何以root权限使用gdb调试程序                        :emacs:
   CLOSED: <2013-03-30 六 14:21>

  - 由于M-x命令中使用sudo输入密码无效，需要配置为允许用户sudo gdb免密码
  #+begin_example
  visudo
  # Allow user to sudo gdb without password
  用户 ALL=NOPASSWD: /usr/bin/gdb
  #+end_example

  - 使用root权限启动gdb
  #+begin_example
  M-x gdb
  sudo gdb <program> <pid> --annotate=3
  #+end_example

** DONE 解决360杀毒报网页HTML.Rce.Gen3恶意程序的问题                    :web:
   CLOSED: <2012-08-01 三 08:55>

*** 问题描述
    测试发现在某些机器上会弹出360杀毒危险警告对话框，导致网页无法打开。

*** 解决方法
    将嵌入的统计js脚本从</html>标签后移到里面去。
    - 修改前
    #+BEGIN_SRC html
    ...
    </body>
    </html>
    <script type="text/javascript">document.write(unescape("%3Cscript%20...%3C/script%3E"));</script>
    #+END_SRC
    - 修改后
    #+BEGIN_SRC html
    ...
    <script type="text/javascript">document.write(unescape("%3Cscript%20...%3C/script%3E"));</script>
    </body>
    </html>
    #+END_SRC

*** 心得
    以后再遇到这种情况，可以采取排除法，将网页另存为本地文件，一点点的删除内容直到360杀毒不再报警为止。

** DONE 解决Archlinux下ati显卡3D硬件加速失效的问题                :archlinux:
   CLOSED: <2012-09-05 三 23:52>

*** 问题描述
    - 症状

      进入gnome3桌面环境后很卡，不动还好，一动gnome-shell进程cpu占用就直奔100%。

    - dmesg异常日志
      #+BEGIN_EXAMPLE
      radeon_cp: Failed to load firmware "radeon/R520_cp.bin"
      radeon 0000:01:00.0: failed initializing CP (-2).
      radeon 0000:01:00.0: Disabling GPU acceleration
      #+END_EXAMPLE
*** 解决办法
#+BEGIN_SRC sh
  sudo ln -s /usr/lib/firmware /lib/
  sudo reboot
#+END_SRC
*** 经验总结
    出现问题时网上不一定能找到你要的答案，像这个问题，网上的论坛里有无数个建议，一个一个试下去其实很浪费时间，
    试几次之后还没能解决就应该尝试主动分析解决，像这里稍微留意到括号里的-2，就能发现其实它是个错误码，
    perror一下就知道意思是“找不到文件或目录”，联想到最近几次升级archlinux在把/lib里的东西往/usr/lib下移，
    其中就包括firemware，这样手工在旧的firmware位置建一个软链接就解决了这个问题。

*** 备注
    这个问题应该是由于之前glibc升级时未全部完成引起的，archlinux现在把/lib改为/usr/lib的软链接了，可以手工进行设置为软链接这一步骤来修复。

** DONE Fnv算法冲突率测试                                          :hash:
   CLOSED: <2012-11-24 六 18:31>

*** [[http://www.isthe.com/chongo/tech/comp/fnv/][Fnv]]介绍
    Fnv是和 [[http://code.google.com/p/cityhash/][CityHash]] 类似的哈希算法。这里重复《[[http://blog.kankanan.com/posts/2012/11/24_cityhash7b976cd551b27a8173876d4b8bd5.html][CityHash算法冲突率测试]]》，做为一个对比。

*** 测试样本数据
    16630591行不重复字符串，每一行内容为以制表符分隔的下载地址和引用页。

*** fnv64测试结果
    没有冲突

*** fnv32测试结果
    共31948次冲突，冲突率约为千分之二。
    同一哈希值上33次冲突二次，31879次冲突一次。
    冲突率比CityHash略低，少了298次。

** DONE 如何做面试
   CLOSED: <2012-10-24 三 14:23>

*** 语言基础
*** 相关技术
*** 性能优化
*** 架构
*** 管理
*** 诉求
** DONE 理解nginx的keepalive_timeout配置项                       :nginx:http:
   CLOSED: [2012-11-12 二 17:05]
   
   不要误以为它是指tcp连接空闲多少秒后关闭，它仅表示连接建立多少秒后关闭，不会在一次请求后重新计时。

** DONE 在python中安装mysqldb模块                                    :python:
   CLOSED: <2012-08-01 三 08:55>

*** 正常的安装过程
#+begin_src sh
  wget "http://downloads.sourceforge.net/project/mysql-python/mysql-python\
/1.2.3/MySQL-python-1.2.3.tar.gz?r=http%3A%2F%2Fsourceforge.net%2Fprojects\
%2Fmysql-python%2Ffiles%2F&ts=1304062611&use_mirror=nchc"
  tar xzvf MySQL-python-1.2.3.tar.gz
  cd MySQL-python-1.2.3
  python setup.py build
  python setup.py install
#+end_src

*** 常见错误及其修复
    - ImportError: No module named setuptools
      #+name: install-setuptools
      #+begin_src sh
      wget http://pypi.python.org/packages/2.4/s/setuptools/setuptools-0.6c11-py2.4.egg\
      #md5=bd639f9b0eac4c42497034dec2ec0c2b
      sh setuptools-0.6c11-py2.4.egg
      #+end_src

    - mysql\_config: command not found
      #+name: edit-site.cfg 
      #+begin_src sh
      sed --in-place -e "s/#mysql_config = \/usr\/local\/bin\/mysql_config/\
      mysql_config = \/usr\/local\/mysql\/bin\/mysql_config/g" site.cfg
      #+end_src

    - ImportError: \dots{} \_mysql.so: undefined symbol: compress
      #+name: edit-setup\_posix.py
      #+begin_src sh
      sed --in-place -e "s/libs = mysql_config(\"libs_r\")/libs = mysql_config(\"libs_r\")\n\
      libs.append('-lz')\n        print libs/g" setup_posix.py
      #+end_src

** DONE 如何学习英语                                               :english:
   CLOSED: <2013-04-07 日 09:49>

   经过一天的英孚及韦博试听，总结出以下几点：
   - 语法 ::
     熟读常用句型，扩展至类似语句，从中提炼语法，另一方面也可以练就一口流利的日用口语。
   - 听力 ::
     不会说就不会听，多说才能够快速识别听到的东西。
   - 阅读 ::
     多记单词，不断的重复重复再重复，直到看到单词脱口而出。
   
** DONE MongoDB基础                                                 :mongodb:
   CLOSED: <2012-10-21 日 17:06>
   
*** MongoDB与Mysql的基本结构对应关系
**** 一台机器
     computer

***** 多个MongoDB实例                                          <--对应-->                    mysql服务器进程
      MongoDB Instance                                        <--对应-->                    Mysqld Instance

      运行着的MongoDB后台服务进程：/etc/rc.d/mongodb start      <--对应-->                     /etc/rc.d/mysqld start

****** 多个数据库                                              <--对应-->                    mysql中的数据库
       MongoDB Database                                       <--对应-->                     Database

******* 多个集合                                               <--对应-->                    mysql中的表
        MongoDB Collection                                    <--对应-->                     Table

******** 多个文档                                             <--对应-->                     mysql中的记录行
         MongoDB Document                                     <--对应-->                    Row

*** CentOS上搭建环境
    - 添加源/etc/yum.repos.d/10gen.repo ::
      #+BEGIN_EXAMPLE
      [10gen]
      name=10gen Repository
      baseurl=http://downloads-distro.mongodb.org/repo/redhat/os/x86_64
      gpgcheck=0
      #+END_EXAMPLE
    - 安装服务器客户端程序 ::
      #+BEGIN_SRC sh
      yum install mongo-10gen mongo-10gen-server
      #+END_SRC
    - 安装php扩展 ::
      #+BEGIN_SRC sh
      yum -y install make gcc php-devel
      yum install php-pear
      PATH=$PATH:/usr/local/php/bin/ pecl install mongo
      #+END_SRC
      php.ini中添加：extension=mongo.so
    - 启动服务 ::
      /etc/rc.d/init.d/mongodb start
     
** DONE 解决mysql_connect慢的问题                                     :mysql:
   CLOSED: <2012-12-06 四 10:25>

  压测时发现mysql\_connect耗时超过30秒，登录mysql后执行show processlist，显示超过800个连接状态如下：

  #+BEGIN_EXAMPLE
   unauthenticated user | XXXX.XXX.XXX.XXX:XXXX  | NULL | Connect     |  NULL | login    
  #+END_EXAMPLE

  经求教运维，在my.cnf中的“[mysqld]”下添加以下配置行即可：

  #+BEGIN_EXAMPLE
    skip-name-resolve
  #+END_EXAMPLE

** DONE Nginx Comet: 基于 HTTP 长连接的“服务器推”技术         :nginx:comet:
   CLOSED: <2012-12-14 五 21:09>

*** 简介
    可参考这篇文章：[[http://www.ibm.com/developerworks/cn/web/wa-lo-comet/][Comet：基于 HTTP 长连接的“服务器推”技术]]

*** [[https://github.com/slact/nginx_http_push_module][nginx\_http\_push\_module]] （不建议使用）
  这个模块功能上没有问题，网上介绍的文章相对比较多，但是存在严重的内存泄露问题，而且发现使用kill -HUP的方式优雅重启nginx虽会释放一部分内存，但nginx错误日志显示有共享内存锁相关的冲突，我们不得不每小时彻底重启一次nginx。简单说一下就是它使用一个全局的内存池来分配订阅者及响应需要的内存空间，但是从nginx内存池分配的小内存块（< pagesize，4096）是不会释放的也不会归还到池中进行重用，具体可查看nginx源码的ngx\_palloc和ngx\_pfree函数进行验证。

  可google "nginx中mod\_push模块内存分配改造"，在作者的[[http://http://blog.lifeibo.com/][网站]]正在改版暂时找不到该文章。
  
  [[http://bsd.ee/~hadara/blog/?p=215=1][这里]]也有人[[https://github.com/slact/nginx_http_push_module/pull/60][指出]]该问题，同时该文作者也fork了一个分枝，但是我试了一下，除了不支持push\_channel\_timeout特性外，还是一样有内存泄露。

  - 参考配置 ::
#+BEGIN_EXAMPLE
    location ~ ^/publish$ {
        allow 127.0.0.1;
        deny all;
        set $push_channel_id $arg_id;
        push_publisher;
        push_delete_oldest_received_message on;
        push_message_timeout 5s;
        #push_channel_timeout 60s;
        push_store_messages off;
    }

    location ~ ^/activity$ {
        if ($args ~ "callback=(.+)" ) {
            rewrite ^/activity "/activity_jsonp" last;
        }
        push_subscriber;
        push_subscriber_timeout 60s;
        push_subscriber_concurrency first;
        push_max_channel_subscribers 1;
        set $push_channel_id $arg_id;
        default_type application/json;
    }

    location ~ ^/activity_jsonp$ {
        push_subscriber;
        push_subscriber_timeout 60s;
        push_subscriber_concurrency first;
        push_max_channel_subscribers 1;
        set $push_channel_id $arg_id;
        default_type application/json;
        echo_before_body $arg_callback "(";
        echo_after_body ")";
    }
#+END_EXAMPLE

*** [[https://github.com/wandenberg/nginx-push-stream-module][nginx-push-stream-module]] （建议使用）
  由于 [[https://github.com/slact/nginx_http_push_module][nginx\_http\_push\_module]] 存在内存泄露问题，同时没有人进行正式的修复，我们决定尝试一下[[https://github.com/wandenberg/nginx-push-stream-module][nginx-push-stream-module]]，这个模块功能更强大同时文档更完整，看起来也更活跃。

  - 优点 ::
    + 更成熟
      有内存消耗说明文档，便于决定共享内存容量配置。
      有统计功能。
      可对响应内容进行再处理。
    + 测试中未发现明显的内存泄露
    + 内置支持jsonp
      返回的jsonp是这样的格式callback([text])，可以通过修改ngx\_http\_push\_stream\_module\_utils.h中定义的NGX\_HTTP\_PUSH\_STREAM\_CALLBACK\_INIT\_CHUNK和NGX\_HTTP\_PUSH\_STREAM\_CALLBACK\_END\_CHUNK去除多余的中括号。
  
- 参考配置 ::
#+BEGIN_EXAMPLE
push_stream_store_messages off;
push_stream_max_subscribers_per_channel 1;
push_stream_subscriber_connection_ttl 60s;
push_stream_longpolling_connection_ttl 60s;

server {
    listen 80;
    server_name localhost 127.0.0.1;
    
    ...

    location ~ ^/publish$ {
        allow 127.0.0.1;
        deny all;
        push_stream_publisher admin;
        set $push_stream_channel_id $arg_id;
    }
    
    location ~ ^/activity$ {
        push_stream_subscriber long-polling;
        set $push_stream_channels_path $arg_id;
        push_stream_content_type "application/json";
        push_stream_message_template "~text~";
    }

    ...
}

#+END_EXAMPLE  

** DONE nginx下快速搭建php运行环境                                :nginx:php:
   CLOSED: <2012-08-11 六 21:09>

*** 安装
**** 安装nginx
     yaourt -S nginx
**** 安装php
      yaourt -S php
**** 安装php-fpm
      yaourt -S php-fpm

*** 配置
**** 配置nginx
     - 将nginx.conf中的以下部分：
       #+BEGIN_EXAMPLE
         #location ~ \.php$ {
         ...
         #}
       #+END_EXAMPLE
     - 修改为
       #+BEGIN_EXAMPLE
          location ~ \.php$ {
             root           /usr/share/nginx/html;
             fastcgi_pass   127.0.0.1:9000;
             fastcgi_index  index.php;
             fastcgi_param  SCRIPT_FILENAME  /usr/share/nginx/html$fastcgi_script_name;
             include        fastcgi_params;
          }
       #+END_EXAMPLE
**** 配置php
     在open\_basedir中添加：/usr/share/nginx/html
**** 配置php-fpm.conf
     启用以下listen配置：
     listen = 127.0.0.1:9000

*** 运行
    - 重启nginx
      #+BEGIN_SRC sh
      sudo /etc/rc.d/nginx restart
      #+END_SRC
    - 启动php-fpm
      #+BEGIN_SRC sh
      sudo php-fpm
      #+END_SRC
    - 然后在/usr/share/nginx/html目录中写php脚本即可。

** DONE php中DOMDocument类createElement和createTextNode的区别           :php:
   CLOSED: <2012-09-27 四 19:05>

*** DOMDocument::createElement
    - 原型：DOMElement DOMDocument::createElement ( string $name [, string $value ] )

      创建一个元素，其中第二个参数是可选的，不会对它进行转义。当value中包含特殊字符（如：&）会出错。
   
*** Domdocument::createTextNode
    - 原型：DOMText DOMDocument::createTextNode ( string $content )

      创建一个文本结点，会对其内容进行转义。

*** 典型示例：创建一个文本元素
    #+begin_src php
    $element = $doc->createElement("city");
    $node = $doc->createTextNode("shenzhen");
    $element->appendChild($node);
    $doc->appendChild($element);
    #+end_src
    - 对应的xml文档：
    #+begin_src xml
    <city>shenzhen</city>
    #+end_src
     
** DONE 当php遇上redis                                            :php:redis:
   CLOSED: <2012-12-08 六 13:41>

   在最近的项目中，我们需要在php中访问redis，我们选择了使用[[https://github.com/nicolasff/phpredis][phpredis]]库，下面是遇到的一些问题。

*** redis持久连接不靠谱。

    可以说这是php的通病了，不管是mysql、memcache还是redis，指望由php本身（包含php扩展）来实现持久连接都是行不通的。

    - 为什么这么说呢？ ::
      首先，所谓的持久连接的实现不外乎在进程（php-fpm）内建一个连接池，当php需要连接时，先以ip+port等信息为key在池中查找，找到则直接返回已有连接没有则新建连接。而当一个请求执行结束时，不关闭连接，而是把连接归还到池中。
      
      这样当php需要用到多个redis实例时（分库），因为一个php-fpm进程会持有每个redis实例的一个连接，所以需要“php-fpm进程数“*“redis实例数"个redis连接，而对于每个redis服务器则有“php-fpm进程数“个客户端连接。

      举个例子：一个web应用开了1000个php-fpm进程，有10个redis实例，那么保持的redis连接数就为1000*10也就是10000，每个redis实例有1000个客户端连接。如果前端或redis再扩容所需要的连接就会以乘积方式增加。一个redis实例有php-fpm进程数个连接的情况下表现如何呢，这就要好好测一测了，反正是每连接一线程的mysql是直接堵死了。

*** RedisArray不靠谱。
    RedisArray实现了一致性hash分布式，但是它在初始化的时候就会连接上每个实例，这在web应用中简直是胡闹，它对一致性hash实现得比较完善，结点失效、动态添加结点时重新hash都有处理，在万不得已进行水平扩容时，可能会用得上。

*** 需要自已关闭redis连接。
  Redis的析构函数没有关闭redis连接，这会导致redis网络负载过高，要确保脚本结束时关闭连接，最好是能够封装一下Redis类再使用。

  - 示例封装 ::
#+BEGIN_SRC php
/// 分布式Redis.
class RedisShard {
    /// 构造函数.
    public function __construct($shards) {
        $this->reinit($shards);
    }

    /// 析构函数.
    /// 脚本结束时，phpredis不会自动关闭redis连接，这里添加自动关闭连接支持.
    /// 可以通过手动unset本类对象快速释放资源.
    public function __destruct() {
        if(isset($this->shard)){
            $this->shard['redis']->close();
        }
    }

    /// 重新初始化.
    public function reinit($shards){
        $index = 0;
        $this->shards = array();
        foreach($shards as $shard){
            $this->shards[$index] = explode(':', $shard); //格式：host:port:db
            $this->shards[$index]['index'] = $index;
            ++$index;
        }        
    }
    
    /// 转发方法调用到真正的redis对象.
    public function __call($name, $arguments) {
        $result = call_user_func_array(array($this->redis($arguments[0]), $name), $arguments);
        if($result === false and in_array($name, array('set', 'setex', 'incr'))) {
            trigger_error("redis error: " . $this->shard[0] . ':' . $this->shard[1] . ':' .$this->shard[2] . " $name " . implode(' ', $arguments), E_USER_NOTICE);
        }
        return $result;
    }

    /// 获取1至max间的唯一序号name，达到max后会从1开始.
    /// redis的递增到最大值后会返回错误，本方法实现安全的递增。
    /// 失败返回false，最要确保已用redis()方法连到生成序号的某个redis对象.
    public function id($name, $max) {
        if(isset($this->shard)){
            $id = $this->shard['redis']->incr('_id_' . $name);
            if($id){
                $max = intval($max/count($this->shards));
                if($id % $max == 0){
                    while($this->shard['redis']->decrBy('_id_' . $name, $max) >= $max){
                    }
                    $id = $max;
                }
                else if($id > $max){
                    $id %= $max;
                }
                return ($id - 1)*count($this->shards) + ($this->shard['index'] + 1);
            }
        }
        return false;
    }

    /// 连接并返回key对应的redis对象.
    public function redis($key){
        //TODO: crc32在32位系统下会返回负数，因我们是部署在64位系统上，暂时忽略.
        assert(PHP_INT_SIZE === 8);
        $index = crc32($key) % count($this->shards);
        $shard = $this->shards[$index];
        if(isset($this->shard)){
            //尝试重用已有连接.
            if($this->shard[0] == $shard[0] and $this->shard[1] == $shard[1]){
                if($this->shard[2] != $shard[2]){
                    if(! $this->shard['redis']->select($shard[2])){
                        trigger_error('redis error: select ' . $shard[0] . ':' . $shard[1] . ':' .$shard[2], E_USER_ERROR);
                        return false;
                    }
                    $this->shard[2] = $shard[2];
                }
                return $this->shard['redis'];
            }
            $this->shard['redis']->close();
            unset($this->shard);
        }
        //新建连接.
        $shard['redis'] = new Redis();
        if(! $shard['redis']->connect($shard[0], $shard[1])){
            trigger_error('redis error: connect ' . $shard[0] . ':' . $shard[1], E_USER_ERROR);
            return false;
        }
        $db = intval($shard[2]);
        if($db != 0 and !$shard['redis']->select($db)){
            trigger_error('redis error: select ' . $shard[0] . ':' . $shard[1] . ':' .$shard[2], E_USER_ERROR);
            $shard['redis']->close();
            return false;
        }
        if(ENABLE_DEVELOP){
            trigger_error('redis connect success. ' . $shard[0] . ':' . $shard[1] . ':' . $shard[2], E_USER_NOTICE);
        }        
        $this->shard = $shard;
        return $this->shard['redis'];
    }
}
#+END_SRC

** DONE python中的UTC与本地时区处理                                  :python:
   CLOSED: <2013-03-20 三 17:29>

   在通过sqlalchemy使用sqlite3数据库的过程中，发现日期时间字段默认值为CURRENT\_TIMESTAMP，但是查出的值少了8个小时。很明显是遇到时区问题了。

   mysql的TIMESTAMP字段类型和sqlite3一样使用UTC时间保存，因为在存取时自动进行了本地时间与UTC时间互转，所以不会遇到时区问题。但是sqlite3没有自动进行这一转换，需要在sql中自行转换:
   #+begin_src sql
    select datetime(CURRENT_TIMESTAMP, 'localtime')
   #+end_src

   进一步google后，找到了这篇文章：《[[http://lucumr.pocoo.org/2011/7/15/eppur-si-muove/][Dealing with Timezones in Python]]》，文章大意是python中的datetime库默认不携带时区信息，而加上时区后又与不带时区的datetime对象无法一起工作（如：比较），另外像datetime.datetime.utcnow()返回的utc时间和datetime.datetime.now()返回的本地时间也是不携带时区信息的（tzinfo属性为None），容易引起混淆，因此处理的简单性，内部最好统一使用UTC标准时间，和用户交互时再转换为本地时间。

   下面是互转的算法：
   #+begin_src python
      #/usr/bin/env python
      
      import datetime
      import time
      import sys
      
      if sys.version >= '3.2.':
          localtimezone = datetime.timezone(datetime.timedelta(seconds=-time.timezone), time.tzname[0])
          utctimezone = datetime.timezone.utc
      else:
          from dateutil import tz
          localtimezone = tz.tzlocal()
          utctimezone = tz.gettz('UTC')
      
      def parsedatetime(dt, fmt="%Y-%m-%d %H:%M:%S"):
          """parse local datetime string as utc datetime object"""
          return datetime.datetime.strptime(dt, fmt).replace(tzinfo=localtimezone).astimezone(utctimezone)
      
      def formatdatetime(dt, fmt="%Y-%m-%d %H:%M:%S"):
          """format utc datetime object as local datetime string"""
          return dt.replace(tzinfo=utctimezone).astimezone(localtimezone).strftime(fmt)
      
      if __name__ == '__main__':
          input_local_datetime = '2012-01-02 03:04:05'
          parsed_utc_datetime = parsedatetime(input_local_datetime)
          assert(formatdatetime(parsed_utc_datetime) == input_local_datetime)
   #+end_src

** DONE 二维码研究                                                   :qrcode:
   CLOSED: <2013-03-30 六 11:21>

*** 介绍
    - [[http://www.itsc.org.sg/pdf/synthesis08/Three_QR_Code.pdf][Three\_QR\_Code.pdf]] ::
      RFC式的文档

    - [[http://suflow.iteye.com/blog/1100678][二维码 编码原理简介]] ::
      通俗易懂的编码细节介绍

    - [[http://zh.wikipedia.org/wiki/QR%E7%A2%BC][QR碼 - 维基百科，自由的百科全书]] ::

    - [[http://www.qrstuff.com/blog/2011/11/23/qr-code-minimum-size][QR Code Minimum Size]] 与 [[http://www.qrstuff.com/blog/2011/01/18/what-size-should-a-qr-code-be][What Size Should A Printed QR Code Be?]] ::
      关于可识别性的一些结论，该网站上有大量二维码研究相关的文章
    
*** 二维码开发库
    - [[https://github.com/fukuchi/libqrencode][libqrencode]] ::
      基础的c语言二维码编码库，很多语言基于它开发扩展，不包含生成png图的功能，如需生成png可参考[[https://github.com/bitly/simplehttp/blob/master/qrencode/qrencode.c][这里]]
    - [[https://github.com/jeromeetienne/jquery-qrcode][jquery-qrcode]] ::
      使用javascript直接在客户端生成二维码，中文支持参见[[http://suflow.iteye.com/blog/1687396][JS生成二维码，支持中文字符]]
    - [[http://people.freebsd.org/~vanilla/qrencode-0.3.tar.bz2][php's qrencode extension]] ::
      使用nginx的扩展性能会更好一点，参考后面[[nginx的相关扩展]].
    - [[http://trac.koka-in.org/libdecodeqr][libdecodeqr]] ::
      二维码解码库
      
*** nginx的相关扩展
**** 基本的二维码
     [[https://github.com/dcshi/ngx_http_qrcode_module][ngx\_http\_qrcode\_module]]
    
**** 二维码个性化水印
   nginx\_http\_image\_filter加上[[http://forum.nginx.org/read.php?21,235958][水印补丁]]即可。

   下面的是经过修改后的 =nginx image filter= 模块代码，加入居中的水印效果:

#+o_blog_source ./static/ngx_http_image_filter_module.c

**** 编译
     #+begin_src sh
     --with-debug --with-http_image_filter_module --add-module=/home/tangxinfa/Opensource/nginx-1.2.7/../ngx_http_qrcode_module/ --add-module=/home/tangxinfa/Opensource/nginx-1.2.7/../ngx_devel_kit/ --add-module=/home/tangxinfa/Opensource/nginx-1.2.7/../set-misc-nginx-module/ --add-module=/home/tangxinfa/Opensource/nginx-1.2.7/../echo-nginx-module/
     #+end_src

**** 配置
     #+begin_example
          location ~ /qr {
              qrcode_fg_color FF0000;
              qrcode_bg_color FFFFFF;    
              qrcode_level 2;
              qrcode_hint 2;
              qrcode_size 120;
              qrcode_margin 2;
              qrcode_version 5;
              set_unescape_uri $txt $arg_txt;
              qrcode_txt $txt;
              qrcode_casesensitive 1; 
              qrcode_gen;  

              image_filter_watermark "/usr/share/pixmaps/gnome-word.png";
              image_filter_watermark_transparency 95; #0-100
              image_filter watermark;
          }
     #+end_example

**** 访问
#+begin_example
   http://localhost:8080/qr?txt=hello
#+end_example
     - 显示效果：
     [[file:static/hello_qr.png]]

*** 二维码基础服务的一点思索
    - 必须建立在cdn的基础上
    - 用户只需按照约定将内容以及定制参数按照直观的方式编码成二维码图片链接即可

    参考：https://developers.google.com/chart/infographics/docs/qr_codes

** DONE 解决保存快照失败后redis无法写入的问题                         :redis:
   CLOSED: <2012-12-16 日 15:14>
   
   用命令行工具连上后执行“set test 0”出现以下错误提示：
   #+BEGIN_EXAMPLE
   MISCONF Redis is configured to save RDB snapshots, but is currently not able to persist on disk. Commands that may modify the data set are disabled. Please check Redis logs for details about the error.
   #+END_EXAMPLE
   这个应该是之前强制停止redis快照导致的，查看redis快照状态证实了这一点：
   #+BEGIN_EXAMPLE
   redis 127.0.0.1:6379> info
   ...
   rdb_last_bgsave_status:err
   ...
   #+END_EXAMPLE
   通过关闭配置项stop-writes-on-bgsave-error解决该问题。
   #+BEGIN_EXAMPLE
   redis 127.0.0.1:6379> config set stop-writes-on-bgsave-error no
   #+END_EXAMPLE

** DONE 使用hash表结构减少redis内存占用                               :redis:
   CLOSED: <2012-12-16 日 15:14>

   当hash结构中的元素较少（少于redis.conf:hash-max-zipmap-entries指定的数量时，配置成<=1000，过大会减低处理速度，参见： [[http://stackoverflow.com/questions/11281734/redis-using-hashes][这里]] 和 [[http://instagram-engineering.tumblr.com/post/12202313862/storing-hundreds-of-millions-of-simple-key-value-pairs][这里]] ）且数据为整型时，redis使用特殊的方式（数组保存，时间换空间）保存hash结构以减少内存占用，参见 [[http://redis.io/topics/memory-optimization][这里]] 和 [[http://stackoverflow.com/questions/9625246/what-are-the-underlying-data-structures-used-for-redis][这里]] 。但当hash结构超过指定数量时将使用普通的[[http://redis.io/commands#string][字符串]]方式保存，也就无法再节省内存了。

** DONE 估算redis内存占用                                             :redis:
   CLOSED: <2012-12-16 日 15:14>

   参考: [[http://lethain.com/notes-on-redis-memory-usage/][Notes on Redis Memory Usage]]

   - 测试环境
     - redis版本 :: redis\_version:2.4.4
     - 操作系统（uname -a） :: Linux CentOS 2.6.32-220.13.1.el6.x86\_64 #1 SMP Tue Apr 17 23:56:34 BST 2012 x86\_64 x86\_64 x86\_64 GNU/Linux
     - python版本（python --version） :: Python 2.6.6

*** Strings
    - 测试脚本
      #+BEGIN_SRC python
        #!/bin/env python
        
        import redis
        import uuid
        import time
        
        r = redis.Redis(host='localhost', port=6379, db=0)
        for num_strings in (100000,):
            r.flushall()
            time.sleep(1.0)
            initial_size = r.dbsize()
            initial_info = r.info()
        
            for i in xrange(0, num_strings):
                r.set(str(uuid.uuid4()), time.time())
                #r.setex(str(uuid.uuid4()), time.time(), 100000)
            final_size = r.dbsize()
            final_info = r.info()
        
            print "For %s strings." % (num_strings,)
            print "Keys: %s => %s" % (initial_size, final_size)
            print "Memory: %s => %s" % (initial_info['used_memory'],
                                            final_info['used_memory'])
            print "Memory per key: %d"%((int(final_info['used_memory']) - int(initial_info['used_memory'])) / num_strings)
        #+END_SRC
    - 测试结果
      - set :: 每个key-value占用138字节，可见redis本身的维护开销为89字节
      - setex :: 每个key-value占用180字节，可见redis本身的维护开销为131字节，启用过期时间需要42字节开销（这是因为redis使用新的链表保存设置了过期时间的条目）。

*** Sets
    - 测试脚本
      #+BEGIN_SRC python
        #!/bin/env python
        
        import redis
        import math
        import time
        
        r = redis.Redis(host='localhost', port=6379, db=0)
        set_capcity = int(r.config_get("set-max-intset-entries")["set-max-intset-entries"])
        
        def set_name(i, num_strings, set_capcity):
            set_num = math.ceil(num_strings/float(set_capcity))
            return "s%d"%(i%set_num)
            
        for num_strings in (100000,):
            r.flushall()
            time.sleep(1.0)
            initial_size = r.dbsize()
            initial_info = r.info()
        
            for i in xrange(0, num_strings):
                #r.sadd("s", str(i))
                r.sadd(set_name(i, num_strings, set_capcity), str(i))
            final_size = r.dbsize()
            final_info = r.info()
        
            print "For %s strings." % (num_strings,)
            print "Keys: %s => %s" % (initial_size, final_size)
            print "Memory: %s => %s" % (initial_info['used_memory'],
                                            final_info['used_memory'])
            print "Memory per key: %d"%((int(final_info['used_memory']) - int(initial_info['used_memory'])) / num_strings)
        
        #+END_SRC

    - 测试结果
      - 启用压缩 :: 每个value占用4字节
      - 不启用压缩 :: 每个value占用39字节
      注意: redis的set仅当值为整型，压缩才会生效。

*** 内存预留
    除非你能够保证你的机器总是有一半的空闲内存，否则别使用快照方式持久化数据或者通过执行BGREWRITEAOF压缩aof文件。
    redis在执行bgsave时，会进行一次fork，fork后的进程负责将内存中的数据写入磁盘，由于fork采用Copy-On-Write，两个redis进程共享内存中的数据。redis如果有数据更新，则会将对应的共享内存页创建一份副本再更新，当更新操作足够频繁时，共享的内存空间会迅速地副本化，导致物理内存被耗光，系统被迫动用交换空间，从而导致redis服务极不稳定，整个系统堵塞在磁盘io上。

** DONE linux下跨进程传递文件描述符                                   :linux:
   CLOSED: <2013-03-09 六 15:11>

*** 问题
    在web开发中，以典型的php-fpm为例，对于到外部系统的连接（如：mysql、redis）等都提供了持久连接接口（pconnect），但是受限于多进程模型，事实上是每个php-fpm进程都有单独的一个连接池的（参见：《[[file:php_meet_redis.org][当php遇上redis]]》），大量空闲连接的存在不仅对系统资源造成了浪费（不单指fd空间，像mysql的每连接一线程会附带大量内存空间：sort\_buffer、read\_buffer等），而且整个系统将无法横向扩展（如：mysql连接数限制）。如果可以在进程间共享文件描述符，将可以大大提升系统性能，促进多进程模型的应用。

*** 方案
    在linux平台下，sendmsg、recvmsg可以将一个进程的文件描述符传递给另一进程使用，这使得实现系统级的连接池成为可能。

*** 实现
    《The Linux Programming Interface》61.13.3 Passing File Descriptors
     
** DONE Web模型初探                                                     :web:
   CLOSED: <2013-02-28 四 15:07>

*** CGI

    全称为Common Gateway Interface，即公共网关接口。
    当Web服务器收到一个请求时，运行相应的处理程序，相关参数通过标准输入传递给处理程序，处理程序的标准输出做为响应内容，处理程序运行结束后将响应发送给客户端。
    
    - 性能 *

      进程级，每请求一进程。进程创建有很大的开销，并发数与系统资源消耗呈线性增长，有限的系统资源成为瓶颈。
      
*** FastCGI

    为CGI的改良，CGI程序做为独立的网络后台程序运行，当Web服务器收到一个请求时，发起一个tcp请求到处理程序，通过该tcp连接传入相关参数，处理程序的响应也通过该tcp连接发回给Web服务器，处理程序关闭该连接表示处理完毕，Web服务器最终将响应发送给客户端。

    - 性能 **

      网络级，每请求一连接。CGI的改良，重用进程，进程处理完一个请求后再处理下一请求，对于多个请求，只需要付出一次进程创建的开销，可以在后继请求重用资源（从文件载入的配置项、查询到的数据、打开的文件、数据库连接等）。因为处理程序是串行处理请求，往往需要同时运行多个处理程序以提升并发处理能力，这些处理程序无法共享资源以进一步提升性能。
    
    - 附录

      Web服务器可重用到服务程序的连接进一步提升性能（如：nginx的[[http://nginx.org/en/docs/http/ngx_http_upstream_module.html#keepalive][upstream\_keepalive]]）。
      
*** WSGI

*** uWSGI

** DONE memcached_get会重置过期时间吗？                           :memcached:
   CLOSED: <2012-11-13 二 20:29>

   不会。获取数据的操作不会影响数据的过期时间，最新的memcache1.6添加了touch和GAT（get and touch)命令，可以在获取数据时过期时间。
** DONE python中MySQLdb使用utf-8字符集                         :python:mysql:
   CLOSED: <2011-04-29 Fri 01:22>

   - 要避免乱码需要做好以下几点 ::
     - python源代码保存为utf-8
     - 数据库建成utf-8
     - mysql连接设置为utf-8
     - 查询結果中的文本字段是unicode的，转回utf-8

   - 总结性的示例代码 ::
     #+begin_src python
       #!/usr/bin/env python
       #-*- coding: utf-8 -*-
       
       import MySQLdb
       
       if __name__ == '__main__':
           mysql = MySQLdb.connect(host='localhost', user='root', passwd='123456', charset='utf8')
           cursor = mysql.cursor()
           cursor.execute('SET NAMES UTF8')
           sql = 'DROP DATABASE IF EXISTS mysqldb_utf8_test'
           cursor.execute(sql)
           sql = 'CREATE DATABASE mysqldb_utf8_test DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci'
           cursor.execute(sql)
           mysql = MySQLdb.connect(host='localhost', user='root', passwd='123456', db='mysqldb_utf8_test', charset='utf8')
           cursor = mysql.cursor()
           cursor.execute('SET NAMES UTF8')
           sql = 'CREATE TABLE utf8_table(key_field VARCHAR(32) NOT NULL, value_field VARCHAR(255) NOT NULL)'
           cursor.execute(sql)
           key = 'tangxinfa'
           value = '好人一个'
           sql = 'INSERT INTO utf8_table VALUES("%s", "%s")'%(key, value)
           cursor.execute(sql)       #注意某些旧版本的mysql（如4.1.22以下），mysql.character_set_name()总是返回latin1，会引起乱码，需要改为cursor.execute('INSERT INTO utf8_table VALUES("%s", "%s")', (key, value))
           sql = 'select * from utf8_table'
           cursor.execute(sql)
           for record in cursor.fetchall():
               for item in record:
                   print item.encode('utf8')
     #+end_src

   - 参考 ::
     - http://mysql-python.sourceforge.net/MySQLdb.html
     - http://bbs.phpchina.com/viewthread.php?tid=13861
     - http://hi.baidu.com/ak456/blog/item/c318502394aa20569922ed7b.html

** DONE log4cxx使用心得                                             :log4cxx:
   CLOSED: <2008-06-17 Tue 10:01>

   - 简介

     apache出品必属精品。正宗c++日志库，与log4j一脉相承。

     http://logging.apache.org/log4cxx/index.html

   - 下载、编译、安装

     打算安装到${HOME}/libs目录下：

     #+begin_src sh
     cd ~/libs
     wget http://mirror.bjtu.edu.cn/apache//apr/apr-1.4.4.tar.bz2
     tar xjvf apr-1.4.4.tar.bz2
     cd apr-1.4.4
     ./configure --prefix=${HOME}/libs && make && make install
     cd ..
     wget http://mirror.bjtu.edu.cn/apache//apr/apr-util-1.3.11.tar.bz2
     tar xjvf apr-util-1.3.11.tar.bz2
     cd apr-util-1.3.11
     ./configure --prefix=${HOME}/libs --with-apr=${HOME}/libs && make && make install
     cd ..
     wget http://apache.etoak.com//logging/log4cxx/0.10.0/apache-log4cxx-0.10.0.tar.gz
     tar xzvf apache-log4cxx-0.10.0.tar.gz
     cd apache-log4cxx-0.10.0
     ./configure --with-charset=utf-8 --prefix=${HOME}/libs --with-apr=${HOME}/libs --with-apr-util=${HOME}/libs && make && make install
     #+end_src

   - 使用例子

     =hello.cpp= ：
     #+begin_src cpp
       #include "log4cxx/logger.h"
       #include "log4cxx/propertyconfigurator.h"
       
       static log4cxx::LoggerPtr logger(log4cxx::Logger::getLogger("hello"));
       
       int main(int argc, char *argv[])
       {
         log4cxx::PropertyConfigurator::configure("./log4cxx_hello.properties");
         LOG4CXX_INFO(logger, "你好，log4cxx!");
         return 0;
       }
     #+end_src
   
     =log4cxx_hello.properties= ：
     #+begin_example
       log4j.rootLogger=debug, R
       
       log4j.appender.stdout=org.apache.log4j.ConsoleAppender
       log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
       
       # Pattern to output the caller's file name and line number.
       log4j.appender.stdout.layout.ConversionPattern=%5p [%t] (%F:%L) - %m%n
       
       log4j.appender.R=org.apache.log4j.RollingFileAppender
       log4j.appender.R.File=./hello.log
       
       log4j.appender.R.MaxFileSize=100KB
       # Keep one backup file
       log4j.appender.R.MaxBackupIndex=10
       
       log4j.appender.R.layout=org.apache.log4j.PatternLayout
       log4j.appender.R.layout.ConversionPattern=%5p %c [%t] (%F:%L) - %m%n
     #+end_example

     编译：
     #+begin_src sh
       g++ -o hello hello.cpp -I${HOME}/libs/include ${HOME}/libs/lib/liblog4cxx.a ${HOME}/libs/lib/libaprutil-1.a ${HOME}/libs/lib/libapr-1.a  -lexpat -lpthread
     #+end_src

   - 注意事项

     由于一个日志文件写满后会重命名所有已有的日志文件，配置过大MaxBackupIndex的会有性能问题，因此log4cxx编译时限制了它的大小（大概十多个）以避免配置的MaxBackupIndex过大，如果要设置更大一点的MaxFileSize来保存更多日志，需要在编译前进行修改。

     参考：http://objectmix.com/apache/684503-urgent-log4cxx-large-window-sizes-not-allowed.html

   - 使用技巧
     - 决定配置文件的格式（xml，property）。以使用相应的配置器（Configurator）装入配置文件。

       xml虽较property格式繁锁，支持的配置面更全，而property格式的配置文件使用更简单，容易在网上找到现成的配置文件。

     - logger命名

       logger名称反映了软件模块，如果有代表软件模块的类，则在类中包含以该类类名命名的logger对象，该模块功能相关代码通过该logger进行日志记录。
       另外可将logger对象作为全局变量，方便使用，特别是当软件模块较松散，并无对应的封装类时。

     - 在代码中适当地放置日志代码。引用适当的日志对象，对日志进行适当分级。

     - 余下的工作就是修改配置文件，对日志进行控制了。

   　　使用配置文件的好处就是可以方便地配置日志而不需要修改源代码，可以在配置文件中方便配置日志过滤、格式、日志目的地。

   - 体验

   　之前产品中用到的是log4cplus，但是常常有写日志崩溃的情况出现，使用log4cxx正是用于解决该崩溃。
** DONE SSL双方系统时间不一致导致的SSL连接失败及其解决方案        :openssl:c:
   CLOSED: <2008-07-25 五 17:45>

   在产品使用中，实施人员常常报告服务器与客户端无法连接，最终查明原因是双方的时间设置不一致。OpenSSL证书有一个有效时间段，当客户端或服务器的系统时间不在这个时间段内时SSL会因证书验证失败而无法连接。在实施中系统时间错误是很常见的，因不能上网而未开时间自动同步、bios没电了、客户疏忽等原因都会导致系统时间设置错误。如果连接失败后再查看系统时间设置进行故障排查终归是一件麻烦的事情。

   解决这个问题有以下几个办法：

   - 将证书的有效期设置得够大（如：1970-2099）
     
     这样估计可以在一定程度上解决这个问题，不过这也是个馊主意，一般申请的证书总会有一个合理的有效期。

   - 检测及必要时自动同步客户端与服务器的时间
     
     通过用wireshake抓包分析SSL建立连接的过程，发现在SSL握手过程中，会向对方传送本机的系统时间。因此一个显而易见的办法就是，当连接过程中检测到证书过期，将客户端的时间同步为服务器端的时间，再重连即可。

     下面是具体的示例代码：
     #+begin_src c
       #include <openssl/ssl.h>
       #include <openssl/bio.h>
       #include <openssl/err.h>
       #include <winsock2.h>
       #include <stdio.h>
       #include <string.h>
       #include <time.h>
       
       typedef struct _TimeInfo
       {
           time_t client;  /*客户端的时间*/
           time_t server;  /*服务器的时间*/
       } TimeInfo;
       
       /**
        * 同步系统时间.
        */
       BOOL syncSystemTime(time_t t)
       {
           SYSTEMTIME st;
           FILETIME   ft;  
           LONGLONG   ll;  
           
           ll = Int32x32To64(t, 10000000) + 116444736000000000; //1970.01.01  
           
           ft.dwLowDateTime  = (DWORD)ll;  
           ft.dwHighDateTime = (DWORD)(ll >> 32);  
           
           return FileTimeToSystemTime(&ft, &st) && SetSystemTime(&st);
       }
       
       /**
        * 获取SSL握手过程中服务器与客户端双方的系统时间.
        */
       void getSSLHandleShakeTimeInfo(int write_p,
                                      int version,
                                      int content_type,
                                      const unsigned char* buf,
                                      size_t len,
                                      SSL *ssl,
                                      TimeInfo *ti)
       {
           if(content_type != 22)   //require handshake message
               return;
           if(len < 42)
               return;
           if(buf[0] == 1)          //ClientHello Message send from client to server
               ti->client = htonl(*((u_long*)(buf + 6)));
           else if(buf[0] == 2)     //ServerHello Message send from server to client
               ti->server = htonl(*((u_long*)(buf + 6)));
           else
               return;
       }
       
       int main()
       {
           BIO * bio;
           SSL * ssl;
           SSL_CTX * ctx;
           TimeInfo timeInfo = {-1, -1};
           BOOL timeSynced = FALSE;
           long result;
       
           /* Set up the library */
           SSL_library_init();
           ERR_load_BIO_strings();
           SSL_load_error_strings();
       
           /* Set up the SSL context */
           ctx = SSL_CTX_new(SSLv3_client_method());
           if(ctx == NULL)
           {
               fprintf(stderr, "Error new SSL_CTX\n");
               ERR_print_errors_fp(stderr);
               SSL_CTX_free(ctx);
               return 0;
           }
       
           /* Get Server and Client system time via SSL Handshake */
           SSL_CTX_set_msg_callback(ctx, getSSLHandleShakeTimeInfo);
           SSL_CTX_set_msg_callback_arg(ctx, &timeInfo);
           
           /* Load the trust store */
           if(! SSL_CTX_load_verify_locations(ctx, ".\\certs\\cacert.pem", NULL))
           {
               fprintf(stderr, "Error loading trust store\n");
               ERR_print_errors_fp(stderr);
               SSL_CTX_free(ctx);
               return 0;
           }
       
           /* Setup the connection */
           bio = BIO_new_ssl_connect(ctx);
       
           /* Set the SSL_MODE_AUTO_RETRY flag */
           BIO_get_ssl(bio, & ssl);
           SSL_set_mode(ssl, SSL_MODE_AUTO_RETRY);
       
           /* Create and setup the connection */
           BIO_set_conn_hostname(bio, "192.168.1.5:5555");
           if(BIO_do_connect(bio) <= 0)
           {
               fprintf(stderr, "Error attempting to connect\n");
               ERR_print_errors_fp(stderr);
               BIO_free_all(bio);
               SSL_CTX_free(ctx);
               return 0;
           }
           
           /* Check the certificate */
           switch(SSL_get_verify_result(ssl))
           {
           case X509_V_OK:
               break;
           case X509_V_ERR_CERT_NOT_YET_VALID:
           case X509_V_ERR_CERT_HAS_EXPIRED:
               if(timeInfo.server != -1 && timeInfo.client != -1)
               {
                   printf("当前客户端时间: %s", ctime(&timeInfo.client));
                   printf("当前服务器时间: %s", ctime(&timeInfo.server));
                   printf("尝试与服务器时间同步");
                   
                   if(syncSystemTime(timeInfo.server))
                       printf("成功\n");
                   else
                       printf("失败\n");
                   printf("请重试连接服务器！\n");
               }
           default:
               fprintf(stderr, "Certificate verification error: %i\n", SSL_get_verify_result(ssl));
               BIO_free_all(bio);
               SSL_CTX_free(ctx);
               return 0;
           }
       
           /* Close the connection and free the context */
           BIO_free_all(bio);
           SSL_CTX_free(ctx);
           return 0;
       }
     #+end_src
** DONE 搭建jabber服务器                                       :jabber:linux:
   CLOSED: <2011-05-04 三 00:32>

   - 编译安装
     
     =下载=
     #+begin_src sh
       wget http://download.jabberd.org/jabberd14/jabberd14-1.6.1.1.tar.gz
       tar xzvf jabberd14-1.6.1.1.tar.gz
       cd jabberd14-1.6.1.1
     #+end_src

     =修改代码以解决编译错误=
     #+begin_src sh
       diff -r jabberd14-1.6.1.1/jabberd/lib/xmlnode.cc tmp/jabberd14-1.6.1.1/jabberd/lib/xmlnode.cc
       882,884c882,884
       <     const char *next_step = NULL;
       <     const char *start_predicate = NULL;
       <     const char *end_predicate = NULL;
       ---
       >     char *next_step = NULL;
       >     char *start_predicate = NULL;
       >     char *end_predicate = NULL;
       1836c1836
       <         ((char*)strchr(lang, '-'))[0] = 0;
       ---
       >         strchr(lang, '-')[0] = 0;
       diff -r jabberd14-1.6.1.1/jabberd/log.cc tmp/jabberd14-1.6.1.1/jabberd/log.cc
       89c89
       <         pos = (char*)strchr(zone,'.');
       ---
       >     pos = strchr(zone,'.');
       diff -r jabberd14-1.6.1.1/jabberd/mio_tls.cc tmp/jabberd14-1.6.1.1/jabberd/mio_tls.cc
       615c615
       <         ret = gnutls_certificate_set_openpgp_key_file(current_credentials, pubfile, privfile, GNUTLS_OPENPGP_FMT_BASE64);
       ---
       >         ret = gnutls_certificate_set_openpgp_key_file(current_credentials, pubfile, privfile);
       634c634
       <         ret = gnutls_certificate_set_openpgp_keyring_file(current_credentials, file, GNUTLS_OPENPGP_FMT_BASE64);
       ---
       >         ret = gnutls_certificate_set_openpgp_keyring_file(current_credentials, file);
       640a641,657
       >     }
       >
       >     // load GnuPG trustdb
       >     if (j_strcmp(xmlnode_get_localname(cur), "trustdb") == 0) {
       >         char const *const file = xmlnode_get_data(cur);
       >
       >         if (file == NULL) {
       >         log_warn(NULL, "Initializing TLS subsystem: <trustdb/> element inside the TLS configuration, that does not contain a file-name.");
       >         continue;
       >         }
       >
       >         // load the GnuPG trustdb
       >         ret = gnutls_certificate_set_openpgp_trustdb(current_credentials, file);
       >         if (ret < 0) {
       >         log_error(NULL, "Error loading GnuPG trustdb %s: %s", file, gnutls_strerror(ret));
       >         continue;
       >         }
     #+end_src
     
     =编译安装=
     #+begin_src sh
       ./configure && make && sudo make install
     #+end_src

     如出错通常是少了相关依赖库，用包管理工具（如：ubuntu下的新立得）安装即可。

   - 配置

     按照mysql.sql中的注释配置数据库：
     
     #+begin_src sh
       mysql -uroot -p
       mysql> CREATE DATABASE jabber CHARACTER SET utf8;
       mysql> use jabber;
       mysql> grant all on jabber.* to jabber@localhost identified by 'secret';
       mysql> \. mysql.sql
     #+end_src

   - 运行

     #+begin_src sh
       sudo jabberd -h localhost -B
     #+end_src

   - 注册用户1

     #+begin_src sh
       telnet localhost 5222
       <stream:stream
         to='localhost'
         xmlns='jabber:client'
         xmlns:stream='http://etherx.jabber.org/streams'>
       
       <iq id='reg1' type='set'>
         <query xmlns='jabber:iq:register'>
           <username>jack</username>
           <password>jack</password>
           <name>jack</name>
           <email></email>
         </query>
       </iq>
       
       </stream:stream>
     #+end_src
   
   - 登录用户1

     #+begin_example
       Empathy菜单->编辑->帐户->添加：
       协议: Jabber
       登录ID: jack@localhost
       记住密码
       密码: jack
       登录
     #+end_example

   - 注册用户2
     
     #+begin_src sh
       telnet localhost 5222
       <stream:stream
         to='localhost'
         xmlns='jabber:client'
         xmlns:stream='http://etherx.jabber.org/streams'>
       
       <iq id='reg1' type='set'>
         <query xmlns='jabber:iq:register'>
           <username>rose</username>
           <password>rose</password>
           <name>rose</name>
           <email></email>
         </query>
       </iq>
       
       </stream:stream>
     #+end_src

   - 用户1加用户2为联系人
     
     #+begin_example
       Empathy菜单->聊天->添加联系人:
       帐户：jack@localhost
       标识符: rose@localhost
       添加
     #+end_example

   - 登录用户2，并发一个消息给用户1

     #+begin_src sh
       telnet localhost 5222
       <stream:stream
         to='localhost'
         xmlns='jabber:client'
         xmlns:stream='http://etherx.jabber.org/streams'>
       
       <iq id='auth1' type='set'>
         <query xmlns='jabber:iq:auth'>
           <username>rose</username>
           <password>rose</password>
           <resource>test</resource>
         </query>
       </iq>
       
       <presence/>
       
       <message to='jack@localhost'>
         <body>hello, jack</body>
       </message>
       
       </stream:stream>
     #+end_src
** TODO Node.js学习                                                 :node:
   
*** 适用范围
    
    - 引用[[http://nodejs.org/docs/latest/][原文]] ::

      #begin_example
        Node.js is a platform built on Chrome's JavaScript runtime for easily building fast, scalable network applications. Node.js uses an event-driven, non-blocking I/O model that makes it lightweight and efficient, perfect for data-intensive real-time applications that run across distributed devices.
      #end_example
    
    - 可以归结如下 ::

      - 较低的资源消耗处理海量网络请求
      - 开发分布式的数据密集型实时应用

*** 参考资源
    
    - [[http://www.nodebeginner.org/index-zh-cn.html][Node入门]] ::

      从Hello World到图片上传示例演示了如何以正确的方式开发[[http://nodejs.org][Node.js]]应用。
    
    - [[http://nodejs.org/docs/latest/api/all.html][Node.js官方API手册]]

** DONE log4php初步使用                                             :log4php:
   CLOSED: [2013-05-06 一 18:32]
   
*** 简介
    apache出品必属精品。正宗php日志库，与log4j一脉相承。

    [[http://logging.apache.org/log4php/]]

*** 安装
    参考：[[http://logging.apache.org/log4php/install.html]]

    - 有root权限，安装到系统目录

      #+begin_src sh
        sudo apt-get install php-pear
        sudo pear channel-discover pear.apache.org/log4php
        sudo pear install log4php/Apache_log4php
      #+end_src

    - 没有root权限，安装到当前目录下
       
      #+begin_src sh
        cd libs
        wget http://mirrors.tuna.tsinghua.edu.cn/apache/logging/log4php/2.3.0/apache-log4php-2.3.0-src.tar.gz
        tar xzvf apache-log4php-2.3.0-src.tar.gz
        ln -sf apache-log4php-2.3.0/src/main/php ./log4php
      #+end_src

*** 使用
    
    - 进行一下封装定制，可以满足绝大部分情况下的使用

      - 类似nginx的访问日志记录格式
      - 日志中输出文件名及行号
      - 日志文件数据限制为10个，每个日志文件大小为10MB

#+o_blog_source ./static/logging.inc

    - 使用示例

      =example.php=
      #+begin_src php
        <?php
        define('LOGGING_APPNAME', 'example');
        require_once(dirname(__FILE__) . "/logging.inc");
        
        $logger = Logger::getLogger("main");
        $logger->debug("info log");
        $logger->warn("info log");
        $logger->error("info log");
        ?>
      #+end_src

    - 运行结果

      #+begin_src sh
        $ php ./example.php
        $ tail -f ./logs/example.log
        2013-05-06 18:24:57,925 [DEBUG] main: info log (/home/tangxinfa/php/example.php:6)
        2013-05-06 18:24:57,930 [WARN] main: info log (/home/tangxinfa/php/example.php:7)
        2013-05-06 18:24:57,930 [ERROR] main: info log (/home/tangxinfa/php/example.php:8)
      #+end_src

** TODO 使用boost.coroutine异步访问mysql                          :cpp:mysql:
   
   开发高性能、高并发后台服务时，访问mysql总是一件头疼的事情，这绝对算是整个系统中最伤性能的部分，访问mysql总是很慢的，并且连接数受限，阻碍了开发高性能可线性扩展的后台服务。这也导致了像memcache、redis之类的NoSQL数据库的流行。

   但是，到目前为止mysql在可靠存储数据方面仍无法替代，NoSQL一般也仅用于做为mysql的缓存层，以减轻mysql的压力，所以探究一下如何更高效地访问mysql还是很有必要的。
   
   提高访问mysql效率的常见方法是异步化：用独立的数据库访问线程来执行数据库操作，在执行完成后通知应用逻辑进行后继处理，这种程序往往主程序是一个事件循环，而应用逻辑被切分成一个个回调函数，导致程序流程变得更加复杂，不易理解也容易滋生问题。

   接下来我打算使用协程来异步访问mysql，协程（[[http://www.boost.org/doc/libs/release/libs/coroutine/][boost.coroutine]]）可以让我们线性的书写处理逻辑，而不必引入复杂的状态机。

** TODO 深入理解Ember.js                                           :ember.js:
   
*** Ember.js的组件层次

    从下往上依次为：
    - 模板（templates）
      使用Handlebars模板语言描述用户界面，除了纯html还包含以下组件：
      - 表达式。{{firstName}}，以html来展示控制器和模型的信息，并保持同步。
      - 插座。{{outlet}}，路由根据应用当前所处的位置将对应的模板插入到相应的插座中。
      - 视图。{{view}}，将原始的用户事件（如：点击）转化为语义事件（如：增、删、改)并发送到控制器。
    - 控制器（controller）
      保存应用状态的对象。通常用于将模型进行进一步包装后暴露给模板。
    - 模型（model）
      保存持久状态的对象。通常从服务器端装入并最终会保存回去。
    - 路由（router）
      管理应用状态的对象。根据当前的url显示相应的模板，以及为模板指定配对的模型。
** DONE 《理解Http与Spdy协议》培训课件                            :http:spdy:
   CLOSED: [2013-05-23 四 13:11]
   
   本课件针对刚入职的毕业生，讲解Http与Spdy协议的基础知识。

*** 开发计划 [1/5]
    - [X] 编写Http部分大纲
    - [ ] 编写Http部分章节内容
    - [ ] 编写Spdy部分大纲
    - [ ] 编写Spdy部分章节内容
    - [ ] 制作Microsoft PowerPoint格式文档
   
*** 在线演示
    [[http://blog.kankanan.com/slides/理解Http与Spdy协议.html][《理解Http与Spdy协议》]]

** TODO 开源MQ（Message Queue）调研                                      :MQ:
   
*** ZeroMQ
    
    - 语言 :: c++
    - 协议 :: ZMQP
    - 定位 :: 类似于POSIX message queue，在socket之上搭建的IPC（机制），它不是消息中间件，由于其库的本质，速度上比MQ中间件快了一个数量级。
    - 总结 :: 和其它的MQ中间件没有可比性，在不需要持久化、稳定性、追求极致性能、易部署的情况下可以考虑使用，或根据情况同时使用其它的MQ服务。

*** RabbitMQ

    - 语言 :: Erlang
    - 协议 :: AMQP
    - 定位 :: 消息中间件
    - 总结 :: 应该是性能最好的开源消息中间件，在需要保证消息不丢失的情况下，可以考虑采用。像mysql一样需要启动服务，有各种语言的客户端库（一般使用不会去定制服务端的代码，大可不必介意自已是否熟悉Erlang语言）。

** TODO Hash、Bitmap和BloomFilter算法           :hash:algorithms:bitmap:bloomfilter:

   Hash、Bitmap和BloomFilter都可用于判断某个元素是否在集合中。

   参考：[[http://blog.csdn.net/jiaomeng/article/details/1496329][从哈希存储到Bloom Filter]]

*** Hash
    
    - 原理
      准备好哈希空间（足够保存集合中的所有元素），对于每个元素通过哈希函数求出其在哈希空间保存的位置，由于两个不同元素可能被哈希函数映射到同一哈希空间位置（碰撞、冲突），
      这需要进行一次解冲突，通常使用冲突链解决：获取哈希空间映射位置已存在的元素，如果元素值与当前元素不等，则挂在该哈希空间的冲突链中，图示如下：

      #+begin_src artist
        
        hash space 
        +-------------------------------------------------------------------+
        |     key1   key2   key3   key4   key5   key6                     --+--> hash keys
        |   +------+------+------+------+------+------+-----------------+   |        
        |   | val1 | val2 | val3 | val4 | val5 | val6 |  ...            | --+--> element values
        |   |   |  | NULL | NULL | NULL | NULL | NULL |                 | --+--> collision link head 
        |   +---+--+------+------+------+------+------+-----------------+   |                       
        |       |                                                           |                    
        |   +---+--+                                                        |                    
        |   |val1.1| -------------------------------------------------------+--> collision element values
        |   | NULL | -------------------------------------------------------+--> collision link pointer
        |   +------+                                                        |
        +-------------------------------------------------------------------+
        
      #+end_src
      
    - 特点

      - 0误差 :: 判断结果100%可信
      - 空间浪费 :: 由于哈希函数不可能做到没有冲突，所以哈希空间必然大于元素集合空间
      - 需要有好的哈希函数 :: 当哈希不均匀时，会导致一些哈希位置冲突链过长，访问这个哈希位置时算法复杂度由哈希表（O(1)）退化成链表（O(n)）。

*** Bitmap
    
    - 原理
      准备好位图空间（足够保存集合中的所有元素的位数），对于每个元素通过哈希函数求出其在位图空间占用的位，位置为1表示元素存在，由于位图空间没有保存元素值，因此无法检测哈希冲突。

    - 特点
      
      - 有误差 :: 仅能给出元素一定不在集合内以及元素可能在集合内的判断。当哈希函数能做到完全均匀才能达到0误差。
      - 节省空间 :: 每个元素只需要一个位来存储。

*** BloomFilter
    
    - 参考 :: [[http://zh.wikipedia.org/wiki/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8][布隆过滤器 - 维基百科]]、[[http://en.wikipedia.org/wiki/Bloom_filter][Bloom filter - Wikipedia]]
    
    
    - 原理
      类似于位图，只不过每个元素由n个哈希函数来映射到n个位，元素映射的所有位都为1方表示元素存在。
      
    - 特点

      - 有误差 :: 比起Bitmap误差率可以很好的控制（除了通过选择更好的哈希函数，还可以通过增加更多的哈希函数以及相应的哈希空间来减少误差率）
      - 节省空间 :: 每个元素只需要n个位来存储，n可自定。

** TODO p2p系统构建                                                     :p2p:

*** 结点间的连通
    
    - 双方外网 :: 直连
    
    - 一内一外 :: 直连／反连
      - 中间服务器 :: 发送被反连方指令给反连方，所有内网服务器都需要在中间服务器上保持一个连接，以接收控制指令。

    - 双方内网 :: 穿透
      
      - 使用UDP进行NAT穿透
        
        - 穿透服务器 :: 为穿透双方服务的外网服务器

*** 结点网
    
    - 结点标识符 :: 硬件标识（mac地址）或用户id
    - 所有结点启动时加入到网络中，并发送心跳，结点主动关闭或通过心跳检测出已下线时退出网络。
    - 需要记录结点以下信息
      - 类型 :: 外网、可穿透内网、封闭内网
      - 负载 :: 上传能力

    这就是状态服务器，状态服务器需在结点状态变化时同步结点状态信息到资源服务器

*** 资源网

    所有结点拥有的资源需要在资源服务器上呈现。

    - 资源标识符 :: 如文件内容的sha1
    - 资源组织，满足以下需求：
      - 根据资源id查找拥有该资源的一批活跃结点，支持各种查找条件（按：同运营商、随机取、按地理位置）
      - 更新结点id拥有的资源
      
      #+begin_src artist
        +-------------------+
        | p2p://example.com |
        +---------+---------+
                  |            +------------------------------------------+
                  +------------+ 1111111111111111111111111111111111111111 |
                  |            +----------------------+-------------------+
                  |                                   |   +-------+
                  |                                   +---+ user1 |
                  |                                   |   +-------+
                  |                                   |           
                  |                                   |   +-------+
                  |                                   +---+ user2 |
                  |                                   |   +-------+
                  |                                   |           
      #+end_src

*** 实施
    |------------+--------------------------------------------------------------------+--------|
    | 组件       | 功能                                                               | 人／月 |
    |------------+--------------------------------------------------------------------+--------|
    | 穿透服务器 | 协助客户端进行穿透的外网服务器                                     | 2/0.5  |
    |------------+--------------------------------------------------------------------+--------|
    | 状态服务器 | 与所有客户端保持连接，记录客户端的上下线状态及属性、转发反连指令   | 3/1    |
    |------------+--------------------------------------------------------------------+--------|
    | 资源服务器 | 索引所有资源，根据各种策略为客户端查找拥有该资源的其它客户端信息， | 5/3    |
    |            | 客户端存储的资源变动时，更新资源对应的客户端列表                   |        |
    |------------+--------------------------------------------------------------------+--------|

*** 协议
    #+begin_src ditaa :file ../static/p2p_protocol.png :cmdline -r -S -s 3

















    #+end_src
** DONE 《理解Node.js》培训课件                                     :node:
   CLOSED: [2013-07-04 四 18:31]
   
   本课件介绍Node.js的特点及其初步使用。

*** 开发计划 [1/3]
    - [X] 编写大纲
    - [ ] 编写内容
    - [ ] 制作Microsoft PowerPoint格式文档

*** 在线演示
    [[http://blog.kankanan.com/slides/理解Node.js.html][《理解Node.js》]]

** DONE Archlinux下解决更新grub后无法进入gnome3桌面的问题         :archlinux:
   CLOSED: [2013-06-26 Wed 10:07]
   
   在启动界面上会看到以下错误日志：
   #+begin_example
   kernel: [    8.398186] [drm:radeon_init] *ERROR* No UMS support in radeon module!
   #+end_example

   这个是由于grub配置文件中指定了内核参数 =nomodeset= 导致，linux的默认配置是为了运行服务器，以减少启动过程中出错的可能性，使用gnome3桌面时，需去掉内核参数 =nomodeset= ，以下为[[https://wiki.archlinux.org/index.php/ATI#Disable_KMS][原文]]：

   #+begin_example
     Note: Adding nomodeset to the kernel boot line might prevent GNOME 3's gnome-shell or KDE's desktop effects from running.
   #+end_example

** DONE linux下翻墙访问bitbucket.org仓库                    :linux:hg:bitbucket:
   CLOSED: [2013-06-28 Fri 13:57]
   
   今天往bitbucket.org push时才发现bitbucket被GFW了。我的仓库为Mercurial hg，hg项目根目录下的 =.hg/hgrc= 配置文件中可指定http\_proxy，试了一下不支持socks代理（我的浏览器用它来翻墙），最终使用tsocks软件实现翻墙访问bitbucket.org仓库。

   - 利用vps建本地socks代理的脚本 =ssh_proxy.sh=
     #+begin_src sh
       #!/bin/bash
       
       n=`ps waux | grep 'bash .*/ssh_proxy.sh' | grep -v grep | wc -l`
       if [ $n -lt 3 ]; then
           while [ true ]; do
               n=`ps aux | grep 'ssh' | grep '7070' | grep -v grep | wc -l`
               if [ $n -lt 1 ]; then
                   echo "start ssh connecting"
                   ssh -qTnNf -D 7070 user@host
               fi
               echo "wait for next checking"
               sleep 30
           done
       fi
       echo "ssh_proxy.sh already running"
       
     #+end_src

     请将user@host改为你的vps用户及主机，并配置为免输入密码。

   - 启动socks代理脚本
     
     #+begin_src sh
       nohup bash ./ssh_proxy.sh &
     #+end_src

     浏览器也可以利用它来翻墙。

   - 安装tsocks
     #+begin_src sh
       yaourt -S tsocks
     #+end_src

   - 配置tsocks

     =/etc/tsocks.conf=
     #+begin_example
       # We can access 192.168.0.* directly
       local = 192.168.0.0/255.255.255.0
       local = 10.0.0.0/255.0.0.0
       
       # Otherwise we use the server
       server = 127.0.0.1
       server_port = 7070
     #+end_example
     具体用法 =man tsocks.conf=

   - 使用tsocks让hg用上socks代理功能
     #+begin_src sh
       tsocks hg push
     #+end_src
     tsocks看起来很通用，应该也可以让git等进行socks代理访问。

** TODO 《架构风格与基于网络的软件架构设计》读书笔记           :REST:reading:
   
   #+begin_quote
   架构设计的目标是创建一个包含一组架构属性的架构，这些架构属性形成了系统需求的一个超集。不同架构属性的相对重要性取决于想要得到的系统本身的特性。
   #+end_quote

   我们对架构的学习和使用应该更明智一些，通过学习能够做到对一种架构的相关特性（包括优点及缺点）了然于胸，同时在使用的时候能够摆脱潮流及个人主观喜好的影响，选择正确的架构，这样才能获得架构所带来的质量保证，我们才能够对在此基础上构建的系统充满信心。

   
   #+begin_quote
   一种架构风格是一组协作的架构约束，这些约束限制了架构元素的角色和功能，以及在任何一个遵循该风格的架构中允许存在的元素之间的关系。
   #+end_quote

   #+begin_quote
   一个好的设计师应该选择一种与正在解决的特定问题最为匹配的风格。为一个基于网络的应用选择正确的架构风格必须要理解该问题领域，因此需要了解应用的通信需求，知道不同的架构风格和它们所导致的特殊问题，并且有能力根据基于网络的通信的特性来预测每种交互风格的敏感度。
   #+end_quote

** TODO 理解REST [0/3]                                                 :REST:

   - [ ] REST介绍

     REST（Representational State Transfer，表述性状态转移）, 是一种针对网络应用的设计和开发方式，可以降低开发的复杂性，提高系统的可伸缩性。
     
     REST 指的是一组架构约束条件和原则，满足这些约束条件和原则的应用程序或设计就是RESTful。RESTful的Web应用可以获得接口统一、结构优良以及充分使用HTTP协议的好处。

     REST 是Web的架构风格，HTTP 1.1规范的指导原理。

     #+begin_src ditaa :file ./rest_arch.png :cmdline -S -E -s 1.5
               +------------+
               | cBLU       |
               | Hypermedia |         --=--> 三级：超媒体做为应用状态的引擎
               |            |
           +---+------------+---+
           | c0FF               |
           |        HTTP        |     --=--> 二级：使用多个HTTP方法来操作（CRUD）资源
           |                    |
       +---+--------------------+---+
       |  cGRE                      |
       |            URI             | --=--> 一级：使用很多URI暴露很多资源 
       |                            |
       +----------------------------+
       
                                   
                                WEB服务成熟度模型
     #+end_src

     资源由URI标识，资源与URI为一对多关系。

     对资源的操作由HTTP方法对应（Create(POST)、Update(PUT)、Read(GET)、Delete(DELETE)）。
     
     客户端与服务器通过交换资源表述驱动应用状态变迁。

   
   - [ ] REST实现

     REST
     
   - [ ] REST应用

** TODO 实现RESTful Web服务                                            :REST:

*** 环节

    - 找出资源
    - 找出服务接口

** DONE 使用番茄工作法的感受                                       :pomodoro:
   CLOSED: [2013-07-08 一 13:10]

*** 基本要领
    
    从事务清单中选出今天要做的事

    按优先级填入今日工作计划表

    从表中选择第一项未完成事务按下计时器

    专心做这件事

    25钟后铃响立即停止做事

    在当前事务后标记用掉了一个番茄

    事务完成则在今日事务清单划掉当前任务

    专心休息地5分钟（每4个周期长休息15-30分钟）

    按下计时器

    继续做事

    如此往复

*** 掌控干扰因素

    - 做事时如遇实发事件酌情处理：

      - 添加到事务清单中明天再处理
      - 直接安排到今日事务清单稍后处理
      - 立即取消当前事务开始处理突发事件

    - 在当前事务后方打个中断标记

*** 解读工作记录

    一天结束后我们将获得以下信息：

      - 知道处理某个事务用时多少。怎样让时间用得更少？

      - 知道时间花在哪里去了。能否将时间更多花在有效处理工作上？

    当新的一天开始时，我们会清楚地知道每天有多少个番茄可用，今天可以安排多少事务，每个事务需要消耗多少个番茄。

    随着我们不断地根据这些记录改进我们的工作效率，最终我们能够安排时间、掌控时间。

*** 番茄工作法遵从习惯法则

    当我跟老婆解释番茄工作法时，她说了句：“这个和你之前说的习惯法则很像”，细细一想不无道理。

    习惯的形成的三个步骤：暗示、惯常行为、奖赏。以及习惯回路。

    番茄工作法也有这三个要素：

    　　暗示　　　　　　按下计时器

    　　惯常行为　　　　处理事务

    　　奖赏　　　　　　清脆的铃响、标记番茄的成就感、休息时间的放松

    而习惯回路的形成也容易发现，每天一早来到公司，谁不渴望今天能够过得充满成就感、休息时能够毫无顾忌呢。

    遵从习惯法则的方法论才会更容易展开并长久地坚持下去。

*** 参考资料
    [[http://www.pomodorotechnique.com/download/pdf/ThePomodoroTechnique-CHN_v1-3.pdf][《番茄工作法》]]
    [[http://baike.baidu.com/view/5259318.htm][番茄工作法_百度百科]]
    [[http://pomodoro.kankanan.com][番茄工作法在线服务]]

** TODO 番茄园                                                     :pomodoro:
   
   番茄园是一个在线的番茄工作法实施环境。

*** 用例
    
    - 添加任务
    
    - 开启番茄钟

    - 取消番茄钟
 
    - 任务上记录完成的番茄数
     
    - 任务上记录中断的番茄数

*** 模型

    #+Caption: 用户
    |-------------------------+------------|
    | 字段                    | 意义       |
    |-------------------------+------------|
    | id                      | 用户标识符 |
    | profile.provider        | 身份提供者 |
    | profile.identifier      | 身份标识符 |
    | profile.name            | 用户名称   |
    | profile.email           | 用户邮箱   |
    | preferences.tick.volume | 嘀嗒声音量 |
    |-------------------------+------------|

    #+Caption: 任务
    |-----------+--------------------|
    | 字段      | 意义               |
    |-----------+--------------------|
    | id        | 任务标识符         |
    | name      | 名称               |
    | priority  | 优先级             |
    | pomodoros | 关联的番茄标识列表 |
    | user      | 所属用户           |
    |-----------+--------------------|

    #+Caption: 番茄
    |--------+------------|
    | 字段   | 意义       |
    |--------+------------|
    | id     | 番茄标识符 |
    | begin  | 起始时间   |
    | end    | 结束时间   |
    | length | 持续时长   |
    | task   | 所属的任务 |
    |--------+------------|

    - 番茄状态
      
      已完成：结束时间 - 起始时间 >= 持续时间
      已取消：结束时间 - 起始时间 < 持续时间
      进行中：其它

*** 界面

    #+begin_src ditaa :file ../static/pomodoro_ui.png :cmdline -r -S -s 3
      +---------------------------------------------------------------------+
      |                   +-------+                                         | 
      |                   | timer | stop                                    | 
      |                   +-------+                                         | 
      |                                                                     | 
      |        +------------------------------+                             | 
      |        |                              | add                         | 
      |        +------------------------------+                             | 
      |                                                                     | 
      |        +------------------------------------+                       | 
      |        |   task 1             xxx           | delete start up down  | 
      |        +------------------------------------+                       | 
      |        |   task 2             xx            | delete start up down  | 
      |        +------------------------------------+                       | 
      |        |   task 3                           | delete start up down  | 
      |        +------------------------------------+                       | 
      |        |               ...                  |                       | 
      |        +------------------------------------+                       | 
      +---------------------------------------------------------------------+
    #+end_src

*** URL接口
    
    工作：/users/:user_id/works/:work_date/
    任务：                                 tasks/:task_id/
    番茄：                                                pomodoros/:pomodoro_id

** TODO 图解linux启动过程                                             :linux:

   #+begin_src ditaa :file ../static/linux_boot.png :cmdline -r -S -s 3
     +------------+
     |  power on  |
     +------------+
           
             +-----------+
             | load bios |
             +-----------+
                                                               
                                                                                                 
                                                               
                       boot device
                                
                             MBR 
                                
                                PRE-BOOT    PARTITION TABLE
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
   #+end_src

** TODO git-svn搭配sshfs实现远程代码编辑及代码管理            :git:svn:linux:

   公司使用内网中统一的svn服务器进行集中式的代码管理，项目的测试环境布署在内网中的虚拟机集群上。

   因为测试环境上的代码树是由多个开发人员同时访问的，因此布署的是从svn中export出来的代码。有的人通过“本地修改副本->上传副本到测试机->测试通过->提交本地副本”方式工作，有的人通过“直接远程修改测试机代码->测试通过->拉回本地->提交代码”。无论是哪种方式都有代码覆盖的风险、以及遗漏提交代码的风险。

   

*** 解决的问题   

** DONE node.js下访问mysql注意事项                            :node:mysql:
   CLOSED: [2013-10-11 五 10:45]
   
   本文仅针对 [[https://github.com/felixge/node-mysql][node-mysql]] 模块。

   - Connection 对象为一个到mysql的连接，在其上的query是串行进行的。

     由于mysql协议类似http是串行的，在一个mysql连接上的多个query必须依次进行。
     
     [[https://github.com/felixge/node-mysql][node-mysql]] 的 Connection对象上同时发起的多个query会队列化，
     
     处理完一个query再进行下一query的处理，传递给回调函数的query结果不会错乱。

     在有一定访问量的服务中应该总是使用 =连接池= 。

     
   - 处理Connection对象的重连。

     mysql连接空闲一段时间后（默认8小时）会自动关闭，
   
     可以在Connection对象的 =error= 事件中检测后连接断开时进行重连。

     使用 =连接池= 不会有问题，连接断开后会默认从连接池中剔除。

** DONE 为什么不能在构造函数中调用shared_from_this                      :cpp:
   CLOSED: [2013-12-20 Fri 01:02]

   先看示例代码：

   #+begin_src c++
     class Chicken : public enable_shared_from_this<Chicken>
     {
     public:
         Chicken()
         {
             shared_ptr<Chicken> chicken_ptr = shared_from_this();    //throw std::bad_weak_ptr
         }
     };
   #+end_src

   再看shared\_from\_this()的行为：
   #+begin_src c++
     return _weak_ptr->lock();
   #+end_src

   =_weak_ptr= 为父类（ =enable_shared_from_this= <Chicken>）的成员变量，需要一个 =shared_ptr= <Chicken>对象来初始化它，而 =shared_ptr= <Chicken>需要一个Chicken对象来创建，但此时Chicken对象正在构造中，这是个鸡与蛋的无解问题。
   
   其实 =_weak_ptr= 成员变量是在 =shared_ptr= 的构造函数中延迟初始化的，不只是在构造函数中不能调用 =shared_from_this= ，像下面的使用方式同样不行：
   #+begin_src c++
     Chicken* chicken = new Chicken();
     shared_ptr<Chicken> chicken_ptr = chicken->shared_from_this();  //throw std::bad_weak_ptr
   #+end_src
   
   =enable_shared_from_this= 不是从this祼指针变出智能指针的魔法，它只是一个辅助类，为一个只使用 =shared_ptr= 管理对象生命周期的类添加一个自身的智能指针成员变量供内部使用。

   而“不能在构造函数中调用 =shared_from_this= ”这个问题仅仅是标准实现上的一个漏洞。

   你应该像下面这样用：
   #+begin_src c++
     class Chicken : public enable_shared_from_this<Chicken>
     {
     public:
         Chicken()
         {
         }
     
         void use()
         {
             shared_ptr<Chicken> chicken_ptr = shared_from_this();
         }
     };
     
     shared_ptr<Chicken> chicken_ptr(new Chicken);
     chicken_ptr->use();
   #+end_src

   突然想起一段对话：
   #+begin_quote
   阿漆：闻西，事情进行的怎么样了，闻西？

   达闻西： 最近我发明了些东西，相信能帮得到你。

   达闻西拿出手电筒。

   阿漆：手电筒？

   达闻西：错，这支不是一只普通的手电筒，这支是一支不需要电池的太阳能手电筒，在有光的时候他就会亮。

   司令：那如果没有光呢？

   达闻西：绝对不亮。

   阿漆：有没有可能没光的时候它也会亮？

   达闻西：问的好，关灯。

   达闻西：你拿另一只手电筒照它呢，它就会亮。

   达闻西：哈哈，怎么样啊？

   阿漆：这个发明还真有创意啊。
   #+end_quote



   参考：《[[http://hi.baidu.com/cpuramdisk/item/7c2f8d77385e0f29d7a89cf0][shared\_from\_this 几个值得注意的地方]]》

** DONE Discuz访问推广任务反作弊                                 :php:discuz:
   CLOSED: [2013-12-20 Fri 01:02]

   - 识别作弊

     发贴、回复较少的用户具有偏高的积分、等级通常就是潜在的作弊对象。在后台查看该用户的积分历史，如果来历不明，那么很可能是通过访问推广作弊获得的。

     在我们的例子里就发现有一个用户金钱数过高，先查看该用户的积分表：

     #+begin_example
       mysql> SELECT total, cyclenum, extcredits2 FROM g_common_credit_rule_log WHERE rid=8 and uid=119;
       +-------+----------+-------------+
       | total | cyclenum | extcredits2 |
       +-------+----------+-------------+
       |  3454 |     3454 |           1 |
       +-------+----------+-------------+
       1 row in set (0.00 sec)
     #+end_example
     
     相关字段说明
       - total :: 策略被执行总次数
       - cyclenum :: 周期被执行次数 
       - extcredits2 :: 我们的系统里对应金钱数
       - rid :: 值8为访问推广任务类型
       - uid :: 值119为作弊用户id

     从上面可以看出该用户完成了3454次任务， 接下来就需要确认这些任务是通过作弊完成的了。
     
     搜索该用户推广链接在web服务器中留下的访问日志：
     #+begin_example
       logs# grep 'fromuid=119' /usr/local/nginx/logs/access.log*
       "GET /?fromuid=119.jpg HTTP/1.1" 301 6243 "http://xxxx.org/details.php?id=178668"
       ...
     #+end_example

     可以初步断定，该用户通过在其它论坛中发布信息并将推广url注入到图片的url中，这样我们的站点在访问量没有任何增长的情况下该用户的推广数却瞬间彪升了。

   - 阻止作弊

     通过使用引用页中的用户标识进行记录来解决这个问题，这样只有当用户来到论坛并进行了相关操作才算推荐有效。

     修改source/class/discuz/discuz\_application.php文件，将下面的内容：
     #+begin_src php
       if((!empty($_GET['fromuid']) || !empty($_GET['fromuser'])) && ($this->var['setting']['creditspolicy']['promotion_visit'] || $this->var['setting']['creditspolicy']['promotion_register'])) {
           require_once libfile('misc/promotion', 'include');
       }
     #+end_src
     改为：
     #+begin_src php
       if (isset($_SERVER['HTTP_REFERER']) && strpos($_SERVER['HTTP_REFERER'], 'http://g.xunlei.com/') === 0) {
           $referer_query = parse_url($_SERVER['HTTP_REFERER'], PHP_URL_QUERY);
           if ($referer_query) {
               parse_str($referer_query, $referer_get);
               if((!empty($referer_get['fromuid']) || !empty($referer_get['fromuser'])) && ($this->var['setting']['creditspolicy']['promotion_visit'] || $this->var['setting']['creditspolicy']['promotion_register'])) {
                   require_once libfile('misc/promotion', 'include');
               }
           }
       }
     #+end_src

     修改source/include/misc/misc\_promotion.php文件，将下面的内容：
     #+begin_src php
       if(!empty($_GET['fromuid'])) {
           $fromuid = intval($_GET['fromuid']);
           $fromuser = '';
       } else {
           $fromuser = $_GET['fromuser'];
           $fromuid = '';
       }
     #+end_src
     改为：
     #+begin_src php
       if(!empty($referer_get['fromuid'])) {
           $fromuid = intval($referer_get['fromuid']);
           $fromuser = '';
       } else {
           $fromuser = $referer_get['fromuser'];
           $fromuid = '';
       }
     #+end_src

** DONE linux下允许普通用户执行需要root权限的命令                   :linux:c:
   CLOSED: [2013-12-26 四 15:44]

   最典型的情况是要实现一个通过web界面重启系统的功能，通常为了安全会以非root用户身份（通常是nobody）运行服务端脚本，这样脚本中就不能执行危险操作了。

   下面的c工具程序可以允许任意用户执行需要root权限的命令：

#+o_blog_source ./static/as_root.c

   编译：
   #+begin_src sh
     gcc -g as_root.c -o as_root
   #+end_src

   配置：
   #+begin_src sh
     chown root:root ./as_root; chmod 4755 ./as_root
   #+end_src

   运行：
   #+begin_src sh
     sudo -u "nobody" ./as_root "reboot"
   #+end_src
   
   参考：[[http://blog.tianya.cn/blogger/post_show.asp?BlogID=126326&PostID=1629441][如何在普通用户下执行一些需要root用户执行的命令]]

** DONE express.js中如何在第一次请求的响应中取得connect.sid            :node:
   CLOSED: [2014-02-14 Fri 23:34]

   在web页面通过iframe跨域登录访问服务的情况下，是不方便取cookie中的sessionid的，于是想到将sessionid直接放到响应体中，
   这就需要在node.js中直接获取connect.sid这个cookie值，一开始想当然地以为系统（使用的是passport.js）会在登录认证通过后
   执行res.cookie('connect.sid', ...)进行设置，就想直接从res的Set-Cookie头解析出设置的值，结果发现这个cookie压根不存在，
   甚至在库代码中搜索cookie都不管用，着实急得人直抓头。最后dump出res后确在req中见到了connect.sid值的影子：req.sessionID，
   然后在 [[http://stackoverflow.com/questions/13693101/express-sessionid-differs-from-sessionid-in-cookie][《Express SessionID differs from SessionID in Cookie》]] 中找到了从req.sessionID计算出connect.sid的方法：

   #+begin_src js
     var signature = require('express/node_modules/cookie-signature');
     var connectSid = 's:' + signature.sign(req.sessionID, sessionOptions.secret);
   #+end_src

   其实，connect.sid这个cookie是在请求到来后在req上设置的（不存在则设置），不管有没有登录都会设置。

** TODO 安装archlinux实录                                         :archlinux:

   - 机器型号

   - 首先按照 [[https://bbs.archlinuxcn.org/viewtopic.php?id=1037][这篇文章]] 进行安装

   - 因为是直接插网线的，启用网络服务
     
     #+begin_src sh
       systemctl enable dhcpcd.service
     #+end_src

   - 安装完成重启后出现“device not found”的错误，并提示指定uuid的分区不存在
     
     在archlinux启动项上按c进入命令行，记下/boot分区（这里是hda0,msdos1）的uuid，再次重启机器，在archlinux启动项上按e，将里面的uuid值替换为之前记下来的正确的uuid，
     按F10后应该可以正常启动了，使用root帐号登录后，再次执行“grub-mkconfig -o /boot/grub/grub.cfg”出现out of memory及其它错误（很可能在参考前一篇文章执行时就有这个错误，只是被忽视了），
     参考 [[https://bbs.archlinux.org/viewtopic.php?id=173921][这篇文章]] 在/etc/default/grub.cfg中追加下面一行内容：
     #+begin_example
     GRUB_DISABLE_SUBMENU=y
     #+end_example
     再次生成grub.cfg，就好了。
     
** DONE 编译安装node.js                                                :node:
   CLOSED: [2014-02-17 Mon 16:23]
   
   - 下载

     node.js是一个新兴的开发平台，版本更新非常活跃，因此应该尽量下载安装最新的版本。

     到 [[http://nodejs.org/]] 下载最新的版本。

   - 安装
   
     解压后参照 README.md 进行安装：

     #+begin_src sh
       ./configure
       make
       make install
     #+end_src
   
   - 安装后
     
     默认安装到/usr/local。

     + /usr/local/bin/node :: node主程序
     + /usr/local/bin/npm :: node模块管理程序
     + /usr/local/lib/node\_modules :: node全局模块目录

     像一些需要全局安装的模块也会把文件安装在/usr/local目录下。
     
** DONE 编译安装redis                                                 :redis:
   CLOSED: [2014-02-17 Mon 16:40]
   
   - 下载
     
     到 [[http://redis.io/download]] 下载最新稳定版本。

   - 安装
   
     解压后参照 README 进行安装：

     #+begin_src sh
       make
       make install
     #+end_src
   
   - 安装后
     
     默认安装到/usr/local。

     + /usr/local/bin/redis-cli :: redis客户端程序 
     + /usr/local/bin/redis-server :: redis服务器程序
** TODO 当心烦意乱接下来不知道要做什么的时候                           :心理健康:

   - 试着通过深呼吸、走一走、微笑让自已平静下来，回归理性的自已。
     
   - 使用待办事项记录，一定要细致到可以直接采取行动，不用等到有好心情才能做成一些事情。
** TODO 迅雷路由水晶版内测资格申请页面上线的故事                      :story:

   - 先看看注册页面的svn日志吧:)

     #+begin_example
       ------------------------------------------------------------------------
       r922 | tangxinfa | 2014-03-03 18:21:31 +0800 (Mon, 03 Mar 2014) | 4 lines
       
       修复discuz进行xss检查导致的用户申请丢失的bug。
       
       ------------------------------------------------------------------------
       r744 | tangxinfa | 2014-02-24 13:04:47 +0800 (Mon, 24 Feb 2014) | 3 lines
       
       申请表单去除”身份证号码“字段。
       ”市、县级市“改为非必填（在选“广东省”，“中山市”时出现）。
       
       ------------------------------------------------------------------------
       r740 | tangxinfa | 2014-02-22 19:36:03 +0800 (Sat, 22 Feb 2014) | 4 lines
       
       身份证号 手机号码 邮箱 QQ号码 申请理由不得重复.
       修复缓存导致的登录跳转死循环bug.
       图片引用绝对路径以支持正式环境上的url重写.
       
       ------------------------------------------------------------------------
       r721 | tangxinfa | 2014-02-22 16:24:12 +0800 (Sat, 22 Feb 2014) | 3 lines
       
       兼容ie6.
       修复缓存相关bug.
       
       ------------------------------------------------------------------------
       r704 | tangxinfa | 2014-02-22 00:02:59 +0800 (Sat, 22 Feb 2014) | 1 line
     #+end_example

   - r704 :: 周五晚上，刚过12点，哥哼着小曲，心满意足的提交了代码（再三要求不许再改设计图之后，终于调好了）。同事：very good，看来明天我可以不用来加班了，有事给我电话。
   
   - r721 r740 :: 上午快11点才到的公司，看来今天收收尾就就能早点回家了。

             + 打算就错误处理这一块进行了完善 :: 提交数据时检查下字段是否有重复值，有重复值还要给用户提示错误。
    
               懒得一个一个字段的地判断重复了，数据库结构一改：不能重复定义为UNIQUE就是了，插入记录出错时如果错误码表明因重复的字段值引起则从错误描述中匹配出字段名，
   
               然后返回给客户端进行提示即可。天衣无缝啊，几年前就想这么干了，总算得手了。


             + 同事反映了一个问题 :: ”市、县级市“中有重复项
   
               一查还真是有，网上找的东东问题多啊，直接给js地址库加了个检测重复值的方法，控制台打印出重复项的位置，好多重复的“城关镇”啊，删掉重复项，收工。

             + 有热心网友反馈ie6/ie7下的兼容性问题

               这个问题必须有，压根没想到要给页面做ie6/ie7兼容，哥没空啊，忙得都忘了还有用ie6/ie7的人了。不过思来想去还是得改啊，开门做生意哪能拒人于千里之外呢，更何况这网友能耐大着呢，看图：

               [[file:static/ie6bugfix1.png]]

               [[file:static/ie6bugfix2.png]]

               见过给我提意见的，没见过直接列出解决方案的，做前端肯定比我专业。

             + 在测试环境上跑了一遍上线，整理了一下要点，就叫它《20140224-水晶版内测上线指南》吧，等周一过来切下主页就完事了，晚上8点哼着小曲瘪着肚子回家。

   - r744 :: 早上9:20就到公司，10点准时上线申请页面。才半个小时就有1000多人注册，比我想像的多多了。

             + 同事反映有部分网友登记时不愿提供身份证号码，去掉这一项话更友好

               那就改吧。一条SQL语句“ALTER TABLE `XXXXXX` CHANGE `idnumber` `idnumber` char(32) NOT NULL DEFAULT ''”去掉必填限制，html表单中去掉该字段，测了一下没问题立即上线。

             + 5分钟后，论坛、微博有不少网友反映点提交按钮没反映，同事那里也重现了，原来改数据库字段定义时UNIQUE属性不会自动删除，Google了一下，再来一条SQL语句“ALTER TABLE `g_custom_open` DROP INDEX idnumber;”。

             + 有网友反映，收货地址选“广东省”，“中山市”后，”县级市“下拉空就空了，现在又必填才能提交

               修改html表单校验js，去掉必填限制。

   - r922 :: 同事给出了选中进行内测的用户id列表，结果在申请数据表中竟然没有申请记录，一开始怀疑是用户有多个迅雷帐号，可能使用的是其它帐号提交的申请，不过很快排除了这种可能，查了一下RTX记录，申请的用户数也一直正常在增长，
             
             于是在错误处理进行得更严格了一些，很快用户反映提交出错，在用户的协助下从服务器抓包后发现提交申请的响应竟然是一个html页面：您当前的访问请求当中含有非法字符，已经被系统拒绝。
             
             原来，discuz默认情况下会对用户的输入进行检查如果其中包含像"><'()这些符号则会认为是xss攻击，阻止提交。最终通过在这个请求中临时禁用xss检测，解决了这个问题。

             但是粗略估计有1/7的申请丢失，好在挑选内测用户是在论坛所有用户中选取后再获取他们的申请信息，不影响申请结果。

   - 结语

     + 再简单的页面也能养活一堆虫子

     + 一定要有专业的测试人员来把测试关

     + 群众的眼睛是雪亮的

     + 要使用严格的错误检测
** TODO 选择基于Web的项目管理工具                                  :web:tool:

   - [[http://collabtive.o-dyn.de/index.php][Collabtive]] 使用php开发，可自行安装。界面效果非常棒，中文界面。项目管理及帐号管理也很不错。但功能单一，只支持任务跟踪。

   - [[http://trac.edgewall.org/][Trac]] 使用python开发，可自行安装。界面一般，中文支持较差。项目管理及帐号管理很差。功能较丰富，支持Wiki、任务及Bug跟踪。

   - [[https://trello.com][trello]] 使用node.js开发，不可自行安装。界百效果超棒，不支持中文。项目管理及帐号管理很棒。功能单一，只支持任务跟踪，注重团队交流。

** DONE CentOS 6.4下安装redmine                               :linux:redmine:
   CLOSED: [2014-03-07 Fri 14:17]

*** 安装 =ruby=
     
    #+begin_src sh
      yum install ruby
      yum install ruby-devel
      yum install rubygems
    #+end_src

*** 安装 =redmine=
    
    #+begin_src sh
      wget 'http://www.redmine.org/releases/redmine-2.5.0.tar.gz'
      tar xzvf redmine-2.5.0.tar.gz
      gem install bundler
      gem install mysql2.
      yum install ImageMagick ImageMagick-devel
      bundle install --without development test  
    #+end_src

*** 配置 =redmine=

    - 以 root 用户登录 =mysql=

      #+begin_src sh
        mysql -uroot -p
      #+end_src

    - 创建 =redmine= 用户及库

      #+begin_src sql
        CREATE DATABASE redmine CHARACTER SET utf8;
        CREATE USER 'redmine'@'localhost' IDENTIFIED BY 'redmine';
        GRANT ALL PRIVILEGES ON redmine.* TO 'redmine'@'localhost';
      #+end_src
    
    - 修改数据库配置文件

      #+begin_src sh
        cp config/database.yml.example config/database.yml
        diff config/database.yml config/database.yml.example
        10,11c10,11
        <   username: redmine
        <   password: "redmine"
        ---
        >   username: root
        >   password: ""
      #+end_src
    
    - 初始化会话存储
      
      #+begin_src sh
        rake generate_secret_token
      #+end_src
      
    - 创建数据库表结构
    
      #+begin_src sh
        RAILS_ENV=production rake db:migrate
      #+end_src

    - 解决上一步可能出现的错误

      #+BEGIN_QUOTE
        rake aborted!
        Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock' (2)
        
        Tasks: TOP => db:migrate => environment
      #+END_QUOTE
      
      确定 =mysql= 启动时指定的 =mysql.sock= 文件的路径

      #+begin_src sh
        ps aux | grep mysql.sock
      #+end_src

      显示的 =mysql.sock= 路径可能为“ =--socket=/tmp/mysql.sock= ”

      修改 =redmine= 数据库配置，在 =production= 配置中添加 =socket= 项：

      #+begin_example
        production:
          ...
          socket: /tmp/mysql.sock
      #+end_example

      重新进行上一步操作。
       
    - 初始化数据

      #+begin_src sh
        RAILS_ENV=production REDMINE_LANG=zh rake redmine:load_default_data
      #+end_src

    - 创建相关目录

      #+begin_src sh
        mkdir -p tmp tmp/pdf public/plugin_assets
        sudo chown -R nobody:nobody files log tmp public/plugin_assets
        sudo chmod -R 755 files log tmp public/plugin_assets
      #+end_src

*** 试运行 =redmine=

    #+begin_src sh
      ruby script/rails server webrick -e production
    #+end_src

    - 浏览器打开页面
      
      [[http://localhost:3000]]

      使用 用户名 =admin= ，密码 =admin= 登录后，立即修改密码。
  
      使用下面的命令生成随机的密码：
      
      #+begin_src sh
        cat /dev/urandom | head -1 | md5sum | head -c 8
      #+end_src

*** 配置 =redmine=

    - 修改 =config/settings.yml=
      
*** 使用 =Nginx= 和 =passenger=

    #+begin_src sh
      wget 'http://nginx.org/download/nginx-1.4.6.tar.gz'
      tar xzvf nginx-1.4.6.tar.gz
      gem install passenger
      yum install pcre-devel
      passenger-install-nginx-module
    #+end_src

    - 交互式安装过程

      + Automatically download and install Nginx?
        
        选 2. No: I want to customize my Nginx installation. (for advanced users)
  
      + Where is your Nginx source code located?
        
        填解压的 =nginx= 源码包路径
  
      + Where do you want to install Nginx to?
  
        填 =/usr/local/nginx=
  
      + 修改 /usr/local/nginx/conf/nginx.conf
  
        在最后的 =}= 前添加以下配置
  
        #+begin_example
          include vhosts/*.conf;
        #+end_example
        
      + 添加站点配置文件 =/usr/local/nginx/conf/vhosts/redmine.conf=
  
        #+begin_example
          server {
            listen  80;
            server_name <域名>;
            root <redmine根目录>/public;
            passenger_enabled on;
            client_max_body_size 10m; # Max attachemnt size
          }
        #+end_example

    - 启动 =nginx=
      
      #+begin_src sh       
        /usr/local/nginx/sbin/nginx
      #+end_src

    - 现在可以正式访问站点了

      http://<域名>

*** 支持 =OpenID= 第三方帐号登录

    - 安装 =openid= 库

      #+begin_src sh
        gem install ruby-openid
      #+end_src

    - 使用 =admin= 帐号登录系统，在“管理 - 配置 - 认证”中勾选上“允许使用OpenID登录和注册”。 

    - 用户注册时“密码”可以省略， 填上 =OpenID URL= 即可。

    - 如何获得Google的OpenID URL？
      
      + 先在 =Google= 的站点上登录
      + 打开 [[https://profiles.google.com]] 后会跳转到类似这样（ =https://plus.google.com/000000000000000000000/posts= ）的网页
      + 你的 =OpenID URL= 为 http://profiles.google.com/000000000000000000000
  
      上面的 =000000000000000000000= 可能为任意的数字串
    
    - 管理员确认注册后即可在登录界面上输入 =OpenID URL= 直接登录
      
      一般浏览器的输入框是有记忆功能的，双击后会出现输入历史下拉列表，直接选择即可。

    - 安装插件简化 =OpenID= 登录
      
      + [[https://github.com/jorgebg/redmine-openid-selector]] （不推荐） 为原始分枝，在 =redmine-2.5.0= 下不能直接安装会导致站点登录界面出现404错误，解决方案在 [[http://www.redmine.org/boards/3/topics/34327?r=38778#message-38778][这里]] ，简而言之就是把插件目录名中的 =-= 改为 =_= 。
        
      + [[https://github.com/computerminds/redmine\_openid\_selector]] （不推荐） 这个分枝安装后可用，但界面为英文（其实界面就一句英文）。
      
      + https://github.com/tangxinfa/redmine\_openid\_selector （推荐） 为支持中文我fork了上一个分枝。
    
      + 通用的插件安装过程：

        #+begin_src sh
          cd plugins
          git clone https://github.com/tangxinfa/redmine_openid_selector.git
          rake redmine:plugins:migrate RAILS_ENV=production
          touch tmp/restart.txt
        #+end_src

      + 通用的插件卸载过程：
      
        #+begin_src sh
          rake redmine:plugins:migrate NAME=redmine-openid-selector VERSION=0 RAILS_ENV=production
          rm -rf plugins/redmine-openid-selector
          touch tmp/restart.txt
        #+end_src      
     
      现在在登录及注册页面直接点击第三方站点Logo即可。

*** 样式美化

    #+begin_src sh
      git clone git://github.com/pixel-cookers/redmine-theme.git public/themes/pixel-cookers
      touch tmp/restart.txt
    #+end_src

    现在可以使用 =admin= 登录后台，在“管理 - 配置 - 显示 - 主题”中启用主题 =Pixel-cookers= 。
** DONE python应用国际化：Babel
   CLOSED: [2014-03-09 Sun 19:54]
   :PROPERTIES:
   :PAGE:     index.html
   :TEMPLATE: blog_static_no_title.html
   :END:

   =[[http://babel.pocoo.org/][Babel]]= 是 =Python= 的一个国际化工具包，原本为[[Edgewall.org]]下的一个项目，现在已经转为由[[pocoo.org]]维护。
   
*** 统一管理 =Python= 虚拟环境
    
    #+begin_src sh
      yaourt -S python-virtualenvwrapper
      mkdir $HOME/.virtualenvs
      echo 'export WORKON_HOME=$HOME/.virtualenvs' >> ~/.bashrc
      echo 'source virtualenvwrapper.sh' >> ~/.bashrc
      source ~/.bashrc
    #+end_src

*** 建立学习 =Babel= 专用虚拟环境

    #+begin_src sh
      mkvirtualenv --python=/usr/bin/python2 --no-site-packages LearnBabel
    #+end_src

*** 编译安装 =Babel=

    #+begin_src sh
      git clone https://github.com/mitsuhiko/babel.git
      cd babel
      pip install pytz
      python setup.py import_cldr
      pip install --editable .
    #+end_src
   
*** 常用信息国际化

    #+begin_example
      >>> from babel import Locale
      >>> locale = Locale('en', 'US')
      >>> print locale.territories['CN']
      China
      >>> locale = Locale('zh')
      >>> print locale.territories['CN']
      中国
      >>> month_names = locale.months['format']['wide'].items()
      >>> for idx, name in sorted(month_names):
      ...   print name
      ... 
      一月
      二月
      三月
      四月
      五月
      六月
      七月
      八月
      九月
      十月
      十一月
      十二月
      >>> from datetime import date
      >>> from babel.dates import format_date
      >>> today = date.today()
      >>> print format_date(today, locale='zh')
      2014年3月9日
    #+end_example

*** 任意信息国际化

    - =hello.py=

      #+begin_src python
        import gettext
        gettext.bindtextdomain('messages', './hello.i18n')
        _ = gettext.gettext
        print _('Hello')
      #+end_src

    - =hello.babel=

      #+begin_example
        [python: hello.py]
      #+end_example

    #+begin_src sh
      mkdir hello.i18n
      pybabel extract -F hello.babel . -o hello.i18n/messages.pot    # 从源代码中提取可翻译的文本到POT（PO模板）文件
      pybabel init -l zh_CN -d ./hello.i18n -i ./hello.i18n/messages.pot    # 将POT文本拷贝出一份指定语言的PO文件
      # 开始翻译指定语言的PO文件
      pybabel compile -f -d ./hello.i18n    #编译PO文件为MO文件
    #+end_src

    - =./hello.i18n/zh_CN/LC_MESSAGES/messages.po=

      #+begin_example
        # Chinese (Simplified, China) translations for PROJECT.
        # Copyright (C) 2014 ORGANIZATION
        # This file is distributed under the same license as the PROJECT project.
        # FIRST AUTHOR <EMAIL@ADDRESS>, 2014.
        #
        #, fuzzy
        msgid ""
        msgstr ""
        "Project-Id-Version: PROJECT VERSION\n"
        "Report-Msgid-Bugs-To: EMAIL@ADDRESS\n"
        "POT-Creation-Date: 2014-03-09 19:08+0800\n"
        "PO-Revision-Date: 2014-03-09 19:12+0800\n"
        "Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
        "Language-Team: zh_Hans_CN <LL@li.org>\n"
        "Plural-Forms: nplurals=2; plural=(n != 1)\n"
        "MIME-Version: 1.0\n"
        "Content-Type: text/plain; charset=utf-8\n"
        "Content-Transfer-Encoding: 8bit\n"
        "Generated-By: Babel 2.0-dev\n"
        
        #: hello.py:1
        msgid "Hello"
        msgstr "喂"
        
      #+end_example
    
    - 英文环境下运行

      #+begin_example
        python ./hello.py
        Hello
      #+end_example

    - 中文环境下运行
      
      #+begin_example
        LC_ALL=zh_CN python ./hello.py
        喂
      #+end_example

    - 更新 =hello.py= ，追加一句“      print \_('World')”

    - 再译“World”

      #+begin_src sh
        pybabel extract -F hello.babel . -o hello.i18n/messages.pot    # 从源代码中提取可翻译的文本到POT（PO模板）文件
        pybabel update -l zh_CN -d ./hello.i18n -i ./hello.i18n/messages.pot    # 从POT文本更新指定语言的PO文件
        # 开始翻译指定语言的PO文件： hello.i18n/zh_CN/LC_MESSAGES/messages.po
        pybabel compile -f -d ./hello.i18n    #编译PO文件为MO文件
      #+end_src

    - 再次运行

      #+begin_example
        LC_ALL=zh_CN python ./hello.py
        喂
        世界
      #+end_example    

    - 强制使用某种语言
      
      + =hello.cn.py=

        #+begin_src python
          import gettext
          
          t = gettext.translation('messages', './hello.i18n', languages=['zh_CN'])
          _ = t.gettext
          
          print _('Hello')
          print _('World')
        #+end_src
      
        #+begin_example
          LC_ALL=en_US python ./hello.py
          喂
          世界
        #+end_example
