#+TITLE: 看看俺 - KanKanAn.com
#+DESCRIPTION: 记我所思，忆我所为。
#+DATE: 2013-04-09 12:00:00
#+LANGUAGE: zh-CN
#+STARTUP: logdone

#+PUBLISH_DIR: .
#+URL: http://blog.kankanan.com

#+DEFAULT_CATEGORY: Posts
#+DISQUS: kankananblog
#+FILENAME_SANITIZER: ob-sanitize-string
#+POST_SORTER: ob-sort-posts-by-title

#+POST_BUILD_SHELL: cmd 1
#+POST_BUILD_SHELL: cmd 2
#+POST_BUILD_SHELL: cmd 3
#+POST_BUILD_SHELL: cmd 4


* Blog details
** Copyright
  :PROPERTIES:
  :SNIPPET:  t
  :END:

版权所有 © 2011-2013 看看俺 – KanKanAn.com

** About
  :PROPERTIES:
  :SNIPPET:  t
  :END:

记我所思，忆我所为

** Navigation
  :PROPERTIES:
  :SNIPPET:  t
  :END:

- [[file:{lisp}(ob:path-to-root){/lisp}/archives.html][/icon-list icon-white/ {lisp}(ob:gettext :archives){/lisp}]]

- [[file:{lisp}(ob:path-to-root){/lisp}/tags.html][/icon-tags icon-white/ {lisp}(ob:gettext :tags){/lisp}]]

- [[file:{lisp}(ob:path-to-root){/lisp}/index.xml][/icon-rss icon-white/ {lisp}(ob:gettext :rss){/lisp}]]


** Navigation Footer
  :PROPERTIES:
  :SNIPPET:  t
  :END:

  - [[file:{lisp}(ob:path-to-root){/lisp}/index.html][/icon-home icon-white/ {lisp}(ob:gettext :home){/lisp}]]

  - [[file:{lisp}(ob:path-to-root){/lisp}/tags.html][/icon-tags icon-white/ {lisp}(ob:gettext :tags){/lisp}]]

  - [[file:{lisp}(ob:path-to-root){/lisp}/archives.html][/icon-list icon-white/ {lisp}(ob:gettext :archives){/lisp}]]

  - [[file:{lisp}(ob:path-to-root){/lisp}/index.xml][/icon-rss icon-white/ {lisp}(ob:gettext :rss){/lisp}]]

  - [[file:{lisp}(ob:path-to-root){/lisp}/changelog.html][/icon-pencil icon-white/ {lisp}(ob:gettext :changelog){/lisp}]]


** {lisp}(ob:gettext :tags){/lisp}
  :PROPERTIES:
  :PAGE:     tags.html
  :TEMPLATE: blog_post-by-tags.html
  :END:

* Changelog
  :PROPERTIES:
  :PAGE:     changelog.html
  :END:

- 2013-04-09
  - 使用[[http://renard.github.com/o-blog][o-blog]]搭建个人博客.

* Posts
** DONE 使用o-blog搭建个人博客                                       :o@blog:
   CLOSED: [2013-04-09 二 12:30]
   :PROPERTIES:
   :PAGE:     index.html
   :TEMPLATE: blog_static_no_title.html
   :END:

   新的博客使用[[http://renard.github.com/o-blog][o-blog]]搭建，使用的是自已的分枝[[https://github.com/tangxinfa/o-blog][tangxinfa-o-blog]]，我的分枝主要是对原系统做了一定的简化以便适用于创建个人博客，另修复了一些bug（主要是中文相关），可使用以下配置安装我的分枝：
   #+begin_src lisp
     (setq el-get-sources '((:name tangxinfa-o-blog
                                       :type git 
                                       :url "https://github.com/tangxinfa/o-blog.git"
                                       :load "o-blog.el"
                                       :features o-blog)))
   #+end_src
   #+begin_src sh
     M-x el-get-install tangxinfa-o-blog
   #+end_src

   具体使用可参考本博客的原始org文件：

   #+begin_src sh
     git clone https://github.com/tangxinfa/tangxinfa.github.com.git
   #+end_src

** DONE Archlinux下安装fcitx输入法                          :archlinux:fcitx:
   CLOSED: [2012-12-15 六 21:56]

  - 安装 ::
#+BEGIN_SRC sh
sudo pacman -S fcitx-gtk2 fcitx-gtk3 fcitx-qt
cp /etc/xdg/autostart/fcitx-autostart.desktop  ~/.config/autostart/
#+END_SRC  

  - 配置 ::
    在配置文件~/.xprofile中添加以下内容：
#+BEGIN_EXAMPLE
export GTK_IM_MODULE=fcitx
export QT_IM_MODULE=fcitx
export XMODIFIERS="@im=fcitx"
export LC_CTYPE="zh_CN.UTF-8"
#+END_EXAMPLE           

** DONE Archlinux下安装cups打印系统                          :archlinux:
   CLOSED: <2013-03-27 三 21:56>

  - 安装 ::
#+BEGIN_SRC sh
yaourt -S cups-pdf
#+END_SRC
  
  - 启动 ::
#+BEGIN_SRC sh
sudo systemctl start cups
#+END_SRC

  - 配置 ::
    参考：https://wiki.archlinux.org/index.php/Cups#PDF_virtual_printer

    登录的用户名要为root，否则后面还是无法添加打印机，web界面没有退出登录的选项，可以试试重启cups服务浏览器清除缓存的数据。

** DONE 网页中的自动完成的下拉列表框                      :web:jquery:chosen:
   CLOSED: <2013-03-10 日 21:23>

*** jqueryui的[[http://jqueryui.com/autocomplete/#combobox][组件]]
    示例效果看起来挻好，不过发现几个问题：

    - 和[[http://twitter.github.com/bootstrap/][bootstrap]]有冲突，导致右边的下拉箭头部分都看不见。
    - 操作过程中有时候显示的值和实际的值不一致，应该是中文输入法按键事件在firefox下未触发引起的显示的界面部分和隐藏的select输入框值不同步。
    - 没有提供设置当前选中项、禁用的功能，要自行对生成的界面元素进行处理。
  
    这个只是jqueryui自动完成输入框的一个定制示例，不是很完善，而jqueryui自带的正式版看起来只是一个输入框。

*** [[https://github.com/harvesthq/chosen][chosen]]
    非常完美，配置很简单，而且界面很漂亮，在github上评分很高。

** DONE CityHash算法冲突率测试                                     :hash:
   CLOSED: <2012-11-24 六 18:21>

*** [[http://code.google.com/p/cityhash/][CityHash]]介绍
    [[http://www.google.com][Google]] 2010年开始开发并开源的字符串哈希算法，主要包含CityHash32()、CityHash64()和CityHash128()，分别对应32位、64位、128位哈希算法。

*** 测试样本数据
    16630591行不重复字符串，每一行内容为以制表符分隔的下载地址和引用页。

*** cityhash64测试结果
    没有冲突

*** cityhash32测试结果
    共32246次冲突，冲突率约为千分之二。
    同一哈希值上55次冲突二次，32136次冲突一次。

** DONE C++的函数、闭包与协程                                           :cpp:
    CLOSED: <2013-03-15 五 10:04>
    
*** 实现序号生成器
**** 函数（Function）
     #+begin_src c++
     #include <cassert>
     
     int id_generator(int& base, int step)
     {
         int result = *base;
         *base += step;
         return result;
     }
     
     int main(int argc, char *argv[])
     {
         int odd_base = 1;
         int even_base = 0;    
         assert(id_generator(odd_base, 2) == 1);
         assert(id_generator(odd_base, 2) == 3);
         assert(id_generator(odd_base, 2) == 5);
         assert(id_generator(even_base, 2) == 0);
         assert(id_generator(even_base, 2) == 2);
         assert(id_generator(even_base, 2) == 4);        
         return 0;
     }
     #+end_src

     - 编译 ::
       #+begin_example
       g++ -g add.cpp -o add
       #+end_example

**** 闭包（Closure）
     #+begin_src c++
     #include <cassert>
       
     int main(int argc, char *argv[])
     {
         int base = 1;
         auto id_generator_odd = [=]() mutable { int result = base; base += 2; return result; };
         base = 0;
         auto id_generator_even = [=]() mutable { int result = base; base += 2; return result; };
         assert(id_generator_odd() == 1);
         assert(id_generator_odd() == 3);
         assert(id_generator_odd() == 5);
         assert(id_generator_even() == 0);
         assert(id_generator_even() == 2);
         assert(id_generator_even() == 4);
         assert(base == 0);
         return 0;
     }
     #+end_src

     - 编译 ::
       #+begin_example
       g++ -g closure.cpp -o closure -std=c++0x
       #+end_example

**** 协程（Coroutine）
     #+begin_src c++
     #include <boost/bind.hpp>
     #include <boost/coroutine/all.hpp>
       
     typedef boost::coroutines::coroutine< int(void) > IDGenerator;
       
     void idGenerator(IDGenerator::caller_type& ca, int base, int step)
     {
         do{
             ca(base);
             base += step;
         }while(true);
     }
       
     int main(int argc, char *argv[])
     {
         IDGenerator id_generator_odd(boost::bind(idGenerator, _1, 1, 2));
         IDGenerator id_generator_even(boost::bind(idGenerator, _1, 0, 2));
         assert(id_generator_odd.get() == 1);
         assert(id_generator_odd().get() == 3);
         assert(id_generator_odd().get() == 5);
         assert(id_generator_even.get() == 0);
         assert(id_generator_even().get() == 2);
         assert(id_generator_even().get() == 4);
         return 0;
     }
     #+end_src

     - 编译 ::
       #+begin_example
       g++ -g coroutine.cpp -lboost_context -o coroutine -std=c++0x
       #+end_example

*** 特性比较
**** 函数（Function）
     - 无状态
     - 需要独立定义执行体
     - 调用过程中从头到尾执行体内所有代码
     - 在输入相同的情况下，能够保证输出也相同
     - 没有副作用，多线程安全
     - 要借助外部变量保存状态
     - 调用比较麻烦，需要传入保存状态的参数

**** 闭包（Closure）
     - 有状态，内部直接保存
     - 直接内联定义执行体
     - 调用过程中从头到尾执行体内所有代码
     - 输入相同的情况下，输出可能不同
     - 有副作用，非多线程安全
     - 定义时可以多种方式安全地引用外部变量
     - 调用简单，不需要传入保存状态的参数
       
**** 协程（Coroutine）
     - 有状态，内部直接保存
     - 需要独立定义执行体
     - 调用过程中直接从上次的运行状态继续运行
     - 输入相同的情况下，输出可能不同
     - 严禁多线程访问
     - 调用简单，不需要传入保存状态的参数    

** DONE 在emacs模式行上显示图片的尺寸                                 :emacs:
   CLOSED: <2012-08-03 五 08:55>

   下面的lisp代码用于在emacs模式行上显示图片的尺寸：
   #+BEGIN_SRC lisp
   (add-hook 'image-mode-hook (lambda ()
                             "display image size on mode line."
                             (setq mode-name (format "Image[%s](%s*%s)" 
                                                     image-type 
                                                     (car (image-size (image-get-display-property) t)) 
                                                     (cdr (image-size (image-get-display-property) t))))))
   #+END_SRC

   - 效果如下 ::
   #+begin_example
   [(Image[png](181*415))]
   #+end_example
   
** DONE 在emacs中如何以root权限使用gdb调试程序                        :emacs:
   CLOSED: <2013-03-30 六 14:21>

  - 由于M-x命令中使用sudo输入密码无效，需要配置为允许用户sudo gdb免密码
  #+begin_example
  visudo
  # Allow user to sudo gdb without password
  用户 ALL=NOPASSWD: /usr/bin/gdb
  #+end_example

  - 使用root权限启动gdb
  #+begin_example
  M-x gdb
  sudo gdb <program> <pid> --annotate=3
  #+end_example

** DONE 解决360杀毒报网页HTML.Rce.Gen3恶意程序的问题                    :web:
   CLOSED: <2012-08-01 三 08:55>

*** 问题描述
    测试发现在某些机器上会弹出360杀毒危险警告对话框，导致网页无法打开。

*** 解决方法
    将嵌入的统计js脚本从</html>标签后移到里面去。
    - 修改前
    #+BEGIN_SRC html
    ...
    </body>
    </html>
    <script type="text/javascript">document.write(unescape("%3Cscript%20...%3C/script%3E"));</script>
    #+END_SRC
    - 修改后
    #+BEGIN_SRC html
    ...
    <script type="text/javascript">document.write(unescape("%3Cscript%20...%3C/script%3E"));</script>
    </body>
    </html>
    #+END_SRC

*** 心得
    以后再遇到这种情况，可以采取排除法，将网页另存为本地文件，一点点的删除内容直到360杀毒不再报警为止。

** DONE 解决Archlinux下ati显卡3D硬件加速失效的问题                :archlinux:
   CLOSED: <2012-09-05 三 23:52>

*** 问题描述
    - 症状

      进入gnome3桌面环境后很卡，不动还好，一动gnome-shell进程cpu占用就直奔100%。

    - dmesg异常日志
      #+BEGIN_EXAMPLE
      radeon_cp: Failed to load firmware "radeon/R520_cp.bin"
      radeon 0000:01:00.0: failed initializing CP (-2).
      radeon 0000:01:00.0: Disabling GPU acceleration
      #+END_EXAMPLE
*** 解决办法
#+BEGIN_SRC sh
  sudo ln -s /usr/lib/firmware /lib/
  sudo reboot
#+END_SRC
*** 经验总结
    出现问题时网上不一定能找到你要的答案，像这个问题，网上的论坛里有无数个建议，一个一个试下去其实很浪费时间，
    试几次之后还没能解决就应该尝试主动分析解决，像这里稍微留意到括号里的-2，就能发现其实它是个错误码，
    perror一下就知道意思是“找不到文件或目录”，联想到最近几次升级archlinux在把/lib里的东西往/usr/lib下移，
    其中就包括firemware，这样手工在旧的firmware位置建一个软链接就解决了这个问题。

*** 备注
    这个问题应该是由于之前glibc升级时未全部完成引起的，archlinux现在把/lib改为/usr/lib的软链接了，可以手工进行设置为软链接这一步骤来修复。

** DONE Fnv算法冲突率测试                                          :hash:
   CLOSED: <2012-11-24 六 18:31>

*** [[http://www.isthe.com/chongo/tech/comp/fnv/][Fnv]]介绍
    Fnv是和 [[http://code.google.com/p/cityhash/][CityHash]] 类似的哈希算法。这里重复《[[http://blog.kankanan.com/posts/2012/11/24_cityhash7b976cd551b27a8173876d4b8bd5.html][CityHash算法冲突率测试]]》，做为一个对比。

*** 测试样本数据
    16630591行不重复字符串，每一行内容为以制表符分隔的下载地址和引用页。

*** fnv64测试结果
    没有冲突

*** fnv32测试结果
    共31948次冲突，冲突率约为千分之二。
    同一哈希值上33次冲突二次，31879次冲突一次。
    冲突率比CityHash略低，少了298次。

** DONE 如何做面试
   CLOSED: <2012-10-24 三 14:23>

*** 语言基础
*** 相关技术
*** 性能优化
*** 架构
*** 管理
*** 诉求
** DONE 理解nginx的keepalive_timeout配置项                       :nginx:http:
   CLOSED: [2012-11-12 二 17:05]
   
   不要误以为它是指tcp连接空闲多少秒后关闭，它仅表示连接建立多少秒后关闭，不会在一次请求后重新计时。

** DONE 在python中安装mysqldb模块                                    :python:
   CLOSED: <2012-08-01 三 08:55>

*** 正常的安装过程
#+begin_src sh
  wget "http://downloads.sourceforge.net/project/mysql-python/mysql-python\
/1.2.3/MySQL-python-1.2.3.tar.gz?r=http%3A%2F%2Fsourceforge.net%2Fprojects\
%2Fmysql-python%2Ffiles%2F&ts=1304062611&use_mirror=nchc"
  tar xzvf MySQL-python-1.2.3.tar.gz
  cd MySQL-python-1.2.3
  python setup.py build
  python setup.py install
#+end_src

*** 常见错误及其修复
    - ImportError: No module named setuptools
      #+name: install-setuptools
      #+begin_src sh
      wget http://pypi.python.org/packages/2.4/s/setuptools/setuptools-0.6c11-py2.4.egg\
      #md5=bd639f9b0eac4c42497034dec2ec0c2b
      sh setuptools-0.6c11-py2.4.egg
      #+end_src

    - mysql\_config: command not found
      #+name: edit-site.cfg 
      #+begin_src sh
      sed --in-place -e "s/#mysql_config = \/usr\/local\/bin\/mysql_config/\
      mysql_config = \/usr\/local\/mysql\/bin\/mysql_config/g" site.cfg
      #+end_src

    - ImportError: \dots{} \_mysql.so: undefined symbol: compress
      #+name: edit-setup\_posix.py
      #+begin_src sh
      sed --in-place -e "s/libs = mysql_config(\"libs_r\")/libs = mysql_config(\"libs_r\")\n\
      libs.append('-lz')\n        print libs/g" setup_posix.py
      #+end_src

** DONE 如何学习英语                                               :english:
   CLOSED: <2013-04-07 日 09:49>

   经过一天的英孚及韦博试听，总结出以下几点：
   - 语法 ::
     熟读常用句型，扩展至类似语句，从中提炼语法，另一方面也可以练就一口流利的日用口语。
   - 听力 ::
     不会说就不会听，多说才能够快速识别听到的东西。
   - 阅读 ::
     多记单词，不断的重复重复再重复，直到看到单词脱口而出。
   
** DONE MongoDB基础                                                 :mongodb:
   CLOSED: <2012-10-21 日 17:06>
   
*** MongoDB与Mysql的基本结构对应关系
**** 一台机器
     computer

***** 多个MongoDB实例                                          <--对应-->                    mysql服务器进程
      MongoDB Instance                                        <--对应-->                    Mysqld Instance

      运行着的MongoDB后台服务进程：/etc/rc.d/mongodb start      <--对应-->                     /etc/rc.d/mysqld start

****** 多个数据库                                              <--对应-->                    mysql中的数据库
       MongoDB Database                                       <--对应-->                     Database

******* 多个集合                                               <--对应-->                    mysql中的表
        MongoDB Collection                                    <--对应-->                     Table

******** 多个文档                                             <--对应-->                     mysql中的记录行
         MongoDB Document                                     <--对应-->                    Row

*** CentOS上搭建环境
    - 添加源/etc/yum.repos.d/10gen.repo ::
      #+BEGIN_EXAMPLE
      [10gen]
      name=10gen Repository
      baseurl=http://downloads-distro.mongodb.org/repo/redhat/os/x86_64
      gpgcheck=0
      #+END_EXAMPLE
    - 安装服务器客户端程序 ::
      #+BEGIN_SRC sh
      yum install mongo-10gen mongo-10gen-server
      #+END_SRC
    - 安装php扩展 ::
      #+BEGIN_SRC sh
      yum -y install make gcc php-devel
      yum install php-pear
      PATH=$PATH:/usr/local/php/bin/ pecl install mongo
      #+END_SRC
      php.ini中添加：extension=mongo.so
    - 启动服务 ::
      /etc/rc.d/init.d/mongodb start
     
** DONE 解决mysql_connect慢的问题                                     :mysql:
   CLOSED: <2012-12-06 四 10:25>

  压测时发现mysql\_connect耗时超过30秒，登录mysql后执行show processlist，显示超过800个连接状态如下：

  #+BEGIN_EXAMPLE
   unauthenticated user | XXXX.XXX.XXX.XXX:XXXX  | NULL | Connect     |  NULL | login    
  #+END_EXAMPLE

  经求教运维，在my.cnf中的“[mysqld]”下添加以下配置行即可：

  #+BEGIN_EXAMPLE
    skip-name-resolve
  #+END_EXAMPLE

** DONE Nginx Comet: 基于 HTTP 长连接的“服务器推”技术         :nginx:comet:
   CLOSED: <2012-12-14 五 21:09>

*** 简介
    可参考这篇文章：[[http://www.ibm.com/developerworks/cn/web/wa-lo-comet/][Comet：基于 HTTP 长连接的“服务器推”技术]]

*** [[https://github.com/slact/nginx_http_push_module][nginx\_http\_push\_module]] （不建议使用）
  这个模块功能上没有问题，网上介绍的文章相对比较多，但是存在严重的内存泄露问题，而且发现使用kill -HUP的方式优雅重启nginx虽会释放一部分内存，但nginx错误日志显示有共享内存锁相关的冲突，我们不得不每小时彻底重启一次nginx。简单说一下就是它使用一个全局的内存池来分配订阅者及响应需要的内存空间，但是从nginx内存池分配的小内存块（< pagesize，4096）是不会释放的也不会归还到池中进行重用，具体可查看nginx源码的ngx\_palloc和ngx\_pfree函数进行验证。

  可google "nginx中mod\_push模块内存分配改造"，在作者的[[http://http://blog.lifeibo.com/][网站]]正在改版暂时找不到该文章。
  
  [[http://bsd.ee/~hadara/blog/?p=215=1][这里]]也有人[[https://github.com/slact/nginx_http_push_module/pull/60][指出]]该问题，同时该文作者也fork了一个分枝，但是我试了一下，除了不支持push\_channel\_timeout特性外，还是一样有内存泄露。

  - 参考配置 ::
#+BEGIN_EXAMPLE
    location ~ ^/publish$ {
        allow 127.0.0.1;
        deny all;
        set $push_channel_id $arg_id;
        push_publisher;
        push_delete_oldest_received_message on;
        push_message_timeout 5s;
        #push_channel_timeout 60s;
        push_store_messages off;
    }

    location ~ ^/activity$ {
        if ($args ~ "callback=(.+)" ) {
            rewrite ^/activity "/activity_jsonp" last;
        }
        push_subscriber;
        push_subscriber_timeout 60s;
        push_subscriber_concurrency first;
        push_max_channel_subscribers 1;
        set $push_channel_id $arg_id;
        default_type application/json;
    }

    location ~ ^/activity_jsonp$ {
        push_subscriber;
        push_subscriber_timeout 60s;
        push_subscriber_concurrency first;
        push_max_channel_subscribers 1;
        set $push_channel_id $arg_id;
        default_type application/json;
        echo_before_body $arg_callback "(";
        echo_after_body ")";
    }
#+END_EXAMPLE

*** [[https://github.com/wandenberg/nginx-push-stream-module][nginx-push-stream-module]] （建议使用）
  由于 [[https://github.com/slact/nginx_http_push_module][nginx\_http\_push\_module]] 存在内存泄露问题，同时没有人进行正式的修复，我们决定尝试一下[[https://github.com/wandenberg/nginx-push-stream-module][nginx-push-stream-module]]，这个模块功能更强大同时文档更完整，看起来也更活跃。

  - 优点 ::
    + 更成熟
      有内存消耗说明文档，便于决定共享内存容量配置。
      有统计功能。
      可对响应内容进行再处理。
    + 测试中未发现明显的内存泄露
    + 内置支持jsonp
      返回的jsonp是这样的格式callback([text])，可以通过修改ngx\_http\_push\_stream\_module\_utils.h中定义的NGX\_HTTP\_PUSH\_STREAM\_CALLBACK\_INIT\_CHUNK和NGX\_HTTP\_PUSH\_STREAM\_CALLBACK\_END\_CHUNK去除多余的中括号。
  
- 参考配置 ::
#+BEGIN_EXAMPLE
push_stream_store_messages off;
push_stream_max_subscribers_per_channel 1;
push_stream_subscriber_connection_ttl 60s;
push_stream_longpolling_connection_ttl 60s;

server {
    listen 80;
    server_name localhost 127.0.0.1;
    
    ...

    location ~ ^/publish$ {
        allow 127.0.0.1;
        deny all;
        push_stream_publisher admin;
        set $push_stream_channel_id $arg_id;
    }
    
    location ~ ^/activity$ {
        push_stream_subscriber long-polling;
        set $push_stream_channels_path $arg_id;
        push_stream_content_type "application/json";
        push_stream_message_template "~text~";
    }

    ...
}

#+END_EXAMPLE  

** DONE nginx下快速搭建php运行环境                                :nginx:php:
   CLOSED: <2012-08-11 六 21:09>

*** 安装
**** 安装nginx
     yaourt -S nginx
**** 安装php
      yaourt -S php
**** 安装php-fpm
      yaourt -S php-fpm

*** 配置
**** 配置nginx
     - 将nginx.conf中的以下部分：
       #+BEGIN_EXAMPLE
         #location ~ \.php$ {
         ...
         #}
       #+END_EXAMPLE
     - 修改为
       #+BEGIN_EXAMPLE
          location ~ \.php$ {
             root           /usr/share/nginx/html;
             fastcgi_pass   127.0.0.1:9000;
             fastcgi_index  index.php;
             fastcgi_param  SCRIPT_FILENAME  /usr/share/nginx/html$fastcgi_script_name;
             include        fastcgi_params;
          }
       #+END_EXAMPLE
**** 配置php
     在open\_basedir中添加：/usr/share/nginx/html
**** 配置php-fpm.conf
     启用以下listen配置：
     listen = 127.0.0.1:9000

*** 运行
    - 重启nginx
      #+BEGIN_SRC sh
      sudo /etc/rc.d/nginx restart
      #+END_SRC
    - 启动php-fpm
      #+BEGIN_SRC sh
      sudo php-fpm
      #+END_SRC
    - 然后在/usr/share/nginx/html目录中写php脚本即可。

** DONE php中DOMDocument类createElement和createTextNode的区别           :php:
   CLOSED: <2012-09-27 四 19:05>

*** DOMDocument::createElement
    - 原型：DOMElement DOMDocument::createElement ( string $name [, string $value ] )

      创建一个元素，其中第二个参数是可选的，不会对它进行转义。当value中包含特殊字符（如：&）会出错。
   
*** Domdocument::createTextNode
    - 原型：DOMText DOMDocument::createTextNode ( string $content )

      创建一个文本结点，会对其内容进行转义。

*** 典型示例：创建一个文本元素
    #+begin_src php
    $element = $doc->createElement("city");
    $node = $doc->createTextNode("shenzhen");
    $element->appendChild($node);
    $doc->appendChild($element);
    #+end_src
    - 对应的xml文档：
    #+begin_src xml
    <city>shenzhen</city>
    #+end_src
     
** DONE 当php遇上redis                                            :php:redis:
   CLOSED: <2012-12-08 六 13:41>

   在最近的项目中，我们需要在php中访问redis，我们选择了使用[[https://github.com/nicolasff/phpredis][phpredis]]库，下面是遇到的一些问题。

*** redis持久连接不靠谱。

    可以说这是php的通病了，不管是mysql、memcache还是redis，指望由php本身（包含php扩展）来实现持久连接都是行不通的。

    - 为什么这么说呢？ ::
      首先，所谓的持久连接的实现不外乎在进程（php-fpm）内建一个连接池，当php需要连接时，先以ip+port等信息为key在池中查找，找到则直接返回已有连接没有则新建连接。而当一个请求执行结束时，不关闭连接，而是把连接归还到池中。
      
      这样当php需要用到多个redis实例时（分库），因为一个php-fpm进程会持有每个redis实例的一个连接，所以需要“php-fpm进程数“*“redis实例数"个redis连接，而对于每个redis服务器则有“php-fpm进程数“个客户端连接。

      举个例子：一个web应用开了1000个php-fpm进程，有10个redis实例，那么保持的redis连接数就为1000*10也就是10000，每个redis实例有1000个客户端连接。如果前端或redis再扩容所需要的连接就会以乘积方式增加。一个redis实例有php-fpm进程数个连接的情况下表现如何呢，这就要好好测一测了，反正是每连接一线程的mysql是直接堵死了。

*** RedisArray不靠谱。
    RedisArray实现了一致性hash分布式，但是它在初始化的时候就会连接上每个实例，这在web应用中简直是胡闹，它对一致性hash实现得比较完善，结点失效、动态添加结点时重新hash都有处理，在万不得已进行水平扩容时，可能会用得上。

*** 需要自已关闭redis连接。
  Redis的析构函数没有关闭redis连接，这会导致redis网络负载过高，要确保脚本结束时关闭连接，最好是能够封装一下Redis类再使用。

  - 示例封装 ::
#+BEGIN_SRC php
/// 分布式Redis.
class RedisShard {
    /// 构造函数.
    public function __construct($shards) {
        $this->reinit($shards);
    }

    /// 析构函数.
    /// 脚本结束时，phpredis不会自动关闭redis连接，这里添加自动关闭连接支持.
    /// 可以通过手动unset本类对象快速释放资源.
    public function __destruct() {
        if(isset($this->shard)){
            $this->shard['redis']->close();
        }
    }

    /// 重新初始化.
    public function reinit($shards){
        $index = 0;
        $this->shards = array();
        foreach($shards as $shard){
            $this->shards[$index] = explode(':', $shard); //格式：host:port:db
            $this->shards[$index]['index'] = $index;
            ++$index;
        }        
    }
    
    /// 转发方法调用到真正的redis对象.
    public function __call($name, $arguments) {
        $result = call_user_func_array(array($this->redis($arguments[0]), $name), $arguments);
        if($result === false and in_array($name, array('set', 'setex', 'incr'))) {
            trigger_error("redis error: " . $this->shard[0] . ':' . $this->shard[1] . ':' .$this->shard[2] . " $name " . implode(' ', $arguments), E_USER_NOTICE);
        }
        return $result;
    }

    /// 获取1至max间的唯一序号name，达到max后会从1开始.
    /// redis的递增到最大值后会返回错误，本方法实现安全的递增。
    /// 失败返回false，最要确保已用redis()方法连到生成序号的某个redis对象.
    public function id($name, $max) {
        if(isset($this->shard)){
            $id = $this->shard['redis']->incr('_id_' . $name);
            if($id){
                $max = intval($max/count($this->shards));
                if($id % $max == 0){
                    while($this->shard['redis']->decrBy('_id_' . $name, $max) >= $max){
                    }
                    $id = $max;
                }
                else if($id > $max){
                    $id %= $max;
                }
                return ($id - 1)*count($this->shards) + ($this->shard['index'] + 1);
            }
        }
        return false;
    }

    /// 连接并返回key对应的redis对象.
    public function redis($key){
        //TODO: crc32在32位系统下会返回负数，因我们是部署在64位系统上，暂时忽略.
        assert(PHP_INT_SIZE === 8);
        $index = crc32($key) % count($this->shards);
        $shard = $this->shards[$index];
        if(isset($this->shard)){
            //尝试重用已有连接.
            if($this->shard[0] == $shard[0] and $this->shard[1] == $shard[1]){
                if($this->shard[2] != $shard[2]){
                    if(! $this->shard['redis']->select($shard[2])){
                        trigger_error('redis error: select ' . $shard[0] . ':' . $shard[1] . ':' .$shard[2], E_USER_ERROR);
                        return false;
                    }
                    $this->shard[2] = $shard[2];
                }
                return $this->shard['redis'];
            }
            $this->shard['redis']->close();
            unset($this->shard);
        }
        //新建连接.
        $shard['redis'] = new Redis();
        if(! $shard['redis']->connect($shard[0], $shard[1])){
            trigger_error('redis error: connect ' . $shard[0] . ':' . $shard[1], E_USER_ERROR);
            return false;
        }
        $db = intval($shard[2]);
        if($db != 0 and !$shard['redis']->select($db)){
            trigger_error('redis error: select ' . $shard[0] . ':' . $shard[1] . ':' .$shard[2], E_USER_ERROR);
            $shard['redis']->close();
            return false;
        }
        if(ENABLE_DEVELOP){
            trigger_error('redis connect success. ' . $shard[0] . ':' . $shard[1] . ':' . $shard[2], E_USER_NOTICE);
        }        
        $this->shard = $shard;
        return $this->shard['redis'];
    }
}
#+END_SRC

** DONE python中的UTC与本地时区处理                                  :python:
   CLOSED: <2013-03-20 三 17:29>

   在通过sqlalchemy使用sqlite3数据库的过程中，发现日期时间字段默认值为CURRENT\_TIMESTAMP，但是查出的值少了8个小时。很明显是遇到时区问题了。

   mysql的TIMESTAMP字段类型和sqlite3一样使用UTC时间保存，因为在存取时自动进行了本地时间与UTC时间互转，所以不会遇到时区问题。但是sqlite3没有自动进行这一转换，需要在sql中自行转换:
   #+begin_src sql
    select datetime(CURRENT_TIMESTAMP, 'localtime')
   #+end_src

   进一步google后，找到了这篇文章：《[[http://lucumr.pocoo.org/2011/7/15/eppur-si-muove/][Dealing with Timezones in Python]]》，文章大意是python中的datetime库默认不携带时区信息，而加上时区后又与不带时区的datetime对象无法一起工作（如：比较），另外像datetime.datetime.utcnow()返回的utc时间和datetime.datetime.now()返回的本地时间也是不携带时区信息的（tzinfo属性为None），容易引起混淆，因此处理的简单性，内部最好统一使用UTC标准时间，和用户交互时再转换为本地时间。

   下面是互转的算法：
   #+begin_src python
      #/usr/bin/env python
      
      import datetime
      import time
      import sys
      
      if sys.version >= '3.2.':
          localtimezone = datetime.timezone(datetime.timedelta(seconds=-time.timezone), time.tzname[0])
          utctimezone = datetime.timezone.utc
      else:
          from dateutil import tz
          localtimezone = tz.tzlocal()
          utctimezone = tz.gettz('UTC')
      
      def parsedatetime(dt, fmt="%Y-%m-%d %H:%M:%S"):
          """parse local datetime string as utc datetime object"""
          return datetime.datetime.strptime(dt, fmt).replace(tzinfo=localtimezone).astimezone(utctimezone)
      
      def formatdatetime(dt, fmt="%Y-%m-%d %H:%M:%S"):
          """format utc datetime object as local datetime string"""
          return dt.replace(tzinfo=utctimezone).astimezone(localtimezone).strftime(fmt)
      
      if __name__ == '__main__':
          input_local_datetime = '2012-01-02 03:04:05'
          parsed_utc_datetime = parsedatetime(input_local_datetime)
          assert(formatdatetime(parsed_utc_datetime) == input_local_datetime)
   #+end_src

** DONE 二维码研究                                                   :qrcode:
   CLOSED: <2013-03-30 六 11:21>

*** 介绍
    - [[http://www.itsc.org.sg/pdf/synthesis08/Three_QR_Code.pdf][Three\_QR\_Code.pdf]] ::
      RFC式的文档

    - [[http://suflow.iteye.com/blog/1100678][二维码 编码原理简介]] ::
      通俗易懂的编码细节介绍

    - [[http://zh.wikipedia.org/wiki/QR%E7%A2%BC][QR碼 - 维基百科，自由的百科全书]] ::

    - [[http://www.qrstuff.com/blog/2011/11/23/qr-code-minimum-size][QR Code Minimum Size]] 与 [[http://www.qrstuff.com/blog/2011/01/18/what-size-should-a-qr-code-be][What Size Should A Printed QR Code Be?]] ::
      关于可识别性的一些结论，该网站上有大量二维码研究相关的文章
    
*** 二维码开发库
    - [[https://github.com/fukuchi/libqrencode][libqrencode]] ::
      基础的c语言二维码编码库，很多语言基于它开发扩展，不包含生成png图的功能，如需生成png可参考[[https://github.com/bitly/simplehttp/blob/master/qrencode/qrencode.c][这里]]
    - [[https://github.com/jeromeetienne/jquery-qrcode][jquery-qrcode]] ::
      使用javascript直接在客户端生成二维码，中文支持参见[[http://suflow.iteye.com/blog/1687396][JS生成二维码，支持中文字符]]
    - [[http://people.freebsd.org/~vanilla/qrencode-0.3.tar.bz2][php's qrencode extension]] ::
      使用nginx的扩展性能会更好一点，参考后面[[nginx的相关扩展]].
    - [[http://trac.koka-in.org/libdecodeqr][libdecodeqr]] ::
      二维码解码库
      
*** nginx的相关扩展
**** 基本的二维码
     [[https://github.com/dcshi/ngx_http_qrcode_module][ngx\_http\_qrcode\_module]]
    
**** 二维码个性化水印
   nginx\_http\_image\_filter加上[[http://forum.nginx.org/read.php?21,235958][水印补丁]]即可。

   下面的是经过修改后的 =nginx image filter= 模块代码，加入居中的水印效果:

#+o_blog_source ./static/ngx_http_image_filter_module.c

**** 编译
     #+begin_src sh
     --with-debug --with-http_image_filter_module --add-module=/home/tangxinfa/Opensource/nginx-1.2.7/../ngx_http_qrcode_module/ --add-module=/home/tangxinfa/Opensource/nginx-1.2.7/../ngx_devel_kit/ --add-module=/home/tangxinfa/Opensource/nginx-1.2.7/../set-misc-nginx-module/ --add-module=/home/tangxinfa/Opensource/nginx-1.2.7/../echo-nginx-module/
     #+end_src

**** 配置
     #+begin_example
          location ~ /qr {
              qrcode_fg_color FF0000;
              qrcode_bg_color FFFFFF;    
              qrcode_level 2;
              qrcode_hint 2;
              qrcode_size 120;
              qrcode_margin 2;
              qrcode_version 5;
              set_unescape_uri $txt $arg_txt;
              qrcode_txt $txt;
              qrcode_casesensitive 1; 
              qrcode_gen;  

              image_filter_watermark "/usr/share/pixmaps/gnome-word.png";
              image_filter_watermark_transparency 95; #0-100
              image_filter watermark;
          }
     #+end_example

**** 访问
#+begin_example
   http://localhost:8080/qr?txt=hello
#+end_example
     - 显示效果：
     [[file:static/hello_qr.png]]

*** 二维码基础服务的一点思索
    - 必须建立在cdn的基础上
    - 用户只需按照约定将内容以及定制参数按照直观的方式编码成二维码图片链接即可

    参考：https://developers.google.com/chart/infographics/docs/qr_codes

** DONE 解决保存快照失败后redis无法写入的问题                         :redis:
   CLOSED: <2012-12-16 日 15:14>
   
   用命令行工具连上后执行“set test 0”出现以下错误提示：
   #+BEGIN_EXAMPLE
   MISCONF Redis is configured to save RDB snapshots, but is currently not able to persist on disk. Commands that may modify the data set are disabled. Please check Redis logs for details about the error.
   #+END_EXAMPLE
   这个应该是之前强制停止redis快照导致的，查看redis快照状态证实了这一点：
   #+BEGIN_EXAMPLE
   redis 127.0.0.1:6379> info
   ...
   rdb_last_bgsave_status:err
   ...
   #+END_EXAMPLE
   通过关闭配置项stop-writes-on-bgsave-error解决该问题。
   #+BEGIN_EXAMPLE
   redis 127.0.0.1:6379> config set stop-writes-on-bgsave-error no
   #+END_EXAMPLE

** DONE 使用hash表结构减少redis内存占用                               :redis:
   CLOSED: <2012-12-16 日 15:14>

   当hash结构中的元素较少（少于redis.conf:hash-max-zipmap-entries指定的数量时，配置成<=1000，过大会减低处理速度，参见： [[http://stackoverflow.com/questions/11281734/redis-using-hashes][这里]] 和 [[http://instagram-engineering.tumblr.com/post/12202313862/storing-hundreds-of-millions-of-simple-key-value-pairs][这里]] ）且数据为整型时，redis使用特殊的方式（数组保存，时间换空间）保存hash结构以减少内存占用，参见 [[http://redis.io/topics/memory-optimization][这里]] 和 [[http://stackoverflow.com/questions/9625246/what-are-the-underlying-data-structures-used-for-redis][这里]] 。但当hash结构超过指定数量时将使用普通的[[http://redis.io/commands#string][字符串]]方式保存，也就无法再节省内存了。

** DONE 估算redis内存占用                                             :redis:
   CLOSED: <2012-12-16 日 15:14>

   参考: [[http://lethain.com/notes-on-redis-memory-usage/][Notes on Redis Memory Usage]]

   - 测试环境
     - redis版本 :: redis\_version:2.4.4
     - 操作系统（uname -a） :: Linux CentOS 2.6.32-220.13.1.el6.x86\_64 #1 SMP Tue Apr 17 23:56:34 BST 2012 x86\_64 x86\_64 x86\_64 GNU/Linux
     - python版本（python --version） :: Python 2.6.6

*** Strings
    - 测试脚本
      #+BEGIN_SRC python
        #!/bin/env python
        
        import redis
        import uuid
        import time
        
        r = redis.Redis(host='localhost', port=6379, db=0)
        for num_strings in (100000,):
            r.flushall()
            time.sleep(1.0)
            initial_size = r.dbsize()
            initial_info = r.info()
        
            for i in xrange(0, num_strings):
                r.set(str(uuid.uuid4()), time.time())
                #r.setex(str(uuid.uuid4()), time.time(), 100000)
            final_size = r.dbsize()
            final_info = r.info()
        
            print "For %s strings." % (num_strings,)
            print "Keys: %s => %s" % (initial_size, final_size)
            print "Memory: %s => %s" % (initial_info['used_memory'],
                                            final_info['used_memory'])
            print "Memory per key: %d"%((int(final_info['used_memory']) - int(initial_info['used_memory'])) / num_strings)
        #+END_SRC
    - 测试结果
      - set :: 每个key-value占用138字节，可见redis本身的维护开销为89字节
      - setex :: 每个key-value占用180字节，可见redis本身的维护开销为131字节，启用过期时间需要42字节开销（这是因为redis使用新的链表保存设置了过期时间的条目）。

*** Sets
    - 测试脚本
      #+BEGIN_SRC python
        #!/bin/env python
        
        import redis
        import math
        import time
        
        r = redis.Redis(host='localhost', port=6379, db=0)
        set_capcity = int(r.config_get("set-max-intset-entries")["set-max-intset-entries"])
        
        def set_name(i, num_strings, set_capcity):
            set_num = math.ceil(num_strings/float(set_capcity))
            return "s%d"%(i%set_num)
            
        for num_strings in (100000,):
            r.flushall()
            time.sleep(1.0)
            initial_size = r.dbsize()
            initial_info = r.info()
        
            for i in xrange(0, num_strings):
                #r.sadd("s", str(i))
                r.sadd(set_name(i, num_strings, set_capcity), str(i))
            final_size = r.dbsize()
            final_info = r.info()
        
            print "For %s strings." % (num_strings,)
            print "Keys: %s => %s" % (initial_size, final_size)
            print "Memory: %s => %s" % (initial_info['used_memory'],
                                            final_info['used_memory'])
            print "Memory per key: %d"%((int(final_info['used_memory']) - int(initial_info['used_memory'])) / num_strings)
        
        #+END_SRC

    - 测试结果
      - 启用压缩 :: 每个value占用4字节
      - 不启用压缩 :: 每个value占用39字节
      注意: redis的set仅当值为整型，压缩才会生效。

*** 内存预留
    除非你能够保证你的机器总是有一半的空闲内存，否则别使用快照方式持久化数据或者通过执行BGREWRITEAOF压缩aof文件。
    redis在执行bgsave时，会进行一次fork，fork后的进程负责将内存中的数据写入磁盘，由于fork采用Copy-On-Write，两个redis进程共享内存中的数据。redis如果有数据更新，则会将对应的共享内存页创建一份副本再更新，当更新操作足够频繁时，共享的内存空间会迅速地副本化，导致物理内存被耗光，系统被迫动用交换空间，从而导致redis服务极不稳定，整个系统堵塞在磁盘io上。

** DONE linux下跨进程传递文件描述符                                   :linux:
   CLOSED: <2013-03-09 六 15:11>

*** 问题
    在web开发中，以典型的php-fpm为例，对于到外部系统的连接（如：mysql、redis）等都提供了持久连接接口（pconnect），但是受限于多进程模型，事实上是每个php-fpm进程都有单独的一个连接池的（参见：《[[file:php_meet_redis.org][当php遇上redis]]》），大量空闲连接的存在不仅对系统资源造成了浪费（不单指fd空间，像mysql的每连接一线程会附带大量内存空间：sort\_buffer、read\_buffer等），而且整个系统将无法横向扩展（如：mysql连接数限制）。如果可以在进程间共享文件描述符，将可以大大提升系统性能，促进多进程模型的应用。

*** 方案
    在linux平台下，sendmsg、recvmsg可以将一个进程的文件描述符传递给另一进程使用，这使得实现系统级的连接池成为可能。

*** 实现
    《The Linux Programming Interface》61.13.3 Passing File Descriptors
     
** DONE Web模型初探                                                     :web:
   CLOSED: <2013-02-28 四 15:07>
*** CGI
    全称为Common Gateway Interface，即公共网关接口。
    当Web服务器收到一个请求时，运行相应的处理程序，相关参数通过标准输入传递给处理程序，处理程序的标准输出做为响应内容，处理程序运行结束后将响应发送给客户端。
    
    - 性能 *
      进程级，每请求一进程。进程创建有很大的开销，并发数与系统资源消耗呈线性增长，有限的系统资源成为瓶颈。
      
*** FastCGI
    为CGI的改良，CGI程序做为独立的网络后台程序运行，当Web服务器收到一个请求时，发起一个tcp请求到处理程序，通过该tcp连接传入相关参数，处理程序的响应也通过该tcp连接发回给Web服务器，处理程序关闭该连接表示处理完毕，Web服务器最终将响应发送给客户端。

    - 性能 **
      网络级，每请求一连接。CGI的改良，重用进程，进程处理完一个请求后再处理下一请求，对于多个请求，只需要付出一次进程创建的开销，可以在后继请求重用资源（从文件载入的配置项、查询到的数据、打开的文件、数据库连接等）。因为处理程序是串行处理请求，往往需要同时运行多个处理程序以提升并发处理能力，这些处理程序无法共享资源以进一步提升性能。
    
    - 附录
      Web服务器可重用到服务程序的连接进一步提升性能（如：nginx的[[http://nginx.org/en/docs/http/ngx_http_upstream_module.html#keepalive][upstream\_keepalive]]）。
      
*** WSGI

*** uWSGI
** DONE memcached_get会重置过期时间吗？                           :memcached:
   CLOSED: <2012-11-13 二 20:29>

   不会。获取数据的操作不会影响数据的过期时间，最新的memcache1.6添加了touch和GAT（get and touch)命令，可以在获取数据时过期时间。
** DONE python中MySQLdb使用utf-8字符集                         :python:mysql:
   CLOSED: <2011-04-29 Fri 01:22>

   - 要避免乱码需要做好以下几点 ::
     - python源代码保存为utf-8
     - 数据库建成utf-8
     - mysql连接设置为utf-8
     - 查询結果中的文本字段是unicode的，转回utf-8

   - 总结性的示例代码 ::
     #+begin_src python
       #!/usr/bin/env python
       #-*- coding: utf-8 -*-
       
       import MySQLdb
       
       if __name__ == '__main__':
           mysql = MySQLdb.connect(host='localhost', user='root', passwd='123456', charset='utf8')
           cursor = mysql.cursor()
           cursor.execute('SET NAMES UTF8')
           sql = 'DROP DATABASE IF EXISTS mysqldb_utf8_test'
           cursor.execute(sql)
           sql = 'CREATE DATABASE mysqldb_utf8_test DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci'
           cursor.execute(sql)
           mysql = MySQLdb.connect(host='localhost', user='root', passwd='123456', db='mysqldb_utf8_test', charset='utf8')
           cursor = mysql.cursor()
           cursor.execute('SET NAMES UTF8')
           sql = 'CREATE TABLE utf8_table(key_field VARCHAR(32) NOT NULL, value_field VARCHAR(255) NOT NULL)'
           cursor.execute(sql)
           key = 'tangxinfa'
           value = '好人一个'
           sql = 'INSERT INTO utf8_table VALUES("%s", "%s")'%(key, value)
           cursor.execute(sql)       #注意某些旧版本的mysql（如4.1.22以下），mysql.character_set_name()总是返回latin1，会引起乱码，需要改为cursor.execute('INSERT INTO utf8_table VALUES("%s", "%s")', (key, value))
           sql = 'select * from utf8_table'
           cursor.execute(sql)
           for record in cursor.fetchall():
               for item in record:
                   print item.encode('utf8')
     #+end_src

   - 参考 ::
     - http://mysql-python.sourceforge.net/MySQLdb.html
     - http://bbs.phpchina.com/viewthread.php?tid=13861
     - http://hi.baidu.com/ak456/blog/item/c318502394aa20569922ed7b.html

** DONE log4cxx使用心得                                             :log4cxx:
   CLOSED: <2008-06-17 Tue 10:01>

   - 简介

     apache出品必属精品。正宗c++日志库，与log4j一脉相承。

     http://logging.apache.org/log4cxx/index.html

   - 下载、编译、安装

     打算安装到${HOME}/libs目录下：

     #+begin_src sh
     cd ~/libs
     wget http://mirror.bjtu.edu.cn/apache//apr/apr-1.4.4.tar.bz2
     tar xjvf apr-1.4.4.tar.bz2
     cd apr-1.4.4
     ./configure --prefix=${HOME}/libs && make && make install
     cd ..
     wget http://mirror.bjtu.edu.cn/apache//apr/apr-util-1.3.11.tar.bz2
     tar xjvf apr-util-1.3.11.tar.bz2
     cd apr-util-1.3.11
     ./configure --prefix=${HOME}/libs --with-apr=${HOME}/libs && make && make install
     cd ..
     wget http://apache.etoak.com//logging/log4cxx/0.10.0/apache-log4cxx-0.10.0.tar.gz
     tar xzvf apache-log4cxx-0.10.0.tar.gz
     cd apache-log4cxx-0.10.0
     ./configure --with-charset=utf-8 --prefix=${HOME}/libs --with-apr=${HOME}/libs --with-apr-util=${HOME}/libs && make && make install
     #+end_src

   - 使用例子

     =hello.cpp= ：
     #+begin_src cpp
       #include "log4cxx/logger.h"
       #include "log4cxx/propertyconfigurator.h"
       
       static log4cxx::LoggerPtr logger(log4cxx::Logger::getLogger("hello"));
       
       int main(int argc, char *argv[])
       {
         log4cxx::PropertyConfigurator::configure("./log4cxx_hello.properties");
         LOG4CXX_INFO(logger, "你好，log4cxx!");
         return 0;
       }
     #+end_src
   
     =log4cxx_hello.properties= ：
     #+begin_example
       log4j.rootLogger=debug, R
       
       log4j.appender.stdout=org.apache.log4j.ConsoleAppender
       log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
       
       # Pattern to output the caller's file name and line number.
       log4j.appender.stdout.layout.ConversionPattern=%5p [%t] (%F:%L) - %m%n
       
       log4j.appender.R=org.apache.log4j.RollingFileAppender
       log4j.appender.R.File=./hello.log
       
       log4j.appender.R.MaxFileSize=100KB
       # Keep one backup file
       log4j.appender.R.MaxBackupIndex=10
       
       log4j.appender.R.layout=org.apache.log4j.PatternLayout
       log4j.appender.R.layout.ConversionPattern=%5p %c [%t] (%F:%L) - %m%n
     #+end_example

     编译：
     #+begin_src sh
       g++ -o hello hello.cpp -I${HOME}/libs/include ${HOME}/libs/lib/liblog4cxx.a ${HOME}/libs/lib/libaprutil-1.a ${HOME}/libs/lib/libapr-1.a  -lexpat -lpthread
     #+end_src

   - 注意事项

     由于一个日志文件写满后会重命名所有已有的日志文件，配置过大MaxBackupIndex的会有性能问题，因此log4cxx编译时限制了它的大小（大概十多个）以避免配置的MaxBackupIndex过大，如果要设置更大一点的MaxFileSize来保存更多日志，需要在编译前进行修改。

     参考：http://objectmix.com/apache/684503-urgent-log4cxx-large-window-sizes-not-allowed.html

   - 使用技巧
     - 决定配置文件的格式（xml，property）。以使用相应的配置器（Configurator）装入配置文件。

       xml虽较property格式繁锁，支持的配置面更全，而property格式的配置文件使用更简单，容易在网上找到现成的配置文件。

     - logger命名

       logger名称反映了软件模块，如果有代表软件模块的类，则在类中包含以该类类名命名的logger对象，该模块功能相关代码通过该logger进行日志记录。
       另外可将logger对象作为全局变量，方便使用，特别是当软件模块较松散，并无对应的封装类时。

     - 在代码中适当地放置日志代码。引用适当的日志对象，对日志进行适当分级。

     - 余下的工作就是修改配置文件，对日志进行控制了。

   　　使用配置文件的好处就是可以方便地配置日志而不需要修改源代码，可以在配置文件中方便配置日志过滤、格式、日志目的地。

   - 体验

   　之前产品中用到的是log4cplus，但是常常有写日志崩溃的情况出现，使用log4cxx正是用于解决该崩溃。
** DONE SSL双方系统时间不一致导致的SSL连接失败及其解决方案        :openssl:c:
   CLOSED: <2008-07-25 五 17:45>

   在产品使用中，实施人员常常报告服务器与客户端无法连接，最终查明原因是双方的时间设置不一致。OpenSSL证书有一个有效时间段，当客户端或服务器的系统时间不在这个时间段内时SSL会因证书验证失败而无法连接。在实施中系统时间错误是很常见的，因不能上网而未开时间自动同步、bios没电了、客户疏忽等原因都会导致系统时间设置错误。如果连接失败后再查看系统时间设置进行故障排查终归是一件麻烦的事情。

   解决这个问题有以下几个办法：

   - 将证书的有效期设置得够大（如：1970-2099）
     
     这样估计可以在一定程度上解决这个问题，不过这也是个馊主意，一般申请的证书总会有一个合理的有效期。

   - 检测及必要时自动同步客户端与服务器的时间
     
     通过用wireshake抓包分析SSL建立连接的过程，发现在SSL握手过程中，会向对方传送本机的系统时间。因此一个显而易见的办法就是，当连接过程中检测到证书过期，将客户端的时间同步为服务器端的时间，再重连即可。

     下面是具体的示例代码：
     #+begin_src c
       #include <openssl/ssl.h>
       #include <openssl/bio.h>
       #include <openssl/err.h>
       #include <winsock2.h>
       #include <stdio.h>
       #include <string.h>
       #include <time.h>
       
       typedef struct _TimeInfo
       {
           time_t client;  /*客户端的时间*/
           time_t server;  /*服务器的时间*/
       } TimeInfo;
       
       /**
        * 同步系统时间.
        */
       BOOL syncSystemTime(time_t t)
       {
           SYSTEMTIME st;
           FILETIME   ft;  
           LONGLONG   ll;  
           
           ll = Int32x32To64(t, 10000000) + 116444736000000000; //1970.01.01  
           
           ft.dwLowDateTime  = (DWORD)ll;  
           ft.dwHighDateTime = (DWORD)(ll >> 32);  
           
           return FileTimeToSystemTime(&ft, &st) && SetSystemTime(&st);
       }
       
       /**
        * 获取SSL握手过程中服务器与客户端双方的系统时间.
        */
       void getSSLHandleShakeTimeInfo(int write_p,
                                      int version,
                                      int content_type,
                                      const unsigned char* buf,
                                      size_t len,
                                      SSL *ssl,
                                      TimeInfo *ti)
       {
           if(content_type != 22)   //require handshake message
               return;
           if(len < 42)
               return;
           if(buf[0] == 1)          //ClientHello Message send from client to server
               ti->client = htonl(*((u_long*)(buf + 6)));
           else if(buf[0] == 2)     //ServerHello Message send from server to client
               ti->server = htonl(*((u_long*)(buf + 6)));
           else
               return;
       }
       
       int main()
       {
           BIO * bio;
           SSL * ssl;
           SSL_CTX * ctx;
           TimeInfo timeInfo = {-1, -1};
           BOOL timeSynced = FALSE;
           long result;
       
           /* Set up the library */
           SSL_library_init();
           ERR_load_BIO_strings();
           SSL_load_error_strings();
       
           /* Set up the SSL context */
           ctx = SSL_CTX_new(SSLv3_client_method());
           if(ctx == NULL)
           {
               fprintf(stderr, "Error new SSL_CTX\n");
               ERR_print_errors_fp(stderr);
               SSL_CTX_free(ctx);
               return 0;
           }
       
           /* Get Server and Client system time via SSL Handshake */
           SSL_CTX_set_msg_callback(ctx, getSSLHandleShakeTimeInfo);
           SSL_CTX_set_msg_callback_arg(ctx, &timeInfo);
           
           /* Load the trust store */
           if(! SSL_CTX_load_verify_locations(ctx, ".\\certs\\cacert.pem", NULL))
           {
               fprintf(stderr, "Error loading trust store\n");
               ERR_print_errors_fp(stderr);
               SSL_CTX_free(ctx);
               return 0;
           }
       
           /* Setup the connection */
           bio = BIO_new_ssl_connect(ctx);
       
           /* Set the SSL_MODE_AUTO_RETRY flag */
           BIO_get_ssl(bio, & ssl);
           SSL_set_mode(ssl, SSL_MODE_AUTO_RETRY);
       
           /* Create and setup the connection */
           BIO_set_conn_hostname(bio, "192.168.1.5:5555");
           if(BIO_do_connect(bio) <= 0)
           {
               fprintf(stderr, "Error attempting to connect\n");
               ERR_print_errors_fp(stderr);
               BIO_free_all(bio);
               SSL_CTX_free(ctx);
               return 0;
           }
           
           /* Check the certificate */
           switch(SSL_get_verify_result(ssl))
           {
           case X509_V_OK:
               break;
           case X509_V_ERR_CERT_NOT_YET_VALID:
           case X509_V_ERR_CERT_HAS_EXPIRED:
               if(timeInfo.server != -1 && timeInfo.client != -1)
               {
                   printf("当前客户端时间: %s", ctime(&timeInfo.client));
                   printf("当前服务器时间: %s", ctime(&timeInfo.server));
                   printf("尝试与服务器时间同步");
                   
                   if(syncSystemTime(timeInfo.server))
                       printf("成功\n");
                   else
                       printf("失败\n");
                   printf("请重试连接服务器！\n");
               }
           default:
               fprintf(stderr, "Certificate verification error: %i\n", SSL_get_verify_result(ssl));
               BIO_free_all(bio);
               SSL_CTX_free(ctx);
               return 0;
           }
       
           /* Close the connection and free the context */
           BIO_free_all(bio);
           SSL_CTX_free(ctx);
           return 0;
       }
     #+end_src
** DONE 搭建jabber服务器                                       :jabber:linux:
   CLOSED: <2011-05-04 三 00:32>

   - 编译安装
     
     =下载=
     #+begin_src sh
       wget http://download.jabberd.org/jabberd14/jabberd14-1.6.1.1.tar.gz
       tar xzvf jabberd14-1.6.1.1.tar.gz
       cd jabberd14-1.6.1.1
     #+end_src

     =修改代码以解决编译错误=
     #+begin_src sh
       diff -r jabberd14-1.6.1.1/jabberd/lib/xmlnode.cc tmp/jabberd14-1.6.1.1/jabberd/lib/xmlnode.cc
       882,884c882,884
       <     const char *next_step = NULL;
       <     const char *start_predicate = NULL;
       <     const char *end_predicate = NULL;
       ---
       >     char *next_step = NULL;
       >     char *start_predicate = NULL;
       >     char *end_predicate = NULL;
       1836c1836
       <         ((char*)strchr(lang, '-'))[0] = 0;
       ---
       >         strchr(lang, '-')[0] = 0;
       diff -r jabberd14-1.6.1.1/jabberd/log.cc tmp/jabberd14-1.6.1.1/jabberd/log.cc
       89c89
       <         pos = (char*)strchr(zone,'.');
       ---
       >     pos = strchr(zone,'.');
       diff -r jabberd14-1.6.1.1/jabberd/mio_tls.cc tmp/jabberd14-1.6.1.1/jabberd/mio_tls.cc
       615c615
       <         ret = gnutls_certificate_set_openpgp_key_file(current_credentials, pubfile, privfile, GNUTLS_OPENPGP_FMT_BASE64);
       ---
       >         ret = gnutls_certificate_set_openpgp_key_file(current_credentials, pubfile, privfile);
       634c634
       <         ret = gnutls_certificate_set_openpgp_keyring_file(current_credentials, file, GNUTLS_OPENPGP_FMT_BASE64);
       ---
       >         ret = gnutls_certificate_set_openpgp_keyring_file(current_credentials, file);
       640a641,657
       >     }
       >
       >     // load GnuPG trustdb
       >     if (j_strcmp(xmlnode_get_localname(cur), "trustdb") == 0) {
       >         char const *const file = xmlnode_get_data(cur);
       >
       >         if (file == NULL) {
       >         log_warn(NULL, "Initializing TLS subsystem: <trustdb/> element inside the TLS configuration, that does not contain a file-name.");
       >         continue;
       >         }
       >
       >         // load the GnuPG trustdb
       >         ret = gnutls_certificate_set_openpgp_trustdb(current_credentials, file);
       >         if (ret < 0) {
       >         log_error(NULL, "Error loading GnuPG trustdb %s: %s", file, gnutls_strerror(ret));
       >         continue;
       >         }
     #+end_src
     
     =编译安装=
     #+begin_src sh
       ./configure && make && sudo make install
     #+end_src

     如出错通常是少了相关依赖库，用包管理工具（如：ubuntu下的新立得）安装即可。

   - 配置

     按照mysql.sql中的注释配置数据库：
     
     #+begin_src sh
       mysql -uroot -p
       mysql> CREATE DATABASE jabber CHARACTER SET utf8;
       mysql> use jabber;
       mysql> grant all on jabber.* to jabber@localhost identified by 'secret';
       mysql> \. mysql.sql
     #+end_src

   - 运行

     #+begin_src sh
       sudo jabberd -h localhost -B
     #+end_src

   - 注册用户1

     #+begin_src sh
       telnet localhost 5222
       <stream:stream
         to='localhost'
         xmlns='jabber:client'
         xmlns:stream='http://etherx.jabber.org/streams'>
       
       <iq id='reg1' type='set'>
         <query xmlns='jabber:iq:register'>
           <username>jack</username>
           <password>jack</password>
           <name>jack</name>
           <email></email>
         </query>
       </iq>
       
       </stream:stream>
     #+end_src
   
   - 登录用户1

     #+begin_example
       Empathy菜单->编辑->帐户->添加：
       协议: Jabber
       登录ID: jack@localhost
       记住密码
       密码: jack
       登录
     #+end_example

   - 注册用户2
     
     #+begin_src sh
       telnet localhost 5222
       <stream:stream
         to='localhost'
         xmlns='jabber:client'
         xmlns:stream='http://etherx.jabber.org/streams'>
       
       <iq id='reg1' type='set'>
         <query xmlns='jabber:iq:register'>
           <username>rose</username>
           <password>rose</password>
           <name>rose</name>
           <email></email>
         </query>
       </iq>
       
       </stream:stream>
     #+end_src

   - 用户1加用户2为联系人
     
     #+begin_example
       Empathy菜单->聊天->添加联系人:
       帐户：jack@localhost
       标识符: rose@localhost
       添加
     #+end_example

   - 登录用户2，并发一个消息给用户1

     #+begin_src sh
       telnet localhost 5222
       <stream:stream
         to='localhost'
         xmlns='jabber:client'
         xmlns:stream='http://etherx.jabber.org/streams'>
       
       <iq id='auth1' type='set'>
         <query xmlns='jabber:iq:auth'>
           <username>rose</username>
           <password>rose</password>
           <resource>test</resource>
         </query>
       </iq>
       
       <presence/>
       
       <message to='jack@localhost'>
         <body>hello, jack</body>
       </message>
       
       </stream:stream>
     #+end_src
** TODO Node.js学习                                                 :node.js:
   
*** 适用范围
    
    - 引用[[http://nodejs.org/docs/latest/][原文]] ::

      #begin_example
        Node.js is a platform built on Chrome's JavaScript runtime for easily building fast, scalable network applications. Node.js uses an event-driven, non-blocking I/O model that makes it lightweight and efficient, perfect for data-intensive real-time applications that run across distributed devices.
      #end_example
    
    - 可以归结如下 ::

      - 较低的资源消耗处理海量网络请求
      - 开发分布式的数据密集型实时应用

*** 参考资源
    
    - [[http://www.nodebeginner.org/index-zh-cn.html][Node入门]] ::

      从Hello World到图片上传示例演示了如何以正确的方式开发[[http://nodejs.org][Node.js]]应用。
    
    - [[http://nodejs.org/docs/latest/api/all.html][Node.js官方API手册]]

** DONE log4php初步使用                                             :log4php:
   CLOSED: [2013-05-06 一 18:32]
   
*** 简介
    apache出品必属精品。正宗php日志库，与log4j一脉相承。

    [[http://logging.apache.org/log4php/]]

*** 安装
    参考：[[http://logging.apache.org/log4php/install.html]]

    - 有root权限，安装到系统目录

      #+begin_src sh
        sudo apt-get install php-pear
        sudo pear channel-discover pear.apache.org/log4php
        sudo pear install log4php/Apache_log4php
      #+end_src

    - 没有root权限，安装到当前目录下
       
      #+begin_src sh
        cd libs
        wget http://mirrors.tuna.tsinghua.edu.cn/apache/logging/log4php/2.3.0/apache-log4php-2.3.0-src.tar.gz
        tar xzvf apache-log4php-2.3.0-src.tar.gz
        ln -sf apache-log4php-2.3.0/src/main/php ./log4php
      #+end_src

*** 使用
    
    - 进行一下封装定制，可以满足绝大部分情况下的使用

      - 类似nginx的访问日志记录格式
      - 日志中输出文件名及行号
      - 日志文件数据限制为10个，每个日志文件大小为10MB

#+o_blog_source ./static/logging.inc

    - 使用示例

      =example.php=
      #+begin_src php
        <?php
        define('LOGGING_APPNAME', 'example');
        require_once(dirname(__FILE__) . "/logging.inc");
        
        $logger = Logger::getLogger("main");
        $logger->debug("info log");
        $logger->warn("info log");
        $logger->error("info log");
        ?>
      #+end_src

    - 运行结果

      #+begin_src sh
        $ php ./example.php
        $ tail -f ./logs/example.log
        2013-05-06 18:24:57,925 [DEBUG] main: info log (/home/tangxinfa/php/example.php:6)
        2013-05-06 18:24:57,930 [WARN] main: info log (/home/tangxinfa/php/example.php:7)
        2013-05-06 18:24:57,930 [ERROR] main: info log (/home/tangxinfa/php/example.php:8)
      #+end_src

** TODO 使用boost.coroutine异步访问mysql                          :cpp:mysql:
   
   开发高性能、高并发后台服务时，访问mysql总是一件头疼的事情，这绝对算是整个系统中最伤性能的部分，访问mysql总是很慢的，并且连接数受限，阻碍了开发高性能可线性扩展的后台服务。这也导致了像memcache、redis之类的NoSQL数据库的流行。

   但是，到目前为止mysql在可靠存储数据方面仍无法替代，NoSQL一般也仅用于做为mysql的缓存层，以减轻mysql的压力，所以探究一下如何更高效地访问mysql还是很有必要的。
   
   提高访问mysql效率的常见方法是异步化：用独立的数据库访问线程来执行数据库操作，在执行完成后通知应用逻辑进行后继处理，这种程序往往主程序是一个事件循环，而应用逻辑被切分成一个个回调函数，导致程序流程变得更加复杂，不易理解也容易滋生问题。

   接下来我打算使用协程来异步访问mysql，协程（[[http://www.boost.org/doc/libs/release/libs/coroutine/][boost.coroutine]]）可以让我们线性的书写处理逻辑，而不必引入复杂的状态机。

** TODO 深入理解Ember.js                                           :ember.js:
   
*** Ember.jsr的组件层次

    从下往上依次为：
    - 模板（templates）
      使用Handlebars模板语言描述用户界面，除了纯html还包含以下组件：
      - 表达式。{{firstName}}，以html来展示控制器和模型的信息，并保持同步。
      - 插座。{{outlet}}，路由根据应用当前所处的位置将对应的模板插入到相应的插座中。
      - 视图。{{view}}，将原始的用户事件（如：点击）转化为语义事件（如：增、删、改)并发送到控制器。
    - 控制器（controller）
      保存应用状态的对象。通常用于将模型进行进一步包装后暴露给模板。
    - 模型（model）
      保存持久状态的对象。通常从服务器端装入并最终会保存回去。
    - 路由（router）
      管理应用状态的对象。根据当前的url显示相应的模板，以及为模板指定配对的模型。
** DONE 《理解Http与Spdy协议》培训课件                            :http:spdy:
   CLOSED: [2013-05-23 四 13:11]
   
   本课件针对刚入职的毕业生，讲解Http与Spdy协议的基础知识。

*** 开发计划 [1/5]
    - [X] 编写Http部分大纲
    - [ ] 编写Http部分章节内容
    - [ ] 编写Spdy部分大纲
    - [ ] 编写Spdy部分章节内容
    - [ ] 制作Microsoft PowerPoint格式文档
   
*** 在线演示
    [[http://blog.kankanan.com/slides/理解Http与Spdy协议.html][《理解Http与Spdy协议》]]

** TODO 开源MQ（Message Queue）调研                                      :MQ:
   
*** ZeroMQ
    
    - 语言 :: c++
    - 协议 :: ZMQP
    - 定位 :: 类似于POSIX message queue，在socket之上搭建的IPC（机制），它不是消息中间件，由于其库的本质，速度上比MQ中间件快了一个数量级。
    - 总结 :: 和其它的MQ中间件没有可比性，在不需要持久化、稳定性、追求极致性能、易部署的情况下可以考虑使用，或根据情况同时使用其它的MQ服务。

*** RabbitMQ

    - 语言 :: Erlang
    - 协议 :: AMQP
    - 定位 :: 消息中间件
    - 总结 :: 应该是性能最好的开源消息中间件，在需要保证消息不丢失的情况下，可以考虑采用。像mysql一样需要启动服务，有各种语言的客户端库（一般使用不会去定制服务端的代码，大可不必介意自已是否熟悉Erlang语言）。

** TODO Hash、Bitmap和BloomFilter算法           :hash:algorithms:bitmap:bloomfilter:

   Hash、Bitmap和BloomFilter都可用于判断某个元素是否在集合中。

   参考：[[http://blog.csdn.net/jiaomeng/article/details/1496329][从哈希存储到Bloom Filter]]

*** Hash
    
    - 原理
      准备好哈希空间（足够保存集合中的所有元素），对于每个元素通过哈希函数求出其在哈希空间保存的位置，由于两个不同元素可能被哈希函数映射到同一哈希空间位置（碰撞、冲突），
      这需要进行一次解冲突，通常使用冲突链解决：获取哈希空间映射位置已存在的元素，如果元素值与当前元素不等，则挂在该哈希空间的冲突链中，图示如下：

      #+begin_src artist
        
        hash space 
        +-------------------------------------------------------------------+
        |     key1   key2   key3   key4   key5   key6                     --+--> hash keys
        |   +------+------+------+------+------+------+-----------------+   |        
        |   | val1 | val2 | val3 | val4 | val5 | val6 |  ...            | --+--> element values
        |   |   |  | NULL | NULL | NULL | NULL | NULL |                 | --+--> collision link head 
        |   +---+--+------+------+------+------+------+-----------------+   |                       
        |       |                                                           |                    
        |   +---+--+                                                        |                    
        |   |val1.1| -------------------------------------------------------+--> collision element values
        |   | NULL | -------------------------------------------------------+--> collision link pointer
        |   +------+                                                        |
        +-------------------------------------------------------------------+
        
      #+end_src
      
    - 特点

      - 0误差 :: 判断结果100%可信
      - 空间浪费 :: 由于哈希函数不可能做到没有冲突，所以哈希空间必然大于元素集合空间
      - 需要有好的哈希函数 :: 当哈希不均匀时，会导致一些哈希位置冲突链过长，访问这个哈希位置时算法复杂度由哈希表（O(1)）退化成链表（O(n)）。

*** Bitmap
    
    - 原理
      准备好位图空间（足够保存集合中的所有元素的位数），对于每个元素通过哈希函数求出其在位图空间占用的位，位置为1表示元素存在，由于位图空间没有保存元素值，因此无法检测哈希冲突。

    - 特点
      
      - 有误差 :: 仅能给出元素一定不在集合内以及元素可能在集合内的判断。当哈希函数能做到完全均匀才能达到0误差。
      - 节省空间 :: 每个元素只需要一个位来存储。

*** BloomFilter
    
    - 参考 :: [[http://zh.wikipedia.org/wiki/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8][布隆过滤器 - 维基百科]]、[[http://en.wikipedia.org/wiki/Bloom_filter][Bloom filter - Wikipedia]]
    
    
    - 原理
      类似于位图，只不过每个元素由n个哈希函数来映射到n个位，元素映射的所有位都为1方表示元素存在。
      
    - 特点

      - 有误差 :: 比起Bitmap误差率可以很好的控制（除了通过选择更好的哈希函数，还可以通过增加更多的哈希函数以及相应的哈希空间来减少误差率）
      - 节省空间 :: 每个元素只需要n个位来存储，n可自定。

** TODO p2p系统构建                                                     :p2p:

*** 结点间的连通
    
    - 双方外网 :: 直连
    
    - 一内一外 :: 直连／反连
      - 中间服务器 :: 发送被反连方指令给反连方，所有内网服务器都需要在中间服务器上保持一个连接，以接收控制指令。

    - 双方内网 :: 穿透
      
      - 使用UDP进行NAT穿透
        
        - 穿透服务器 :: 为穿透双方服务的外网服务器

*** 结点网
    
    - 结点标识符 :: 硬件标识（mac地址）或用户id
    - 所有结点启动时加入到网络中，并发送心跳，结点主动关闭或通过心跳检测出已下线时退出网络。
    - 需要记录结点以下信息
      - 类型 :: 外网、可穿透内网、封闭内网
      - 负载 :: 上传能力

    这就是状态服务器，状态服务器需在结点状态变化时同步结点状态信息到资源服务器

*** 资源网

    所有结点拥有的资源需要在资源服务器上呈现。

    - 资源标识符 :: 如文件内容的sha1
    - 资源组织，满足以下需求：
      - 根据资源id查找拥有该资源的一批活跃结点，支持各种查找条件（按：同运营商、随机取、按地理位置）
      - 更新结点id拥有的资源
      
      #+begin_src artist
        +-------------------+
        | p2p://example.com |
        +---------+---------+
                  |            +------------------------------------------+
                  +------------+ 1111111111111111111111111111111111111111 |
                  |            +----------------------+-------------------+
                  |                                   |   +-------+
                  |                                   +---+ user1 |
                  |                                   |   +-------+
                  |                                   |           
                  |                                   |   +-------+
                  |                                   +---+ user2 |
                  |                                   |   +-------+
                  |                                   |           
      #+end_src

*** 实施
    |------------+--------------------------------------------------------------------+--------|
    | 组件       | 功能                                                               | 人／月 |
    |------------+--------------------------------------------------------------------+--------|
    | 穿透服务器 | 协助客户端进行穿透的外网服务器                                     | 2/0.5  |
    |------------+--------------------------------------------------------------------+--------|
    | 状态服务器 | 与所有客户端保持连接，记录客户端的上下线状态及属性、转发反连指令   | 3/1    |
    |------------+--------------------------------------------------------------------+--------|
    | 资源服务器 | 索引所有资源，根据各种策略为客户端查找拥有该资源的其它客户端信息， | 5/3    |
    |            | 客户端存储的资源变动时，更新资源对应的客户端列表                   |        |
    |------------+--------------------------------------------------------------------+--------|

** DONE 《理解Node.js》培训课件                                     :node.js:
   CLOSED: [2013-07-04 四 18:31]
   
   本课件介绍Node.js的特点及其初步使用。

*** 开发计划 [1/3]
    - [X] 编写大纲
    - [ ] 编写内容
    - [ ] 制作Microsoft PowerPoint格式文档

*** 在线演示
    [[http://blog.kankanan.com/slides/理解Node.js.html][《理解Node.js》]]

** DONE Archlinux下解决更新grub后无法进入gnome3桌面的问题         :archlinux:
   CLOSED: [2013-06-26 Wed 10:07]
   
   在启动界面上会看到以下错误日志：
   #+begin_example
   kernel: [    8.398186] [drm:radeon_init] *ERROR* No UMS support in radeon module!
   #+end_example

   这个是由于grub配置文件中指定了内核参数 =nomodeset= 导致，linux的默认配置是为了运行服务器，以减少启动过程中出错的可能性，使用gnome3桌面时，需去掉内核参数 =nomodeset= ，以下为[[https://wiki.archlinux.org/index.php/ATI#Disable_KMS][原文]]：

   #+begin_example
     Note: Adding nomodeset to the kernel boot line might prevent GNOME 3's gnome-shell or KDE's desktop effects from running.
   #+end_example

** DONE linux下翻墙访问bitbucket.org仓库                    :linux:hg:bitbucket:
   CLOSED: [2013-06-28 Fri 13:57]
   
   今天往bitbucket.org push时才发现bitbucket被GFW了。我的仓库为Mercurial hg，hg项目根目录下的 =.hg/hgrc= 配置文件中可指定http\_proxy，试了一下不支持socks代理（我的浏览器用它来翻墙），最终使用tsocks软件实现翻墙访问bitbucket.org仓库。

   - 利用vps建本地socks代理的脚本 =ssh_proxy.sh=
     #+begin_src sh
       #!/bin/bash
       
       n=`ps waux | grep 'bash .*/ssh_proxy.sh' | grep -v grep | wc -l`
       if [ $n -lt 3 ]; then
           while [ true ]; do
               n=`ps aux | grep 'ssh' | grep '7070' | grep -v grep | wc -l`
               if [ $n -lt 1 ]; then
                   echo "start ssh connecting"
                   ssh -qTnNf -D 7070 user@host
               fi
               echo "wait for next checking"
               sleep 30
           done
       fi
       echo "ssh_proxy.sh already running"
       
     #+end_src

     请将user@host改为你的vps用户及主机，并配置为免输入密码。

   - 启动socks代理脚本
     
     #+begin_src sh
       nohup bash ./ssh_proxy.sh &
     #+end_src

     浏览器也可以利用它来翻墙。

   - 安装tsocks
     #+begin_src sh
       yaourt -S tsocks
     #+end_src

   - 配置tsocks

     =/etc/tsocks.conf=
     #+begin_example
       # We can access 192.168.0.* directly
       local = 192.168.0.0/255.255.255.0
       local = 10.0.0.0/255.0.0.0
       
       # Otherwise we use the server
       server = 127.0.0.1
       server_port = 7070
     #+end_example
     具体用法 =man tsocks.conf=

   - 使用tsocks让hg用上socks代理功能
     #+begin_src sh
       tsocks hg push
     #+end_src
     tsocks看起来很通用，应该也可以让git等进行socks代理访问。

** TODO 《架构风格与基于网络的软件架构设计》读书笔记           :REST:reading:
   
   #+begin_quote
   架构设计的目标是创建一个包含一组架构属性的架构，这些架构属性形成了系统需求的一个超集。不同架构属性的相对重要性取决于想要得到的系统本身的特性。
   #+end_quote

   我们对架构的学习和使用应该更明智一些，通过学习能够做到对一种架构的相关特性（包括优点及缺点）了然于胸，同时在使用的时候能够摆脱潮流及个人主观喜好的影响，选择正确的架构，这样才能获得架构所带来的质量保证，我们才能够对在此基础上构建的系统的充满信心。

   
   #+begin_quote
   一种架构风格是一组协作的架构约束，这些约束限制了架构元素的角色和功能，以及在任何一个遵循该风格的架构中允许存在的元素之间的关系。
   #+end_quote

   #+begin_quote
   一个好的设计师应该选择一种与正在解决的特定问题最为匹配的风格。为一个基于网络的应用选择正确的架构风格必须要理解该问题领域，因此需要了解应用的通信需求，知道不同的架构风格和它们所导致的特殊问题，并且有能力根据基于网络的通信的特性来预测每种交互风格的敏感度。
   #+end_quote

** TODO 理解REST [0/3]                                                 :REST:

   - [ ] REST介绍

     REST（Representational State Transfer，表述性状态转移）, 是一种针对网络应用的设计和开发方式，可以降低开发的复杂性，提高系统的可伸缩性。
     
     REST 指的是一组架构约束条件和原则。满足这些约束条件和原则的应用程序或设计就是RESTful。
     
   - [ ] REST实现
     
   - [ ] REST应用
